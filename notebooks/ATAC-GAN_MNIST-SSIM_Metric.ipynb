{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "# https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/acgan/acgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# Models\n",
    "from torchvision.models import vgg19\n",
    "from sys import path\n",
    "path.append(\"../utils\")\n",
    "path.append(\"../\")\n",
    "from models import LeNet5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\"ATAC-GAN MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "\n",
    "cuda = True\n",
    "\n",
    "n_epochs=200\n",
    "batch_size=64\n",
    "lr=0.02\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "latent_dim=100\n",
    "n_classes=10\n",
    "img_size=28\n",
    "channels=1\n",
    "sample_interval=30\n",
    "\n",
    "d_real_loss_coeff = 0.6\n",
    "d_fake_loss_coeff = 0.4\n",
    "\n",
    "adv_loss_coeff = 1\n",
    "aux_loss_coeff = 1\n",
    "tar_loss_coeff = .05\n",
    "\n",
    "tar_loss_default = 22.2  # This is equal to the max possible tar_loss value\n",
    "\n",
    "# target classifier conditional constants\n",
    "adv_loss_threshold = 0.9\n",
    "aux_loss_threshold = 1.465\n",
    "\n",
    "lenet5_state_path = \"../utils/models/trained_lenet5.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LeNet5():\n",
    "    net = LeNet5()\n",
    "    if cuda:\n",
    "        net.cuda()\n",
    "    \n",
    "    # remove map location = cpu if using cuda\n",
    "    net.load_state_dict(torch.load(lenet5_state_path, map_location=torch.device('cpu')))\n",
    "    \n",
    "    # set model to eval mode so nothing is changed\n",
    "    net.eval()\n",
    "    \n",
    "    return net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, latent_dim)\n",
    "\n",
    "        self.init_size = img_size // 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_msssim import ssim, SSIM, MS_SSIM\n",
    "# reuse the gaussian kernel with SSIM & MS_SSIM. \n",
    "ssim_module = SSIM(data_range=255, size_average=True, channel=1, nonnegative_ssim=True)\n",
    "ms_ssim_module = MS_SSIM(size_average=True, channel=1, nonnegative_ssim=True)\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "target_classifier_loss = nn.CrossEntropyLoss() # negate target classifier output when passing to this loss function\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Load target classifier\n",
    "\n",
    "target_classifier = load_LeNet5()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    target_classifier = target_classifier.cuda()\n",
    "    target_classifier_loss = target_classifier_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "\n",
    "# Configure data loader\n",
    "os.makedirs(\"../data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Configure data loader\n",
    "os.makedirs(\"../data/mnist\", exist_ok=True)\n",
    "ssim_dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM Metric Loss Functions\n",
    "import importlib\n",
    "import pytorch_ssim\n",
    "importlib.reload(pytorch_ssim)\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "ssim_loss = pytorch_ssim.SSIM()\n",
    "def ssim_to_classes(imgs):\n",
    "    ret = []\n",
    "    #for img in imgs:\n",
    "    ss = np.zeros(10)\n",
    "    counts = np.zeros(10)\n",
    "    for i, (img_ref, label) in enumerate(ssim_dataloader):\n",
    "        #print(img_ref.shape)\n",
    "        #print(imgs.shape)\n",
    "        x = pytorch_ssim.ssim(img_ref, imgs, window_size=5)\n",
    "        print(x, label)\n",
    "        ss[label.item()] += x\n",
    "        counts[label.item()] += 1\n",
    "        if i > 1000:\n",
    "            break\n",
    "    ret.append(np.divide(ss, counts))\n",
    "    return ret\n",
    "        \n",
    "c = 0\n",
    "ref_imgs = {}\n",
    "while c < 10:\n",
    "    for i, (img_ref, label) in enumerate(ssim_dataloader):\n",
    "        if ref_imgs.get(label.item()) is None:\n",
    "            ref_imgs[label.item()] = img_ref.cuda()\n",
    "            c += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6258317376486957"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_ssim(label, img):\n",
    "    return pytorch_ssim.ssim(ref_imgs[label.item()], img, window_size=4)\n",
    "    \n",
    "def batch_ssim(labels, imgs):\n",
    "    ret = np.zeros(batch_size)\n",
    "    for i in range(batch_size):\n",
    "        ret[i] = single_ssim(labels[i], imgs[i].view(1, 1, 28, 28))\n",
    "    return np.mean(ret)\n",
    "\n",
    "imgs, l = next(iter(dataloader))\n",
    "batch_ssim(l, imgs.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"../images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "\n",
    "def get_target_loss(ssim_loss, target_classification, true_classification):\n",
    "    #print(target_classification[0])\n",
    "    if (ssim_loss < 0.5):\n",
    "        return target_classifier_loss(target_classification * -1, true_classification)\n",
    "    return Variable(FloatTensor([tar_loss_default]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "Epoch 0/200\n",
      " ssim loss: 0.059007, tar loss: 0.118902\n",
      "=====================\n",
      "Epoch 30/200\n",
      " ssim loss: 0.066125, tar loss: 0.095602\n",
      "=====================\n",
      "Epoch 60/200\n",
      " ssim loss: 0.060761, tar loss: 0.118868\n",
      "=====================\n",
      "Epoch 90/200\n",
      " ssim loss: 0.048219, tar loss: 0.112018\n",
      "=====================\n",
      "Epoch 120/200\n",
      " ssim loss: 0.058537, tar loss: 0.128916\n",
      "=====================\n",
      "Epoch 150/200\n",
      " ssim loss: 0.066134, tar loss: 0.118855\n",
      "=====================\n",
      "Epoch 180/200\n",
      " ssim loss: 0.047678, tar loss: 0.113372\n",
      "=====================\n",
      "Epoch 210/200\n",
      " ssim loss: 0.051258, tar loss: 0.105030\n",
      "=====================\n",
      "Epoch 240/200\n",
      " ssim loss: 0.052911, tar loss: 0.105000\n",
      "=====================\n",
      "Epoch 270/200\n",
      " ssim loss: 0.051425, tar loss: 0.105033\n",
      "=====================\n",
      "Epoch 300/200\n",
      " ssim loss: 0.046613, tar loss: 0.113382\n",
      "=====================\n",
      "Epoch 330/200\n",
      " ssim loss: 0.062374, tar loss: 0.106011\n",
      "=====================\n",
      "Epoch 360/200\n",
      " ssim loss: 0.053357, tar loss: 0.105004\n",
      "=====================\n",
      "Epoch 390/200\n",
      " ssim loss: 0.063432, tar loss: 0.095595\n",
      "=====================\n",
      "Epoch 420/200\n",
      " ssim loss: 0.048440, tar loss: 0.113385\n",
      "=====================\n",
      "Epoch 450/200\n",
      " ssim loss: 0.049497, tar loss: 0.113344\n",
      "=====================\n",
      "Epoch 480/200\n",
      " ssim loss: 0.081319, tar loss: 0.165670\n",
      "=====================\n",
      "Epoch 510/200\n",
      " ssim loss: 0.058318, tar loss: 0.128923\n",
      "=====================\n",
      "Epoch 540/200\n",
      " ssim loss: 0.072890, tar loss: 0.110020\n",
      "=====================\n",
      "Epoch 570/200\n",
      " ssim loss: 0.049925, tar loss: 0.105044\n",
      "=====================\n",
      "Epoch 600/200\n",
      " ssim loss: 0.062496, tar loss: 0.123849\n",
      "=====================\n",
      "Epoch 630/200\n",
      " ssim loss: 0.055229, tar loss: 0.128921\n",
      "=====================\n",
      "Epoch 660/200\n",
      " ssim loss: 0.055116, tar loss: 0.128921\n",
      "=====================\n",
      "Epoch 690/200\n",
      " ssim loss: 0.062716, tar loss: 0.118865\n",
      "=====================\n",
      "Epoch 720/200\n",
      " ssim loss: 0.054232, tar loss: 0.128917\n",
      "=====================\n",
      "Epoch 750/200\n",
      " ssim loss: 0.062405, tar loss: 0.095604\n",
      "=====================\n",
      "Epoch 780/200\n",
      " ssim loss: 0.062999, tar loss: 0.123851\n",
      "=====================\n",
      "Epoch 810/200\n",
      " ssim loss: 0.051444, tar loss: 0.128926\n",
      "=====================\n",
      "Epoch 840/200\n",
      " ssim loss: 0.051683, tar loss: 0.105020\n",
      "=====================\n",
      "Epoch 870/200\n",
      " ssim loss: 0.048226, tar loss: 0.113783\n",
      "=====================\n",
      "Epoch 900/200\n",
      " ssim loss: 0.079766, tar loss: 0.165666\n",
      "=====================\n",
      "Epoch 930/200\n",
      " ssim loss: 0.057964, tar loss: 0.128939\n",
      "=====================\n",
      "Epoch 960/200\n",
      " ssim loss: 0.059325, tar loss: 0.118872\n",
      "=====================\n",
      "Epoch 990/200\n",
      " ssim loss: 0.070894, tar loss: 0.110020\n",
      "=====================\n",
      "Epoch 1020/200\n",
      " ssim loss: 0.062485, tar loss: 0.095611\n",
      "=====================\n",
      "Epoch 1050/200\n",
      " ssim loss: 0.054197, tar loss: 0.112007\n",
      "=====================\n",
      "Epoch 1080/200\n",
      " ssim loss: 0.060409, tar loss: 0.095600\n",
      "=====================\n",
      "Epoch 1110/200\n",
      " ssim loss: 0.050883, tar loss: 0.105019\n",
      "=====================\n",
      "Epoch 1140/200\n",
      " ssim loss: 0.064270, tar loss: 0.123854\n",
      "=====================\n",
      "Epoch 1170/200\n",
      " ssim loss: 0.067253, tar loss: 0.106031\n",
      "=====================\n",
      "Epoch 1200/200\n",
      " ssim loss: 0.064851, tar loss: 0.123841\n",
      "=====================\n",
      "Epoch 1230/200\n",
      " ssim loss: 0.062402, tar loss: 0.118863\n",
      "=====================\n",
      "Epoch 1260/200\n",
      " ssim loss: 0.048679, tar loss: 0.113375\n",
      "=====================\n",
      "Epoch 1290/200\n",
      " ssim loss: 0.065206, tar loss: 0.123831\n",
      "=====================\n",
      "Epoch 1320/200\n",
      " ssim loss: 0.060012, tar loss: 0.118884\n",
      "=====================\n",
      "Epoch 1350/200\n",
      " ssim loss: 0.052083, tar loss: 0.112028\n",
      "=====================\n",
      "Epoch 1380/200\n",
      " ssim loss: 0.062826, tar loss: 0.095586\n",
      "=====================\n",
      "Epoch 1410/200\n",
      " ssim loss: 0.060544, tar loss: 0.095613\n",
      "=====================\n",
      "Epoch 1440/200\n",
      " ssim loss: 0.049778, tar loss: 0.113346\n",
      "=====================\n",
      "Epoch 1470/200\n",
      " ssim loss: 0.074914, tar loss: 0.110021\n",
      "=====================\n",
      "Epoch 1500/200\n",
      " ssim loss: 0.074407, tar loss: 0.110014\n",
      "=====================\n",
      "Epoch 1530/200\n",
      " ssim loss: 0.053828, tar loss: 0.105028\n",
      "=====================\n",
      "Epoch 1560/200\n",
      " ssim loss: 0.048544, tar loss: 0.113355\n",
      "=====================\n",
      "Epoch 1590/200\n",
      " ssim loss: 0.084711, tar loss: 0.165652\n",
      "=====================\n",
      "Epoch 1620/200\n",
      " ssim loss: 0.062112, tar loss: 0.118877\n",
      "=====================\n",
      "Epoch 1650/200\n",
      " ssim loss: 0.068077, tar loss: 0.095611\n",
      "=====================\n",
      "Epoch 1680/200\n",
      " ssim loss: 0.074422, tar loss: 0.110020\n",
      "=====================\n",
      "Epoch 1710/200\n",
      " ssim loss: 0.063698, tar loss: 0.118847\n",
      "=====================\n",
      "Epoch 1740/200\n",
      " ssim loss: 0.050624, tar loss: 0.105010\n",
      "=====================\n",
      "Epoch 1770/200\n",
      " ssim loss: 0.063317, tar loss: 0.118826\n",
      "=====================\n",
      "Epoch 1800/200\n",
      " ssim loss: 0.065905, tar loss: 0.095600\n",
      "=====================\n",
      "Epoch 1830/200\n",
      " ssim loss: 0.063118, tar loss: 0.095608\n",
      "=====================\n",
      "Epoch 1860/200\n",
      " ssim loss: 0.062207, tar loss: 0.118876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-2ef74d1783ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#refs = torch.from_numpy(refs).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#ssim_loss = batch_ssim(gen_labels, gen_imgs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mssim_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtar_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtar_loss_coeff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mget_target_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssim_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_classifier_pred_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssim_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtar_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AdversarialRobustness/venv/lib/python3.8/site-packages/pytorch_msssim/ssim.py\u001b[0m in \u001b[0;36mssim\u001b[0;34m(X, Y, win_size, win_sigma, win, data_range, size_average, full, K, nonnegative_ssim)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mwin_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     ssim_val, cs = _ssim(X, Y,\n\u001b[0m\u001b[1;32m    129\u001b[0m                          \u001b[0mwin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                          \u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AdversarialRobustness/venv/lib/python3.8/site-packages/pytorch_msssim/ssim.py\u001b[0m in \u001b[0;36m_ssim\u001b[0;34m(X, Y, win, data_range, size_average, full, K, nonnegative_ssim)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0msigma12\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcompensation\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mgaussian_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu1_mu2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcs_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigma12\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigma1_sq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msigma2_sq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set alpha=beta=gamma=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnonnegative_ssim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcs_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcs_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import csv\n",
    "f = open('../models/RunSSIM1_log.csv', 'a')\n",
    "log_writer = csv.writer(f, delimiter=',')\n",
    "log_writer.writerow(['Epoch', 'SSIMLoss', 'TarLoss', 'GLoss'])\n",
    "for epoch in range(40000):\n",
    "    batch_size = 1\n",
    "    # -----------------\n",
    "    #  Train Generator\n",
    "    # -----------------\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # Sample noise and labels as generator input\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))), requires_grad=True)\n",
    "    gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n",
    "\n",
    "    # Generate a batch of images\n",
    "    gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "    target_classifier_pred_label = target_classifier(gen_imgs)\n",
    "\n",
    "    t_acc = np.mean(np.argmax(target_classifier_pred_label.data.cpu().numpy(), axis=1) == gen_labels.data.cpu().numpy())\n",
    "\n",
    "    refs = torch.zeros([batch_size, 1, 28, 28]).cuda()\n",
    "    for i,l in enumerate(gen_labels):\n",
    "        refs[i] = ref_imgs[l.item()][0]\n",
    "    #refs = torch.from_numpy(refs).cuda()\n",
    "    #ssim_loss = batch_ssim(gen_labels, gen_imgs)\n",
    "    ssim_loss = 1-ssim(refs, gen_imgs, size_average=True)\n",
    "    tar_loss = tar_loss_coeff * get_target_loss(ssim_loss, target_classifier_pred_label, gen_labels)\n",
    "    g_loss = ssim_loss + tar_loss\n",
    "\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    log_writer.writerow([epoch, ssim_loss.item(), tar_loss.item(), g_loss.item()])\n",
    "\n",
    "    if epoch % sample_interval == 0:\n",
    "        sample_image(n_row=10, batches_done=epoch)\n",
    "        # Saves weights\n",
    "        #torch.save(generator.state_dict(), \"../models/SSIM1_G\")\n",
    "        print(\n",
    "            \"=====================\\nEpoch %d/%d\\n ssim loss: %f, tar loss: %f\"\n",
    "            % (epoch, n_epochs, ssim_loss.item(), tar_loss.item())\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves weights\n",
    "torch.save(generator.state_dict(), \"../models/Success2_G\")\n",
    "torch.save(discriminator.state_dict(), \"../models/Success2_D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "batch_size = 1000\n",
    "z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n",
    "\n",
    "# Generate a batch of images\n",
    "gen_imgs = generator(z, gen_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Gen Label: 0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots a sample\n",
    "import matplotlib.pyplot as plt\n",
    "sample_idx = 28\n",
    "print(gen_imgs[sample_idx].shape)\n",
    "plt.imshow(gen_imgs[sample_idx][0].cpu().detach().numpy(), cmap='gray', interpolation='none')\n",
    "plt.title(\"Gen Label: \" + str(gen_labels.cpu().detach().numpy()[sample_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6328097760>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots a ref\n",
    "print(ref_imgs[0].view(1, 28, 28).shape)\n",
    "plt.imshow(ref_imgs[9][0][0].cpu().detach().numpy(), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finds target classification for sample\n",
    "pred_labels = target_classifier(gen_imgs)\n",
    "np.argmax(pred_labels.data.cpu().numpy()[sample_idx])\n",
    "#pred_labels.data.cpu().numpy()[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 28, 120, 163, 301, 308, 338, 357, 381, 411, 473, 481, 630, 671,\n",
       "        733, 763, 859, 939, 950, 952, 954, 961, 970]),)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finds indexes that have adversarial examples\n",
    "t_acc = np.argmax(pred_labels.data.cpu().numpy(), axis=1) == gen_labels.data.cpu().numpy()\n",
    "np.where(t_acc == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen = gen_imgs.cpu().detach().numpy()\n",
    "preds = pred_labels.data.cpu().numpy()\n",
    "true = gen_labels.data.cpu().numpy()\n",
    "v = validity.data.cpu().numpy()\n",
    "dpred = dpred_labels.data.cpu().numpy()\n",
    "for i in range(len(true)):\n",
    "    if np.argmax(preds[i]) != true[i]:\n",
    "        plt.title(\"Gen Label: \" + str(true[i]) + \"; LeNet Label: \" + str(np.argmax(preds[i])))\n",
    "        plt.xlabel(\"Discriminator Valid: \" + str(v[i]) +\" Discriminator Class: \" + str(np.argmax(dpred[i])))\n",
    "        plt.imshow(gen[i][0], cmap='gray')\n",
    "        plt.savefig(\"../images/SecondRun/AdversarialExamples/\" + str(1000+i) + \".png\")\n",
    "        \n",
    "#for i in range(len(true)):\n",
    "#    plt.title(\"Gen Label: \" + str(true[i]) + \"; LeNet Label: \" + str(np.argmax(preds[i])))\n",
    "#    plt.imshow(gen[i][0], cmap='gray')\n",
    "#    plt.savefig(\"../images/SecondRun/AllSamples/\" + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra saving\n",
    "torch.save(gen_imgs, \"../models/Success2_GenSample\")\n",
    "torch.save(gen_labels, \"../models/Success2_GenLabels\")\n",
    "torch.save(pred_labels, \"../models/Success2_LeNetLabels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achyut/Projects/AdversarialRobustness/venv/lib/python3.8/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "validity, dpred_labels = discriminator(gen_imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
