{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "# https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/acgan/acgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "\n",
    "n_epochs=200\n",
    "batch_size=64\n",
    "lr=0.0002\n",
    "b1=0.5\n",
    "b2=0.999\n",
    "latent_dim=100\n",
    "n_classes=10\n",
    "img_size=32\n",
    "channels=1\n",
    "sample_interval=400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions and Model\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(n_classes, latent_dim)\n",
    "\n",
    "        self.init_size = img_size // 4  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        gen_input = torch.mul(self.label_emb(labels), noise)\n",
    "        out = self.l1(gen_input)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"Returns layers of each discriminator block\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "\n",
    "        # Output layers\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, n_classes), nn.Softmax())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return validity, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "cuda = True\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.5%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "# Configure data loader\n",
    "os.makedirs(\"../data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = generator(z, labels)\n",
    "    save_image(gen_imgs.data, \"../images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/938] [D loss: 1.497853, acc: 9%] [G loss: 1.491239]\n",
      "[Epoch 0/200] [Batch 1/938] [D loss: 1.497986, acc: 7%] [G loss: 1.491616]\n",
      "[Epoch 0/200] [Batch 2/938] [D loss: 1.497748, acc: 14%] [G loss: 1.491213]\n",
      "[Epoch 0/200] [Batch 3/938] [D loss: 1.497929, acc: 7%] [G loss: 1.491696]\n",
      "[Epoch 0/200] [Batch 4/938] [D loss: 1.497744, acc: 5%] [G loss: 1.491741]\n",
      "[Epoch 0/200] [Batch 5/938] [D loss: 1.497814, acc: 9%] [G loss: 1.491944]\n",
      "[Epoch 0/200] [Batch 6/938] [D loss: 1.497926, acc: 7%] [G loss: 1.492474]\n",
      "[Epoch 0/200] [Batch 7/938] [D loss: 1.497587, acc: 14%] [G loss: 1.492329]\n",
      "[Epoch 0/200] [Batch 8/938] [D loss: 1.497893, acc: 11%] [G loss: 1.492996]\n",
      "[Epoch 0/200] [Batch 9/938] [D loss: 1.497888, acc: 7%] [G loss: 1.493207]\n",
      "[Epoch 0/200] [Batch 10/938] [D loss: 1.497869, acc: 8%] [G loss: 1.493077]\n",
      "[Epoch 0/200] [Batch 11/938] [D loss: 1.497617, acc: 7%] [G loss: 1.493303]\n",
      "[Epoch 0/200] [Batch 12/938] [D loss: 1.497687, acc: 8%] [G loss: 1.493407]\n",
      "[Epoch 0/200] [Batch 13/938] [D loss: 1.497570, acc: 14%] [G loss: 1.493619]\n",
      "[Epoch 0/200] [Batch 14/938] [D loss: 1.497909, acc: 6%] [G loss: 1.493859]\n",
      "[Epoch 0/200] [Batch 15/938] [D loss: 1.497692, acc: 3%] [G loss: 1.493961]\n",
      "[Epoch 0/200] [Batch 16/938] [D loss: 1.497383, acc: 11%] [G loss: 1.493848]\n",
      "[Epoch 0/200] [Batch 17/938] [D loss: 1.497451, acc: 12%] [G loss: 1.494013]\n",
      "[Epoch 0/200] [Batch 18/938] [D loss: 1.497347, acc: 10%] [G loss: 1.493751]\n",
      "[Epoch 0/200] [Batch 19/938] [D loss: 1.497456, acc: 9%] [G loss: 1.493921]\n",
      "[Epoch 0/200] [Batch 20/938] [D loss: 1.497544, acc: 12%] [G loss: 1.493787]\n",
      "[Epoch 0/200] [Batch 21/938] [D loss: 1.497619, acc: 10%] [G loss: 1.493802]\n",
      "[Epoch 0/200] [Batch 22/938] [D loss: 1.497478, acc: 9%] [G loss: 1.493568]\n",
      "[Epoch 0/200] [Batch 23/938] [D loss: 1.497653, acc: 9%] [G loss: 1.493245]\n",
      "[Epoch 0/200] [Batch 24/938] [D loss: 1.497718, acc: 8%] [G loss: 1.493683]\n",
      "[Epoch 0/200] [Batch 25/938] [D loss: 1.497679, acc: 10%] [G loss: 1.493914]\n",
      "[Epoch 0/200] [Batch 26/938] [D loss: 1.497727, acc: 12%] [G loss: 1.493650]\n",
      "[Epoch 0/200] [Batch 27/938] [D loss: 1.497755, acc: 10%] [G loss: 1.493726]\n",
      "[Epoch 0/200] [Batch 28/938] [D loss: 1.497624, acc: 9%] [G loss: 1.494380]\n",
      "[Epoch 0/200] [Batch 29/938] [D loss: 1.497637, acc: 7%] [G loss: 1.495325]\n",
      "[Epoch 0/200] [Batch 30/938] [D loss: 1.497781, acc: 11%] [G loss: 1.494887]\n",
      "[Epoch 0/200] [Batch 31/938] [D loss: 1.497471, acc: 14%] [G loss: 1.495074]\n",
      "[Epoch 0/200] [Batch 32/938] [D loss: 1.497447, acc: 17%] [G loss: 1.495278]\n",
      "[Epoch 0/200] [Batch 33/938] [D loss: 1.497400, acc: 12%] [G loss: 1.495866]\n",
      "[Epoch 0/200] [Batch 34/938] [D loss: 1.497061, acc: 13%] [G loss: 1.496092]\n",
      "[Epoch 0/200] [Batch 35/938] [D loss: 1.497433, acc: 8%] [G loss: 1.496614]\n",
      "[Epoch 0/200] [Batch 36/938] [D loss: 1.496934, acc: 14%] [G loss: 1.497234]\n",
      "[Epoch 0/200] [Batch 37/938] [D loss: 1.496710, acc: 11%] [G loss: 1.498052]\n",
      "[Epoch 0/200] [Batch 38/938] [D loss: 1.496680, acc: 8%] [G loss: 1.498125]\n",
      "[Epoch 0/200] [Batch 39/938] [D loss: 1.496797, acc: 12%] [G loss: 1.499121]\n",
      "[Epoch 0/200] [Batch 40/938] [D loss: 1.496622, acc: 10%] [G loss: 1.499411]\n",
      "[Epoch 0/200] [Batch 41/938] [D loss: 1.496108, acc: 9%] [G loss: 1.499145]\n",
      "[Epoch 0/200] [Batch 42/938] [D loss: 1.496069, acc: 10%] [G loss: 1.500115]\n",
      "[Epoch 0/200] [Batch 43/938] [D loss: 1.495883, acc: 9%] [G loss: 1.500262]\n",
      "[Epoch 0/200] [Batch 44/938] [D loss: 1.494596, acc: 15%] [G loss: 1.500982]\n",
      "[Epoch 0/200] [Batch 45/938] [D loss: 1.495216, acc: 14%] [G loss: 1.500243]\n",
      "[Epoch 0/200] [Batch 46/938] [D loss: 1.495850, acc: 10%] [G loss: 1.499463]\n",
      "[Epoch 0/200] [Batch 47/938] [D loss: 1.496639, acc: 9%] [G loss: 1.497885]\n",
      "[Epoch 0/200] [Batch 48/938] [D loss: 1.495538, acc: 10%] [G loss: 1.494608]\n",
      "[Epoch 0/200] [Batch 49/938] [D loss: 1.493623, acc: 9%] [G loss: 1.494325]\n",
      "[Epoch 0/200] [Batch 50/938] [D loss: 1.494525, acc: 10%] [G loss: 1.490024]\n",
      "[Epoch 0/200] [Batch 51/938] [D loss: 1.493057, acc: 8%] [G loss: 1.486102]\n",
      "[Epoch 0/200] [Batch 52/938] [D loss: 1.491899, acc: 7%] [G loss: 1.488108]\n",
      "[Epoch 0/200] [Batch 53/938] [D loss: 1.492470, acc: 9%] [G loss: 1.482167]\n",
      "[Epoch 0/200] [Batch 54/938] [D loss: 1.491186, acc: 12%] [G loss: 1.478413]\n",
      "[Epoch 0/200] [Batch 55/938] [D loss: 1.491101, acc: 17%] [G loss: 1.472812]\n",
      "[Epoch 0/200] [Batch 56/938] [D loss: 1.493382, acc: 8%] [G loss: 1.469747]\n",
      "[Epoch 0/200] [Batch 57/938] [D loss: 1.497790, acc: 7%] [G loss: 1.462028]\n",
      "[Epoch 0/200] [Batch 58/938] [D loss: 1.493835, acc: 8%] [G loss: 1.469677]\n",
      "[Epoch 0/200] [Batch 59/938] [D loss: 1.494562, acc: 14%] [G loss: 1.476686]\n",
      "[Epoch 0/200] [Batch 60/938] [D loss: 1.496574, acc: 7%] [G loss: 1.473667]\n",
      "[Epoch 0/200] [Batch 61/938] [D loss: 1.495788, acc: 9%] [G loss: 1.476126]\n",
      "[Epoch 0/200] [Batch 62/938] [D loss: 1.498301, acc: 11%] [G loss: 1.478529]\n",
      "[Epoch 0/200] [Batch 63/938] [D loss: 1.495204, acc: 9%] [G loss: 1.484841]\n",
      "[Epoch 0/200] [Batch 64/938] [D loss: 1.495740, acc: 15%] [G loss: 1.483861]\n",
      "[Epoch 0/200] [Batch 65/938] [D loss: 1.498625, acc: 10%] [G loss: 1.483089]\n",
      "[Epoch 0/200] [Batch 66/938] [D loss: 1.498427, acc: 11%] [G loss: 1.485439]\n",
      "[Epoch 0/200] [Batch 67/938] [D loss: 1.499358, acc: 10%] [G loss: 1.489188]\n",
      "[Epoch 0/200] [Batch 68/938] [D loss: 1.496945, acc: 13%] [G loss: 1.490099]\n",
      "[Epoch 0/200] [Batch 69/938] [D loss: 1.499553, acc: 10%] [G loss: 1.490067]\n",
      "[Epoch 0/200] [Batch 70/938] [D loss: 1.496348, acc: 10%] [G loss: 1.489557]\n",
      "[Epoch 0/200] [Batch 71/938] [D loss: 1.499646, acc: 7%] [G loss: 1.491138]\n",
      "[Epoch 0/200] [Batch 72/938] [D loss: 1.498446, acc: 10%] [G loss: 1.491316]\n",
      "[Epoch 0/200] [Batch 73/938] [D loss: 1.497130, acc: 16%] [G loss: 1.489176]\n",
      "[Epoch 0/200] [Batch 74/938] [D loss: 1.496112, acc: 10%] [G loss: 1.495023]\n",
      "[Epoch 0/200] [Batch 75/938] [D loss: 1.498497, acc: 11%] [G loss: 1.495596]\n",
      "[Epoch 0/200] [Batch 76/938] [D loss: 1.498215, acc: 11%] [G loss: 1.494271]\n",
      "[Epoch 0/200] [Batch 77/938] [D loss: 1.498395, acc: 6%] [G loss: 1.495497]\n",
      "[Epoch 0/200] [Batch 78/938] [D loss: 1.498011, acc: 8%] [G loss: 1.498094]\n",
      "[Epoch 0/200] [Batch 79/938] [D loss: 1.498374, acc: 5%] [G loss: 1.498637]\n",
      "[Epoch 0/200] [Batch 80/938] [D loss: 1.498021, acc: 11%] [G loss: 1.501648]\n",
      "[Epoch 0/200] [Batch 81/938] [D loss: 1.498417, acc: 14%] [G loss: 1.502700]\n",
      "[Epoch 0/200] [Batch 82/938] [D loss: 1.498836, acc: 10%] [G loss: 1.504490]\n",
      "[Epoch 0/200] [Batch 83/938] [D loss: 1.498992, acc: 14%] [G loss: 1.506309]\n",
      "[Epoch 0/200] [Batch 84/938] [D loss: 1.497709, acc: 13%] [G loss: 1.507097]\n",
      "[Epoch 0/200] [Batch 85/938] [D loss: 1.498513, acc: 14%] [G loss: 1.506429]\n",
      "[Epoch 0/200] [Batch 86/938] [D loss: 1.498786, acc: 5%] [G loss: 1.507578]\n",
      "[Epoch 0/200] [Batch 87/938] [D loss: 1.496930, acc: 7%] [G loss: 1.505911]\n",
      "[Epoch 0/200] [Batch 88/938] [D loss: 1.497092, acc: 9%] [G loss: 1.504300]\n",
      "[Epoch 0/200] [Batch 89/938] [D loss: 1.497285, acc: 7%] [G loss: 1.503031]\n",
      "[Epoch 0/200] [Batch 90/938] [D loss: 1.497389, acc: 4%] [G loss: 1.500300]\n",
      "[Epoch 0/200] [Batch 91/938] [D loss: 1.497895, acc: 12%] [G loss: 1.501559]\n",
      "[Epoch 0/200] [Batch 92/938] [D loss: 1.497308, acc: 10%] [G loss: 1.500493]\n",
      "[Epoch 0/200] [Batch 93/938] [D loss: 1.496986, acc: 10%] [G loss: 1.499844]\n",
      "[Epoch 0/200] [Batch 94/938] [D loss: 1.497957, acc: 12%] [G loss: 1.499052]\n",
      "[Epoch 0/200] [Batch 95/938] [D loss: 1.498731, acc: 12%] [G loss: 1.497872]\n",
      "[Epoch 0/200] [Batch 96/938] [D loss: 1.498679, acc: 11%] [G loss: 1.499722]\n",
      "[Epoch 0/200] [Batch 97/938] [D loss: 1.497054, acc: 13%] [G loss: 1.499937]\n",
      "[Epoch 0/200] [Batch 98/938] [D loss: 1.498204, acc: 14%] [G loss: 1.496778]\n",
      "[Epoch 0/200] [Batch 99/938] [D loss: 1.496852, acc: 10%] [G loss: 1.502053]\n",
      "[Epoch 0/200] [Batch 100/938] [D loss: 1.497255, acc: 7%] [G loss: 1.501432]\n",
      "[Epoch 0/200] [Batch 101/938] [D loss: 1.497970, acc: 6%] [G loss: 1.502454]\n",
      "[Epoch 0/200] [Batch 102/938] [D loss: 1.498096, acc: 7%] [G loss: 1.502578]\n",
      "[Epoch 0/200] [Batch 103/938] [D loss: 1.496572, acc: 10%] [G loss: 1.504135]\n",
      "[Epoch 0/200] [Batch 104/938] [D loss: 1.496472, acc: 13%] [G loss: 1.504264]\n",
      "[Epoch 0/200] [Batch 105/938] [D loss: 1.496999, acc: 9%] [G loss: 1.509066]\n",
      "[Epoch 0/200] [Batch 106/938] [D loss: 1.498093, acc: 10%] [G loss: 1.503962]\n",
      "[Epoch 0/200] [Batch 107/938] [D loss: 1.498970, acc: 10%] [G loss: 1.507281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 108/938] [D loss: 1.498500, acc: 10%] [G loss: 1.505882]\n",
      "[Epoch 0/200] [Batch 109/938] [D loss: 1.499792, acc: 8%] [G loss: 1.501962]\n",
      "[Epoch 0/200] [Batch 110/938] [D loss: 1.500608, acc: 7%] [G loss: 1.500743]\n",
      "[Epoch 0/200] [Batch 111/938] [D loss: 1.500042, acc: 13%] [G loss: 1.499482]\n",
      "[Epoch 0/200] [Batch 112/938] [D loss: 1.499197, acc: 10%] [G loss: 1.499197]\n",
      "[Epoch 0/200] [Batch 113/938] [D loss: 1.499562, acc: 7%] [G loss: 1.499289]\n",
      "[Epoch 0/200] [Batch 114/938] [D loss: 1.496945, acc: 10%] [G loss: 1.499475]\n",
      "[Epoch 0/200] [Batch 115/938] [D loss: 1.495512, acc: 11%] [G loss: 1.499715]\n",
      "[Epoch 0/200] [Batch 116/938] [D loss: 1.494918, acc: 10%] [G loss: 1.497970]\n",
      "[Epoch 0/200] [Batch 117/938] [D loss: 1.495335, acc: 13%] [G loss: 1.495018]\n",
      "[Epoch 0/200] [Batch 118/938] [D loss: 1.495097, acc: 12%] [G loss: 1.490754]\n",
      "[Epoch 0/200] [Batch 119/938] [D loss: 1.496156, acc: 6%] [G loss: 1.488932]\n",
      "[Epoch 0/200] [Batch 120/938] [D loss: 1.495815, acc: 5%] [G loss: 1.485494]\n",
      "[Epoch 0/200] [Batch 121/938] [D loss: 1.496890, acc: 7%] [G loss: 1.474643]\n",
      "[Epoch 0/200] [Batch 122/938] [D loss: 1.502124, acc: 4%] [G loss: 1.472060]\n",
      "[Epoch 0/200] [Batch 123/938] [D loss: 1.502455, acc: 14%] [G loss: 1.476200]\n",
      "[Epoch 0/200] [Batch 124/938] [D loss: 1.502155, acc: 14%] [G loss: 1.477047]\n",
      "[Epoch 0/200] [Batch 125/938] [D loss: 1.501133, acc: 8%] [G loss: 1.486101]\n",
      "[Epoch 0/200] [Batch 126/938] [D loss: 1.499930, acc: 13%] [G loss: 1.490631]\n",
      "[Epoch 0/200] [Batch 127/938] [D loss: 1.499272, acc: 6%] [G loss: 1.495105]\n",
      "[Epoch 0/200] [Batch 128/938] [D loss: 1.497216, acc: 9%] [G loss: 1.499234]\n",
      "[Epoch 0/200] [Batch 129/938] [D loss: 1.498924, acc: 3%] [G loss: 1.501218]\n",
      "[Epoch 0/200] [Batch 130/938] [D loss: 1.496739, acc: 9%] [G loss: 1.502962]\n",
      "[Epoch 0/200] [Batch 131/938] [D loss: 1.495695, acc: 7%] [G loss: 1.508524]\n",
      "[Epoch 0/200] [Batch 132/938] [D loss: 1.493916, acc: 10%] [G loss: 1.508181]\n",
      "[Epoch 0/200] [Batch 133/938] [D loss: 1.493522, acc: 9%] [G loss: 1.508673]\n",
      "[Epoch 0/200] [Batch 134/938] [D loss: 1.494089, acc: 12%] [G loss: 1.509336]\n",
      "[Epoch 0/200] [Batch 135/938] [D loss: 1.491335, acc: 15%] [G loss: 1.513446]\n",
      "[Epoch 0/200] [Batch 136/938] [D loss: 1.492833, acc: 11%] [G loss: 1.513246]\n",
      "[Epoch 0/200] [Batch 137/938] [D loss: 1.493017, acc: 10%] [G loss: 1.511958]\n",
      "[Epoch 0/200] [Batch 138/938] [D loss: 1.493777, acc: 13%] [G loss: 1.510988]\n",
      "[Epoch 0/200] [Batch 139/938] [D loss: 1.496491, acc: 8%] [G loss: 1.507927]\n",
      "[Epoch 0/200] [Batch 140/938] [D loss: 1.499123, acc: 14%] [G loss: 1.501241]\n",
      "[Epoch 0/200] [Batch 141/938] [D loss: 1.504364, acc: 7%] [G loss: 1.491969]\n",
      "[Epoch 0/200] [Batch 142/938] [D loss: 1.507317, acc: 10%] [G loss: 1.487540]\n",
      "[Epoch 0/200] [Batch 143/938] [D loss: 1.505457, acc: 10%] [G loss: 1.484494]\n",
      "[Epoch 0/200] [Batch 144/938] [D loss: 1.504399, acc: 8%] [G loss: 1.487249]\n",
      "[Epoch 0/200] [Batch 145/938] [D loss: 1.498762, acc: 13%] [G loss: 1.490371]\n",
      "[Epoch 0/200] [Batch 146/938] [D loss: 1.496901, acc: 11%] [G loss: 1.492268]\n",
      "[Epoch 0/200] [Batch 147/938] [D loss: 1.497202, acc: 13%] [G loss: 1.492031]\n",
      "[Epoch 0/200] [Batch 148/938] [D loss: 1.493521, acc: 10%] [G loss: 1.493581]\n",
      "[Epoch 0/200] [Batch 149/938] [D loss: 1.489311, acc: 14%] [G loss: 1.496735]\n",
      "[Epoch 0/200] [Batch 150/938] [D loss: 1.487392, acc: 7%] [G loss: 1.494692]\n",
      "[Epoch 0/200] [Batch 151/938] [D loss: 1.487143, acc: 11%] [G loss: 1.489692]\n",
      "[Epoch 0/200] [Batch 152/938] [D loss: 1.489949, acc: 8%] [G loss: 1.481824]\n",
      "[Epoch 0/200] [Batch 153/938] [D loss: 1.492685, acc: 10%] [G loss: 1.468292]\n",
      "[Epoch 0/200] [Batch 154/938] [D loss: 1.497954, acc: 7%] [G loss: 1.456874]\n",
      "[Epoch 0/200] [Batch 155/938] [D loss: 1.502157, acc: 10%] [G loss: 1.446244]\n",
      "[Epoch 0/200] [Batch 156/938] [D loss: 1.510992, acc: 13%] [G loss: 1.445526]\n",
      "[Epoch 0/200] [Batch 157/938] [D loss: 1.505218, acc: 12%] [G loss: 1.454183]\n",
      "[Epoch 0/200] [Batch 158/938] [D loss: 1.506156, acc: 10%] [G loss: 1.472808]\n",
      "[Epoch 0/200] [Batch 159/938] [D loss: 1.502923, acc: 14%] [G loss: 1.478416]\n",
      "[Epoch 0/200] [Batch 160/938] [D loss: 1.499629, acc: 8%] [G loss: 1.489509]\n",
      "[Epoch 0/200] [Batch 161/938] [D loss: 1.500785, acc: 13%] [G loss: 1.496185]\n",
      "[Epoch 0/200] [Batch 162/938] [D loss: 1.499703, acc: 14%] [G loss: 1.500814]\n",
      "[Epoch 0/200] [Batch 163/938] [D loss: 1.496878, acc: 11%] [G loss: 1.508282]\n",
      "[Epoch 0/200] [Batch 164/938] [D loss: 1.495975, acc: 11%] [G loss: 1.512307]\n",
      "[Epoch 0/200] [Batch 165/938] [D loss: 1.496051, acc: 15%] [G loss: 1.513414]\n",
      "[Epoch 0/200] [Batch 166/938] [D loss: 1.497260, acc: 10%] [G loss: 1.518124]\n",
      "[Epoch 0/200] [Batch 167/938] [D loss: 1.494481, acc: 11%] [G loss: 1.515315]\n",
      "[Epoch 0/200] [Batch 168/938] [D loss: 1.493362, acc: 12%] [G loss: 1.519544]\n",
      "[Epoch 0/200] [Batch 169/938] [D loss: 1.494225, acc: 9%] [G loss: 1.518885]\n",
      "[Epoch 0/200] [Batch 170/938] [D loss: 1.495438, acc: 14%] [G loss: 1.519441]\n",
      "[Epoch 0/200] [Batch 171/938] [D loss: 1.498399, acc: 7%] [G loss: 1.514892]\n",
      "[Epoch 0/200] [Batch 172/938] [D loss: 1.496005, acc: 10%] [G loss: 1.515269]\n",
      "[Epoch 0/200] [Batch 173/938] [D loss: 1.496320, acc: 10%] [G loss: 1.512084]\n",
      "[Epoch 0/200] [Batch 174/938] [D loss: 1.498347, acc: 12%] [G loss: 1.507795]\n",
      "[Epoch 0/200] [Batch 175/938] [D loss: 1.500833, acc: 13%] [G loss: 1.508844]\n",
      "[Epoch 0/200] [Batch 176/938] [D loss: 1.499626, acc: 14%] [G loss: 1.508364]\n",
      "[Epoch 0/200] [Batch 177/938] [D loss: 1.499586, acc: 12%] [G loss: 1.505892]\n",
      "[Epoch 0/200] [Batch 178/938] [D loss: 1.500279, acc: 14%] [G loss: 1.503894]\n",
      "[Epoch 0/200] [Batch 179/938] [D loss: 1.499294, acc: 19%] [G loss: 1.502012]\n",
      "[Epoch 0/200] [Batch 180/938] [D loss: 1.500436, acc: 14%] [G loss: 1.499680]\n",
      "[Epoch 0/200] [Batch 181/938] [D loss: 1.498891, acc: 18%] [G loss: 1.499610]\n",
      "[Epoch 0/200] [Batch 182/938] [D loss: 1.497998, acc: 15%] [G loss: 1.497248]\n",
      "[Epoch 0/200] [Batch 183/938] [D loss: 1.498649, acc: 17%] [G loss: 1.498867]\n",
      "[Epoch 0/200] [Batch 184/938] [D loss: 1.500479, acc: 17%] [G loss: 1.497392]\n",
      "[Epoch 0/200] [Batch 185/938] [D loss: 1.499184, acc: 10%] [G loss: 1.496604]\n",
      "[Epoch 0/200] [Batch 186/938] [D loss: 1.498442, acc: 14%] [G loss: 1.497965]\n",
      "[Epoch 0/200] [Batch 187/938] [D loss: 1.496962, acc: 18%] [G loss: 1.496541]\n",
      "[Epoch 0/200] [Batch 188/938] [D loss: 1.497935, acc: 17%] [G loss: 1.496513]\n",
      "[Epoch 0/200] [Batch 189/938] [D loss: 1.498821, acc: 12%] [G loss: 1.495866]\n",
      "[Epoch 0/200] [Batch 190/938] [D loss: 1.497074, acc: 10%] [G loss: 1.495918]\n",
      "[Epoch 0/200] [Batch 191/938] [D loss: 1.497182, acc: 10%] [G loss: 1.496298]\n",
      "[Epoch 0/200] [Batch 192/938] [D loss: 1.498968, acc: 10%] [G loss: 1.494672]\n",
      "[Epoch 0/200] [Batch 193/938] [D loss: 1.498076, acc: 21%] [G loss: 1.494290]\n",
      "[Epoch 0/200] [Batch 194/938] [D loss: 1.498455, acc: 21%] [G loss: 1.494202]\n",
      "[Epoch 0/200] [Batch 195/938] [D loss: 1.496947, acc: 13%] [G loss: 1.494487]\n",
      "[Epoch 0/200] [Batch 196/938] [D loss: 1.496528, acc: 16%] [G loss: 1.497108]\n",
      "[Epoch 0/200] [Batch 197/938] [D loss: 1.497962, acc: 15%] [G loss: 1.498844]\n",
      "[Epoch 0/200] [Batch 198/938] [D loss: 1.497687, acc: 16%] [G loss: 1.497650]\n",
      "[Epoch 0/200] [Batch 199/938] [D loss: 1.498401, acc: 17%] [G loss: 1.497994]\n",
      "[Epoch 0/200] [Batch 200/938] [D loss: 1.498737, acc: 14%] [G loss: 1.497553]\n",
      "[Epoch 0/200] [Batch 201/938] [D loss: 1.499208, acc: 22%] [G loss: 1.499358]\n",
      "[Epoch 0/200] [Batch 202/938] [D loss: 1.498384, acc: 10%] [G loss: 1.501690]\n",
      "[Epoch 0/200] [Batch 203/938] [D loss: 1.497643, acc: 15%] [G loss: 1.502126]\n",
      "[Epoch 0/200] [Batch 204/938] [D loss: 1.495738, acc: 20%] [G loss: 1.503315]\n",
      "[Epoch 0/200] [Batch 205/938] [D loss: 1.496994, acc: 14%] [G loss: 1.501068]\n",
      "[Epoch 0/200] [Batch 206/938] [D loss: 1.496848, acc: 17%] [G loss: 1.502069]\n",
      "[Epoch 0/200] [Batch 207/938] [D loss: 1.496110, acc: 17%] [G loss: 1.503186]\n",
      "[Epoch 0/200] [Batch 208/938] [D loss: 1.496888, acc: 20%] [G loss: 1.500672]\n",
      "[Epoch 0/200] [Batch 209/938] [D loss: 1.496677, acc: 21%] [G loss: 1.503081]\n",
      "[Epoch 0/200] [Batch 210/938] [D loss: 1.496889, acc: 25%] [G loss: 1.500707]\n",
      "[Epoch 0/200] [Batch 211/938] [D loss: 1.495926, acc: 18%] [G loss: 1.503231]\n",
      "[Epoch 0/200] [Batch 212/938] [D loss: 1.496310, acc: 19%] [G loss: 1.501437]\n",
      "[Epoch 0/200] [Batch 213/938] [D loss: 1.497122, acc: 13%] [G loss: 1.501361]\n",
      "[Epoch 0/200] [Batch 214/938] [D loss: 1.495347, acc: 23%] [G loss: 1.501516]\n",
      "[Epoch 0/200] [Batch 215/938] [D loss: 1.496793, acc: 14%] [G loss: 1.500702]\n",
      "[Epoch 0/200] [Batch 216/938] [D loss: 1.496695, acc: 20%] [G loss: 1.498831]\n",
      "[Epoch 0/200] [Batch 217/938] [D loss: 1.496779, acc: 16%] [G loss: 1.501345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 218/938] [D loss: 1.496170, acc: 19%] [G loss: 1.500919]\n",
      "[Epoch 0/200] [Batch 219/938] [D loss: 1.495437, acc: 20%] [G loss: 1.498939]\n",
      "[Epoch 0/200] [Batch 220/938] [D loss: 1.496962, acc: 16%] [G loss: 1.499902]\n",
      "[Epoch 0/200] [Batch 221/938] [D loss: 1.495389, acc: 14%] [G loss: 1.498770]\n",
      "[Epoch 0/200] [Batch 222/938] [D loss: 1.497842, acc: 16%] [G loss: 1.499172]\n",
      "[Epoch 0/200] [Batch 223/938] [D loss: 1.496120, acc: 16%] [G loss: 1.496592]\n",
      "[Epoch 0/200] [Batch 224/938] [D loss: 1.497908, acc: 15%] [G loss: 1.495459]\n",
      "[Epoch 0/200] [Batch 225/938] [D loss: 1.494958, acc: 18%] [G loss: 1.498078]\n",
      "[Epoch 0/200] [Batch 226/938] [D loss: 1.496416, acc: 19%] [G loss: 1.492516]\n",
      "[Epoch 0/200] [Batch 227/938] [D loss: 1.497437, acc: 23%] [G loss: 1.490687]\n",
      "[Epoch 0/200] [Batch 228/938] [D loss: 1.495046, acc: 25%] [G loss: 1.494759]\n",
      "[Epoch 0/200] [Batch 229/938] [D loss: 1.497625, acc: 19%] [G loss: 1.492430]\n",
      "[Epoch 0/200] [Batch 230/938] [D loss: 1.494865, acc: 22%] [G loss: 1.494442]\n",
      "[Epoch 0/200] [Batch 231/938] [D loss: 1.497983, acc: 18%] [G loss: 1.493432]\n",
      "[Epoch 0/200] [Batch 232/938] [D loss: 1.497850, acc: 14%] [G loss: 1.491730]\n",
      "[Epoch 0/200] [Batch 233/938] [D loss: 1.495594, acc: 15%] [G loss: 1.495302]\n",
      "[Epoch 0/200] [Batch 234/938] [D loss: 1.496756, acc: 18%] [G loss: 1.494558]\n",
      "[Epoch 0/200] [Batch 235/938] [D loss: 1.496622, acc: 14%] [G loss: 1.498027]\n",
      "[Epoch 0/200] [Batch 236/938] [D loss: 1.493055, acc: 20%] [G loss: 1.499686]\n",
      "[Epoch 0/200] [Batch 237/938] [D loss: 1.494948, acc: 14%] [G loss: 1.502153]\n",
      "[Epoch 0/200] [Batch 238/938] [D loss: 1.494834, acc: 15%] [G loss: 1.502260]\n",
      "[Epoch 0/200] [Batch 239/938] [D loss: 1.496014, acc: 19%] [G loss: 1.498894]\n",
      "[Epoch 0/200] [Batch 240/938] [D loss: 1.496321, acc: 17%] [G loss: 1.499993]\n",
      "[Epoch 0/200] [Batch 241/938] [D loss: 1.496081, acc: 15%] [G loss: 1.497464]\n",
      "[Epoch 0/200] [Batch 242/938] [D loss: 1.496679, acc: 17%] [G loss: 1.498321]\n",
      "[Epoch 0/200] [Batch 243/938] [D loss: 1.495799, acc: 16%] [G loss: 1.494710]\n",
      "[Epoch 0/200] [Batch 244/938] [D loss: 1.496620, acc: 17%] [G loss: 1.496909]\n",
      "[Epoch 0/200] [Batch 245/938] [D loss: 1.497748, acc: 17%] [G loss: 1.494353]\n",
      "[Epoch 0/200] [Batch 246/938] [D loss: 1.499346, acc: 17%] [G loss: 1.492706]\n",
      "[Epoch 0/200] [Batch 247/938] [D loss: 1.499619, acc: 15%] [G loss: 1.492465]\n",
      "[Epoch 0/200] [Batch 248/938] [D loss: 1.496078, acc: 17%] [G loss: 1.494726]\n",
      "[Epoch 0/200] [Batch 249/938] [D loss: 1.496317, acc: 17%] [G loss: 1.491073]\n",
      "[Epoch 0/200] [Batch 250/938] [D loss: 1.495788, acc: 18%] [G loss: 1.494324]\n",
      "[Epoch 0/200] [Batch 251/938] [D loss: 1.492378, acc: 21%] [G loss: 1.493589]\n",
      "[Epoch 0/200] [Batch 252/938] [D loss: 1.493351, acc: 18%] [G loss: 1.493074]\n",
      "[Epoch 0/200] [Batch 253/938] [D loss: 1.490893, acc: 21%] [G loss: 1.494543]\n",
      "[Epoch 0/200] [Batch 254/938] [D loss: 1.491892, acc: 21%] [G loss: 1.490044]\n",
      "[Epoch 0/200] [Batch 255/938] [D loss: 1.491940, acc: 18%] [G loss: 1.489759]\n",
      "[Epoch 0/200] [Batch 256/938] [D loss: 1.490587, acc: 16%] [G loss: 1.487599]\n",
      "[Epoch 0/200] [Batch 257/938] [D loss: 1.489315, acc: 21%] [G loss: 1.488134]\n",
      "[Epoch 0/200] [Batch 258/938] [D loss: 1.495617, acc: 18%] [G loss: 1.479142]\n",
      "[Epoch 0/200] [Batch 259/938] [D loss: 1.496179, acc: 21%] [G loss: 1.474983]\n",
      "[Epoch 0/200] [Batch 260/938] [D loss: 1.501364, acc: 20%] [G loss: 1.476588]\n",
      "[Epoch 0/200] [Batch 261/938] [D loss: 1.500277, acc: 19%] [G loss: 1.477237]\n",
      "[Epoch 0/200] [Batch 262/938] [D loss: 1.502823, acc: 16%] [G loss: 1.484120]\n",
      "[Epoch 0/200] [Batch 263/938] [D loss: 1.495016, acc: 20%] [G loss: 1.493707]\n",
      "[Epoch 0/200] [Batch 264/938] [D loss: 1.497339, acc: 19%] [G loss: 1.487437]\n",
      "[Epoch 0/200] [Batch 265/938] [D loss: 1.499004, acc: 15%] [G loss: 1.500499]\n",
      "[Epoch 0/200] [Batch 266/938] [D loss: 1.491667, acc: 25%] [G loss: 1.499714]\n",
      "[Epoch 0/200] [Batch 267/938] [D loss: 1.491469, acc: 18%] [G loss: 1.505908]\n",
      "[Epoch 0/200] [Batch 268/938] [D loss: 1.488952, acc: 23%] [G loss: 1.511008]\n",
      "[Epoch 0/200] [Batch 269/938] [D loss: 1.486682, acc: 18%] [G loss: 1.507932]\n",
      "[Epoch 0/200] [Batch 270/938] [D loss: 1.484906, acc: 17%] [G loss: 1.518967]\n",
      "[Epoch 0/200] [Batch 271/938] [D loss: 1.481920, acc: 24%] [G loss: 1.512342]\n",
      "[Epoch 0/200] [Batch 272/938] [D loss: 1.475862, acc: 18%] [G loss: 1.514239]\n",
      "[Epoch 0/200] [Batch 273/938] [D loss: 1.476845, acc: 21%] [G loss: 1.503224]\n",
      "[Epoch 0/200] [Batch 274/938] [D loss: 1.472358, acc: 22%] [G loss: 1.491552]\n",
      "[Epoch 0/200] [Batch 275/938] [D loss: 1.472635, acc: 19%] [G loss: 1.484198]\n",
      "[Epoch 0/200] [Batch 276/938] [D loss: 1.482012, acc: 21%] [G loss: 1.460351]\n",
      "[Epoch 0/200] [Batch 277/938] [D loss: 1.487614, acc: 23%] [G loss: 1.422656]\n",
      "[Epoch 0/200] [Batch 278/938] [D loss: 1.500401, acc: 21%] [G loss: 1.430920]\n",
      "[Epoch 0/200] [Batch 279/938] [D loss: 1.491171, acc: 14%] [G loss: 1.433941]\n",
      "[Epoch 0/200] [Batch 280/938] [D loss: 1.493403, acc: 17%] [G loss: 1.452462]\n",
      "[Epoch 0/200] [Batch 281/938] [D loss: 1.496455, acc: 17%] [G loss: 1.461719]\n",
      "[Epoch 0/200] [Batch 282/938] [D loss: 1.490188, acc: 25%] [G loss: 1.473487]\n",
      "[Epoch 0/200] [Batch 283/938] [D loss: 1.485328, acc: 25%] [G loss: 1.474880]\n",
      "[Epoch 0/200] [Batch 284/938] [D loss: 1.473302, acc: 25%] [G loss: 1.505500]\n",
      "[Epoch 0/200] [Batch 285/938] [D loss: 1.476388, acc: 24%] [G loss: 1.503490]\n",
      "[Epoch 0/200] [Batch 286/938] [D loss: 1.478003, acc: 28%] [G loss: 1.520006]\n",
      "[Epoch 0/200] [Batch 287/938] [D loss: 1.459246, acc: 21%] [G loss: 1.519556]\n",
      "[Epoch 0/200] [Batch 288/938] [D loss: 1.467085, acc: 22%] [G loss: 1.517423]\n",
      "[Epoch 0/200] [Batch 289/938] [D loss: 1.453398, acc: 24%] [G loss: 1.528990]\n",
      "[Epoch 0/200] [Batch 290/938] [D loss: 1.470137, acc: 22%] [G loss: 1.508343]\n",
      "[Epoch 0/200] [Batch 291/938] [D loss: 1.480512, acc: 22%] [G loss: 1.495860]\n",
      "[Epoch 0/200] [Batch 292/938] [D loss: 1.490141, acc: 27%] [G loss: 1.465087]\n",
      "[Epoch 0/200] [Batch 293/938] [D loss: 1.478428, acc: 25%] [G loss: 1.454298]\n",
      "[Epoch 0/200] [Batch 294/938] [D loss: 1.478112, acc: 28%] [G loss: 1.437041]\n",
      "[Epoch 0/200] [Batch 295/938] [D loss: 1.473607, acc: 27%] [G loss: 1.447288]\n",
      "[Epoch 0/200] [Batch 296/938] [D loss: 1.468042, acc: 19%] [G loss: 1.448477]\n",
      "[Epoch 0/200] [Batch 297/938] [D loss: 1.461613, acc: 28%] [G loss: 1.441327]\n",
      "[Epoch 0/200] [Batch 298/938] [D loss: 1.453635, acc: 28%] [G loss: 1.439008]\n",
      "[Epoch 0/200] [Batch 299/938] [D loss: 1.441064, acc: 27%] [G loss: 1.446761]\n",
      "[Epoch 0/200] [Batch 300/938] [D loss: 1.447954, acc: 27%] [G loss: 1.483387]\n",
      "[Epoch 0/200] [Batch 301/938] [D loss: 1.454959, acc: 22%] [G loss: 1.498889]\n",
      "[Epoch 0/200] [Batch 302/938] [D loss: 1.415172, acc: 31%] [G loss: 1.524062]\n",
      "[Epoch 0/200] [Batch 303/938] [D loss: 1.453648, acc: 27%] [G loss: 1.510162]\n",
      "[Epoch 0/200] [Batch 304/938] [D loss: 1.456046, acc: 32%] [G loss: 1.508766]\n",
      "[Epoch 0/200] [Batch 305/938] [D loss: 1.443735, acc: 24%] [G loss: 1.509148]\n",
      "[Epoch 0/200] [Batch 306/938] [D loss: 1.449420, acc: 29%] [G loss: 1.500514]\n",
      "[Epoch 0/200] [Batch 307/938] [D loss: 1.442060, acc: 35%] [G loss: 1.480914]\n",
      "[Epoch 0/200] [Batch 308/938] [D loss: 1.444126, acc: 28%] [G loss: 1.480725]\n",
      "[Epoch 0/200] [Batch 309/938] [D loss: 1.414735, acc: 35%] [G loss: 1.437320]\n",
      "[Epoch 0/200] [Batch 310/938] [D loss: 1.424422, acc: 30%] [G loss: 1.441135]\n",
      "[Epoch 0/200] [Batch 311/938] [D loss: 1.414629, acc: 32%] [G loss: 1.446527]\n",
      "[Epoch 0/200] [Batch 312/938] [D loss: 1.416590, acc: 32%] [G loss: 1.404691]\n",
      "[Epoch 0/200] [Batch 313/938] [D loss: 1.431456, acc: 41%] [G loss: 1.403445]\n",
      "[Epoch 0/200] [Batch 314/938] [D loss: 1.432101, acc: 35%] [G loss: 1.407961]\n",
      "[Epoch 0/200] [Batch 315/938] [D loss: 1.428853, acc: 36%] [G loss: 1.452908]\n",
      "[Epoch 0/200] [Batch 316/938] [D loss: 1.448865, acc: 33%] [G loss: 1.463357]\n",
      "[Epoch 0/200] [Batch 317/938] [D loss: 1.444863, acc: 32%] [G loss: 1.444948]\n",
      "[Epoch 0/200] [Batch 318/938] [D loss: 1.430300, acc: 35%] [G loss: 1.476557]\n",
      "[Epoch 0/200] [Batch 319/938] [D loss: 1.404130, acc: 39%] [G loss: 1.472991]\n",
      "[Epoch 0/200] [Batch 320/938] [D loss: 1.429723, acc: 32%] [G loss: 1.466768]\n",
      "[Epoch 0/200] [Batch 321/938] [D loss: 1.411554, acc: 33%] [G loss: 1.493181]\n",
      "[Epoch 0/200] [Batch 322/938] [D loss: 1.396349, acc: 35%] [G loss: 1.459845]\n",
      "[Epoch 0/200] [Batch 323/938] [D loss: 1.412153, acc: 32%] [G loss: 1.478754]\n",
      "[Epoch 0/200] [Batch 324/938] [D loss: 1.397841, acc: 42%] [G loss: 1.503781]\n",
      "[Epoch 0/200] [Batch 325/938] [D loss: 1.389606, acc: 35%] [G loss: 1.504940]\n",
      "[Epoch 0/200] [Batch 326/938] [D loss: 1.403149, acc: 32%] [G loss: 1.532757]\n",
      "[Epoch 0/200] [Batch 327/938] [D loss: 1.411312, acc: 35%] [G loss: 1.512368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 328/938] [D loss: 1.409642, acc: 40%] [G loss: 1.519229]\n",
      "[Epoch 0/200] [Batch 329/938] [D loss: 1.403790, acc: 32%] [G loss: 1.505138]\n",
      "[Epoch 0/200] [Batch 330/938] [D loss: 1.402722, acc: 42%] [G loss: 1.491199]\n",
      "[Epoch 0/200] [Batch 331/938] [D loss: 1.411333, acc: 37%] [G loss: 1.465479]\n",
      "[Epoch 0/200] [Batch 332/938] [D loss: 1.405832, acc: 38%] [G loss: 1.479071]\n",
      "[Epoch 0/200] [Batch 333/938] [D loss: 1.417900, acc: 30%] [G loss: 1.466012]\n",
      "[Epoch 0/200] [Batch 334/938] [D loss: 1.398239, acc: 37%] [G loss: 1.445237]\n",
      "[Epoch 0/200] [Batch 335/938] [D loss: 1.364596, acc: 44%] [G loss: 1.434312]\n",
      "[Epoch 0/200] [Batch 336/938] [D loss: 1.382176, acc: 40%] [G loss: 1.421601]\n",
      "[Epoch 0/200] [Batch 337/938] [D loss: 1.362144, acc: 41%] [G loss: 1.437453]\n",
      "[Epoch 0/200] [Batch 338/938] [D loss: 1.359351, acc: 45%] [G loss: 1.422779]\n",
      "[Epoch 0/200] [Batch 339/938] [D loss: 1.369110, acc: 39%] [G loss: 1.452441]\n",
      "[Epoch 0/200] [Batch 340/938] [D loss: 1.353384, acc: 39%] [G loss: 1.428556]\n",
      "[Epoch 0/200] [Batch 341/938] [D loss: 1.347632, acc: 45%] [G loss: 1.447714]\n",
      "[Epoch 0/200] [Batch 342/938] [D loss: 1.356928, acc: 40%] [G loss: 1.468803]\n",
      "[Epoch 0/200] [Batch 343/938] [D loss: 1.360963, acc: 41%] [G loss: 1.457009]\n",
      "[Epoch 0/200] [Batch 344/938] [D loss: 1.379626, acc: 40%] [G loss: 1.482074]\n",
      "[Epoch 0/200] [Batch 345/938] [D loss: 1.402976, acc: 39%] [G loss: 1.483228]\n",
      "[Epoch 0/200] [Batch 346/938] [D loss: 1.385184, acc: 46%] [G loss: 1.415433]\n",
      "[Epoch 0/200] [Batch 347/938] [D loss: 1.370092, acc: 47%] [G loss: 1.420346]\n",
      "[Epoch 0/200] [Batch 348/938] [D loss: 1.400144, acc: 38%] [G loss: 1.422129]\n",
      "[Epoch 0/200] [Batch 349/938] [D loss: 1.404868, acc: 38%] [G loss: 1.420158]\n",
      "[Epoch 0/200] [Batch 350/938] [D loss: 1.379122, acc: 42%] [G loss: 1.417336]\n",
      "[Epoch 0/200] [Batch 351/938] [D loss: 1.378675, acc: 42%] [G loss: 1.454982]\n",
      "[Epoch 0/200] [Batch 352/938] [D loss: 1.381017, acc: 39%] [G loss: 1.445618]\n",
      "[Epoch 0/200] [Batch 353/938] [D loss: 1.344996, acc: 47%] [G loss: 1.465698]\n",
      "[Epoch 0/200] [Batch 354/938] [D loss: 1.367899, acc: 42%] [G loss: 1.475145]\n",
      "[Epoch 0/200] [Batch 355/938] [D loss: 1.358781, acc: 43%] [G loss: 1.512499]\n",
      "[Epoch 0/200] [Batch 356/938] [D loss: 1.381817, acc: 38%] [G loss: 1.527665]\n",
      "[Epoch 0/200] [Batch 357/938] [D loss: 1.370418, acc: 39%] [G loss: 1.517539]\n",
      "[Epoch 0/200] [Batch 358/938] [D loss: 1.362973, acc: 40%] [G loss: 1.485243]\n",
      "[Epoch 0/200] [Batch 359/938] [D loss: 1.357907, acc: 47%] [G loss: 1.496820]\n",
      "[Epoch 0/200] [Batch 360/938] [D loss: 1.380474, acc: 47%] [G loss: 1.477450]\n",
      "[Epoch 0/200] [Batch 361/938] [D loss: 1.374708, acc: 42%] [G loss: 1.483649]\n",
      "[Epoch 0/200] [Batch 362/938] [D loss: 1.373864, acc: 50%] [G loss: 1.423656]\n",
      "[Epoch 0/200] [Batch 363/938] [D loss: 1.363121, acc: 44%] [G loss: 1.446330]\n",
      "[Epoch 0/200] [Batch 364/938] [D loss: 1.347527, acc: 48%] [G loss: 1.434711]\n",
      "[Epoch 0/200] [Batch 365/938] [D loss: 1.324512, acc: 51%] [G loss: 1.427953]\n",
      "[Epoch 0/200] [Batch 366/938] [D loss: 1.369381, acc: 40%] [G loss: 1.468079]\n",
      "[Epoch 0/200] [Batch 367/938] [D loss: 1.344335, acc: 49%] [G loss: 1.438745]\n",
      "[Epoch 0/200] [Batch 368/938] [D loss: 1.350483, acc: 45%] [G loss: 1.430387]\n",
      "[Epoch 0/200] [Batch 369/938] [D loss: 1.340304, acc: 47%] [G loss: 1.421447]\n",
      "[Epoch 0/200] [Batch 370/938] [D loss: 1.328156, acc: 51%] [G loss: 1.392369]\n",
      "[Epoch 0/200] [Batch 371/938] [D loss: 1.372206, acc: 39%] [G loss: 1.463481]\n",
      "[Epoch 0/200] [Batch 372/938] [D loss: 1.340279, acc: 48%] [G loss: 1.469645]\n",
      "[Epoch 0/200] [Batch 373/938] [D loss: 1.340966, acc: 50%] [G loss: 1.402098]\n",
      "[Epoch 0/200] [Batch 374/938] [D loss: 1.360291, acc: 41%] [G loss: 1.503115]\n",
      "[Epoch 0/200] [Batch 375/938] [D loss: 1.357313, acc: 46%] [G loss: 1.437874]\n",
      "[Epoch 0/200] [Batch 376/938] [D loss: 1.353771, acc: 44%] [G loss: 1.442615]\n",
      "[Epoch 0/200] [Batch 377/938] [D loss: 1.348004, acc: 50%] [G loss: 1.461421]\n",
      "[Epoch 0/200] [Batch 378/938] [D loss: 1.339630, acc: 49%] [G loss: 1.457020]\n",
      "[Epoch 0/200] [Batch 379/938] [D loss: 1.363986, acc: 42%] [G loss: 1.474860]\n",
      "[Epoch 0/200] [Batch 380/938] [D loss: 1.326312, acc: 53%] [G loss: 1.407493]\n",
      "[Epoch 0/200] [Batch 381/938] [D loss: 1.344494, acc: 44%] [G loss: 1.431083]\n",
      "[Epoch 0/200] [Batch 382/938] [D loss: 1.336240, acc: 46%] [G loss: 1.434016]\n",
      "[Epoch 0/200] [Batch 383/938] [D loss: 1.335766, acc: 49%] [G loss: 1.477340]\n",
      "[Epoch 0/200] [Batch 384/938] [D loss: 1.374509, acc: 42%] [G loss: 1.468375]\n",
      "[Epoch 0/200] [Batch 385/938] [D loss: 1.353875, acc: 46%] [G loss: 1.449401]\n",
      "[Epoch 0/200] [Batch 386/938] [D loss: 1.364295, acc: 46%] [G loss: 1.451873]\n",
      "[Epoch 0/200] [Batch 387/938] [D loss: 1.340980, acc: 46%] [G loss: 1.496938]\n",
      "[Epoch 0/200] [Batch 388/938] [D loss: 1.330554, acc: 50%] [G loss: 1.490998]\n",
      "[Epoch 0/200] [Batch 389/938] [D loss: 1.354273, acc: 48%] [G loss: 1.501620]\n",
      "[Epoch 0/200] [Batch 390/938] [D loss: 1.335250, acc: 46%] [G loss: 1.484792]\n",
      "[Epoch 0/200] [Batch 391/938] [D loss: 1.321187, acc: 53%] [G loss: 1.461464]\n",
      "[Epoch 0/200] [Batch 392/938] [D loss: 1.318986, acc: 52%] [G loss: 1.413983]\n",
      "[Epoch 0/200] [Batch 393/938] [D loss: 1.313202, acc: 55%] [G loss: 1.443611]\n",
      "[Epoch 0/200] [Batch 394/938] [D loss: 1.318194, acc: 53%] [G loss: 1.411922]\n",
      "[Epoch 0/200] [Batch 395/938] [D loss: 1.303102, acc: 58%] [G loss: 1.434673]\n",
      "[Epoch 0/200] [Batch 396/938] [D loss: 1.341638, acc: 45%] [G loss: 1.424543]\n",
      "[Epoch 0/200] [Batch 397/938] [D loss: 1.309940, acc: 52%] [G loss: 1.394995]\n",
      "[Epoch 0/200] [Batch 398/938] [D loss: 1.323469, acc: 52%] [G loss: 1.387103]\n",
      "[Epoch 0/200] [Batch 399/938] [D loss: 1.314246, acc: 54%] [G loss: 1.357919]\n",
      "[Epoch 0/200] [Batch 400/938] [D loss: 1.295958, acc: 57%] [G loss: 1.374906]\n",
      "[Epoch 0/200] [Batch 401/938] [D loss: 1.331837, acc: 47%] [G loss: 1.389401]\n",
      "[Epoch 0/200] [Batch 402/938] [D loss: 1.321723, acc: 50%] [G loss: 1.410595]\n",
      "[Epoch 0/200] [Batch 403/938] [D loss: 1.329538, acc: 51%] [G loss: 1.412812]\n",
      "[Epoch 0/200] [Batch 404/938] [D loss: 1.338294, acc: 51%] [G loss: 1.431726]\n",
      "[Epoch 0/200] [Batch 405/938] [D loss: 1.328329, acc: 50%] [G loss: 1.470091]\n",
      "[Epoch 0/200] [Batch 406/938] [D loss: 1.341219, acc: 48%] [G loss: 1.464456]\n",
      "[Epoch 0/200] [Batch 407/938] [D loss: 1.313216, acc: 53%] [G loss: 1.434336]\n",
      "[Epoch 0/200] [Batch 408/938] [D loss: 1.314057, acc: 52%] [G loss: 1.417498]\n",
      "[Epoch 0/200] [Batch 409/938] [D loss: 1.321341, acc: 51%] [G loss: 1.425579]\n",
      "[Epoch 0/200] [Batch 410/938] [D loss: 1.337793, acc: 49%] [G loss: 1.441061]\n",
      "[Epoch 0/200] [Batch 411/938] [D loss: 1.330836, acc: 49%] [G loss: 1.402063]\n",
      "[Epoch 0/200] [Batch 412/938] [D loss: 1.303488, acc: 55%] [G loss: 1.413073]\n",
      "[Epoch 0/200] [Batch 413/938] [D loss: 1.325356, acc: 46%] [G loss: 1.451766]\n",
      "[Epoch 0/200] [Batch 414/938] [D loss: 1.326727, acc: 52%] [G loss: 1.460842]\n",
      "[Epoch 0/200] [Batch 415/938] [D loss: 1.310688, acc: 57%] [G loss: 1.397536]\n",
      "[Epoch 0/200] [Batch 416/938] [D loss: 1.339996, acc: 50%] [G loss: 1.462218]\n",
      "[Epoch 0/200] [Batch 417/938] [D loss: 1.317917, acc: 53%] [G loss: 1.428632]\n",
      "[Epoch 0/200] [Batch 418/938] [D loss: 1.315477, acc: 57%] [G loss: 1.420636]\n",
      "[Epoch 0/200] [Batch 419/938] [D loss: 1.320895, acc: 53%] [G loss: 1.406378]\n",
      "[Epoch 0/200] [Batch 420/938] [D loss: 1.319278, acc: 49%] [G loss: 1.432382]\n",
      "[Epoch 0/200] [Batch 421/938] [D loss: 1.314749, acc: 52%] [G loss: 1.413744]\n",
      "[Epoch 0/200] [Batch 422/938] [D loss: 1.310163, acc: 53%] [G loss: 1.437944]\n",
      "[Epoch 0/200] [Batch 423/938] [D loss: 1.322262, acc: 53%] [G loss: 1.408223]\n",
      "[Epoch 0/200] [Batch 424/938] [D loss: 1.315461, acc: 55%] [G loss: 1.436774]\n",
      "[Epoch 0/200] [Batch 425/938] [D loss: 1.275018, acc: 62%] [G loss: 1.362185]\n",
      "[Epoch 0/200] [Batch 426/938] [D loss: 1.357512, acc: 46%] [G loss: 1.430439]\n",
      "[Epoch 0/200] [Batch 427/938] [D loss: 1.317841, acc: 50%] [G loss: 1.397852]\n",
      "[Epoch 0/200] [Batch 428/938] [D loss: 1.293325, acc: 55%] [G loss: 1.382217]\n",
      "[Epoch 0/200] [Batch 429/938] [D loss: 1.310350, acc: 52%] [G loss: 1.436161]\n",
      "[Epoch 0/200] [Batch 430/938] [D loss: 1.329593, acc: 50%] [G loss: 1.449213]\n",
      "[Epoch 0/200] [Batch 431/938] [D loss: 1.303337, acc: 57%] [G loss: 1.376567]\n",
      "[Epoch 0/200] [Batch 432/938] [D loss: 1.314733, acc: 53%] [G loss: 1.442476]\n",
      "[Epoch 0/200] [Batch 433/938] [D loss: 1.314632, acc: 55%] [G loss: 1.382875]\n",
      "[Epoch 0/200] [Batch 434/938] [D loss: 1.319057, acc: 54%] [G loss: 1.441744]\n",
      "[Epoch 0/200] [Batch 435/938] [D loss: 1.270198, acc: 57%] [G loss: 1.392479]\n",
      "[Epoch 0/200] [Batch 436/938] [D loss: 1.286847, acc: 60%] [G loss: 1.383088]\n",
      "[Epoch 0/200] [Batch 437/938] [D loss: 1.305282, acc: 52%] [G loss: 1.427103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 438/938] [D loss: 1.320638, acc: 52%] [G loss: 1.411770]\n",
      "[Epoch 0/200] [Batch 439/938] [D loss: 1.312742, acc: 55%] [G loss: 1.443708]\n",
      "[Epoch 0/200] [Batch 440/938] [D loss: 1.308216, acc: 57%] [G loss: 1.382076]\n",
      "[Epoch 0/200] [Batch 441/938] [D loss: 1.310164, acc: 53%] [G loss: 1.402252]\n",
      "[Epoch 0/200] [Batch 442/938] [D loss: 1.319458, acc: 53%] [G loss: 1.392408]\n",
      "[Epoch 0/200] [Batch 443/938] [D loss: 1.323328, acc: 53%] [G loss: 1.428720]\n",
      "[Epoch 0/200] [Batch 444/938] [D loss: 1.280651, acc: 60%] [G loss: 1.369097]\n",
      "[Epoch 0/200] [Batch 445/938] [D loss: 1.314538, acc: 50%] [G loss: 1.409153]\n",
      "[Epoch 0/200] [Batch 446/938] [D loss: 1.294941, acc: 55%] [G loss: 1.395123]\n",
      "[Epoch 0/200] [Batch 447/938] [D loss: 1.283681, acc: 62%] [G loss: 1.350698]\n",
      "[Epoch 0/200] [Batch 448/938] [D loss: 1.292718, acc: 57%] [G loss: 1.426707]\n",
      "[Epoch 0/200] [Batch 449/938] [D loss: 1.299609, acc: 54%] [G loss: 1.403779]\n",
      "[Epoch 0/200] [Batch 450/938] [D loss: 1.350353, acc: 48%] [G loss: 1.412359]\n",
      "[Epoch 0/200] [Batch 451/938] [D loss: 1.284617, acc: 57%] [G loss: 1.372804]\n",
      "[Epoch 0/200] [Batch 452/938] [D loss: 1.283688, acc: 58%] [G loss: 1.410783]\n",
      "[Epoch 0/200] [Batch 453/938] [D loss: 1.274422, acc: 60%] [G loss: 1.403780]\n",
      "[Epoch 0/200] [Batch 454/938] [D loss: 1.282620, acc: 67%] [G loss: 1.400601]\n",
      "[Epoch 0/200] [Batch 455/938] [D loss: 1.311104, acc: 53%] [G loss: 1.442454]\n",
      "[Epoch 0/200] [Batch 456/938] [D loss: 1.292220, acc: 59%] [G loss: 1.374713]\n",
      "[Epoch 0/200] [Batch 457/938] [D loss: 1.323469, acc: 53%] [G loss: 1.406467]\n",
      "[Epoch 0/200] [Batch 458/938] [D loss: 1.273948, acc: 61%] [G loss: 1.375036]\n",
      "[Epoch 0/200] [Batch 459/938] [D loss: 1.280876, acc: 61%] [G loss: 1.398123]\n",
      "[Epoch 0/200] [Batch 460/938] [D loss: 1.298069, acc: 61%] [G loss: 1.404214]\n",
      "[Epoch 0/200] [Batch 461/938] [D loss: 1.289003, acc: 54%] [G loss: 1.448064]\n",
      "[Epoch 0/200] [Batch 462/938] [D loss: 1.310763, acc: 54%] [G loss: 1.393235]\n",
      "[Epoch 0/200] [Batch 463/938] [D loss: 1.283346, acc: 61%] [G loss: 1.417079]\n",
      "[Epoch 0/200] [Batch 464/938] [D loss: 1.273456, acc: 60%] [G loss: 1.401214]\n",
      "[Epoch 0/200] [Batch 465/938] [D loss: 1.272840, acc: 60%] [G loss: 1.379342]\n",
      "[Epoch 0/200] [Batch 466/938] [D loss: 1.330568, acc: 50%] [G loss: 1.430118]\n",
      "[Epoch 0/200] [Batch 467/938] [D loss: 1.300172, acc: 56%] [G loss: 1.337197]\n",
      "[Epoch 0/200] [Batch 468/938] [D loss: 1.304577, acc: 55%] [G loss: 1.402206]\n",
      "[Epoch 0/200] [Batch 469/938] [D loss: 1.251887, acc: 65%] [G loss: 1.368909]\n",
      "[Epoch 0/200] [Batch 470/938] [D loss: 1.267122, acc: 60%] [G loss: 1.377780]\n",
      "[Epoch 0/200] [Batch 471/938] [D loss: 1.282709, acc: 61%] [G loss: 1.367588]\n",
      "[Epoch 0/200] [Batch 472/938] [D loss: 1.305085, acc: 60%] [G loss: 1.364457]\n",
      "[Epoch 0/200] [Batch 473/938] [D loss: 1.281595, acc: 63%] [G loss: 1.350905]\n",
      "[Epoch 0/200] [Batch 474/938] [D loss: 1.276469, acc: 60%] [G loss: 1.370701]\n",
      "[Epoch 0/200] [Batch 475/938] [D loss: 1.250839, acc: 67%] [G loss: 1.364644]\n",
      "[Epoch 0/200] [Batch 476/938] [D loss: 1.294793, acc: 57%] [G loss: 1.443297]\n",
      "[Epoch 0/200] [Batch 477/938] [D loss: 1.257234, acc: 62%] [G loss: 1.381736]\n",
      "[Epoch 0/200] [Batch 478/938] [D loss: 1.254109, acc: 64%] [G loss: 1.331914]\n",
      "[Epoch 0/200] [Batch 479/938] [D loss: 1.279480, acc: 61%] [G loss: 1.291292]\n",
      "[Epoch 0/200] [Batch 480/938] [D loss: 1.255090, acc: 66%] [G loss: 1.327329]\n",
      "[Epoch 0/200] [Batch 481/938] [D loss: 1.253335, acc: 62%] [G loss: 1.341139]\n",
      "[Epoch 0/200] [Batch 482/938] [D loss: 1.244524, acc: 62%] [G loss: 1.346318]\n",
      "[Epoch 0/200] [Batch 483/938] [D loss: 1.264220, acc: 61%] [G loss: 1.375754]\n",
      "[Epoch 0/200] [Batch 484/938] [D loss: 1.261347, acc: 64%] [G loss: 1.365650]\n",
      "[Epoch 0/200] [Batch 485/938] [D loss: 1.240287, acc: 68%] [G loss: 1.314622]\n",
      "[Epoch 0/200] [Batch 486/938] [D loss: 1.261922, acc: 59%] [G loss: 1.345830]\n",
      "[Epoch 0/200] [Batch 487/938] [D loss: 1.249221, acc: 60%] [G loss: 1.351886]\n",
      "[Epoch 0/200] [Batch 488/938] [D loss: 1.254113, acc: 64%] [G loss: 1.367917]\n",
      "[Epoch 0/200] [Batch 489/938] [D loss: 1.265853, acc: 59%] [G loss: 1.360378]\n",
      "[Epoch 0/200] [Batch 490/938] [D loss: 1.258995, acc: 69%] [G loss: 1.310971]\n",
      "[Epoch 0/200] [Batch 491/938] [D loss: 1.254960, acc: 65%] [G loss: 1.352730]\n",
      "[Epoch 0/200] [Batch 492/938] [D loss: 1.271049, acc: 60%] [G loss: 1.364165]\n",
      "[Epoch 0/200] [Batch 493/938] [D loss: 1.290423, acc: 59%] [G loss: 1.421122]\n",
      "[Epoch 0/200] [Batch 494/938] [D loss: 1.265696, acc: 61%] [G loss: 1.425975]\n",
      "[Epoch 0/200] [Batch 495/938] [D loss: 1.264458, acc: 60%] [G loss: 1.384622]\n",
      "[Epoch 0/200] [Batch 496/938] [D loss: 1.237141, acc: 65%] [G loss: 1.336075]\n",
      "[Epoch 0/200] [Batch 497/938] [D loss: 1.247674, acc: 65%] [G loss: 1.363292]\n",
      "[Epoch 0/200] [Batch 498/938] [D loss: 1.238704, acc: 67%] [G loss: 1.347100]\n",
      "[Epoch 0/200] [Batch 499/938] [D loss: 1.255662, acc: 62%] [G loss: 1.367523]\n",
      "[Epoch 0/200] [Batch 500/938] [D loss: 1.227241, acc: 66%] [G loss: 1.402331]\n",
      "[Epoch 0/200] [Batch 501/938] [D loss: 1.197285, acc: 78%] [G loss: 1.298882]\n",
      "[Epoch 0/200] [Batch 502/938] [D loss: 1.238405, acc: 65%] [G loss: 1.334110]\n",
      "[Epoch 0/200] [Batch 503/938] [D loss: 1.260751, acc: 61%] [G loss: 1.386341]\n",
      "[Epoch 0/200] [Batch 504/938] [D loss: 1.255438, acc: 61%] [G loss: 1.401820]\n",
      "[Epoch 0/200] [Batch 505/938] [D loss: 1.245811, acc: 64%] [G loss: 1.360331]\n",
      "[Epoch 0/200] [Batch 506/938] [D loss: 1.246296, acc: 67%] [G loss: 1.318294]\n",
      "[Epoch 0/200] [Batch 507/938] [D loss: 1.237965, acc: 67%] [G loss: 1.339873]\n",
      "[Epoch 0/200] [Batch 508/938] [D loss: 1.248949, acc: 61%] [G loss: 1.350090]\n",
      "[Epoch 0/200] [Batch 509/938] [D loss: 1.215758, acc: 73%] [G loss: 1.311822]\n",
      "[Epoch 0/200] [Batch 510/938] [D loss: 1.222180, acc: 69%] [G loss: 1.343685]\n",
      "[Epoch 0/200] [Batch 511/938] [D loss: 1.196654, acc: 77%] [G loss: 1.291243]\n",
      "[Epoch 0/200] [Batch 512/938] [D loss: 1.240116, acc: 65%] [G loss: 1.335319]\n",
      "[Epoch 0/200] [Batch 513/938] [D loss: 1.233443, acc: 66%] [G loss: 1.340783]\n",
      "[Epoch 0/200] [Batch 514/938] [D loss: 1.220555, acc: 70%] [G loss: 1.311624]\n",
      "[Epoch 0/200] [Batch 515/938] [D loss: 1.249431, acc: 70%] [G loss: 1.321880]\n",
      "[Epoch 0/200] [Batch 516/938] [D loss: 1.238367, acc: 68%] [G loss: 1.325362]\n",
      "[Epoch 0/200] [Batch 517/938] [D loss: 1.211164, acc: 67%] [G loss: 1.348544]\n",
      "[Epoch 0/200] [Batch 518/938] [D loss: 1.227135, acc: 69%] [G loss: 1.362940]\n",
      "[Epoch 0/200] [Batch 519/938] [D loss: 1.220695, acc: 68%] [G loss: 1.324615]\n",
      "[Epoch 0/200] [Batch 520/938] [D loss: 1.218633, acc: 71%] [G loss: 1.324354]\n",
      "[Epoch 0/200] [Batch 521/938] [D loss: 1.246073, acc: 63%] [G loss: 1.334640]\n",
      "[Epoch 0/200] [Batch 522/938] [D loss: 1.225039, acc: 71%] [G loss: 1.294636]\n",
      "[Epoch 0/200] [Batch 523/938] [D loss: 1.246918, acc: 67%] [G loss: 1.360147]\n",
      "[Epoch 0/200] [Batch 524/938] [D loss: 1.248636, acc: 64%] [G loss: 1.338374]\n",
      "[Epoch 0/200] [Batch 525/938] [D loss: 1.232369, acc: 70%] [G loss: 1.289076]\n",
      "[Epoch 0/200] [Batch 526/938] [D loss: 1.247212, acc: 63%] [G loss: 1.342909]\n",
      "[Epoch 0/200] [Batch 527/938] [D loss: 1.189088, acc: 76%] [G loss: 1.311050]\n",
      "[Epoch 0/200] [Batch 528/938] [D loss: 1.222140, acc: 69%] [G loss: 1.371849]\n",
      "[Epoch 0/200] [Batch 529/938] [D loss: 1.229288, acc: 69%] [G loss: 1.309380]\n",
      "[Epoch 0/200] [Batch 530/938] [D loss: 1.176566, acc: 77%] [G loss: 1.258823]\n",
      "[Epoch 0/200] [Batch 531/938] [D loss: 1.239616, acc: 64%] [G loss: 1.373240]\n",
      "[Epoch 0/200] [Batch 532/938] [D loss: 1.211314, acc: 72%] [G loss: 1.309956]\n",
      "[Epoch 0/200] [Batch 533/938] [D loss: 1.238852, acc: 66%] [G loss: 1.341109]\n",
      "[Epoch 0/200] [Batch 534/938] [D loss: 1.212033, acc: 71%] [G loss: 1.332496]\n",
      "[Epoch 0/200] [Batch 535/938] [D loss: 1.225914, acc: 71%] [G loss: 1.356344]\n",
      "[Epoch 0/200] [Batch 536/938] [D loss: 1.198549, acc: 68%] [G loss: 1.296875]\n",
      "[Epoch 0/200] [Batch 537/938] [D loss: 1.198994, acc: 73%] [G loss: 1.288119]\n",
      "[Epoch 0/200] [Batch 538/938] [D loss: 1.208350, acc: 72%] [G loss: 1.339362]\n",
      "[Epoch 0/200] [Batch 539/938] [D loss: 1.235668, acc: 64%] [G loss: 1.353464]\n",
      "[Epoch 0/200] [Batch 540/938] [D loss: 1.215910, acc: 67%] [G loss: 1.327731]\n",
      "[Epoch 0/200] [Batch 541/938] [D loss: 1.211097, acc: 72%] [G loss: 1.298661]\n",
      "[Epoch 0/200] [Batch 542/938] [D loss: 1.208194, acc: 71%] [G loss: 1.328785]\n",
      "[Epoch 0/200] [Batch 543/938] [D loss: 1.211508, acc: 71%] [G loss: 1.308745]\n",
      "[Epoch 0/200] [Batch 544/938] [D loss: 1.219953, acc: 68%] [G loss: 1.329521]\n",
      "[Epoch 0/200] [Batch 545/938] [D loss: 1.210152, acc: 71%] [G loss: 1.316206]\n",
      "[Epoch 0/200] [Batch 546/938] [D loss: 1.240598, acc: 64%] [G loss: 1.334127]\n",
      "[Epoch 0/200] [Batch 547/938] [D loss: 1.220437, acc: 69%] [G loss: 1.333499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 548/938] [D loss: 1.220129, acc: 71%] [G loss: 1.324256]\n",
      "[Epoch 0/200] [Batch 549/938] [D loss: 1.203725, acc: 72%] [G loss: 1.325092]\n",
      "[Epoch 0/200] [Batch 550/938] [D loss: 1.174666, acc: 78%] [G loss: 1.296050]\n",
      "[Epoch 0/200] [Batch 551/938] [D loss: 1.202023, acc: 75%] [G loss: 1.289108]\n",
      "[Epoch 0/200] [Batch 552/938] [D loss: 1.211989, acc: 71%] [G loss: 1.324744]\n",
      "[Epoch 0/200] [Batch 553/938] [D loss: 1.216978, acc: 71%] [G loss: 1.308737]\n",
      "[Epoch 0/200] [Batch 554/938] [D loss: 1.188698, acc: 75%] [G loss: 1.245867]\n",
      "[Epoch 0/200] [Batch 555/938] [D loss: 1.202302, acc: 75%] [G loss: 1.280064]\n",
      "[Epoch 0/200] [Batch 556/938] [D loss: 1.193927, acc: 75%] [G loss: 1.290085]\n",
      "[Epoch 0/200] [Batch 557/938] [D loss: 1.167601, acc: 77%] [G loss: 1.261519]\n",
      "[Epoch 0/200] [Batch 558/938] [D loss: 1.186581, acc: 81%] [G loss: 1.311727]\n",
      "[Epoch 0/200] [Batch 559/938] [D loss: 1.214119, acc: 71%] [G loss: 1.307144]\n",
      "[Epoch 0/200] [Batch 560/938] [D loss: 1.216901, acc: 71%] [G loss: 1.322167]\n",
      "[Epoch 0/200] [Batch 561/938] [D loss: 1.225714, acc: 67%] [G loss: 1.298350]\n",
      "[Epoch 0/200] [Batch 562/938] [D loss: 1.214115, acc: 67%] [G loss: 1.350618]\n",
      "[Epoch 0/200] [Batch 563/938] [D loss: 1.175818, acc: 75%] [G loss: 1.284106]\n",
      "[Epoch 0/200] [Batch 564/938] [D loss: 1.184344, acc: 72%] [G loss: 1.326793]\n",
      "[Epoch 0/200] [Batch 565/938] [D loss: 1.192465, acc: 72%] [G loss: 1.324758]\n",
      "[Epoch 0/200] [Batch 566/938] [D loss: 1.183155, acc: 75%] [G loss: 1.342216]\n",
      "[Epoch 0/200] [Batch 567/938] [D loss: 1.195125, acc: 71%] [G loss: 1.293011]\n",
      "[Epoch 0/200] [Batch 568/938] [D loss: 1.167372, acc: 79%] [G loss: 1.268635]\n",
      "[Epoch 0/200] [Batch 569/938] [D loss: 1.191880, acc: 70%] [G loss: 1.295732]\n",
      "[Epoch 0/200] [Batch 570/938] [D loss: 1.221361, acc: 67%] [G loss: 1.327430]\n",
      "[Epoch 0/200] [Batch 571/938] [D loss: 1.198390, acc: 71%] [G loss: 1.324566]\n",
      "[Epoch 0/200] [Batch 572/938] [D loss: 1.201210, acc: 69%] [G loss: 1.322783]\n",
      "[Epoch 0/200] [Batch 573/938] [D loss: 1.167558, acc: 78%] [G loss: 1.249181]\n",
      "[Epoch 0/200] [Batch 574/938] [D loss: 1.186165, acc: 75%] [G loss: 1.267450]\n",
      "[Epoch 0/200] [Batch 575/938] [D loss: 1.166811, acc: 79%] [G loss: 1.299689]\n",
      "[Epoch 0/200] [Batch 576/938] [D loss: 1.187127, acc: 75%] [G loss: 1.296901]\n",
      "[Epoch 0/200] [Batch 577/938] [D loss: 1.171072, acc: 76%] [G loss: 1.324495]\n",
      "[Epoch 0/200] [Batch 578/938] [D loss: 1.181636, acc: 75%] [G loss: 1.296571]\n",
      "[Epoch 0/200] [Batch 579/938] [D loss: 1.190127, acc: 72%] [G loss: 1.315636]\n",
      "[Epoch 0/200] [Batch 580/938] [D loss: 1.156375, acc: 81%] [G loss: 1.258385]\n",
      "[Epoch 0/200] [Batch 581/938] [D loss: 1.224241, acc: 67%] [G loss: 1.337997]\n",
      "[Epoch 0/200] [Batch 582/938] [D loss: 1.164996, acc: 78%] [G loss: 1.295746]\n",
      "[Epoch 0/200] [Batch 583/938] [D loss: 1.161425, acc: 79%] [G loss: 1.255385]\n",
      "[Epoch 0/200] [Batch 584/938] [D loss: 1.171158, acc: 75%] [G loss: 1.259936]\n",
      "[Epoch 0/200] [Batch 585/938] [D loss: 1.175246, acc: 78%] [G loss: 1.232852]\n",
      "[Epoch 0/200] [Batch 586/938] [D loss: 1.176592, acc: 77%] [G loss: 1.330014]\n",
      "[Epoch 0/200] [Batch 587/938] [D loss: 1.192878, acc: 74%] [G loss: 1.303055]\n",
      "[Epoch 0/200] [Batch 588/938] [D loss: 1.174381, acc: 78%] [G loss: 1.297081]\n",
      "[Epoch 0/200] [Batch 589/938] [D loss: 1.195200, acc: 75%] [G loss: 1.335429]\n",
      "[Epoch 0/200] [Batch 590/938] [D loss: 1.222455, acc: 67%] [G loss: 1.366047]\n",
      "[Epoch 0/200] [Batch 591/938] [D loss: 1.179914, acc: 78%] [G loss: 1.280514]\n",
      "[Epoch 0/200] [Batch 592/938] [D loss: 1.149851, acc: 84%] [G loss: 1.244882]\n",
      "[Epoch 0/200] [Batch 593/938] [D loss: 1.171326, acc: 77%] [G loss: 1.271396]\n",
      "[Epoch 0/200] [Batch 594/938] [D loss: 1.191671, acc: 74%] [G loss: 1.271559]\n",
      "[Epoch 0/200] [Batch 595/938] [D loss: 1.170766, acc: 72%] [G loss: 1.293039]\n",
      "[Epoch 0/200] [Batch 596/938] [D loss: 1.194297, acc: 75%] [G loss: 1.220777]\n",
      "[Epoch 0/200] [Batch 597/938] [D loss: 1.178737, acc: 75%] [G loss: 1.274193]\n",
      "[Epoch 0/200] [Batch 598/938] [D loss: 1.207716, acc: 71%] [G loss: 1.254989]\n",
      "[Epoch 0/200] [Batch 599/938] [D loss: 1.191887, acc: 77%] [G loss: 1.266651]\n",
      "[Epoch 0/200] [Batch 600/938] [D loss: 1.171016, acc: 75%] [G loss: 1.294758]\n",
      "[Epoch 0/200] [Batch 601/938] [D loss: 1.160053, acc: 79%] [G loss: 1.301719]\n",
      "[Epoch 0/200] [Batch 602/938] [D loss: 1.172405, acc: 81%] [G loss: 1.272134]\n",
      "[Epoch 0/200] [Batch 603/938] [D loss: 1.198741, acc: 77%] [G loss: 1.234569]\n",
      "[Epoch 0/200] [Batch 604/938] [D loss: 1.156704, acc: 81%] [G loss: 1.302938]\n",
      "[Epoch 0/200] [Batch 605/938] [D loss: 1.173203, acc: 77%] [G loss: 1.279507]\n",
      "[Epoch 0/200] [Batch 606/938] [D loss: 1.154127, acc: 82%] [G loss: 1.284483]\n",
      "[Epoch 0/200] [Batch 607/938] [D loss: 1.185181, acc: 72%] [G loss: 1.350297]\n",
      "[Epoch 0/200] [Batch 608/938] [D loss: 1.158804, acc: 81%] [G loss: 1.220652]\n",
      "[Epoch 0/200] [Batch 609/938] [D loss: 1.156325, acc: 81%] [G loss: 1.258984]\n",
      "[Epoch 0/200] [Batch 610/938] [D loss: 1.172023, acc: 75%] [G loss: 1.258880]\n",
      "[Epoch 0/200] [Batch 611/938] [D loss: 1.180777, acc: 75%] [G loss: 1.259312]\n",
      "[Epoch 0/200] [Batch 612/938] [D loss: 1.173993, acc: 76%] [G loss: 1.274923]\n",
      "[Epoch 0/200] [Batch 613/938] [D loss: 1.149848, acc: 81%] [G loss: 1.266065]\n",
      "[Epoch 0/200] [Batch 614/938] [D loss: 1.144284, acc: 78%] [G loss: 1.229323]\n",
      "[Epoch 0/200] [Batch 615/938] [D loss: 1.190340, acc: 78%] [G loss: 1.210707]\n",
      "[Epoch 0/200] [Batch 616/938] [D loss: 1.123608, acc: 82%] [G loss: 1.288715]\n",
      "[Epoch 0/200] [Batch 617/938] [D loss: 1.138784, acc: 85%] [G loss: 1.220109]\n",
      "[Epoch 0/200] [Batch 618/938] [D loss: 1.167431, acc: 77%] [G loss: 1.306764]\n",
      "[Epoch 0/200] [Batch 619/938] [D loss: 1.145063, acc: 79%] [G loss: 1.282473]\n",
      "[Epoch 0/200] [Batch 620/938] [D loss: 1.200201, acc: 75%] [G loss: 1.330746]\n",
      "[Epoch 0/200] [Batch 621/938] [D loss: 1.189246, acc: 72%] [G loss: 1.304163]\n",
      "[Epoch 0/200] [Batch 622/938] [D loss: 1.152858, acc: 82%] [G loss: 1.269711]\n",
      "[Epoch 0/200] [Batch 623/938] [D loss: 1.156063, acc: 82%] [G loss: 1.288664]\n",
      "[Epoch 0/200] [Batch 624/938] [D loss: 1.171545, acc: 75%] [G loss: 1.295574]\n",
      "[Epoch 0/200] [Batch 625/938] [D loss: 1.163632, acc: 80%] [G loss: 1.263222]\n",
      "[Epoch 0/200] [Batch 626/938] [D loss: 1.163152, acc: 79%] [G loss: 1.264714]\n",
      "[Epoch 0/200] [Batch 627/938] [D loss: 1.166747, acc: 78%] [G loss: 1.254206]\n",
      "[Epoch 0/200] [Batch 628/938] [D loss: 1.142581, acc: 85%] [G loss: 1.243688]\n",
      "[Epoch 0/200] [Batch 629/938] [D loss: 1.192089, acc: 75%] [G loss: 1.282701]\n",
      "[Epoch 0/200] [Batch 630/938] [D loss: 1.158443, acc: 78%] [G loss: 1.290954]\n",
      "[Epoch 0/200] [Batch 631/938] [D loss: 1.182792, acc: 75%] [G loss: 1.329695]\n",
      "[Epoch 0/200] [Batch 632/938] [D loss: 1.142349, acc: 81%] [G loss: 1.261337]\n",
      "[Epoch 0/200] [Batch 633/938] [D loss: 1.156574, acc: 83%] [G loss: 1.233383]\n",
      "[Epoch 0/200] [Batch 634/938] [D loss: 1.147147, acc: 83%] [G loss: 1.233307]\n",
      "[Epoch 0/200] [Batch 635/938] [D loss: 1.183766, acc: 75%] [G loss: 1.228551]\n",
      "[Epoch 0/200] [Batch 636/938] [D loss: 1.182569, acc: 71%] [G loss: 1.279198]\n",
      "[Epoch 0/200] [Batch 637/938] [D loss: 1.162250, acc: 79%] [G loss: 1.271593]\n",
      "[Epoch 0/200] [Batch 638/938] [D loss: 1.187774, acc: 75%] [G loss: 1.280505]\n",
      "[Epoch 0/200] [Batch 639/938] [D loss: 1.170954, acc: 78%] [G loss: 1.285774]\n",
      "[Epoch 0/200] [Batch 640/938] [D loss: 1.150668, acc: 80%] [G loss: 1.232832]\n",
      "[Epoch 0/200] [Batch 641/938] [D loss: 1.161331, acc: 82%] [G loss: 1.259194]\n",
      "[Epoch 0/200] [Batch 642/938] [D loss: 1.146779, acc: 80%] [G loss: 1.278624]\n",
      "[Epoch 0/200] [Batch 643/938] [D loss: 1.137097, acc: 78%] [G loss: 1.265583]\n",
      "[Epoch 0/200] [Batch 644/938] [D loss: 1.178061, acc: 78%] [G loss: 1.220240]\n",
      "[Epoch 0/200] [Batch 645/938] [D loss: 1.138698, acc: 83%] [G loss: 1.242351]\n",
      "[Epoch 0/200] [Batch 646/938] [D loss: 1.158519, acc: 78%] [G loss: 1.208655]\n",
      "[Epoch 0/200] [Batch 647/938] [D loss: 1.157203, acc: 81%] [G loss: 1.233735]\n",
      "[Epoch 0/200] [Batch 648/938] [D loss: 1.128870, acc: 82%] [G loss: 1.264588]\n",
      "[Epoch 0/200] [Batch 649/938] [D loss: 1.139864, acc: 84%] [G loss: 1.196776]\n",
      "[Epoch 0/200] [Batch 650/938] [D loss: 1.166641, acc: 79%] [G loss: 1.252666]\n",
      "[Epoch 0/200] [Batch 651/938] [D loss: 1.162833, acc: 82%] [G loss: 1.247549]\n",
      "[Epoch 0/200] [Batch 652/938] [D loss: 1.181090, acc: 71%] [G loss: 1.308862]\n",
      "[Epoch 0/200] [Batch 653/938] [D loss: 1.166045, acc: 77%] [G loss: 1.232178]\n",
      "[Epoch 0/200] [Batch 654/938] [D loss: 1.182752, acc: 75%] [G loss: 1.307214]\n",
      "[Epoch 0/200] [Batch 655/938] [D loss: 1.157904, acc: 80%] [G loss: 1.275961]\n",
      "[Epoch 0/200] [Batch 656/938] [D loss: 1.162076, acc: 78%] [G loss: 1.283447]\n",
      "[Epoch 0/200] [Batch 657/938] [D loss: 1.143474, acc: 82%] [G loss: 1.251444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 658/938] [D loss: 1.175363, acc: 77%] [G loss: 1.301373]\n",
      "[Epoch 0/200] [Batch 659/938] [D loss: 1.138144, acc: 82%] [G loss: 1.282826]\n",
      "[Epoch 0/200] [Batch 660/938] [D loss: 1.144431, acc: 81%] [G loss: 1.237906]\n",
      "[Epoch 0/200] [Batch 661/938] [D loss: 1.139844, acc: 83%] [G loss: 1.268491]\n",
      "[Epoch 0/200] [Batch 662/938] [D loss: 1.176378, acc: 77%] [G loss: 1.256125]\n",
      "[Epoch 0/200] [Batch 663/938] [D loss: 1.155223, acc: 80%] [G loss: 1.240831]\n",
      "[Epoch 0/200] [Batch 664/938] [D loss: 1.193776, acc: 73%] [G loss: 1.277245]\n",
      "[Epoch 0/200] [Batch 665/938] [D loss: 1.166528, acc: 81%] [G loss: 1.271329]\n",
      "[Epoch 0/200] [Batch 666/938] [D loss: 1.158258, acc: 82%] [G loss: 1.230599]\n",
      "[Epoch 0/200] [Batch 667/938] [D loss: 1.161857, acc: 78%] [G loss: 1.315409]\n",
      "[Epoch 0/200] [Batch 668/938] [D loss: 1.155894, acc: 77%] [G loss: 1.294749]\n",
      "[Epoch 0/200] [Batch 669/938] [D loss: 1.165082, acc: 78%] [G loss: 1.234344]\n",
      "[Epoch 0/200] [Batch 670/938] [D loss: 1.159267, acc: 84%] [G loss: 1.244853]\n",
      "[Epoch 0/200] [Batch 671/938] [D loss: 1.165171, acc: 81%] [G loss: 1.255126]\n",
      "[Epoch 0/200] [Batch 672/938] [D loss: 1.186039, acc: 74%] [G loss: 1.291516]\n",
      "[Epoch 0/200] [Batch 673/938] [D loss: 1.155709, acc: 82%] [G loss: 1.259848]\n",
      "[Epoch 0/200] [Batch 674/938] [D loss: 1.119796, acc: 89%] [G loss: 1.192339]\n",
      "[Epoch 0/200] [Batch 675/938] [D loss: 1.171479, acc: 78%] [G loss: 1.275371]\n",
      "[Epoch 0/200] [Batch 676/938] [D loss: 1.112322, acc: 87%] [G loss: 1.255489]\n",
      "[Epoch 0/200] [Batch 677/938] [D loss: 1.164918, acc: 78%] [G loss: 1.306766]\n",
      "[Epoch 0/200] [Batch 678/938] [D loss: 1.166082, acc: 76%] [G loss: 1.265348]\n",
      "[Epoch 0/200] [Batch 679/938] [D loss: 1.138253, acc: 83%] [G loss: 1.255692]\n",
      "[Epoch 0/200] [Batch 680/938] [D loss: 1.142306, acc: 85%] [G loss: 1.189321]\n",
      "[Epoch 0/200] [Batch 681/938] [D loss: 1.159877, acc: 83%] [G loss: 1.237831]\n",
      "[Epoch 0/200] [Batch 682/938] [D loss: 1.157151, acc: 76%] [G loss: 1.282216]\n",
      "[Epoch 0/200] [Batch 683/938] [D loss: 1.163395, acc: 79%] [G loss: 1.233772]\n",
      "[Epoch 0/200] [Batch 684/938] [D loss: 1.114505, acc: 80%] [G loss: 1.253741]\n",
      "[Epoch 0/200] [Batch 685/938] [D loss: 1.159210, acc: 82%] [G loss: 1.194773]\n",
      "[Epoch 0/200] [Batch 686/938] [D loss: 1.189480, acc: 73%] [G loss: 1.279184]\n",
      "[Epoch 0/200] [Batch 687/938] [D loss: 1.160126, acc: 79%] [G loss: 1.261576]\n",
      "[Epoch 0/200] [Batch 688/938] [D loss: 1.122710, acc: 91%] [G loss: 1.162403]\n",
      "[Epoch 0/200] [Batch 689/938] [D loss: 1.140444, acc: 80%] [G loss: 1.235297]\n",
      "[Epoch 0/200] [Batch 690/938] [D loss: 1.163969, acc: 75%] [G loss: 1.352319]\n",
      "[Epoch 0/200] [Batch 691/938] [D loss: 1.080438, acc: 92%] [G loss: 1.184728]\n",
      "[Epoch 0/200] [Batch 692/938] [D loss: 1.148832, acc: 75%] [G loss: 1.307429]\n",
      "[Epoch 0/200] [Batch 693/938] [D loss: 1.153112, acc: 82%] [G loss: 1.282191]\n",
      "[Epoch 0/200] [Batch 694/938] [D loss: 1.168465, acc: 83%] [G loss: 1.259035]\n",
      "[Epoch 0/200] [Batch 695/938] [D loss: 1.124401, acc: 85%] [G loss: 1.224045]\n",
      "[Epoch 0/200] [Batch 696/938] [D loss: 1.134352, acc: 85%] [G loss: 1.232881]\n",
      "[Epoch 0/200] [Batch 697/938] [D loss: 1.137789, acc: 86%] [G loss: 1.193454]\n",
      "[Epoch 0/200] [Batch 698/938] [D loss: 1.150487, acc: 80%] [G loss: 1.217258]\n",
      "[Epoch 0/200] [Batch 699/938] [D loss: 1.155581, acc: 82%] [G loss: 1.251867]\n",
      "[Epoch 0/200] [Batch 700/938] [D loss: 1.153040, acc: 75%] [G loss: 1.273767]\n",
      "[Epoch 0/200] [Batch 701/938] [D loss: 1.141510, acc: 85%] [G loss: 1.260272]\n",
      "[Epoch 0/200] [Batch 702/938] [D loss: 1.148042, acc: 85%] [G loss: 1.262629]\n",
      "[Epoch 0/200] [Batch 703/938] [D loss: 1.135714, acc: 83%] [G loss: 1.213813]\n",
      "[Epoch 0/200] [Batch 704/938] [D loss: 1.190510, acc: 75%] [G loss: 1.239567]\n",
      "[Epoch 0/200] [Batch 705/938] [D loss: 1.144626, acc: 83%] [G loss: 1.228476]\n",
      "[Epoch 0/200] [Batch 706/938] [D loss: 1.137118, acc: 80%] [G loss: 1.239857]\n",
      "[Epoch 0/200] [Batch 707/938] [D loss: 1.149111, acc: 78%] [G loss: 1.256682]\n",
      "[Epoch 0/200] [Batch 708/938] [D loss: 1.170952, acc: 78%] [G loss: 1.272430]\n",
      "[Epoch 0/200] [Batch 709/938] [D loss: 1.113019, acc: 84%] [G loss: 1.257158]\n",
      "[Epoch 0/200] [Batch 710/938] [D loss: 1.123251, acc: 84%] [G loss: 1.292387]\n",
      "[Epoch 0/200] [Batch 711/938] [D loss: 1.156676, acc: 85%] [G loss: 1.194694]\n",
      "[Epoch 0/200] [Batch 712/938] [D loss: 1.149917, acc: 81%] [G loss: 1.230749]\n",
      "[Epoch 0/200] [Batch 713/938] [D loss: 1.105306, acc: 89%] [G loss: 1.213341]\n",
      "[Epoch 0/200] [Batch 714/938] [D loss: 1.160263, acc: 82%] [G loss: 1.224634]\n",
      "[Epoch 0/200] [Batch 715/938] [D loss: 1.203250, acc: 74%] [G loss: 1.249475]\n",
      "[Epoch 0/200] [Batch 716/938] [D loss: 1.156026, acc: 80%] [G loss: 1.214188]\n",
      "[Epoch 0/200] [Batch 717/938] [D loss: 1.152330, acc: 79%] [G loss: 1.210184]\n",
      "[Epoch 0/200] [Batch 718/938] [D loss: 1.134683, acc: 88%] [G loss: 1.220142]\n",
      "[Epoch 0/200] [Batch 719/938] [D loss: 1.170879, acc: 76%] [G loss: 1.311320]\n",
      "[Epoch 0/200] [Batch 720/938] [D loss: 1.147187, acc: 83%] [G loss: 1.266405]\n",
      "[Epoch 0/200] [Batch 721/938] [D loss: 1.133198, acc: 85%] [G loss: 1.232025]\n",
      "[Epoch 0/200] [Batch 722/938] [D loss: 1.151653, acc: 82%] [G loss: 1.276468]\n",
      "[Epoch 0/200] [Batch 723/938] [D loss: 1.133065, acc: 86%] [G loss: 1.223395]\n",
      "[Epoch 0/200] [Batch 724/938] [D loss: 1.152355, acc: 80%] [G loss: 1.226958]\n",
      "[Epoch 0/200] [Batch 725/938] [D loss: 1.158963, acc: 82%] [G loss: 1.255571]\n",
      "[Epoch 0/200] [Batch 726/938] [D loss: 1.152697, acc: 77%] [G loss: 1.229957]\n",
      "[Epoch 0/200] [Batch 727/938] [D loss: 1.131010, acc: 84%] [G loss: 1.280582]\n",
      "[Epoch 0/200] [Batch 728/938] [D loss: 1.134405, acc: 83%] [G loss: 1.275430]\n",
      "[Epoch 0/200] [Batch 729/938] [D loss: 1.118042, acc: 85%] [G loss: 1.222812]\n",
      "[Epoch 0/200] [Batch 730/938] [D loss: 1.109008, acc: 89%] [G loss: 1.199860]\n",
      "[Epoch 0/200] [Batch 731/938] [D loss: 1.133248, acc: 85%] [G loss: 1.203492]\n",
      "[Epoch 0/200] [Batch 732/938] [D loss: 1.121215, acc: 84%] [G loss: 1.198023]\n",
      "[Epoch 0/200] [Batch 733/938] [D loss: 1.157517, acc: 78%] [G loss: 1.231006]\n",
      "[Epoch 0/200] [Batch 734/938] [D loss: 1.157861, acc: 82%] [G loss: 1.203063]\n",
      "[Epoch 0/200] [Batch 735/938] [D loss: 1.164463, acc: 82%] [G loss: 1.224089]\n",
      "[Epoch 0/200] [Batch 736/938] [D loss: 1.126616, acc: 85%] [G loss: 1.197538]\n",
      "[Epoch 0/200] [Batch 737/938] [D loss: 1.134222, acc: 86%] [G loss: 1.196510]\n",
      "[Epoch 0/200] [Batch 738/938] [D loss: 1.130716, acc: 81%] [G loss: 1.232771]\n",
      "[Epoch 0/200] [Batch 739/938] [D loss: 1.147077, acc: 80%] [G loss: 1.285839]\n",
      "[Epoch 0/200] [Batch 740/938] [D loss: 1.126639, acc: 84%] [G loss: 1.263263]\n",
      "[Epoch 0/200] [Batch 741/938] [D loss: 1.139580, acc: 82%] [G loss: 1.204410]\n",
      "[Epoch 0/200] [Batch 742/938] [D loss: 1.143644, acc: 85%] [G loss: 1.186564]\n",
      "[Epoch 0/200] [Batch 743/938] [D loss: 1.129526, acc: 81%] [G loss: 1.205851]\n",
      "[Epoch 0/200] [Batch 744/938] [D loss: 1.136388, acc: 83%] [G loss: 1.182001]\n",
      "[Epoch 0/200] [Batch 745/938] [D loss: 1.145493, acc: 82%] [G loss: 1.169662]\n",
      "[Epoch 0/200] [Batch 746/938] [D loss: 1.126904, acc: 85%] [G loss: 1.232594]\n",
      "[Epoch 0/200] [Batch 747/938] [D loss: 1.168388, acc: 76%] [G loss: 1.316624]\n",
      "[Epoch 0/200] [Batch 748/938] [D loss: 1.154344, acc: 80%] [G loss: 1.235991]\n",
      "[Epoch 0/200] [Batch 749/938] [D loss: 1.144530, acc: 82%] [G loss: 1.229379]\n",
      "[Epoch 0/200] [Batch 750/938] [D loss: 1.124382, acc: 86%] [G loss: 1.213291]\n",
      "[Epoch 0/200] [Batch 751/938] [D loss: 1.111437, acc: 84%] [G loss: 1.239888]\n",
      "[Epoch 0/200] [Batch 752/938] [D loss: 1.117913, acc: 86%] [G loss: 1.193009]\n",
      "[Epoch 0/200] [Batch 753/938] [D loss: 1.121336, acc: 83%] [G loss: 1.218179]\n",
      "[Epoch 0/200] [Batch 754/938] [D loss: 1.142313, acc: 81%] [G loss: 1.192233]\n",
      "[Epoch 0/200] [Batch 755/938] [D loss: 1.151471, acc: 82%] [G loss: 1.227298]\n",
      "[Epoch 0/200] [Batch 756/938] [D loss: 1.115202, acc: 92%] [G loss: 1.170712]\n",
      "[Epoch 0/200] [Batch 757/938] [D loss: 1.140207, acc: 85%] [G loss: 1.249944]\n",
      "[Epoch 0/200] [Batch 758/938] [D loss: 1.127499, acc: 82%] [G loss: 1.257399]\n",
      "[Epoch 0/200] [Batch 759/938] [D loss: 1.121457, acc: 86%] [G loss: 1.227233]\n",
      "[Epoch 0/200] [Batch 760/938] [D loss: 1.142158, acc: 82%] [G loss: 1.272544]\n",
      "[Epoch 0/200] [Batch 761/938] [D loss: 1.178212, acc: 75%] [G loss: 1.288105]\n",
      "[Epoch 0/200] [Batch 762/938] [D loss: 1.163597, acc: 82%] [G loss: 1.228569]\n",
      "[Epoch 0/200] [Batch 763/938] [D loss: 1.128036, acc: 85%] [G loss: 1.215796]\n",
      "[Epoch 0/200] [Batch 764/938] [D loss: 1.134080, acc: 81%] [G loss: 1.278935]\n",
      "[Epoch 0/200] [Batch 765/938] [D loss: 1.152858, acc: 82%] [G loss: 1.241538]\n",
      "[Epoch 0/200] [Batch 766/938] [D loss: 1.113647, acc: 86%] [G loss: 1.200018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 767/938] [D loss: 1.092873, acc: 89%] [G loss: 1.175228]\n",
      "[Epoch 0/200] [Batch 768/938] [D loss: 1.109650, acc: 87%] [G loss: 1.187308]\n",
      "[Epoch 0/200] [Batch 769/938] [D loss: 1.140214, acc: 83%] [G loss: 1.217651]\n",
      "[Epoch 0/200] [Batch 770/938] [D loss: 1.117013, acc: 84%] [G loss: 1.211553]\n",
      "[Epoch 0/200] [Batch 771/938] [D loss: 1.138076, acc: 82%] [G loss: 1.223706]\n",
      "[Epoch 0/200] [Batch 772/938] [D loss: 1.131227, acc: 88%] [G loss: 1.164804]\n",
      "[Epoch 0/200] [Batch 773/938] [D loss: 1.139049, acc: 85%] [G loss: 1.246021]\n",
      "[Epoch 0/200] [Batch 774/938] [D loss: 1.120904, acc: 86%] [G loss: 1.242368]\n",
      "[Epoch 0/200] [Batch 775/938] [D loss: 1.133109, acc: 84%] [G loss: 1.191318]\n",
      "[Epoch 0/200] [Batch 776/938] [D loss: 1.115348, acc: 86%] [G loss: 1.272513]\n",
      "[Epoch 0/200] [Batch 777/938] [D loss: 1.128542, acc: 85%] [G loss: 1.220944]\n",
      "[Epoch 0/200] [Batch 778/938] [D loss: 1.131579, acc: 81%] [G loss: 1.189813]\n",
      "[Epoch 0/200] [Batch 779/938] [D loss: 1.141610, acc: 84%] [G loss: 1.194630]\n",
      "[Epoch 0/200] [Batch 780/938] [D loss: 1.143514, acc: 82%] [G loss: 1.245299]\n",
      "[Epoch 0/200] [Batch 781/938] [D loss: 1.122568, acc: 88%] [G loss: 1.236609]\n",
      "[Epoch 0/200] [Batch 782/938] [D loss: 1.131918, acc: 85%] [G loss: 1.248077]\n",
      "[Epoch 0/200] [Batch 783/938] [D loss: 1.121066, acc: 85%] [G loss: 1.192550]\n",
      "[Epoch 0/200] [Batch 784/938] [D loss: 1.144456, acc: 81%] [G loss: 1.173878]\n",
      "[Epoch 0/200] [Batch 785/938] [D loss: 1.134298, acc: 84%] [G loss: 1.270362]\n",
      "[Epoch 0/200] [Batch 786/938] [D loss: 1.149986, acc: 83%] [G loss: 1.193710]\n",
      "[Epoch 0/200] [Batch 787/938] [D loss: 1.124314, acc: 85%] [G loss: 1.247091]\n",
      "[Epoch 0/200] [Batch 788/938] [D loss: 1.146033, acc: 85%] [G loss: 1.253858]\n",
      "[Epoch 0/200] [Batch 789/938] [D loss: 1.143890, acc: 79%] [G loss: 1.267961]\n",
      "[Epoch 0/200] [Batch 790/938] [D loss: 1.127563, acc: 84%] [G loss: 1.204774]\n",
      "[Epoch 0/200] [Batch 791/938] [D loss: 1.126196, acc: 85%] [G loss: 1.196018]\n",
      "[Epoch 0/200] [Batch 792/938] [D loss: 1.123383, acc: 87%] [G loss: 1.189730]\n",
      "[Epoch 0/200] [Batch 793/938] [D loss: 1.110285, acc: 85%] [G loss: 1.196043]\n",
      "[Epoch 0/200] [Batch 794/938] [D loss: 1.127251, acc: 84%] [G loss: 1.176373]\n",
      "[Epoch 0/200] [Batch 795/938] [D loss: 1.130535, acc: 86%] [G loss: 1.208753]\n",
      "[Epoch 0/200] [Batch 796/938] [D loss: 1.132499, acc: 85%] [G loss: 1.208327]\n",
      "[Epoch 0/200] [Batch 797/938] [D loss: 1.094236, acc: 87%] [G loss: 1.228400]\n",
      "[Epoch 0/200] [Batch 798/938] [D loss: 1.132091, acc: 85%] [G loss: 1.185223]\n",
      "[Epoch 0/200] [Batch 799/938] [D loss: 1.132924, acc: 84%] [G loss: 1.223516]\n",
      "[Epoch 0/200] [Batch 800/938] [D loss: 1.115009, acc: 87%] [G loss: 1.164616]\n",
      "[Epoch 0/200] [Batch 801/938] [D loss: 1.143801, acc: 85%] [G loss: 1.219125]\n",
      "[Epoch 0/200] [Batch 802/938] [D loss: 1.111733, acc: 86%] [G loss: 1.215791]\n",
      "[Epoch 0/200] [Batch 803/938] [D loss: 1.145163, acc: 83%] [G loss: 1.254382]\n",
      "[Epoch 0/200] [Batch 804/938] [D loss: 1.133826, acc: 85%] [G loss: 1.227766]\n",
      "[Epoch 0/200] [Batch 805/938] [D loss: 1.163835, acc: 80%] [G loss: 1.252157]\n",
      "[Epoch 0/200] [Batch 806/938] [D loss: 1.095078, acc: 90%] [G loss: 1.183635]\n",
      "[Epoch 0/200] [Batch 807/938] [D loss: 1.154450, acc: 81%] [G loss: 1.308571]\n",
      "[Epoch 0/200] [Batch 808/938] [D loss: 1.106214, acc: 87%] [G loss: 1.243548]\n",
      "[Epoch 0/200] [Batch 809/938] [D loss: 1.097273, acc: 84%] [G loss: 1.208329]\n",
      "[Epoch 0/200] [Batch 810/938] [D loss: 1.107848, acc: 89%] [G loss: 1.178281]\n",
      "[Epoch 0/200] [Batch 811/938] [D loss: 1.154418, acc: 85%] [G loss: 1.161426]\n",
      "[Epoch 0/200] [Batch 812/938] [D loss: 1.125324, acc: 83%] [G loss: 1.194604]\n",
      "[Epoch 0/200] [Batch 813/938] [D loss: 1.147805, acc: 82%] [G loss: 1.237277]\n",
      "[Epoch 0/200] [Batch 814/938] [D loss: 1.122489, acc: 85%] [G loss: 1.194682]\n",
      "[Epoch 0/200] [Batch 815/938] [D loss: 1.134997, acc: 86%] [G loss: 1.212179]\n",
      "[Epoch 0/200] [Batch 816/938] [D loss: 1.153304, acc: 78%] [G loss: 1.213967]\n",
      "[Epoch 0/200] [Batch 817/938] [D loss: 1.121102, acc: 85%] [G loss: 1.240449]\n",
      "[Epoch 0/200] [Batch 818/938] [D loss: 1.111252, acc: 88%] [G loss: 1.242891]\n",
      "[Epoch 0/200] [Batch 819/938] [D loss: 1.136684, acc: 82%] [G loss: 1.213286]\n",
      "[Epoch 0/200] [Batch 820/938] [D loss: 1.109281, acc: 86%] [G loss: 1.246945]\n",
      "[Epoch 0/200] [Batch 821/938] [D loss: 1.130086, acc: 85%] [G loss: 1.198545]\n",
      "[Epoch 0/200] [Batch 822/938] [D loss: 1.155638, acc: 80%] [G loss: 1.189347]\n",
      "[Epoch 0/200] [Batch 823/938] [D loss: 1.088733, acc: 91%] [G loss: 1.193660]\n",
      "[Epoch 0/200] [Batch 824/938] [D loss: 1.139192, acc: 83%] [G loss: 1.178884]\n",
      "[Epoch 0/200] [Batch 825/938] [D loss: 1.130125, acc: 84%] [G loss: 1.165835]\n",
      "[Epoch 0/200] [Batch 826/938] [D loss: 1.120452, acc: 85%] [G loss: 1.215288]\n",
      "[Epoch 0/200] [Batch 827/938] [D loss: 1.137639, acc: 85%] [G loss: 1.224470]\n",
      "[Epoch 0/200] [Batch 828/938] [D loss: 1.151468, acc: 84%] [G loss: 1.239684]\n",
      "[Epoch 0/200] [Batch 829/938] [D loss: 1.101882, acc: 92%] [G loss: 1.161314]\n",
      "[Epoch 0/200] [Batch 830/938] [D loss: 1.151427, acc: 82%] [G loss: 1.202580]\n",
      "[Epoch 0/200] [Batch 831/938] [D loss: 1.111775, acc: 86%] [G loss: 1.233324]\n",
      "[Epoch 0/200] [Batch 832/938] [D loss: 1.122694, acc: 87%] [G loss: 1.206273]\n",
      "[Epoch 0/200] [Batch 833/938] [D loss: 1.165781, acc: 81%] [G loss: 1.207173]\n",
      "[Epoch 0/200] [Batch 834/938] [D loss: 1.131117, acc: 82%] [G loss: 1.217621]\n",
      "[Epoch 0/200] [Batch 835/938] [D loss: 1.146803, acc: 86%] [G loss: 1.184329]\n",
      "[Epoch 0/200] [Batch 836/938] [D loss: 1.099732, acc: 90%] [G loss: 1.135126]\n",
      "[Epoch 0/200] [Batch 837/938] [D loss: 1.091357, acc: 91%] [G loss: 1.205839]\n",
      "[Epoch 0/200] [Batch 838/938] [D loss: 1.120787, acc: 86%] [G loss: 1.219255]\n",
      "[Epoch 0/200] [Batch 839/938] [D loss: 1.113591, acc: 88%] [G loss: 1.193909]\n",
      "[Epoch 0/200] [Batch 840/938] [D loss: 1.147945, acc: 80%] [G loss: 1.228418]\n",
      "[Epoch 0/200] [Batch 841/938] [D loss: 1.134498, acc: 84%] [G loss: 1.248710]\n",
      "[Epoch 0/200] [Batch 842/938] [D loss: 1.140658, acc: 85%] [G loss: 1.238618]\n",
      "[Epoch 0/200] [Batch 843/938] [D loss: 1.166564, acc: 82%] [G loss: 1.230439]\n",
      "[Epoch 0/200] [Batch 844/938] [D loss: 1.120121, acc: 83%] [G loss: 1.236301]\n",
      "[Epoch 0/200] [Batch 845/938] [D loss: 1.098714, acc: 89%] [G loss: 1.188933]\n",
      "[Epoch 0/200] [Batch 846/938] [D loss: 1.129032, acc: 88%] [G loss: 1.169484]\n",
      "[Epoch 0/200] [Batch 847/938] [D loss: 1.101524, acc: 91%] [G loss: 1.206663]\n",
      "[Epoch 0/200] [Batch 848/938] [D loss: 1.117236, acc: 88%] [G loss: 1.207667]\n",
      "[Epoch 0/200] [Batch 849/938] [D loss: 1.116812, acc: 89%] [G loss: 1.173719]\n",
      "[Epoch 0/200] [Batch 850/938] [D loss: 1.143675, acc: 80%] [G loss: 1.200308]\n",
      "[Epoch 0/200] [Batch 851/938] [D loss: 1.121161, acc: 83%] [G loss: 1.297473]\n",
      "[Epoch 0/200] [Batch 852/938] [D loss: 1.116523, acc: 89%] [G loss: 1.245744]\n",
      "[Epoch 0/200] [Batch 853/938] [D loss: 1.138300, acc: 83%] [G loss: 1.229494]\n",
      "[Epoch 0/200] [Batch 854/938] [D loss: 1.138054, acc: 86%] [G loss: 1.234364]\n",
      "[Epoch 0/200] [Batch 855/938] [D loss: 1.123056, acc: 88%] [G loss: 1.226684]\n",
      "[Epoch 0/200] [Batch 856/938] [D loss: 1.074890, acc: 91%] [G loss: 1.219701]\n",
      "[Epoch 0/200] [Batch 857/938] [D loss: 1.118952, acc: 84%] [G loss: 1.233727]\n",
      "[Epoch 0/200] [Batch 858/938] [D loss: 1.121939, acc: 83%] [G loss: 1.279937]\n",
      "[Epoch 0/200] [Batch 859/938] [D loss: 1.119120, acc: 85%] [G loss: 1.265262]\n",
      "[Epoch 0/200] [Batch 860/938] [D loss: 1.109687, acc: 85%] [G loss: 1.209931]\n",
      "[Epoch 0/200] [Batch 861/938] [D loss: 1.131767, acc: 87%] [G loss: 1.255265]\n",
      "[Epoch 0/200] [Batch 862/938] [D loss: 1.135148, acc: 83%] [G loss: 1.221543]\n",
      "[Epoch 0/200] [Batch 863/938] [D loss: 1.106710, acc: 88%] [G loss: 1.179828]\n",
      "[Epoch 0/200] [Batch 864/938] [D loss: 1.130178, acc: 86%] [G loss: 1.199254]\n",
      "[Epoch 0/200] [Batch 865/938] [D loss: 1.121547, acc: 88%] [G loss: 1.151581]\n",
      "[Epoch 0/200] [Batch 866/938] [D loss: 1.107485, acc: 85%] [G loss: 1.176633]\n",
      "[Epoch 0/200] [Batch 867/938] [D loss: 1.108638, acc: 89%] [G loss: 1.211855]\n",
      "[Epoch 0/200] [Batch 868/938] [D loss: 1.108125, acc: 89%] [G loss: 1.234655]\n",
      "[Epoch 0/200] [Batch 869/938] [D loss: 1.132599, acc: 87%] [G loss: 1.244770]\n",
      "[Epoch 0/200] [Batch 870/938] [D loss: 1.141165, acc: 83%] [G loss: 1.261402]\n",
      "[Epoch 0/200] [Batch 871/938] [D loss: 1.154384, acc: 81%] [G loss: 1.261033]\n",
      "[Epoch 0/200] [Batch 872/938] [D loss: 1.153687, acc: 84%] [G loss: 1.204468]\n",
      "[Epoch 0/200] [Batch 873/938] [D loss: 1.080261, acc: 89%] [G loss: 1.217120]\n",
      "[Epoch 0/200] [Batch 874/938] [D loss: 1.119568, acc: 86%] [G loss: 1.202248]\n",
      "[Epoch 0/200] [Batch 875/938] [D loss: 1.137563, acc: 83%] [G loss: 1.198203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 876/938] [D loss: 1.135795, acc: 86%] [G loss: 1.174840]\n",
      "[Epoch 0/200] [Batch 877/938] [D loss: 1.123793, acc: 88%] [G loss: 1.207698]\n",
      "[Epoch 0/200] [Batch 878/938] [D loss: 1.119362, acc: 85%] [G loss: 1.193918]\n",
      "[Epoch 0/200] [Batch 879/938] [D loss: 1.161178, acc: 82%] [G loss: 1.237579]\n",
      "[Epoch 0/200] [Batch 880/938] [D loss: 1.092522, acc: 90%] [G loss: 1.203563]\n",
      "[Epoch 0/200] [Batch 881/938] [D loss: 1.094617, acc: 87%] [G loss: 1.194644]\n",
      "[Epoch 0/200] [Batch 882/938] [D loss: 1.134389, acc: 84%] [G loss: 1.252664]\n",
      "[Epoch 0/200] [Batch 883/938] [D loss: 1.144380, acc: 85%] [G loss: 1.196904]\n",
      "[Epoch 0/200] [Batch 884/938] [D loss: 1.113763, acc: 88%] [G loss: 1.212908]\n",
      "[Epoch 0/200] [Batch 885/938] [D loss: 1.137220, acc: 84%] [G loss: 1.168547]\n",
      "[Epoch 0/200] [Batch 886/938] [D loss: 1.113646, acc: 87%] [G loss: 1.195321]\n",
      "[Epoch 0/200] [Batch 887/938] [D loss: 1.145785, acc: 85%] [G loss: 1.205641]\n",
      "[Epoch 0/200] [Batch 888/938] [D loss: 1.117303, acc: 85%] [G loss: 1.217315]\n",
      "[Epoch 0/200] [Batch 889/938] [D loss: 1.125701, acc: 88%] [G loss: 1.214584]\n",
      "[Epoch 0/200] [Batch 890/938] [D loss: 1.130264, acc: 88%] [G loss: 1.237890]\n",
      "[Epoch 0/200] [Batch 891/938] [D loss: 1.154289, acc: 78%] [G loss: 1.215895]\n",
      "[Epoch 0/200] [Batch 892/938] [D loss: 1.142442, acc: 82%] [G loss: 1.192905]\n",
      "[Epoch 0/200] [Batch 893/938] [D loss: 1.090829, acc: 91%] [G loss: 1.183765]\n",
      "[Epoch 0/200] [Batch 894/938] [D loss: 1.144403, acc: 84%] [G loss: 1.249932]\n",
      "[Epoch 0/200] [Batch 895/938] [D loss: 1.119191, acc: 88%] [G loss: 1.191135]\n",
      "[Epoch 0/200] [Batch 896/938] [D loss: 1.130024, acc: 84%] [G loss: 1.182421]\n",
      "[Epoch 0/200] [Batch 897/938] [D loss: 1.119466, acc: 85%] [G loss: 1.165844]\n",
      "[Epoch 0/200] [Batch 898/938] [D loss: 1.137280, acc: 83%] [G loss: 1.246829]\n",
      "[Epoch 0/200] [Batch 899/938] [D loss: 1.092114, acc: 89%] [G loss: 1.202204]\n",
      "[Epoch 0/200] [Batch 900/938] [D loss: 1.131984, acc: 83%] [G loss: 1.204451]\n",
      "[Epoch 0/200] [Batch 901/938] [D loss: 1.105109, acc: 86%] [G loss: 1.166006]\n",
      "[Epoch 0/200] [Batch 902/938] [D loss: 1.141552, acc: 85%] [G loss: 1.233762]\n",
      "[Epoch 0/200] [Batch 903/938] [D loss: 1.112624, acc: 87%] [G loss: 1.201736]\n",
      "[Epoch 0/200] [Batch 904/938] [D loss: 1.136460, acc: 84%] [G loss: 1.210007]\n",
      "[Epoch 0/200] [Batch 905/938] [D loss: 1.102178, acc: 89%] [G loss: 1.186809]\n",
      "[Epoch 0/200] [Batch 906/938] [D loss: 1.116550, acc: 85%] [G loss: 1.173731]\n",
      "[Epoch 0/200] [Batch 907/938] [D loss: 1.120082, acc: 89%] [G loss: 1.144933]\n",
      "[Epoch 0/200] [Batch 908/938] [D loss: 1.094531, acc: 87%] [G loss: 1.257870]\n",
      "[Epoch 0/200] [Batch 909/938] [D loss: 1.128304, acc: 92%] [G loss: 1.173444]\n",
      "[Epoch 0/200] [Batch 910/938] [D loss: 1.119794, acc: 86%] [G loss: 1.228680]\n",
      "[Epoch 0/200] [Batch 911/938] [D loss: 1.138547, acc: 82%] [G loss: 1.250342]\n",
      "[Epoch 0/200] [Batch 912/938] [D loss: 1.106235, acc: 92%] [G loss: 1.225364]\n",
      "[Epoch 0/200] [Batch 913/938] [D loss: 1.125506, acc: 85%] [G loss: 1.146561]\n",
      "[Epoch 0/200] [Batch 914/938] [D loss: 1.122887, acc: 83%] [G loss: 1.195722]\n",
      "[Epoch 0/200] [Batch 915/938] [D loss: 1.102719, acc: 87%] [G loss: 1.190515]\n",
      "[Epoch 0/200] [Batch 916/938] [D loss: 1.119329, acc: 85%] [G loss: 1.175441]\n",
      "[Epoch 0/200] [Batch 917/938] [D loss: 1.103335, acc: 92%] [G loss: 1.148849]\n",
      "[Epoch 0/200] [Batch 918/938] [D loss: 1.158932, acc: 87%] [G loss: 1.194171]\n",
      "[Epoch 0/200] [Batch 919/938] [D loss: 1.114264, acc: 86%] [G loss: 1.175157]\n",
      "[Epoch 0/200] [Batch 920/938] [D loss: 1.103288, acc: 92%] [G loss: 1.196309]\n",
      "[Epoch 0/200] [Batch 921/938] [D loss: 1.122160, acc: 87%] [G loss: 1.194497]\n",
      "[Epoch 0/200] [Batch 922/938] [D loss: 1.148716, acc: 85%] [G loss: 1.133487]\n",
      "[Epoch 0/200] [Batch 923/938] [D loss: 1.114156, acc: 90%] [G loss: 1.255029]\n",
      "[Epoch 0/200] [Batch 924/938] [D loss: 1.105116, acc: 89%] [G loss: 1.232364]\n",
      "[Epoch 0/200] [Batch 925/938] [D loss: 1.113347, acc: 85%] [G loss: 1.192795]\n",
      "[Epoch 0/200] [Batch 926/938] [D loss: 1.103003, acc: 91%] [G loss: 1.202339]\n",
      "[Epoch 0/200] [Batch 927/938] [D loss: 1.146496, acc: 81%] [G loss: 1.229495]\n",
      "[Epoch 0/200] [Batch 928/938] [D loss: 1.120163, acc: 89%] [G loss: 1.187192]\n",
      "[Epoch 0/200] [Batch 929/938] [D loss: 1.134826, acc: 88%] [G loss: 1.195532]\n",
      "[Epoch 0/200] [Batch 930/938] [D loss: 1.101059, acc: 84%] [G loss: 1.261646]\n",
      "[Epoch 0/200] [Batch 931/938] [D loss: 1.106444, acc: 88%] [G loss: 1.176821]\n",
      "[Epoch 0/200] [Batch 932/938] [D loss: 1.128052, acc: 87%] [G loss: 1.174028]\n",
      "[Epoch 0/200] [Batch 933/938] [D loss: 1.144442, acc: 85%] [G loss: 1.137093]\n",
      "[Epoch 0/200] [Batch 934/938] [D loss: 1.144778, acc: 83%] [G loss: 1.197092]\n",
      "[Epoch 0/200] [Batch 935/938] [D loss: 1.130003, acc: 87%] [G loss: 1.222096]\n",
      "[Epoch 0/200] [Batch 936/938] [D loss: 1.102903, acc: 89%] [G loss: 1.207195]\n",
      "[Epoch 0/200] [Batch 937/938] [D loss: 1.123277, acc: 89%] [G loss: 1.199025]\n",
      "[Epoch 1/200] [Batch 0/938] [D loss: 1.127448, acc: 85%] [G loss: 1.234599]\n",
      "[Epoch 1/200] [Batch 1/938] [D loss: 1.106084, acc: 89%] [G loss: 1.190379]\n",
      "[Epoch 1/200] [Batch 2/938] [D loss: 1.111370, acc: 87%] [G loss: 1.216901]\n",
      "[Epoch 1/200] [Batch 3/938] [D loss: 1.102062, acc: 92%] [G loss: 1.170772]\n",
      "[Epoch 1/200] [Batch 4/938] [D loss: 1.129030, acc: 85%] [G loss: 1.167512]\n",
      "[Epoch 1/200] [Batch 5/938] [D loss: 1.134629, acc: 86%] [G loss: 1.170152]\n",
      "[Epoch 1/200] [Batch 6/938] [D loss: 1.103255, acc: 91%] [G loss: 1.200315]\n",
      "[Epoch 1/200] [Batch 7/938] [D loss: 1.115169, acc: 88%] [G loss: 1.272176]\n",
      "[Epoch 1/200] [Batch 8/938] [D loss: 1.092414, acc: 90%] [G loss: 1.238665]\n",
      "[Epoch 1/200] [Batch 9/938] [D loss: 1.114969, acc: 85%] [G loss: 1.192823]\n",
      "[Epoch 1/200] [Batch 10/938] [D loss: 1.102180, acc: 89%] [G loss: 1.239032]\n",
      "[Epoch 1/200] [Batch 11/938] [D loss: 1.123226, acc: 89%] [G loss: 1.230474]\n",
      "[Epoch 1/200] [Batch 12/938] [D loss: 1.101095, acc: 89%] [G loss: 1.155201]\n",
      "[Epoch 1/200] [Batch 13/938] [D loss: 1.094289, acc: 89%] [G loss: 1.242562]\n",
      "[Epoch 1/200] [Batch 14/938] [D loss: 1.107187, acc: 86%] [G loss: 1.196312]\n",
      "[Epoch 1/200] [Batch 15/938] [D loss: 1.116437, acc: 87%] [G loss: 1.181729]\n",
      "[Epoch 1/200] [Batch 16/938] [D loss: 1.136248, acc: 86%] [G loss: 1.234595]\n",
      "[Epoch 1/200] [Batch 17/938] [D loss: 1.132018, acc: 82%] [G loss: 1.250644]\n",
      "[Epoch 1/200] [Batch 18/938] [D loss: 1.094918, acc: 90%] [G loss: 1.199970]\n",
      "[Epoch 1/200] [Batch 19/938] [D loss: 1.104008, acc: 91%] [G loss: 1.223916]\n",
      "[Epoch 1/200] [Batch 20/938] [D loss: 1.098410, acc: 90%] [G loss: 1.166472]\n",
      "[Epoch 1/200] [Batch 21/938] [D loss: 1.096686, acc: 90%] [G loss: 1.181676]\n",
      "[Epoch 1/200] [Batch 22/938] [D loss: 1.133630, acc: 87%] [G loss: 1.223216]\n",
      "[Epoch 1/200] [Batch 23/938] [D loss: 1.130855, acc: 85%] [G loss: 1.213691]\n",
      "[Epoch 1/200] [Batch 24/938] [D loss: 1.079894, acc: 89%] [G loss: 1.197095]\n",
      "[Epoch 1/200] [Batch 25/938] [D loss: 1.127939, acc: 85%] [G loss: 1.161372]\n",
      "[Epoch 1/200] [Batch 26/938] [D loss: 1.136289, acc: 85%] [G loss: 1.175390]\n",
      "[Epoch 1/200] [Batch 27/938] [D loss: 1.110235, acc: 86%] [G loss: 1.214440]\n",
      "[Epoch 1/200] [Batch 28/938] [D loss: 1.095272, acc: 92%] [G loss: 1.150011]\n",
      "[Epoch 1/200] [Batch 29/938] [D loss: 1.109535, acc: 85%] [G loss: 1.204041]\n",
      "[Epoch 1/200] [Batch 30/938] [D loss: 1.084220, acc: 92%] [G loss: 1.165266]\n",
      "[Epoch 1/200] [Batch 31/938] [D loss: 1.085589, acc: 94%] [G loss: 1.106516]\n",
      "[Epoch 1/200] [Batch 32/938] [D loss: 1.093531, acc: 91%] [G loss: 1.153843]\n",
      "[Epoch 1/200] [Batch 33/938] [D loss: 1.115908, acc: 89%] [G loss: 1.210898]\n",
      "[Epoch 1/200] [Batch 34/938] [D loss: 1.116951, acc: 89%] [G loss: 1.222308]\n",
      "[Epoch 1/200] [Batch 35/938] [D loss: 1.112575, acc: 84%] [G loss: 1.219765]\n",
      "[Epoch 1/200] [Batch 36/938] [D loss: 1.091034, acc: 91%] [G loss: 1.140913]\n",
      "[Epoch 1/200] [Batch 37/938] [D loss: 1.097113, acc: 85%] [G loss: 1.216858]\n",
      "[Epoch 1/200] [Batch 38/938] [D loss: 1.093250, acc: 94%] [G loss: 1.156603]\n",
      "[Epoch 1/200] [Batch 39/938] [D loss: 1.143231, acc: 82%] [G loss: 1.249406]\n",
      "[Epoch 1/200] [Batch 40/938] [D loss: 1.104767, acc: 88%] [G loss: 1.170880]\n",
      "[Epoch 1/200] [Batch 41/938] [D loss: 1.103286, acc: 89%] [G loss: 1.185996]\n",
      "[Epoch 1/200] [Batch 42/938] [D loss: 1.117261, acc: 86%] [G loss: 1.189662]\n",
      "[Epoch 1/200] [Batch 43/938] [D loss: 1.127495, acc: 85%] [G loss: 1.203940]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 44/938] [D loss: 1.077875, acc: 94%] [G loss: 1.181195]\n",
      "[Epoch 1/200] [Batch 45/938] [D loss: 1.094592, acc: 90%] [G loss: 1.232531]\n",
      "[Epoch 1/200] [Batch 46/938] [D loss: 1.110452, acc: 87%] [G loss: 1.302325]\n",
      "[Epoch 1/200] [Batch 47/938] [D loss: 1.123448, acc: 85%] [G loss: 1.259076]\n",
      "[Epoch 1/200] [Batch 48/938] [D loss: 1.109573, acc: 87%] [G loss: 1.202528]\n",
      "[Epoch 1/200] [Batch 49/938] [D loss: 1.113617, acc: 89%] [G loss: 1.170145]\n",
      "[Epoch 1/200] [Batch 50/938] [D loss: 1.102551, acc: 89%] [G loss: 1.178439]\n",
      "[Epoch 1/200] [Batch 51/938] [D loss: 1.128826, acc: 89%] [G loss: 1.138743]\n",
      "[Epoch 1/200] [Batch 52/938] [D loss: 1.089854, acc: 91%] [G loss: 1.208864]\n",
      "[Epoch 1/200] [Batch 53/938] [D loss: 1.139806, acc: 85%] [G loss: 1.215354]\n",
      "[Epoch 1/200] [Batch 54/938] [D loss: 1.129177, acc: 88%] [G loss: 1.210730]\n",
      "[Epoch 1/200] [Batch 55/938] [D loss: 1.115807, acc: 88%] [G loss: 1.150954]\n",
      "[Epoch 1/200] [Batch 56/938] [D loss: 1.105285, acc: 95%] [G loss: 1.148095]\n",
      "[Epoch 1/200] [Batch 57/938] [D loss: 1.112167, acc: 88%] [G loss: 1.187726]\n",
      "[Epoch 1/200] [Batch 58/938] [D loss: 1.094588, acc: 90%] [G loss: 1.249400]\n",
      "[Epoch 1/200] [Batch 59/938] [D loss: 1.123805, acc: 85%] [G loss: 1.173127]\n",
      "[Epoch 1/200] [Batch 60/938] [D loss: 1.078999, acc: 90%] [G loss: 1.192175]\n",
      "[Epoch 1/200] [Batch 61/938] [D loss: 1.106737, acc: 88%] [G loss: 1.205162]\n",
      "[Epoch 1/200] [Batch 62/938] [D loss: 1.113845, acc: 92%] [G loss: 1.210490]\n",
      "[Epoch 1/200] [Batch 63/938] [D loss: 1.103283, acc: 90%] [G loss: 1.193883]\n",
      "[Epoch 1/200] [Batch 64/938] [D loss: 1.088517, acc: 90%] [G loss: 1.217642]\n",
      "[Epoch 1/200] [Batch 65/938] [D loss: 1.140213, acc: 84%] [G loss: 1.204192]\n",
      "[Epoch 1/200] [Batch 66/938] [D loss: 1.088882, acc: 93%] [G loss: 1.159762]\n",
      "[Epoch 1/200] [Batch 67/938] [D loss: 1.103899, acc: 89%] [G loss: 1.186977]\n",
      "[Epoch 1/200] [Batch 68/938] [D loss: 1.089566, acc: 89%] [G loss: 1.228879]\n",
      "[Epoch 1/200] [Batch 69/938] [D loss: 1.128204, acc: 85%] [G loss: 1.201831]\n",
      "[Epoch 1/200] [Batch 70/938] [D loss: 1.091127, acc: 92%] [G loss: 1.190965]\n",
      "[Epoch 1/200] [Batch 71/938] [D loss: 1.103699, acc: 86%] [G loss: 1.229079]\n",
      "[Epoch 1/200] [Batch 72/938] [D loss: 1.099116, acc: 88%] [G loss: 1.233999]\n",
      "[Epoch 1/200] [Batch 73/938] [D loss: 1.120576, acc: 86%] [G loss: 1.268198]\n",
      "[Epoch 1/200] [Batch 74/938] [D loss: 1.112370, acc: 88%] [G loss: 1.199073]\n",
      "[Epoch 1/200] [Batch 75/938] [D loss: 1.079476, acc: 92%] [G loss: 1.165834]\n",
      "[Epoch 1/200] [Batch 76/938] [D loss: 1.127107, acc: 89%] [G loss: 1.194569]\n",
      "[Epoch 1/200] [Batch 77/938] [D loss: 1.105861, acc: 85%] [G loss: 1.199162]\n",
      "[Epoch 1/200] [Batch 78/938] [D loss: 1.095954, acc: 94%] [G loss: 1.197416]\n",
      "[Epoch 1/200] [Batch 79/938] [D loss: 1.113833, acc: 86%] [G loss: 1.159873]\n",
      "[Epoch 1/200] [Batch 80/938] [D loss: 1.119055, acc: 88%] [G loss: 1.254126]\n",
      "[Epoch 1/200] [Batch 81/938] [D loss: 1.147933, acc: 82%] [G loss: 1.217984]\n",
      "[Epoch 1/200] [Batch 82/938] [D loss: 1.087784, acc: 89%] [G loss: 1.217884]\n",
      "[Epoch 1/200] [Batch 83/938] [D loss: 1.088921, acc: 96%] [G loss: 1.127923]\n",
      "[Epoch 1/200] [Batch 84/938] [D loss: 1.117171, acc: 90%] [G loss: 1.168372]\n",
      "[Epoch 1/200] [Batch 85/938] [D loss: 1.095683, acc: 89%] [G loss: 1.220029]\n",
      "[Epoch 1/200] [Batch 86/938] [D loss: 1.104852, acc: 89%] [G loss: 1.205033]\n",
      "[Epoch 1/200] [Batch 87/938] [D loss: 1.128931, acc: 84%] [G loss: 1.188197]\n",
      "[Epoch 1/200] [Batch 88/938] [D loss: 1.112389, acc: 89%] [G loss: 1.218849]\n",
      "[Epoch 1/200] [Batch 89/938] [D loss: 1.109151, acc: 85%] [G loss: 1.217072]\n",
      "[Epoch 1/200] [Batch 90/938] [D loss: 1.099059, acc: 89%] [G loss: 1.210982]\n",
      "[Epoch 1/200] [Batch 91/938] [D loss: 1.123703, acc: 89%] [G loss: 1.210632]\n",
      "[Epoch 1/200] [Batch 92/938] [D loss: 1.117352, acc: 88%] [G loss: 1.230713]\n",
      "[Epoch 1/200] [Batch 93/938] [D loss: 1.112582, acc: 89%] [G loss: 1.170438]\n",
      "[Epoch 1/200] [Batch 94/938] [D loss: 1.088700, acc: 89%] [G loss: 1.232925]\n",
      "[Epoch 1/200] [Batch 95/938] [D loss: 1.124434, acc: 92%] [G loss: 1.141504]\n",
      "[Epoch 1/200] [Batch 96/938] [D loss: 1.108165, acc: 89%] [G loss: 1.203601]\n",
      "[Epoch 1/200] [Batch 97/938] [D loss: 1.136827, acc: 88%] [G loss: 1.168299]\n",
      "[Epoch 1/200] [Batch 98/938] [D loss: 1.091407, acc: 95%] [G loss: 1.170152]\n",
      "[Epoch 1/200] [Batch 99/938] [D loss: 1.128702, acc: 89%] [G loss: 1.188068]\n",
      "[Epoch 1/200] [Batch 100/938] [D loss: 1.128410, acc: 90%] [G loss: 1.144464]\n",
      "[Epoch 1/200] [Batch 101/938] [D loss: 1.118051, acc: 92%] [G loss: 1.181931]\n",
      "[Epoch 1/200] [Batch 102/938] [D loss: 1.108868, acc: 85%] [G loss: 1.199112]\n",
      "[Epoch 1/200] [Batch 103/938] [D loss: 1.073323, acc: 91%] [G loss: 1.195988]\n",
      "[Epoch 1/200] [Batch 104/938] [D loss: 1.108743, acc: 87%] [G loss: 1.238925]\n",
      "[Epoch 1/200] [Batch 105/938] [D loss: 1.100288, acc: 91%] [G loss: 1.142750]\n",
      "[Epoch 1/200] [Batch 106/938] [D loss: 1.104184, acc: 89%] [G loss: 1.207613]\n",
      "[Epoch 1/200] [Batch 107/938] [D loss: 1.109838, acc: 88%] [G loss: 1.200973]\n",
      "[Epoch 1/200] [Batch 108/938] [D loss: 1.123859, acc: 89%] [G loss: 1.146598]\n",
      "[Epoch 1/200] [Batch 109/938] [D loss: 1.126346, acc: 85%] [G loss: 1.213443]\n",
      "[Epoch 1/200] [Batch 110/938] [D loss: 1.089224, acc: 86%] [G loss: 1.226053]\n",
      "[Epoch 1/200] [Batch 111/938] [D loss: 1.070963, acc: 93%] [G loss: 1.212238]\n",
      "[Epoch 1/200] [Batch 112/938] [D loss: 1.114381, acc: 87%] [G loss: 1.216100]\n",
      "[Epoch 1/200] [Batch 113/938] [D loss: 1.109532, acc: 87%] [G loss: 1.166410]\n",
      "[Epoch 1/200] [Batch 114/938] [D loss: 1.090203, acc: 92%] [G loss: 1.181771]\n",
      "[Epoch 1/200] [Batch 115/938] [D loss: 1.132227, acc: 85%] [G loss: 1.144714]\n",
      "[Epoch 1/200] [Batch 116/938] [D loss: 1.113634, acc: 87%] [G loss: 1.154718]\n",
      "[Epoch 1/200] [Batch 117/938] [D loss: 1.095165, acc: 92%] [G loss: 1.162150]\n",
      "[Epoch 1/200] [Batch 118/938] [D loss: 1.101430, acc: 88%] [G loss: 1.192601]\n",
      "[Epoch 1/200] [Batch 119/938] [D loss: 1.115237, acc: 85%] [G loss: 1.202050]\n",
      "[Epoch 1/200] [Batch 120/938] [D loss: 1.116712, acc: 88%] [G loss: 1.175859]\n",
      "[Epoch 1/200] [Batch 121/938] [D loss: 1.118580, acc: 85%] [G loss: 1.194546]\n",
      "[Epoch 1/200] [Batch 122/938] [D loss: 1.104533, acc: 90%] [G loss: 1.153005]\n",
      "[Epoch 1/200] [Batch 123/938] [D loss: 1.111332, acc: 90%] [G loss: 1.189307]\n",
      "[Epoch 1/200] [Batch 124/938] [D loss: 1.095140, acc: 92%] [G loss: 1.210108]\n",
      "[Epoch 1/200] [Batch 125/938] [D loss: 1.149943, acc: 84%] [G loss: 1.180686]\n",
      "[Epoch 1/200] [Batch 126/938] [D loss: 1.115318, acc: 89%] [G loss: 1.263751]\n",
      "[Epoch 1/200] [Batch 127/938] [D loss: 1.119560, acc: 91%] [G loss: 1.089916]\n",
      "[Epoch 1/200] [Batch 128/938] [D loss: 1.111726, acc: 85%] [G loss: 1.193363]\n",
      "[Epoch 1/200] [Batch 129/938] [D loss: 1.111168, acc: 89%] [G loss: 1.172326]\n",
      "[Epoch 1/200] [Batch 130/938] [D loss: 1.126504, acc: 87%] [G loss: 1.171362]\n",
      "[Epoch 1/200] [Batch 131/938] [D loss: 1.133554, acc: 88%] [G loss: 1.188152]\n",
      "[Epoch 1/200] [Batch 132/938] [D loss: 1.117217, acc: 88%] [G loss: 1.159116]\n",
      "[Epoch 1/200] [Batch 133/938] [D loss: 1.096196, acc: 91%] [G loss: 1.182709]\n",
      "[Epoch 1/200] [Batch 134/938] [D loss: 1.088019, acc: 92%] [G loss: 1.167208]\n",
      "[Epoch 1/200] [Batch 135/938] [D loss: 1.115176, acc: 86%] [G loss: 1.250049]\n",
      "[Epoch 1/200] [Batch 136/938] [D loss: 1.099800, acc: 89%] [G loss: 1.180761]\n",
      "[Epoch 1/200] [Batch 137/938] [D loss: 1.148671, acc: 81%] [G loss: 1.164076]\n",
      "[Epoch 1/200] [Batch 138/938] [D loss: 1.113876, acc: 88%] [G loss: 1.197971]\n",
      "[Epoch 1/200] [Batch 139/938] [D loss: 1.095364, acc: 87%] [G loss: 1.162541]\n",
      "[Epoch 1/200] [Batch 140/938] [D loss: 1.103982, acc: 88%] [G loss: 1.203637]\n",
      "[Epoch 1/200] [Batch 141/938] [D loss: 1.089127, acc: 90%] [G loss: 1.190650]\n",
      "[Epoch 1/200] [Batch 142/938] [D loss: 1.141934, acc: 82%] [G loss: 1.234260]\n",
      "[Epoch 1/200] [Batch 143/938] [D loss: 1.110394, acc: 89%] [G loss: 1.209324]\n",
      "[Epoch 1/200] [Batch 144/938] [D loss: 1.108665, acc: 89%] [G loss: 1.197309]\n",
      "[Epoch 1/200] [Batch 145/938] [D loss: 1.141834, acc: 85%] [G loss: 1.192494]\n",
      "[Epoch 1/200] [Batch 146/938] [D loss: 1.114657, acc: 85%] [G loss: 1.216585]\n",
      "[Epoch 1/200] [Batch 147/938] [D loss: 1.126170, acc: 90%] [G loss: 1.187292]\n",
      "[Epoch 1/200] [Batch 148/938] [D loss: 1.125381, acc: 86%] [G loss: 1.190025]\n",
      "[Epoch 1/200] [Batch 149/938] [D loss: 1.084965, acc: 92%] [G loss: 1.217735]\n",
      "[Epoch 1/200] [Batch 150/938] [D loss: 1.097813, acc: 90%] [G loss: 1.182232]\n",
      "[Epoch 1/200] [Batch 151/938] [D loss: 1.123742, acc: 89%] [G loss: 1.239446]\n",
      "[Epoch 1/200] [Batch 152/938] [D loss: 1.125447, acc: 84%] [G loss: 1.251922]\n",
      "[Epoch 1/200] [Batch 153/938] [D loss: 1.111943, acc: 85%] [G loss: 1.210837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 154/938] [D loss: 1.094877, acc: 92%] [G loss: 1.178237]\n",
      "[Epoch 1/200] [Batch 155/938] [D loss: 1.103047, acc: 89%] [G loss: 1.187190]\n",
      "[Epoch 1/200] [Batch 156/938] [D loss: 1.100133, acc: 90%] [G loss: 1.208161]\n",
      "[Epoch 1/200] [Batch 157/938] [D loss: 1.153569, acc: 82%] [G loss: 1.276012]\n",
      "[Epoch 1/200] [Batch 158/938] [D loss: 1.107519, acc: 91%] [G loss: 1.196168]\n",
      "[Epoch 1/200] [Batch 159/938] [D loss: 1.120828, acc: 88%] [G loss: 1.196736]\n",
      "[Epoch 1/200] [Batch 160/938] [D loss: 1.108984, acc: 89%] [G loss: 1.159266]\n",
      "[Epoch 1/200] [Batch 161/938] [D loss: 1.121348, acc: 85%] [G loss: 1.210591]\n",
      "[Epoch 1/200] [Batch 162/938] [D loss: 1.106357, acc: 86%] [G loss: 1.242735]\n",
      "[Epoch 1/200] [Batch 163/938] [D loss: 1.084383, acc: 94%] [G loss: 1.199827]\n",
      "[Epoch 1/200] [Batch 164/938] [D loss: 1.093789, acc: 89%] [G loss: 1.243374]\n",
      "[Epoch 1/200] [Batch 165/938] [D loss: 1.124706, acc: 83%] [G loss: 1.261372]\n",
      "[Epoch 1/200] [Batch 166/938] [D loss: 1.120171, acc: 89%] [G loss: 1.166814]\n",
      "[Epoch 1/200] [Batch 167/938] [D loss: 1.101357, acc: 89%] [G loss: 1.190392]\n",
      "[Epoch 1/200] [Batch 168/938] [D loss: 1.138157, acc: 87%] [G loss: 1.194735]\n",
      "[Epoch 1/200] [Batch 169/938] [D loss: 1.132480, acc: 87%] [G loss: 1.204100]\n",
      "[Epoch 1/200] [Batch 170/938] [D loss: 1.096237, acc: 92%] [G loss: 1.177087]\n",
      "[Epoch 1/200] [Batch 171/938] [D loss: 1.081855, acc: 87%] [G loss: 1.212213]\n",
      "[Epoch 1/200] [Batch 172/938] [D loss: 1.085697, acc: 91%] [G loss: 1.198127]\n",
      "[Epoch 1/200] [Batch 173/938] [D loss: 1.123935, acc: 90%] [G loss: 1.159525]\n",
      "[Epoch 1/200] [Batch 174/938] [D loss: 1.073045, acc: 91%] [G loss: 1.186286]\n",
      "[Epoch 1/200] [Batch 175/938] [D loss: 1.117391, acc: 86%] [G loss: 1.165383]\n",
      "[Epoch 1/200] [Batch 176/938] [D loss: 1.136296, acc: 89%] [G loss: 1.162740]\n",
      "[Epoch 1/200] [Batch 177/938] [D loss: 1.098699, acc: 89%] [G loss: 1.249651]\n",
      "[Epoch 1/200] [Batch 178/938] [D loss: 1.119663, acc: 88%] [G loss: 1.204402]\n",
      "[Epoch 1/200] [Batch 179/938] [D loss: 1.127923, acc: 88%] [G loss: 1.193443]\n",
      "[Epoch 1/200] [Batch 180/938] [D loss: 1.132754, acc: 85%] [G loss: 1.156726]\n",
      "[Epoch 1/200] [Batch 181/938] [D loss: 1.103860, acc: 89%] [G loss: 1.210502]\n",
      "[Epoch 1/200] [Batch 182/938] [D loss: 1.130942, acc: 87%] [G loss: 1.249622]\n",
      "[Epoch 1/200] [Batch 183/938] [D loss: 1.067562, acc: 92%] [G loss: 1.242392]\n",
      "[Epoch 1/200] [Batch 184/938] [D loss: 1.070506, acc: 93%] [G loss: 1.157592]\n",
      "[Epoch 1/200] [Batch 185/938] [D loss: 1.086571, acc: 90%] [G loss: 1.184149]\n",
      "[Epoch 1/200] [Batch 186/938] [D loss: 1.090240, acc: 92%] [G loss: 1.210748]\n",
      "[Epoch 1/200] [Batch 187/938] [D loss: 1.104946, acc: 88%] [G loss: 1.237547]\n",
      "[Epoch 1/200] [Batch 188/938] [D loss: 1.115443, acc: 89%] [G loss: 1.185469]\n",
      "[Epoch 1/200] [Batch 189/938] [D loss: 1.075907, acc: 94%] [G loss: 1.213572]\n",
      "[Epoch 1/200] [Batch 190/938] [D loss: 1.099221, acc: 93%] [G loss: 1.171937]\n",
      "[Epoch 1/200] [Batch 191/938] [D loss: 1.138697, acc: 89%] [G loss: 1.153286]\n",
      "[Epoch 1/200] [Batch 192/938] [D loss: 1.103884, acc: 91%] [G loss: 1.182662]\n",
      "[Epoch 1/200] [Batch 193/938] [D loss: 1.080139, acc: 92%] [G loss: 1.191811]\n",
      "[Epoch 1/200] [Batch 194/938] [D loss: 1.146691, acc: 83%] [G loss: 1.225541]\n",
      "[Epoch 1/200] [Batch 195/938] [D loss: 1.071741, acc: 94%] [G loss: 1.175517]\n",
      "[Epoch 1/200] [Batch 196/938] [D loss: 1.097212, acc: 95%] [G loss: 1.157947]\n",
      "[Epoch 1/200] [Batch 197/938] [D loss: 1.112829, acc: 88%] [G loss: 1.143904]\n",
      "[Epoch 1/200] [Batch 198/938] [D loss: 1.143783, acc: 87%] [G loss: 1.166091]\n",
      "[Epoch 1/200] [Batch 199/938] [D loss: 1.115173, acc: 86%] [G loss: 1.175633]\n",
      "[Epoch 1/200] [Batch 200/938] [D loss: 1.116401, acc: 89%] [G loss: 1.166334]\n",
      "[Epoch 1/200] [Batch 201/938] [D loss: 1.078771, acc: 92%] [G loss: 1.217537]\n",
      "[Epoch 1/200] [Batch 202/938] [D loss: 1.102829, acc: 85%] [G loss: 1.222031]\n",
      "[Epoch 1/200] [Batch 203/938] [D loss: 1.089397, acc: 93%] [G loss: 1.182820]\n",
      "[Epoch 1/200] [Batch 204/938] [D loss: 1.108351, acc: 87%] [G loss: 1.209249]\n",
      "[Epoch 1/200] [Batch 205/938] [D loss: 1.121865, acc: 89%] [G loss: 1.154749]\n",
      "[Epoch 1/200] [Batch 206/938] [D loss: 1.120124, acc: 89%] [G loss: 1.176816]\n",
      "[Epoch 1/200] [Batch 207/938] [D loss: 1.119012, acc: 88%] [G loss: 1.122788]\n",
      "[Epoch 1/200] [Batch 208/938] [D loss: 1.121912, acc: 87%] [G loss: 1.172060]\n",
      "[Epoch 1/200] [Batch 209/938] [D loss: 1.099539, acc: 89%] [G loss: 1.188005]\n",
      "[Epoch 1/200] [Batch 210/938] [D loss: 1.103913, acc: 90%] [G loss: 1.193794]\n",
      "[Epoch 1/200] [Batch 211/938] [D loss: 1.119011, acc: 89%] [G loss: 1.229480]\n",
      "[Epoch 1/200] [Batch 212/938] [D loss: 1.100633, acc: 92%] [G loss: 1.212075]\n",
      "[Epoch 1/200] [Batch 213/938] [D loss: 1.089604, acc: 88%] [G loss: 1.210434]\n",
      "[Epoch 1/200] [Batch 214/938] [D loss: 1.114737, acc: 89%] [G loss: 1.147267]\n",
      "[Epoch 1/200] [Batch 215/938] [D loss: 1.083972, acc: 90%] [G loss: 1.236005]\n",
      "[Epoch 1/200] [Batch 216/938] [D loss: 1.089360, acc: 89%] [G loss: 1.189273]\n",
      "[Epoch 1/200] [Batch 217/938] [D loss: 1.096026, acc: 90%] [G loss: 1.185912]\n",
      "[Epoch 1/200] [Batch 218/938] [D loss: 1.082294, acc: 90%] [G loss: 1.205745]\n",
      "[Epoch 1/200] [Batch 219/938] [D loss: 1.119907, acc: 84%] [G loss: 1.205614]\n",
      "[Epoch 1/200] [Batch 220/938] [D loss: 1.100353, acc: 92%] [G loss: 1.118521]\n",
      "[Epoch 1/200] [Batch 221/938] [D loss: 1.120201, acc: 87%] [G loss: 1.169091]\n",
      "[Epoch 1/200] [Batch 222/938] [D loss: 1.137748, acc: 87%] [G loss: 1.164983]\n",
      "[Epoch 1/200] [Batch 223/938] [D loss: 1.076837, acc: 90%] [G loss: 1.163084]\n",
      "[Epoch 1/200] [Batch 224/938] [D loss: 1.130305, acc: 85%] [G loss: 1.218561]\n",
      "[Epoch 1/200] [Batch 225/938] [D loss: 1.092180, acc: 93%] [G loss: 1.162788]\n",
      "[Epoch 1/200] [Batch 226/938] [D loss: 1.102476, acc: 88%] [G loss: 1.211980]\n",
      "[Epoch 1/200] [Batch 227/938] [D loss: 1.115830, acc: 84%] [G loss: 1.241334]\n",
      "[Epoch 1/200] [Batch 228/938] [D loss: 1.079952, acc: 92%] [G loss: 1.278599]\n",
      "[Epoch 1/200] [Batch 229/938] [D loss: 1.100517, acc: 89%] [G loss: 1.230854]\n",
      "[Epoch 1/200] [Batch 230/938] [D loss: 1.090964, acc: 87%] [G loss: 1.195397]\n",
      "[Epoch 1/200] [Batch 231/938] [D loss: 1.110445, acc: 85%] [G loss: 1.175573]\n",
      "[Epoch 1/200] [Batch 232/938] [D loss: 1.075538, acc: 90%] [G loss: 1.183564]\n",
      "[Epoch 1/200] [Batch 233/938] [D loss: 1.093035, acc: 89%] [G loss: 1.179249]\n",
      "[Epoch 1/200] [Batch 234/938] [D loss: 1.114431, acc: 87%] [G loss: 1.218020]\n",
      "[Epoch 1/200] [Batch 235/938] [D loss: 1.088194, acc: 90%] [G loss: 1.226901]\n",
      "[Epoch 1/200] [Batch 236/938] [D loss: 1.092467, acc: 92%] [G loss: 1.208477]\n",
      "[Epoch 1/200] [Batch 237/938] [D loss: 1.081509, acc: 90%] [G loss: 1.208060]\n",
      "[Epoch 1/200] [Batch 238/938] [D loss: 1.097115, acc: 89%] [G loss: 1.194311]\n",
      "[Epoch 1/200] [Batch 239/938] [D loss: 1.091357, acc: 90%] [G loss: 1.200782]\n",
      "[Epoch 1/200] [Batch 240/938] [D loss: 1.095890, acc: 92%] [G loss: 1.138109]\n",
      "[Epoch 1/200] [Batch 241/938] [D loss: 1.102202, acc: 91%] [G loss: 1.212228]\n",
      "[Epoch 1/200] [Batch 242/938] [D loss: 1.106516, acc: 89%] [G loss: 1.182660]\n",
      "[Epoch 1/200] [Batch 243/938] [D loss: 1.101036, acc: 90%] [G loss: 1.189184]\n",
      "[Epoch 1/200] [Batch 244/938] [D loss: 1.118243, acc: 89%] [G loss: 1.210938]\n",
      "[Epoch 1/200] [Batch 245/938] [D loss: 1.127162, acc: 85%] [G loss: 1.191010]\n",
      "[Epoch 1/200] [Batch 246/938] [D loss: 1.126408, acc: 90%] [G loss: 1.208173]\n",
      "[Epoch 1/200] [Batch 247/938] [D loss: 1.082403, acc: 93%] [G loss: 1.201532]\n",
      "[Epoch 1/200] [Batch 248/938] [D loss: 1.098579, acc: 91%] [G loss: 1.138827]\n",
      "[Epoch 1/200] [Batch 249/938] [D loss: 1.128674, acc: 84%] [G loss: 1.189683]\n",
      "[Epoch 1/200] [Batch 250/938] [D loss: 1.109633, acc: 88%] [G loss: 1.195975]\n",
      "[Epoch 1/200] [Batch 251/938] [D loss: 1.129179, acc: 89%] [G loss: 1.214535]\n",
      "[Epoch 1/200] [Batch 252/938] [D loss: 1.103192, acc: 90%] [G loss: 1.126605]\n",
      "[Epoch 1/200] [Batch 253/938] [D loss: 1.122944, acc: 87%] [G loss: 1.147036]\n",
      "[Epoch 1/200] [Batch 254/938] [D loss: 1.084169, acc: 92%] [G loss: 1.199319]\n",
      "[Epoch 1/200] [Batch 255/938] [D loss: 1.087231, acc: 92%] [G loss: 1.225287]\n",
      "[Epoch 1/200] [Batch 256/938] [D loss: 1.101270, acc: 92%] [G loss: 1.185626]\n",
      "[Epoch 1/200] [Batch 257/938] [D loss: 1.125493, acc: 88%] [G loss: 1.152340]\n",
      "[Epoch 1/200] [Batch 258/938] [D loss: 1.076275, acc: 92%] [G loss: 1.237582]\n",
      "[Epoch 1/200] [Batch 259/938] [D loss: 1.086771, acc: 90%] [G loss: 1.148145]\n",
      "[Epoch 1/200] [Batch 260/938] [D loss: 1.156224, acc: 82%] [G loss: 1.182983]\n",
      "[Epoch 1/200] [Batch 261/938] [D loss: 1.103151, acc: 91%] [G loss: 1.239039]\n",
      "[Epoch 1/200] [Batch 262/938] [D loss: 1.095003, acc: 89%] [G loss: 1.269118]\n",
      "[Epoch 1/200] [Batch 263/938] [D loss: 1.099316, acc: 88%] [G loss: 1.154248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 264/938] [D loss: 1.096408, acc: 90%] [G loss: 1.206424]\n",
      "[Epoch 1/200] [Batch 265/938] [D loss: 1.103659, acc: 91%] [G loss: 1.187458]\n",
      "[Epoch 1/200] [Batch 266/938] [D loss: 1.099573, acc: 91%] [G loss: 1.193911]\n",
      "[Epoch 1/200] [Batch 267/938] [D loss: 1.096087, acc: 93%] [G loss: 1.216295]\n",
      "[Epoch 1/200] [Batch 268/938] [D loss: 1.108445, acc: 91%] [G loss: 1.184528]\n",
      "[Epoch 1/200] [Batch 269/938] [D loss: 1.103810, acc: 88%] [G loss: 1.195148]\n",
      "[Epoch 1/200] [Batch 270/938] [D loss: 1.088832, acc: 90%] [G loss: 1.208524]\n",
      "[Epoch 1/200] [Batch 271/938] [D loss: 1.098909, acc: 89%] [G loss: 1.196461]\n",
      "[Epoch 1/200] [Batch 272/938] [D loss: 1.067709, acc: 96%] [G loss: 1.153456]\n",
      "[Epoch 1/200] [Batch 273/938] [D loss: 1.141108, acc: 85%] [G loss: 1.260525]\n",
      "[Epoch 1/200] [Batch 274/938] [D loss: 1.112258, acc: 86%] [G loss: 1.250320]\n",
      "[Epoch 1/200] [Batch 275/938] [D loss: 1.102705, acc: 88%] [G loss: 1.209795]\n",
      "[Epoch 1/200] [Batch 276/938] [D loss: 1.102277, acc: 87%] [G loss: 1.165698]\n",
      "[Epoch 1/200] [Batch 277/938] [D loss: 1.051692, acc: 94%] [G loss: 1.190851]\n",
      "[Epoch 1/200] [Batch 278/938] [D loss: 1.079833, acc: 91%] [G loss: 1.204172]\n",
      "[Epoch 1/200] [Batch 279/938] [D loss: 1.110579, acc: 90%] [G loss: 1.217889]\n",
      "[Epoch 1/200] [Batch 280/938] [D loss: 1.150491, acc: 89%] [G loss: 1.158901]\n",
      "[Epoch 1/200] [Batch 281/938] [D loss: 1.133349, acc: 84%] [G loss: 1.155948]\n",
      "[Epoch 1/200] [Batch 282/938] [D loss: 1.100449, acc: 89%] [G loss: 1.197309]\n",
      "[Epoch 1/200] [Batch 283/938] [D loss: 1.118403, acc: 86%] [G loss: 1.197310]\n",
      "[Epoch 1/200] [Batch 284/938] [D loss: 1.080758, acc: 90%] [G loss: 1.202943]\n",
      "[Epoch 1/200] [Batch 285/938] [D loss: 1.079480, acc: 91%] [G loss: 1.274335]\n",
      "[Epoch 1/200] [Batch 286/938] [D loss: 1.135495, acc: 90%] [G loss: 1.174985]\n",
      "[Epoch 1/200] [Batch 287/938] [D loss: 1.108571, acc: 93%] [G loss: 1.196227]\n",
      "[Epoch 1/200] [Batch 288/938] [D loss: 1.086020, acc: 89%] [G loss: 1.168733]\n",
      "[Epoch 1/200] [Batch 289/938] [D loss: 1.102783, acc: 88%] [G loss: 1.132981]\n",
      "[Epoch 1/200] [Batch 290/938] [D loss: 1.101620, acc: 88%] [G loss: 1.182167]\n",
      "[Epoch 1/200] [Batch 291/938] [D loss: 1.098767, acc: 85%] [G loss: 1.136816]\n",
      "[Epoch 1/200] [Batch 292/938] [D loss: 1.119619, acc: 87%] [G loss: 1.199904]\n",
      "[Epoch 1/200] [Batch 293/938] [D loss: 1.076977, acc: 92%] [G loss: 1.226839]\n",
      "[Epoch 1/200] [Batch 294/938] [D loss: 1.085623, acc: 90%] [G loss: 1.168429]\n",
      "[Epoch 1/200] [Batch 295/938] [D loss: 1.096271, acc: 87%] [G loss: 1.191084]\n",
      "[Epoch 1/200] [Batch 296/938] [D loss: 1.088090, acc: 92%] [G loss: 1.196714]\n",
      "[Epoch 1/200] [Batch 297/938] [D loss: 1.097751, acc: 91%] [G loss: 1.189699]\n",
      "[Epoch 1/200] [Batch 298/938] [D loss: 1.115350, acc: 86%] [G loss: 1.276470]\n",
      "[Epoch 1/200] [Batch 299/938] [D loss: 1.096103, acc: 91%] [G loss: 1.178844]\n",
      "[Epoch 1/200] [Batch 300/938] [D loss: 1.118800, acc: 92%] [G loss: 1.099694]\n",
      "[Epoch 1/200] [Batch 301/938] [D loss: 1.129611, acc: 89%] [G loss: 1.174486]\n",
      "[Epoch 1/200] [Batch 302/938] [D loss: 1.108418, acc: 89%] [G loss: 1.187949]\n",
      "[Epoch 1/200] [Batch 303/938] [D loss: 1.091390, acc: 89%] [G loss: 1.240368]\n",
      "[Epoch 1/200] [Batch 304/938] [D loss: 1.073949, acc: 90%] [G loss: 1.207620]\n",
      "[Epoch 1/200] [Batch 305/938] [D loss: 1.098919, acc: 91%] [G loss: 1.197553]\n",
      "[Epoch 1/200] [Batch 306/938] [D loss: 1.119036, acc: 89%] [G loss: 1.183547]\n",
      "[Epoch 1/200] [Batch 307/938] [D loss: 1.093959, acc: 89%] [G loss: 1.278835]\n",
      "[Epoch 1/200] [Batch 308/938] [D loss: 1.119421, acc: 88%] [G loss: 1.231532]\n",
      "[Epoch 1/200] [Batch 309/938] [D loss: 1.093047, acc: 89%] [G loss: 1.242739]\n",
      "[Epoch 1/200] [Batch 310/938] [D loss: 1.070367, acc: 92%] [G loss: 1.158930]\n",
      "[Epoch 1/200] [Batch 311/938] [D loss: 1.088426, acc: 88%] [G loss: 1.180830]\n",
      "[Epoch 1/200] [Batch 312/938] [D loss: 1.099015, acc: 91%] [G loss: 1.126111]\n",
      "[Epoch 1/200] [Batch 313/938] [D loss: 1.097037, acc: 88%] [G loss: 1.119756]\n",
      "[Epoch 1/200] [Batch 314/938] [D loss: 1.104736, acc: 85%] [G loss: 1.226472]\n",
      "[Epoch 1/200] [Batch 315/938] [D loss: 1.097618, acc: 89%] [G loss: 1.183069]\n",
      "[Epoch 1/200] [Batch 316/938] [D loss: 1.098722, acc: 95%] [G loss: 1.168938]\n",
      "[Epoch 1/200] [Batch 317/938] [D loss: 1.090896, acc: 89%] [G loss: 1.204502]\n",
      "[Epoch 1/200] [Batch 318/938] [D loss: 1.082532, acc: 92%] [G loss: 1.218271]\n",
      "[Epoch 1/200] [Batch 319/938] [D loss: 1.102826, acc: 85%] [G loss: 1.208260]\n",
      "[Epoch 1/200] [Batch 320/938] [D loss: 1.088932, acc: 91%] [G loss: 1.127650]\n",
      "[Epoch 1/200] [Batch 321/938] [D loss: 1.132098, acc: 89%] [G loss: 1.171045]\n",
      "[Epoch 1/200] [Batch 322/938] [D loss: 1.113495, acc: 91%] [G loss: 1.241232]\n",
      "[Epoch 1/200] [Batch 323/938] [D loss: 1.085878, acc: 89%] [G loss: 1.240095]\n",
      "[Epoch 1/200] [Batch 324/938] [D loss: 1.087940, acc: 90%] [G loss: 1.182900]\n",
      "[Epoch 1/200] [Batch 325/938] [D loss: 1.118312, acc: 89%] [G loss: 1.199047]\n",
      "[Epoch 1/200] [Batch 326/938] [D loss: 1.112319, acc: 89%] [G loss: 1.223023]\n",
      "[Epoch 1/200] [Batch 327/938] [D loss: 1.075063, acc: 92%] [G loss: 1.242313]\n",
      "[Epoch 1/200] [Batch 328/938] [D loss: 1.086566, acc: 92%] [G loss: 1.153593]\n",
      "[Epoch 1/200] [Batch 329/938] [D loss: 1.091014, acc: 90%] [G loss: 1.170470]\n",
      "[Epoch 1/200] [Batch 330/938] [D loss: 1.094619, acc: 89%] [G loss: 1.188663]\n",
      "[Epoch 1/200] [Batch 331/938] [D loss: 1.089320, acc: 89%] [G loss: 1.232911]\n",
      "[Epoch 1/200] [Batch 332/938] [D loss: 1.084942, acc: 89%] [G loss: 1.192335]\n",
      "[Epoch 1/200] [Batch 333/938] [D loss: 1.105787, acc: 91%] [G loss: 1.198506]\n",
      "[Epoch 1/200] [Batch 334/938] [D loss: 1.103674, acc: 92%] [G loss: 1.181692]\n",
      "[Epoch 1/200] [Batch 335/938] [D loss: 1.090644, acc: 92%] [G loss: 1.148761]\n",
      "[Epoch 1/200] [Batch 336/938] [D loss: 1.100776, acc: 90%] [G loss: 1.194677]\n",
      "[Epoch 1/200] [Batch 337/938] [D loss: 1.046931, acc: 94%] [G loss: 1.219172]\n",
      "[Epoch 1/200] [Batch 338/938] [D loss: 1.102103, acc: 91%] [G loss: 1.155887]\n",
      "[Epoch 1/200] [Batch 339/938] [D loss: 1.077311, acc: 90%] [G loss: 1.142980]\n",
      "[Epoch 1/200] [Batch 340/938] [D loss: 1.104642, acc: 89%] [G loss: 1.149557]\n",
      "[Epoch 1/200] [Batch 341/938] [D loss: 1.060430, acc: 96%] [G loss: 1.168882]\n",
      "[Epoch 1/200] [Batch 342/938] [D loss: 1.119811, acc: 89%] [G loss: 1.160770]\n",
      "[Epoch 1/200] [Batch 343/938] [D loss: 1.064833, acc: 95%] [G loss: 1.220631]\n",
      "[Epoch 1/200] [Batch 344/938] [D loss: 1.091063, acc: 90%] [G loss: 1.186848]\n",
      "[Epoch 1/200] [Batch 345/938] [D loss: 1.091535, acc: 91%] [G loss: 1.245973]\n",
      "[Epoch 1/200] [Batch 346/938] [D loss: 1.099263, acc: 89%] [G loss: 1.217566]\n",
      "[Epoch 1/200] [Batch 347/938] [D loss: 1.122066, acc: 88%] [G loss: 1.112555]\n",
      "[Epoch 1/200] [Batch 348/938] [D loss: 1.107474, acc: 91%] [G loss: 1.195046]\n",
      "[Epoch 1/200] [Batch 349/938] [D loss: 1.125866, acc: 87%] [G loss: 1.217690]\n",
      "[Epoch 1/200] [Batch 350/938] [D loss: 1.073295, acc: 94%] [G loss: 1.130429]\n",
      "[Epoch 1/200] [Batch 351/938] [D loss: 1.076962, acc: 93%] [G loss: 1.206800]\n",
      "[Epoch 1/200] [Batch 352/938] [D loss: 1.105335, acc: 87%] [G loss: 1.247511]\n",
      "[Epoch 1/200] [Batch 353/938] [D loss: 1.076818, acc: 94%] [G loss: 1.173294]\n",
      "[Epoch 1/200] [Batch 354/938] [D loss: 1.126538, acc: 88%] [G loss: 1.184070]\n",
      "[Epoch 1/200] [Batch 355/938] [D loss: 1.076951, acc: 90%] [G loss: 1.213219]\n",
      "[Epoch 1/200] [Batch 356/938] [D loss: 1.092914, acc: 89%] [G loss: 1.200519]\n",
      "[Epoch 1/200] [Batch 357/938] [D loss: 1.137390, acc: 89%] [G loss: 1.253417]\n",
      "[Epoch 1/200] [Batch 358/938] [D loss: 1.092319, acc: 93%] [G loss: 1.180939]\n",
      "[Epoch 1/200] [Batch 359/938] [D loss: 1.105311, acc: 87%] [G loss: 1.203031]\n",
      "[Epoch 1/200] [Batch 360/938] [D loss: 1.107106, acc: 91%] [G loss: 1.136284]\n",
      "[Epoch 1/200] [Batch 361/938] [D loss: 1.069902, acc: 89%] [G loss: 1.210640]\n",
      "[Epoch 1/200] [Batch 362/938] [D loss: 1.089171, acc: 94%] [G loss: 1.218690]\n",
      "[Epoch 1/200] [Batch 363/938] [D loss: 1.101209, acc: 89%] [G loss: 1.190299]\n",
      "[Epoch 1/200] [Batch 364/938] [D loss: 1.090005, acc: 91%] [G loss: 1.170166]\n",
      "[Epoch 1/200] [Batch 365/938] [D loss: 1.104233, acc: 89%] [G loss: 1.173936]\n",
      "[Epoch 1/200] [Batch 366/938] [D loss: 1.102331, acc: 88%] [G loss: 1.181141]\n",
      "[Epoch 1/200] [Batch 367/938] [D loss: 1.073163, acc: 93%] [G loss: 1.249976]\n",
      "[Epoch 1/200] [Batch 368/938] [D loss: 1.092738, acc: 90%] [G loss: 1.169982]\n",
      "[Epoch 1/200] [Batch 369/938] [D loss: 1.098981, acc: 88%] [G loss: 1.213576]\n",
      "[Epoch 1/200] [Batch 370/938] [D loss: 1.095879, acc: 92%] [G loss: 1.158319]\n",
      "[Epoch 1/200] [Batch 371/938] [D loss: 1.072122, acc: 92%] [G loss: 1.168260]\n",
      "[Epoch 1/200] [Batch 372/938] [D loss: 1.090074, acc: 92%] [G loss: 1.190579]\n",
      "[Epoch 1/200] [Batch 373/938] [D loss: 1.092656, acc: 91%] [G loss: 1.160137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 374/938] [D loss: 1.068614, acc: 94%] [G loss: 1.209079]\n",
      "[Epoch 1/200] [Batch 375/938] [D loss: 1.104693, acc: 88%] [G loss: 1.194433]\n",
      "[Epoch 1/200] [Batch 376/938] [D loss: 1.097478, acc: 89%] [G loss: 1.204151]\n",
      "[Epoch 1/200] [Batch 377/938] [D loss: 1.084404, acc: 93%] [G loss: 1.133066]\n",
      "[Epoch 1/200] [Batch 378/938] [D loss: 1.124329, acc: 91%] [G loss: 1.128941]\n",
      "[Epoch 1/200] [Batch 379/938] [D loss: 1.133941, acc: 91%] [G loss: 1.131225]\n",
      "[Epoch 1/200] [Batch 380/938] [D loss: 1.125591, acc: 94%] [G loss: 1.219774]\n",
      "[Epoch 1/200] [Batch 381/938] [D loss: 1.073844, acc: 93%] [G loss: 1.232704]\n",
      "[Epoch 1/200] [Batch 382/938] [D loss: 1.092042, acc: 89%] [G loss: 1.197030]\n",
      "[Epoch 1/200] [Batch 383/938] [D loss: 1.091213, acc: 89%] [G loss: 1.187176]\n",
      "[Epoch 1/200] [Batch 384/938] [D loss: 1.088119, acc: 89%] [G loss: 1.205098]\n",
      "[Epoch 1/200] [Batch 385/938] [D loss: 1.111021, acc: 89%] [G loss: 1.214572]\n",
      "[Epoch 1/200] [Batch 386/938] [D loss: 1.084884, acc: 89%] [G loss: 1.241036]\n",
      "[Epoch 1/200] [Batch 387/938] [D loss: 1.078166, acc: 90%] [G loss: 1.224431]\n",
      "[Epoch 1/200] [Batch 388/938] [D loss: 1.077270, acc: 90%] [G loss: 1.191150]\n",
      "[Epoch 1/200] [Batch 389/938] [D loss: 1.103450, acc: 92%] [G loss: 1.120646]\n",
      "[Epoch 1/200] [Batch 390/938] [D loss: 1.074888, acc: 91%] [G loss: 1.233667]\n",
      "[Epoch 1/200] [Batch 391/938] [D loss: 1.110129, acc: 85%] [G loss: 1.242501]\n",
      "[Epoch 1/200] [Batch 392/938] [D loss: 1.099947, acc: 85%] [G loss: 1.218748]\n",
      "[Epoch 1/200] [Batch 393/938] [D loss: 1.083618, acc: 92%] [G loss: 1.250528]\n",
      "[Epoch 1/200] [Batch 394/938] [D loss: 1.119228, acc: 92%] [G loss: 1.216881]\n",
      "[Epoch 1/200] [Batch 395/938] [D loss: 1.097721, acc: 89%] [G loss: 1.174620]\n",
      "[Epoch 1/200] [Batch 396/938] [D loss: 1.087802, acc: 94%] [G loss: 1.117141]\n",
      "[Epoch 1/200] [Batch 397/938] [D loss: 1.097631, acc: 89%] [G loss: 1.179530]\n",
      "[Epoch 1/200] [Batch 398/938] [D loss: 1.119652, acc: 89%] [G loss: 1.147383]\n",
      "[Epoch 1/200] [Batch 399/938] [D loss: 1.058444, acc: 91%] [G loss: 1.213221]\n",
      "[Epoch 1/200] [Batch 400/938] [D loss: 1.111325, acc: 88%] [G loss: 1.249990]\n",
      "[Epoch 1/200] [Batch 401/938] [D loss: 1.092501, acc: 92%] [G loss: 1.187071]\n",
      "[Epoch 1/200] [Batch 402/938] [D loss: 1.082608, acc: 92%] [G loss: 1.209850]\n",
      "[Epoch 1/200] [Batch 403/938] [D loss: 1.077696, acc: 92%] [G loss: 1.223959]\n",
      "[Epoch 1/200] [Batch 404/938] [D loss: 1.088474, acc: 87%] [G loss: 1.188596]\n",
      "[Epoch 1/200] [Batch 405/938] [D loss: 1.099566, acc: 92%] [G loss: 1.230230]\n",
      "[Epoch 1/200] [Batch 406/938] [D loss: 1.106702, acc: 90%] [G loss: 1.202263]\n",
      "[Epoch 1/200] [Batch 407/938] [D loss: 1.074757, acc: 89%] [G loss: 1.217009]\n",
      "[Epoch 1/200] [Batch 408/938] [D loss: 1.109762, acc: 90%] [G loss: 1.170453]\n",
      "[Epoch 1/200] [Batch 409/938] [D loss: 1.090594, acc: 93%] [G loss: 1.255200]\n",
      "[Epoch 1/200] [Batch 410/938] [D loss: 1.076973, acc: 93%] [G loss: 1.207798]\n",
      "[Epoch 1/200] [Batch 411/938] [D loss: 1.108954, acc: 89%] [G loss: 1.140206]\n",
      "[Epoch 1/200] [Batch 412/938] [D loss: 1.079507, acc: 92%] [G loss: 1.164211]\n",
      "[Epoch 1/200] [Batch 413/938] [D loss: 1.080586, acc: 90%] [G loss: 1.101362]\n",
      "[Epoch 1/200] [Batch 414/938] [D loss: 1.102909, acc: 87%] [G loss: 1.148944]\n",
      "[Epoch 1/200] [Batch 415/938] [D loss: 1.070315, acc: 89%] [G loss: 1.181722]\n",
      "[Epoch 1/200] [Batch 416/938] [D loss: 1.090249, acc: 93%] [G loss: 1.182223]\n",
      "[Epoch 1/200] [Batch 417/938] [D loss: 1.120411, acc: 85%] [G loss: 1.227705]\n",
      "[Epoch 1/200] [Batch 418/938] [D loss: 1.077279, acc: 92%] [G loss: 1.165798]\n",
      "[Epoch 1/200] [Batch 419/938] [D loss: 1.067045, acc: 92%] [G loss: 1.157752]\n",
      "[Epoch 1/200] [Batch 420/938] [D loss: 1.060345, acc: 93%] [G loss: 1.139682]\n",
      "[Epoch 1/200] [Batch 421/938] [D loss: 1.096962, acc: 91%] [G loss: 1.224702]\n",
      "[Epoch 1/200] [Batch 422/938] [D loss: 1.102906, acc: 94%] [G loss: 1.187452]\n",
      "[Epoch 1/200] [Batch 423/938] [D loss: 1.106987, acc: 92%] [G loss: 1.247470]\n",
      "[Epoch 1/200] [Batch 424/938] [D loss: 1.093119, acc: 90%] [G loss: 1.221919]\n",
      "[Epoch 1/200] [Batch 425/938] [D loss: 1.097492, acc: 91%] [G loss: 1.212128]\n",
      "[Epoch 1/200] [Batch 426/938] [D loss: 1.115645, acc: 89%] [G loss: 1.175215]\n",
      "[Epoch 1/200] [Batch 427/938] [D loss: 1.102692, acc: 89%] [G loss: 1.258049]\n",
      "[Epoch 1/200] [Batch 428/938] [D loss: 1.122856, acc: 82%] [G loss: 1.168644]\n",
      "[Epoch 1/200] [Batch 429/938] [D loss: 1.093340, acc: 94%] [G loss: 1.116808]\n",
      "[Epoch 1/200] [Batch 430/938] [D loss: 1.107101, acc: 87%] [G loss: 1.213734]\n",
      "[Epoch 1/200] [Batch 431/938] [D loss: 1.097789, acc: 88%] [G loss: 1.217556]\n",
      "[Epoch 1/200] [Batch 432/938] [D loss: 1.083152, acc: 93%] [G loss: 1.229663]\n",
      "[Epoch 1/200] [Batch 433/938] [D loss: 1.074584, acc: 92%] [G loss: 1.165753]\n",
      "[Epoch 1/200] [Batch 434/938] [D loss: 1.106762, acc: 88%] [G loss: 1.150388]\n",
      "[Epoch 1/200] [Batch 435/938] [D loss: 1.093746, acc: 89%] [G loss: 1.199444]\n",
      "[Epoch 1/200] [Batch 436/938] [D loss: 1.092007, acc: 89%] [G loss: 1.158154]\n",
      "[Epoch 1/200] [Batch 437/938] [D loss: 1.121441, acc: 85%] [G loss: 1.243020]\n",
      "[Epoch 1/200] [Batch 438/938] [D loss: 1.116771, acc: 89%] [G loss: 1.176804]\n",
      "[Epoch 1/200] [Batch 439/938] [D loss: 1.075054, acc: 94%] [G loss: 1.185350]\n",
      "[Epoch 1/200] [Batch 440/938] [D loss: 1.098537, acc: 92%] [G loss: 1.145914]\n",
      "[Epoch 1/200] [Batch 441/938] [D loss: 1.116572, acc: 91%] [G loss: 1.200093]\n",
      "[Epoch 1/200] [Batch 442/938] [D loss: 1.098918, acc: 93%] [G loss: 1.187406]\n",
      "[Epoch 1/200] [Batch 443/938] [D loss: 1.072167, acc: 90%] [G loss: 1.215323]\n",
      "[Epoch 1/200] [Batch 444/938] [D loss: 1.098109, acc: 85%] [G loss: 1.285222]\n",
      "[Epoch 1/200] [Batch 445/938] [D loss: 1.088117, acc: 92%] [G loss: 1.230180]\n",
      "[Epoch 1/200] [Batch 446/938] [D loss: 1.110149, acc: 93%] [G loss: 1.145767]\n",
      "[Epoch 1/200] [Batch 447/938] [D loss: 1.093539, acc: 91%] [G loss: 1.149759]\n",
      "[Epoch 1/200] [Batch 448/938] [D loss: 1.095994, acc: 90%] [G loss: 1.125218]\n",
      "[Epoch 1/200] [Batch 449/938] [D loss: 1.126026, acc: 85%] [G loss: 1.163862]\n",
      "[Epoch 1/200] [Batch 450/938] [D loss: 1.089193, acc: 92%] [G loss: 1.187315]\n",
      "[Epoch 1/200] [Batch 451/938] [D loss: 1.087364, acc: 92%] [G loss: 1.143977]\n",
      "[Epoch 1/200] [Batch 452/938] [D loss: 1.092389, acc: 90%] [G loss: 1.242426]\n",
      "[Epoch 1/200] [Batch 453/938] [D loss: 1.083076, acc: 92%] [G loss: 1.188677]\n",
      "[Epoch 1/200] [Batch 454/938] [D loss: 1.094072, acc: 90%] [G loss: 1.227739]\n",
      "[Epoch 1/200] [Batch 455/938] [D loss: 1.082282, acc: 88%] [G loss: 1.175893]\n",
      "[Epoch 1/200] [Batch 456/938] [D loss: 1.121909, acc: 90%] [G loss: 1.154424]\n",
      "[Epoch 1/200] [Batch 457/938] [D loss: 1.083774, acc: 85%] [G loss: 1.190653]\n",
      "[Epoch 1/200] [Batch 458/938] [D loss: 1.101802, acc: 93%] [G loss: 1.221598]\n",
      "[Epoch 1/200] [Batch 459/938] [D loss: 1.071470, acc: 95%] [G loss: 1.234451]\n",
      "[Epoch 1/200] [Batch 460/938] [D loss: 1.081013, acc: 93%] [G loss: 1.204648]\n",
      "[Epoch 1/200] [Batch 461/938] [D loss: 1.089036, acc: 89%] [G loss: 1.142327]\n",
      "[Epoch 1/200] [Batch 462/938] [D loss: 1.089761, acc: 93%] [G loss: 1.167661]\n",
      "[Epoch 1/200] [Batch 463/938] [D loss: 1.077289, acc: 92%] [G loss: 1.205080]\n",
      "[Epoch 1/200] [Batch 464/938] [D loss: 1.071574, acc: 91%] [G loss: 1.168638]\n",
      "[Epoch 1/200] [Batch 465/938] [D loss: 1.128993, acc: 88%] [G loss: 1.257668]\n",
      "[Epoch 1/200] [Batch 466/938] [D loss: 1.123663, acc: 86%] [G loss: 1.234271]\n",
      "[Epoch 1/200] [Batch 467/938] [D loss: 1.094550, acc: 90%] [G loss: 1.213995]\n",
      "[Epoch 1/200] [Batch 468/938] [D loss: 1.085056, acc: 93%] [G loss: 1.188845]\n",
      "[Epoch 1/200] [Batch 469/938] [D loss: 1.122747, acc: 85%] [G loss: 1.244576]\n",
      "[Epoch 1/200] [Batch 470/938] [D loss: 1.075113, acc: 89%] [G loss: 1.187276]\n",
      "[Epoch 1/200] [Batch 471/938] [D loss: 1.088887, acc: 93%] [G loss: 1.172508]\n",
      "[Epoch 1/200] [Batch 472/938] [D loss: 1.096882, acc: 89%] [G loss: 1.192293]\n",
      "[Epoch 1/200] [Batch 473/938] [D loss: 1.071451, acc: 92%] [G loss: 1.217771]\n",
      "[Epoch 1/200] [Batch 474/938] [D loss: 1.098510, acc: 90%] [G loss: 1.208626]\n",
      "[Epoch 1/200] [Batch 475/938] [D loss: 1.098534, acc: 89%] [G loss: 1.199528]\n",
      "[Epoch 1/200] [Batch 476/938] [D loss: 1.124103, acc: 89%] [G loss: 1.218768]\n",
      "[Epoch 1/200] [Batch 477/938] [D loss: 1.089044, acc: 89%] [G loss: 1.157867]\n",
      "[Epoch 1/200] [Batch 478/938] [D loss: 1.098246, acc: 92%] [G loss: 1.126215]\n",
      "[Epoch 1/200] [Batch 479/938] [D loss: 1.100918, acc: 90%] [G loss: 1.174994]\n",
      "[Epoch 1/200] [Batch 480/938] [D loss: 1.084981, acc: 93%] [G loss: 1.187350]\n",
      "[Epoch 1/200] [Batch 481/938] [D loss: 1.067603, acc: 92%] [G loss: 1.191118]\n",
      "[Epoch 1/200] [Batch 482/938] [D loss: 1.120650, acc: 88%] [G loss: 1.274276]\n",
      "[Epoch 1/200] [Batch 483/938] [D loss: 1.094924, acc: 92%] [G loss: 1.155817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 484/938] [D loss: 1.104111, acc: 88%] [G loss: 1.217979]\n",
      "[Epoch 1/200] [Batch 485/938] [D loss: 1.110420, acc: 89%] [G loss: 1.159465]\n",
      "[Epoch 1/200] [Batch 486/938] [D loss: 1.074221, acc: 92%] [G loss: 1.146690]\n",
      "[Epoch 1/200] [Batch 487/938] [D loss: 1.042798, acc: 94%] [G loss: 1.191715]\n",
      "[Epoch 1/200] [Batch 488/938] [D loss: 1.082659, acc: 92%] [G loss: 1.237466]\n",
      "[Epoch 1/200] [Batch 489/938] [D loss: 1.090207, acc: 92%] [G loss: 1.207860]\n",
      "[Epoch 1/200] [Batch 490/938] [D loss: 1.101827, acc: 88%] [G loss: 1.214970]\n",
      "[Epoch 1/200] [Batch 491/938] [D loss: 1.082277, acc: 87%] [G loss: 1.235993]\n",
      "[Epoch 1/200] [Batch 492/938] [D loss: 1.069154, acc: 89%] [G loss: 1.232799]\n",
      "[Epoch 1/200] [Batch 493/938] [D loss: 1.081760, acc: 93%] [G loss: 1.172628]\n",
      "[Epoch 1/200] [Batch 494/938] [D loss: 1.093252, acc: 89%] [G loss: 1.219278]\n",
      "[Epoch 1/200] [Batch 495/938] [D loss: 1.114705, acc: 89%] [G loss: 1.169200]\n",
      "[Epoch 1/200] [Batch 496/938] [D loss: 1.054632, acc: 96%] [G loss: 1.183283]\n",
      "[Epoch 1/200] [Batch 497/938] [D loss: 1.096852, acc: 89%] [G loss: 1.188236]\n",
      "[Epoch 1/200] [Batch 498/938] [D loss: 1.057681, acc: 94%] [G loss: 1.194627]\n",
      "[Epoch 1/200] [Batch 499/938] [D loss: 1.116619, acc: 91%] [G loss: 1.119026]\n",
      "[Epoch 1/200] [Batch 500/938] [D loss: 1.119935, acc: 86%] [G loss: 1.225080]\n",
      "[Epoch 1/200] [Batch 501/938] [D loss: 1.094062, acc: 94%] [G loss: 1.186927]\n",
      "[Epoch 1/200] [Batch 502/938] [D loss: 1.075479, acc: 94%] [G loss: 1.179145]\n",
      "[Epoch 1/200] [Batch 503/938] [D loss: 1.106684, acc: 87%] [G loss: 1.141612]\n",
      "[Epoch 1/200] [Batch 504/938] [D loss: 1.115011, acc: 89%] [G loss: 1.156272]\n",
      "[Epoch 1/200] [Batch 505/938] [D loss: 1.091780, acc: 91%] [G loss: 1.188298]\n",
      "[Epoch 1/200] [Batch 506/938] [D loss: 1.083431, acc: 87%] [G loss: 1.177349]\n",
      "[Epoch 1/200] [Batch 507/938] [D loss: 1.107203, acc: 88%] [G loss: 1.187810]\n",
      "[Epoch 1/200] [Batch 508/938] [D loss: 1.097738, acc: 92%] [G loss: 1.205459]\n",
      "[Epoch 1/200] [Batch 509/938] [D loss: 1.069979, acc: 89%] [G loss: 1.190762]\n",
      "[Epoch 1/200] [Batch 510/938] [D loss: 1.089179, acc: 93%] [G loss: 1.121851]\n",
      "[Epoch 1/200] [Batch 511/938] [D loss: 1.064853, acc: 91%] [G loss: 1.205530]\n",
      "[Epoch 1/200] [Batch 512/938] [D loss: 1.044155, acc: 92%] [G loss: 1.279454]\n",
      "[Epoch 1/200] [Batch 513/938] [D loss: 1.078539, acc: 92%] [G loss: 1.198053]\n",
      "[Epoch 1/200] [Batch 514/938] [D loss: 1.080125, acc: 92%] [G loss: 1.278832]\n",
      "[Epoch 1/200] [Batch 515/938] [D loss: 1.073097, acc: 92%] [G loss: 1.230361]\n",
      "[Epoch 1/200] [Batch 516/938] [D loss: 1.075978, acc: 93%] [G loss: 1.185333]\n",
      "[Epoch 1/200] [Batch 517/938] [D loss: 1.100788, acc: 85%] [G loss: 1.187251]\n",
      "[Epoch 1/200] [Batch 518/938] [D loss: 1.067914, acc: 93%] [G loss: 1.162301]\n",
      "[Epoch 1/200] [Batch 519/938] [D loss: 1.096812, acc: 95%] [G loss: 1.153807]\n",
      "[Epoch 1/200] [Batch 520/938] [D loss: 1.107071, acc: 92%] [G loss: 1.150070]\n",
      "[Epoch 1/200] [Batch 521/938] [D loss: 1.110358, acc: 90%] [G loss: 1.201850]\n",
      "[Epoch 1/200] [Batch 522/938] [D loss: 1.072732, acc: 94%] [G loss: 1.218681]\n",
      "[Epoch 1/200] [Batch 523/938] [D loss: 1.079298, acc: 90%] [G loss: 1.197752]\n",
      "[Epoch 1/200] [Batch 524/938] [D loss: 1.076899, acc: 92%] [G loss: 1.192093]\n",
      "[Epoch 1/200] [Batch 525/938] [D loss: 1.088498, acc: 88%] [G loss: 1.232778]\n",
      "[Epoch 1/200] [Batch 526/938] [D loss: 1.055442, acc: 95%] [G loss: 1.173831]\n",
      "[Epoch 1/200] [Batch 527/938] [D loss: 1.101970, acc: 89%] [G loss: 1.232093]\n",
      "[Epoch 1/200] [Batch 528/938] [D loss: 1.101366, acc: 92%] [G loss: 1.274285]\n",
      "[Epoch 1/200] [Batch 529/938] [D loss: 1.093677, acc: 89%] [G loss: 1.240788]\n",
      "[Epoch 1/200] [Batch 530/938] [D loss: 1.086406, acc: 92%] [G loss: 1.140516]\n",
      "[Epoch 1/200] [Batch 531/938] [D loss: 1.098837, acc: 87%] [G loss: 1.234360]\n",
      "[Epoch 1/200] [Batch 532/938] [D loss: 1.083982, acc: 93%] [G loss: 1.181403]\n",
      "[Epoch 1/200] [Batch 533/938] [D loss: 1.071374, acc: 94%] [G loss: 1.240609]\n",
      "[Epoch 1/200] [Batch 534/938] [D loss: 1.087072, acc: 92%] [G loss: 1.183550]\n",
      "[Epoch 1/200] [Batch 535/938] [D loss: 1.087899, acc: 90%] [G loss: 1.174934]\n",
      "[Epoch 1/200] [Batch 536/938] [D loss: 1.033459, acc: 95%] [G loss: 1.222564]\n",
      "[Epoch 1/200] [Batch 537/938] [D loss: 1.095191, acc: 89%] [G loss: 1.152702]\n",
      "[Epoch 1/200] [Batch 538/938] [D loss: 1.077790, acc: 93%] [G loss: 1.174572]\n",
      "[Epoch 1/200] [Batch 539/938] [D loss: 1.073721, acc: 92%] [G loss: 1.220194]\n",
      "[Epoch 1/200] [Batch 540/938] [D loss: 1.092498, acc: 92%] [G loss: 1.244328]\n",
      "[Epoch 1/200] [Batch 541/938] [D loss: 1.077083, acc: 91%] [G loss: 1.132458]\n",
      "[Epoch 1/200] [Batch 542/938] [D loss: 1.113861, acc: 86%] [G loss: 1.136585]\n",
      "[Epoch 1/200] [Batch 543/938] [D loss: 1.078637, acc: 93%] [G loss: 1.208883]\n",
      "[Epoch 1/200] [Batch 544/938] [D loss: 1.091670, acc: 93%] [G loss: 1.228471]\n",
      "[Epoch 1/200] [Batch 545/938] [D loss: 1.104172, acc: 90%] [G loss: 1.130664]\n",
      "[Epoch 1/200] [Batch 546/938] [D loss: 1.149908, acc: 81%] [G loss: 1.216571]\n",
      "[Epoch 1/200] [Batch 547/938] [D loss: 1.093845, acc: 89%] [G loss: 1.141385]\n",
      "[Epoch 1/200] [Batch 548/938] [D loss: 1.108126, acc: 89%] [G loss: 1.207501]\n",
      "[Epoch 1/200] [Batch 549/938] [D loss: 1.087161, acc: 94%] [G loss: 1.096932]\n",
      "[Epoch 1/200] [Batch 550/938] [D loss: 1.053873, acc: 94%] [G loss: 1.156377]\n",
      "[Epoch 1/200] [Batch 551/938] [D loss: 1.105448, acc: 89%] [G loss: 1.206703]\n",
      "[Epoch 1/200] [Batch 552/938] [D loss: 1.077537, acc: 92%] [G loss: 1.223590]\n",
      "[Epoch 1/200] [Batch 553/938] [D loss: 1.060763, acc: 92%] [G loss: 1.231710]\n",
      "[Epoch 1/200] [Batch 554/938] [D loss: 1.064584, acc: 92%] [G loss: 1.186135]\n",
      "[Epoch 1/200] [Batch 555/938] [D loss: 1.067622, acc: 92%] [G loss: 1.241904]\n",
      "[Epoch 1/200] [Batch 556/938] [D loss: 1.089722, acc: 90%] [G loss: 1.195920]\n",
      "[Epoch 1/200] [Batch 557/938] [D loss: 1.068158, acc: 95%] [G loss: 1.175095]\n",
      "[Epoch 1/200] [Batch 558/938] [D loss: 1.085126, acc: 95%] [G loss: 1.152553]\n",
      "[Epoch 1/200] [Batch 559/938] [D loss: 1.054029, acc: 95%] [G loss: 1.181109]\n",
      "[Epoch 1/200] [Batch 560/938] [D loss: 1.090367, acc: 90%] [G loss: 1.200933]\n",
      "[Epoch 1/200] [Batch 561/938] [D loss: 1.101264, acc: 89%] [G loss: 1.168527]\n",
      "[Epoch 1/200] [Batch 562/938] [D loss: 1.105415, acc: 94%] [G loss: 1.264741]\n",
      "[Epoch 1/200] [Batch 563/938] [D loss: 1.079742, acc: 93%] [G loss: 1.159016]\n",
      "[Epoch 1/200] [Batch 564/938] [D loss: 1.091475, acc: 85%] [G loss: 1.227052]\n",
      "[Epoch 1/200] [Batch 565/938] [D loss: 1.058856, acc: 89%] [G loss: 1.173418]\n",
      "[Epoch 1/200] [Batch 566/938] [D loss: 1.066484, acc: 92%] [G loss: 1.195064]\n",
      "[Epoch 1/200] [Batch 567/938] [D loss: 1.103812, acc: 90%] [G loss: 1.208814]\n",
      "[Epoch 1/200] [Batch 568/938] [D loss: 1.095269, acc: 86%] [G loss: 1.197814]\n",
      "[Epoch 1/200] [Batch 569/938] [D loss: 1.079166, acc: 92%] [G loss: 1.216712]\n",
      "[Epoch 1/200] [Batch 570/938] [D loss: 1.076602, acc: 92%] [G loss: 1.137974]\n",
      "[Epoch 1/200] [Batch 571/938] [D loss: 1.067179, acc: 92%] [G loss: 1.172454]\n",
      "[Epoch 1/200] [Batch 572/938] [D loss: 1.074127, acc: 94%] [G loss: 1.236338]\n",
      "[Epoch 1/200] [Batch 573/938] [D loss: 1.119100, acc: 86%] [G loss: 1.157611]\n",
      "[Epoch 1/200] [Batch 574/938] [D loss: 1.112876, acc: 92%] [G loss: 1.224994]\n",
      "[Epoch 1/200] [Batch 575/938] [D loss: 1.101625, acc: 87%] [G loss: 1.227762]\n",
      "[Epoch 1/200] [Batch 576/938] [D loss: 1.085318, acc: 92%] [G loss: 1.201785]\n",
      "[Epoch 1/200] [Batch 577/938] [D loss: 1.089346, acc: 92%] [G loss: 1.125246]\n",
      "[Epoch 1/200] [Batch 578/938] [D loss: 1.163456, acc: 85%] [G loss: 1.139443]\n",
      "[Epoch 1/200] [Batch 579/938] [D loss: 1.095371, acc: 92%] [G loss: 1.161080]\n",
      "[Epoch 1/200] [Batch 580/938] [D loss: 1.089214, acc: 89%] [G loss: 1.225537]\n",
      "[Epoch 1/200] [Batch 581/938] [D loss: 1.102517, acc: 90%] [G loss: 1.285824]\n",
      "[Epoch 1/200] [Batch 582/938] [D loss: 1.087950, acc: 92%] [G loss: 1.250815]\n",
      "[Epoch 1/200] [Batch 583/938] [D loss: 1.062094, acc: 92%] [G loss: 1.231926]\n",
      "[Epoch 1/200] [Batch 584/938] [D loss: 1.058346, acc: 93%] [G loss: 1.163742]\n",
      "[Epoch 1/200] [Batch 585/938] [D loss: 1.104028, acc: 89%] [G loss: 1.242559]\n",
      "[Epoch 1/200] [Batch 586/938] [D loss: 1.059893, acc: 93%] [G loss: 1.203763]\n",
      "[Epoch 1/200] [Batch 587/938] [D loss: 1.136017, acc: 86%] [G loss: 1.228036]\n",
      "[Epoch 1/200] [Batch 588/938] [D loss: 1.102566, acc: 89%] [G loss: 1.258201]\n",
      "[Epoch 1/200] [Batch 589/938] [D loss: 1.057182, acc: 91%] [G loss: 1.260692]\n",
      "[Epoch 1/200] [Batch 590/938] [D loss: 1.058193, acc: 93%] [G loss: 1.164638]\n",
      "[Epoch 1/200] [Batch 591/938] [D loss: 1.056930, acc: 95%] [G loss: 1.138876]\n",
      "[Epoch 1/200] [Batch 592/938] [D loss: 1.044320, acc: 92%] [G loss: 1.200672]\n",
      "[Epoch 1/200] [Batch 593/938] [D loss: 1.079469, acc: 89%] [G loss: 1.242227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 594/938] [D loss: 1.063663, acc: 93%] [G loss: 1.171716]\n",
      "[Epoch 1/200] [Batch 595/938] [D loss: 1.046409, acc: 92%] [G loss: 1.139101]\n",
      "[Epoch 1/200] [Batch 596/938] [D loss: 1.094777, acc: 89%] [G loss: 1.211040]\n",
      "[Epoch 1/200] [Batch 597/938] [D loss: 1.126401, acc: 84%] [G loss: 1.185203]\n",
      "[Epoch 1/200] [Batch 598/938] [D loss: 1.074717, acc: 95%] [G loss: 1.190376]\n",
      "[Epoch 1/200] [Batch 599/938] [D loss: 1.096409, acc: 92%] [G loss: 1.209532]\n",
      "[Epoch 1/200] [Batch 600/938] [D loss: 1.106092, acc: 91%] [G loss: 1.220609]\n",
      "[Epoch 1/200] [Batch 601/938] [D loss: 1.112378, acc: 92%] [G loss: 1.165605]\n",
      "[Epoch 1/200] [Batch 602/938] [D loss: 1.095069, acc: 91%] [G loss: 1.192388]\n",
      "[Epoch 1/200] [Batch 603/938] [D loss: 1.105735, acc: 92%] [G loss: 1.192751]\n",
      "[Epoch 1/200] [Batch 604/938] [D loss: 1.080370, acc: 89%] [G loss: 1.187865]\n",
      "[Epoch 1/200] [Batch 605/938] [D loss: 1.083506, acc: 89%] [G loss: 1.209511]\n",
      "[Epoch 1/200] [Batch 606/938] [D loss: 1.117077, acc: 92%] [G loss: 1.173446]\n",
      "[Epoch 1/200] [Batch 607/938] [D loss: 1.100768, acc: 91%] [G loss: 1.188439]\n",
      "[Epoch 1/200] [Batch 608/938] [D loss: 1.068448, acc: 92%] [G loss: 1.186857]\n",
      "[Epoch 1/200] [Batch 609/938] [D loss: 1.090221, acc: 91%] [G loss: 1.208021]\n",
      "[Epoch 1/200] [Batch 610/938] [D loss: 1.076925, acc: 89%] [G loss: 1.267695]\n",
      "[Epoch 1/200] [Batch 611/938] [D loss: 1.105762, acc: 89%] [G loss: 1.243001]\n",
      "[Epoch 1/200] [Batch 612/938] [D loss: 1.061022, acc: 90%] [G loss: 1.240982]\n",
      "[Epoch 1/200] [Batch 613/938] [D loss: 1.111670, acc: 93%] [G loss: 1.193707]\n",
      "[Epoch 1/200] [Batch 614/938] [D loss: 1.081460, acc: 91%] [G loss: 1.269183]\n",
      "[Epoch 1/200] [Batch 615/938] [D loss: 1.082607, acc: 94%] [G loss: 1.152714]\n",
      "[Epoch 1/200] [Batch 616/938] [D loss: 1.070834, acc: 89%] [G loss: 1.177302]\n",
      "[Epoch 1/200] [Batch 617/938] [D loss: 1.097945, acc: 91%] [G loss: 1.225175]\n",
      "[Epoch 1/200] [Batch 618/938] [D loss: 1.130617, acc: 88%] [G loss: 1.231846]\n",
      "[Epoch 1/200] [Batch 619/938] [D loss: 1.127760, acc: 88%] [G loss: 1.172201]\n",
      "[Epoch 1/200] [Batch 620/938] [D loss: 1.066769, acc: 95%] [G loss: 1.150810]\n",
      "[Epoch 1/200] [Batch 621/938] [D loss: 1.079239, acc: 90%] [G loss: 1.200869]\n",
      "[Epoch 1/200] [Batch 622/938] [D loss: 1.103847, acc: 89%] [G loss: 1.140267]\n",
      "[Epoch 1/200] [Batch 623/938] [D loss: 1.079778, acc: 89%] [G loss: 1.175892]\n",
      "[Epoch 1/200] [Batch 624/938] [D loss: 1.068966, acc: 94%] [G loss: 1.228220]\n",
      "[Epoch 1/200] [Batch 625/938] [D loss: 1.096356, acc: 89%] [G loss: 1.172410]\n",
      "[Epoch 1/200] [Batch 626/938] [D loss: 1.047776, acc: 91%] [G loss: 1.214353]\n",
      "[Epoch 1/200] [Batch 627/938] [D loss: 1.043992, acc: 96%] [G loss: 1.272941]\n",
      "[Epoch 1/200] [Batch 628/938] [D loss: 1.048502, acc: 92%] [G loss: 1.196517]\n",
      "[Epoch 1/200] [Batch 629/938] [D loss: 1.102053, acc: 90%] [G loss: 1.187997]\n",
      "[Epoch 1/200] [Batch 630/938] [D loss: 1.066199, acc: 93%] [G loss: 1.235526]\n",
      "[Epoch 1/200] [Batch 631/938] [D loss: 1.088295, acc: 92%] [G loss: 1.161811]\n",
      "[Epoch 1/200] [Batch 632/938] [D loss: 1.068710, acc: 92%] [G loss: 1.211429]\n",
      "[Epoch 1/200] [Batch 633/938] [D loss: 1.107016, acc: 89%] [G loss: 1.258040]\n",
      "[Epoch 1/200] [Batch 634/938] [D loss: 1.090193, acc: 89%] [G loss: 1.132131]\n",
      "[Epoch 1/200] [Batch 635/938] [D loss: 1.103458, acc: 91%] [G loss: 1.171160]\n",
      "[Epoch 1/200] [Batch 636/938] [D loss: 1.105474, acc: 90%] [G loss: 1.179469]\n",
      "[Epoch 1/200] [Batch 637/938] [D loss: 1.096033, acc: 87%] [G loss: 1.234106]\n",
      "[Epoch 1/200] [Batch 638/938] [D loss: 1.116316, acc: 90%] [G loss: 1.182650]\n",
      "[Epoch 1/200] [Batch 639/938] [D loss: 1.056842, acc: 95%] [G loss: 1.198152]\n",
      "[Epoch 1/200] [Batch 640/938] [D loss: 1.102225, acc: 89%] [G loss: 1.214241]\n",
      "[Epoch 1/200] [Batch 641/938] [D loss: 1.130363, acc: 89%] [G loss: 1.159739]\n",
      "[Epoch 1/200] [Batch 642/938] [D loss: 1.100168, acc: 94%] [G loss: 1.157038]\n",
      "[Epoch 1/200] [Batch 643/938] [D loss: 1.082711, acc: 88%] [G loss: 1.200124]\n",
      "[Epoch 1/200] [Batch 644/938] [D loss: 1.080437, acc: 92%] [G loss: 1.194253]\n",
      "[Epoch 1/200] [Batch 645/938] [D loss: 1.094812, acc: 90%] [G loss: 1.179818]\n",
      "[Epoch 1/200] [Batch 646/938] [D loss: 1.069086, acc: 95%] [G loss: 1.212381]\n",
      "[Epoch 1/200] [Batch 647/938] [D loss: 1.122092, acc: 89%] [G loss: 1.211347]\n",
      "[Epoch 1/200] [Batch 648/938] [D loss: 1.053070, acc: 91%] [G loss: 1.183460]\n",
      "[Epoch 1/200] [Batch 649/938] [D loss: 1.092085, acc: 92%] [G loss: 1.256991]\n",
      "[Epoch 1/200] [Batch 650/938] [D loss: 1.062552, acc: 92%] [G loss: 1.150530]\n",
      "[Epoch 1/200] [Batch 651/938] [D loss: 1.074908, acc: 89%] [G loss: 1.197689]\n",
      "[Epoch 1/200] [Batch 652/938] [D loss: 1.067859, acc: 95%] [G loss: 1.153008]\n",
      "[Epoch 1/200] [Batch 653/938] [D loss: 1.055570, acc: 92%] [G loss: 1.212534]\n",
      "[Epoch 1/200] [Batch 654/938] [D loss: 1.062854, acc: 91%] [G loss: 1.210337]\n",
      "[Epoch 1/200] [Batch 655/938] [D loss: 1.077399, acc: 89%] [G loss: 1.209814]\n",
      "[Epoch 1/200] [Batch 656/938] [D loss: 1.068876, acc: 92%] [G loss: 1.204008]\n",
      "[Epoch 1/200] [Batch 657/938] [D loss: 1.077688, acc: 90%] [G loss: 1.266797]\n",
      "[Epoch 1/200] [Batch 658/938] [D loss: 1.098422, acc: 93%] [G loss: 1.213688]\n",
      "[Epoch 1/200] [Batch 659/938] [D loss: 1.082108, acc: 91%] [G loss: 1.223216]\n",
      "[Epoch 1/200] [Batch 660/938] [D loss: 1.102914, acc: 89%] [G loss: 1.153998]\n",
      "[Epoch 1/200] [Batch 661/938] [D loss: 1.109586, acc: 92%] [G loss: 1.130979]\n",
      "[Epoch 1/200] [Batch 662/938] [D loss: 1.100242, acc: 89%] [G loss: 1.183059]\n",
      "[Epoch 1/200] [Batch 663/938] [D loss: 1.049690, acc: 87%] [G loss: 1.218799]\n",
      "[Epoch 1/200] [Batch 664/938] [D loss: 1.055642, acc: 94%] [G loss: 1.217705]\n",
      "[Epoch 1/200] [Batch 665/938] [D loss: 1.068319, acc: 91%] [G loss: 1.173727]\n",
      "[Epoch 1/200] [Batch 666/938] [D loss: 1.072758, acc: 89%] [G loss: 1.249403]\n",
      "[Epoch 1/200] [Batch 667/938] [D loss: 1.084652, acc: 91%] [G loss: 1.158563]\n",
      "[Epoch 1/200] [Batch 668/938] [D loss: 1.088066, acc: 92%] [G loss: 1.194824]\n",
      "[Epoch 1/200] [Batch 669/938] [D loss: 1.054610, acc: 92%] [G loss: 1.195385]\n",
      "[Epoch 1/200] [Batch 670/938] [D loss: 1.068016, acc: 91%] [G loss: 1.275797]\n",
      "[Epoch 1/200] [Batch 671/938] [D loss: 1.123035, acc: 88%] [G loss: 1.191727]\n",
      "[Epoch 1/200] [Batch 672/938] [D loss: 1.075406, acc: 92%] [G loss: 1.172792]\n",
      "[Epoch 1/200] [Batch 673/938] [D loss: 1.109807, acc: 89%] [G loss: 1.216381]\n",
      "[Epoch 1/200] [Batch 674/938] [D loss: 1.100759, acc: 90%] [G loss: 1.226217]\n",
      "[Epoch 1/200] [Batch 675/938] [D loss: 1.087648, acc: 89%] [G loss: 1.170222]\n",
      "[Epoch 1/200] [Batch 676/938] [D loss: 1.118464, acc: 95%] [G loss: 1.162806]\n",
      "[Epoch 1/200] [Batch 677/938] [D loss: 1.094053, acc: 88%] [G loss: 1.212906]\n",
      "[Epoch 1/200] [Batch 678/938] [D loss: 1.108452, acc: 89%] [G loss: 1.212092]\n",
      "[Epoch 1/200] [Batch 679/938] [D loss: 1.084656, acc: 89%] [G loss: 1.142769]\n",
      "[Epoch 1/200] [Batch 680/938] [D loss: 1.117366, acc: 92%] [G loss: 1.174046]\n",
      "[Epoch 1/200] [Batch 681/938] [D loss: 1.092284, acc: 88%] [G loss: 1.209889]\n",
      "[Epoch 1/200] [Batch 682/938] [D loss: 1.083763, acc: 91%] [G loss: 1.202569]\n",
      "[Epoch 1/200] [Batch 683/938] [D loss: 1.076409, acc: 90%] [G loss: 1.201077]\n",
      "[Epoch 1/200] [Batch 684/938] [D loss: 1.059451, acc: 92%] [G loss: 1.187456]\n",
      "[Epoch 1/200] [Batch 685/938] [D loss: 1.080184, acc: 92%] [G loss: 1.232502]\n",
      "[Epoch 1/200] [Batch 686/938] [D loss: 1.128903, acc: 92%] [G loss: 1.245525]\n",
      "[Epoch 1/200] [Batch 687/938] [D loss: 1.104043, acc: 90%] [G loss: 1.245631]\n",
      "[Epoch 1/200] [Batch 688/938] [D loss: 1.089811, acc: 92%] [G loss: 1.211379]\n",
      "[Epoch 1/200] [Batch 689/938] [D loss: 1.106236, acc: 90%] [G loss: 1.153490]\n",
      "[Epoch 1/200] [Batch 690/938] [D loss: 1.088132, acc: 89%] [G loss: 1.202306]\n",
      "[Epoch 1/200] [Batch 691/938] [D loss: 1.087582, acc: 94%] [G loss: 1.145979]\n",
      "[Epoch 1/200] [Batch 692/938] [D loss: 1.100702, acc: 94%] [G loss: 1.195401]\n",
      "[Epoch 1/200] [Batch 693/938] [D loss: 1.054206, acc: 94%] [G loss: 1.251132]\n",
      "[Epoch 1/200] [Batch 694/938] [D loss: 1.081571, acc: 91%] [G loss: 1.111644]\n",
      "[Epoch 1/200] [Batch 695/938] [D loss: 1.121772, acc: 89%] [G loss: 1.162096]\n",
      "[Epoch 1/200] [Batch 696/938] [D loss: 1.091059, acc: 94%] [G loss: 1.161933]\n",
      "[Epoch 1/200] [Batch 697/938] [D loss: 1.072561, acc: 96%] [G loss: 1.142223]\n",
      "[Epoch 1/200] [Batch 698/938] [D loss: 1.087804, acc: 92%] [G loss: 1.234824]\n",
      "[Epoch 1/200] [Batch 699/938] [D loss: 1.050448, acc: 95%] [G loss: 1.227127]\n",
      "[Epoch 1/200] [Batch 700/938] [D loss: 1.049791, acc: 93%] [G loss: 1.182539]\n",
      "[Epoch 1/200] [Batch 701/938] [D loss: 1.123459, acc: 90%] [G loss: 1.229792]\n",
      "[Epoch 1/200] [Batch 702/938] [D loss: 1.075365, acc: 94%] [G loss: 1.275083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 703/938] [D loss: 1.110881, acc: 87%] [G loss: 1.284045]\n",
      "[Epoch 1/200] [Batch 704/938] [D loss: 1.056074, acc: 92%] [G loss: 1.191466]\n",
      "[Epoch 1/200] [Batch 705/938] [D loss: 1.069681, acc: 94%] [G loss: 1.234897]\n",
      "[Epoch 1/200] [Batch 706/938] [D loss: 1.052445, acc: 95%] [G loss: 1.148785]\n",
      "[Epoch 1/200] [Batch 707/938] [D loss: 1.135362, acc: 89%] [G loss: 1.127294]\n",
      "[Epoch 1/200] [Batch 708/938] [D loss: 1.073953, acc: 90%] [G loss: 1.174437]\n",
      "[Epoch 1/200] [Batch 709/938] [D loss: 1.118593, acc: 90%] [G loss: 1.211040]\n",
      "[Epoch 1/200] [Batch 710/938] [D loss: 1.086593, acc: 93%] [G loss: 1.228438]\n",
      "[Epoch 1/200] [Batch 711/938] [D loss: 1.084966, acc: 90%] [G loss: 1.136594]\n",
      "[Epoch 1/200] [Batch 712/938] [D loss: 1.087773, acc: 91%] [G loss: 1.152157]\n",
      "[Epoch 1/200] [Batch 713/938] [D loss: 1.109334, acc: 91%] [G loss: 1.160594]\n",
      "[Epoch 1/200] [Batch 714/938] [D loss: 1.106945, acc: 92%] [G loss: 1.191035]\n",
      "[Epoch 1/200] [Batch 715/938] [D loss: 1.114890, acc: 86%] [G loss: 1.222505]\n",
      "[Epoch 1/200] [Batch 716/938] [D loss: 1.079959, acc: 89%] [G loss: 1.217811]\n",
      "[Epoch 1/200] [Batch 717/938] [D loss: 1.114224, acc: 87%] [G loss: 1.125951]\n",
      "[Epoch 1/200] [Batch 718/938] [D loss: 1.068570, acc: 90%] [G loss: 1.163221]\n",
      "[Epoch 1/200] [Batch 719/938] [D loss: 1.091131, acc: 89%] [G loss: 1.155298]\n",
      "[Epoch 1/200] [Batch 720/938] [D loss: 1.108875, acc: 91%] [G loss: 1.212297]\n",
      "[Epoch 1/200] [Batch 721/938] [D loss: 1.114452, acc: 87%] [G loss: 1.158436]\n",
      "[Epoch 1/200] [Batch 722/938] [D loss: 1.078618, acc: 92%] [G loss: 1.141459]\n",
      "[Epoch 1/200] [Batch 723/938] [D loss: 1.133192, acc: 86%] [G loss: 1.169389]\n",
      "[Epoch 1/200] [Batch 724/938] [D loss: 1.097935, acc: 92%] [G loss: 1.223374]\n",
      "[Epoch 1/200] [Batch 725/938] [D loss: 1.093188, acc: 93%] [G loss: 1.156810]\n",
      "[Epoch 1/200] [Batch 726/938] [D loss: 1.077715, acc: 93%] [G loss: 1.183304]\n",
      "[Epoch 1/200] [Batch 727/938] [D loss: 1.082450, acc: 96%] [G loss: 1.174749]\n",
      "[Epoch 1/200] [Batch 728/938] [D loss: 1.070448, acc: 92%] [G loss: 1.166625]\n",
      "[Epoch 1/200] [Batch 729/938] [D loss: 1.083664, acc: 92%] [G loss: 1.175035]\n",
      "[Epoch 1/200] [Batch 730/938] [D loss: 1.123488, acc: 89%] [G loss: 1.231658]\n",
      "[Epoch 1/200] [Batch 731/938] [D loss: 1.089323, acc: 92%] [G loss: 1.220507]\n",
      "[Epoch 1/200] [Batch 732/938] [D loss: 1.075787, acc: 91%] [G loss: 1.114731]\n",
      "[Epoch 1/200] [Batch 733/938] [D loss: 1.102590, acc: 90%] [G loss: 1.171952]\n",
      "[Epoch 1/200] [Batch 734/938] [D loss: 1.106193, acc: 91%] [G loss: 1.204004]\n",
      "[Epoch 1/200] [Batch 735/938] [D loss: 1.090528, acc: 96%] [G loss: 1.198525]\n",
      "[Epoch 1/200] [Batch 736/938] [D loss: 1.083103, acc: 92%] [G loss: 1.218306]\n",
      "[Epoch 1/200] [Batch 737/938] [D loss: 1.110699, acc: 92%] [G loss: 1.130070]\n",
      "[Epoch 1/200] [Batch 738/938] [D loss: 1.063935, acc: 92%] [G loss: 1.145528]\n",
      "[Epoch 1/200] [Batch 739/938] [D loss: 1.080523, acc: 92%] [G loss: 1.177307]\n",
      "[Epoch 1/200] [Batch 740/938] [D loss: 1.082967, acc: 91%] [G loss: 1.140171]\n",
      "[Epoch 1/200] [Batch 741/938] [D loss: 1.059944, acc: 99%] [G loss: 1.196072]\n",
      "[Epoch 1/200] [Batch 742/938] [D loss: 1.088640, acc: 89%] [G loss: 1.209263]\n",
      "[Epoch 1/200] [Batch 743/938] [D loss: 1.095054, acc: 91%] [G loss: 1.141957]\n",
      "[Epoch 1/200] [Batch 744/938] [D loss: 1.104833, acc: 91%] [G loss: 1.152841]\n",
      "[Epoch 1/200] [Batch 745/938] [D loss: 1.099632, acc: 92%] [G loss: 1.174059]\n",
      "[Epoch 1/200] [Batch 746/938] [D loss: 1.067052, acc: 93%] [G loss: 1.172183]\n",
      "[Epoch 1/200] [Batch 747/938] [D loss: 1.032220, acc: 94%] [G loss: 1.219522]\n",
      "[Epoch 1/200] [Batch 748/938] [D loss: 1.077605, acc: 91%] [G loss: 1.263858]\n",
      "[Epoch 1/200] [Batch 749/938] [D loss: 1.097247, acc: 89%] [G loss: 1.227296]\n",
      "[Epoch 1/200] [Batch 750/938] [D loss: 1.092302, acc: 92%] [G loss: 1.188670]\n",
      "[Epoch 1/200] [Batch 751/938] [D loss: 1.085200, acc: 94%] [G loss: 1.148969]\n",
      "[Epoch 1/200] [Batch 752/938] [D loss: 1.083398, acc: 93%] [G loss: 1.170128]\n",
      "[Epoch 1/200] [Batch 753/938] [D loss: 1.078316, acc: 94%] [G loss: 1.197646]\n",
      "[Epoch 1/200] [Batch 754/938] [D loss: 1.072784, acc: 91%] [G loss: 1.226876]\n",
      "[Epoch 1/200] [Batch 755/938] [D loss: 1.055406, acc: 96%] [G loss: 1.249269]\n",
      "[Epoch 1/200] [Batch 756/938] [D loss: 1.063912, acc: 95%] [G loss: 1.217058]\n",
      "[Epoch 1/200] [Batch 757/938] [D loss: 1.091115, acc: 89%] [G loss: 1.140489]\n",
      "[Epoch 1/200] [Batch 758/938] [D loss: 1.112569, acc: 95%] [G loss: 1.133002]\n",
      "[Epoch 1/200] [Batch 759/938] [D loss: 1.089162, acc: 88%] [G loss: 1.192994]\n",
      "[Epoch 1/200] [Batch 760/938] [D loss: 1.070013, acc: 96%] [G loss: 1.212113]\n",
      "[Epoch 1/200] [Batch 761/938] [D loss: 1.095670, acc: 92%] [G loss: 1.282411]\n",
      "[Epoch 1/200] [Batch 762/938] [D loss: 1.090072, acc: 91%] [G loss: 1.205778]\n",
      "[Epoch 1/200] [Batch 763/938] [D loss: 1.071481, acc: 92%] [G loss: 1.159438]\n",
      "[Epoch 1/200] [Batch 764/938] [D loss: 1.113068, acc: 90%] [G loss: 1.203766]\n",
      "[Epoch 1/200] [Batch 765/938] [D loss: 1.081574, acc: 91%] [G loss: 1.221045]\n",
      "[Epoch 1/200] [Batch 766/938] [D loss: 1.101599, acc: 93%] [G loss: 1.129584]\n",
      "[Epoch 1/200] [Batch 767/938] [D loss: 1.082133, acc: 92%] [G loss: 1.239334]\n",
      "[Epoch 1/200] [Batch 768/938] [D loss: 1.096642, acc: 86%] [G loss: 1.173911]\n",
      "[Epoch 1/200] [Batch 769/938] [D loss: 1.083535, acc: 93%] [G loss: 1.222180]\n",
      "[Epoch 1/200] [Batch 770/938] [D loss: 1.095224, acc: 89%] [G loss: 1.206866]\n",
      "[Epoch 1/200] [Batch 771/938] [D loss: 1.098772, acc: 92%] [G loss: 1.105923]\n",
      "[Epoch 1/200] [Batch 772/938] [D loss: 1.087735, acc: 93%] [G loss: 1.156518]\n",
      "[Epoch 1/200] [Batch 773/938] [D loss: 1.063599, acc: 95%] [G loss: 1.119843]\n",
      "[Epoch 1/200] [Batch 774/938] [D loss: 1.062068, acc: 91%] [G loss: 1.217452]\n",
      "[Epoch 1/200] [Batch 775/938] [D loss: 1.108655, acc: 93%] [G loss: 1.215775]\n",
      "[Epoch 1/200] [Batch 776/938] [D loss: 1.101549, acc: 91%] [G loss: 1.180443]\n",
      "[Epoch 1/200] [Batch 777/938] [D loss: 1.091139, acc: 93%] [G loss: 1.183429]\n",
      "[Epoch 1/200] [Batch 778/938] [D loss: 1.084697, acc: 93%] [G loss: 1.181469]\n",
      "[Epoch 1/200] [Batch 779/938] [D loss: 1.069255, acc: 90%] [G loss: 1.185618]\n",
      "[Epoch 1/200] [Batch 780/938] [D loss: 1.089679, acc: 90%] [G loss: 1.177485]\n",
      "[Epoch 1/200] [Batch 781/938] [D loss: 1.097498, acc: 92%] [G loss: 1.175615]\n",
      "[Epoch 1/200] [Batch 782/938] [D loss: 1.086960, acc: 92%] [G loss: 1.176144]\n",
      "[Epoch 1/200] [Batch 783/938] [D loss: 1.111632, acc: 92%] [G loss: 1.146626]\n",
      "[Epoch 1/200] [Batch 784/938] [D loss: 1.087788, acc: 95%] [G loss: 1.156623]\n",
      "[Epoch 1/200] [Batch 785/938] [D loss: 1.097238, acc: 93%] [G loss: 1.191937]\n",
      "[Epoch 1/200] [Batch 786/938] [D loss: 1.083446, acc: 93%] [G loss: 1.153930]\n",
      "[Epoch 1/200] [Batch 787/938] [D loss: 1.086484, acc: 92%] [G loss: 1.179217]\n",
      "[Epoch 1/200] [Batch 788/938] [D loss: 1.097311, acc: 92%] [G loss: 1.164403]\n",
      "[Epoch 1/200] [Batch 789/938] [D loss: 1.107925, acc: 94%] [G loss: 1.195298]\n",
      "[Epoch 1/200] [Batch 790/938] [D loss: 1.106240, acc: 92%] [G loss: 1.176725]\n",
      "[Epoch 1/200] [Batch 791/938] [D loss: 1.097026, acc: 91%] [G loss: 1.179124]\n",
      "[Epoch 1/200] [Batch 792/938] [D loss: 1.100344, acc: 92%] [G loss: 1.107627]\n",
      "[Epoch 1/200] [Batch 793/938] [D loss: 1.097122, acc: 92%] [G loss: 1.121847]\n",
      "[Epoch 1/200] [Batch 794/938] [D loss: 1.075285, acc: 93%] [G loss: 1.178970]\n",
      "[Epoch 1/200] [Batch 795/938] [D loss: 1.090412, acc: 92%] [G loss: 1.191601]\n",
      "[Epoch 1/200] [Batch 796/938] [D loss: 1.047211, acc: 96%] [G loss: 1.170726]\n",
      "[Epoch 1/200] [Batch 797/938] [D loss: 1.085568, acc: 94%] [G loss: 1.237914]\n",
      "[Epoch 1/200] [Batch 798/938] [D loss: 1.112370, acc: 89%] [G loss: 1.228124]\n",
      "[Epoch 1/200] [Batch 799/938] [D loss: 1.108948, acc: 89%] [G loss: 1.225407]\n",
      "[Epoch 1/200] [Batch 800/938] [D loss: 1.131793, acc: 85%] [G loss: 1.172108]\n",
      "[Epoch 1/200] [Batch 801/938] [D loss: 1.100316, acc: 93%] [G loss: 1.162632]\n",
      "[Epoch 1/200] [Batch 802/938] [D loss: 1.053721, acc: 93%] [G loss: 1.143514]\n",
      "[Epoch 1/200] [Batch 803/938] [D loss: 1.092249, acc: 91%] [G loss: 1.176521]\n",
      "[Epoch 1/200] [Batch 804/938] [D loss: 1.070526, acc: 92%] [G loss: 1.200626]\n",
      "[Epoch 1/200] [Batch 805/938] [D loss: 1.092707, acc: 92%] [G loss: 1.173152]\n",
      "[Epoch 1/200] [Batch 806/938] [D loss: 1.107671, acc: 89%] [G loss: 1.193423]\n",
      "[Epoch 1/200] [Batch 807/938] [D loss: 1.096479, acc: 95%] [G loss: 1.207252]\n",
      "[Epoch 1/200] [Batch 808/938] [D loss: 1.071251, acc: 95%] [G loss: 1.250716]\n",
      "[Epoch 1/200] [Batch 809/938] [D loss: 1.071937, acc: 90%] [G loss: 1.204785]\n",
      "[Epoch 1/200] [Batch 810/938] [D loss: 1.055834, acc: 91%] [G loss: 1.223630]\n",
      "[Epoch 1/200] [Batch 811/938] [D loss: 1.078452, acc: 89%] [G loss: 1.221042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 812/938] [D loss: 1.084442, acc: 95%] [G loss: 1.173476]\n",
      "[Epoch 1/200] [Batch 813/938] [D loss: 1.083265, acc: 91%] [G loss: 1.161555]\n",
      "[Epoch 1/200] [Batch 814/938] [D loss: 1.087108, acc: 94%] [G loss: 1.181778]\n",
      "[Epoch 1/200] [Batch 815/938] [D loss: 1.086213, acc: 89%] [G loss: 1.257107]\n",
      "[Epoch 1/200] [Batch 816/938] [D loss: 1.091258, acc: 91%] [G loss: 1.205799]\n",
      "[Epoch 1/200] [Batch 817/938] [D loss: 1.077052, acc: 93%] [G loss: 1.205646]\n",
      "[Epoch 1/200] [Batch 818/938] [D loss: 1.121982, acc: 94%] [G loss: 1.135620]\n",
      "[Epoch 1/200] [Batch 819/938] [D loss: 1.064527, acc: 90%] [G loss: 1.248376]\n",
      "[Epoch 1/200] [Batch 820/938] [D loss: 1.081683, acc: 93%] [G loss: 1.182791]\n",
      "[Epoch 1/200] [Batch 821/938] [D loss: 1.058604, acc: 97%] [G loss: 1.170238]\n",
      "[Epoch 1/200] [Batch 822/938] [D loss: 1.099361, acc: 94%] [G loss: 1.128874]\n",
      "[Epoch 1/200] [Batch 823/938] [D loss: 1.088974, acc: 92%] [G loss: 1.180853]\n",
      "[Epoch 1/200] [Batch 824/938] [D loss: 1.088386, acc: 95%] [G loss: 1.238029]\n",
      "[Epoch 1/200] [Batch 825/938] [D loss: 1.095839, acc: 93%] [G loss: 1.115719]\n",
      "[Epoch 1/200] [Batch 826/938] [D loss: 1.079270, acc: 89%] [G loss: 1.213540]\n",
      "[Epoch 1/200] [Batch 827/938] [D loss: 1.113809, acc: 89%] [G loss: 1.246579]\n",
      "[Epoch 1/200] [Batch 828/938] [D loss: 1.138078, acc: 89%] [G loss: 1.215410]\n",
      "[Epoch 1/200] [Batch 829/938] [D loss: 1.074318, acc: 92%] [G loss: 1.204886]\n",
      "[Epoch 1/200] [Batch 830/938] [D loss: 1.073570, acc: 92%] [G loss: 1.215200]\n",
      "[Epoch 1/200] [Batch 831/938] [D loss: 1.080511, acc: 96%] [G loss: 1.110016]\n",
      "[Epoch 1/200] [Batch 832/938] [D loss: 1.075515, acc: 93%] [G loss: 1.203033]\n",
      "[Epoch 1/200] [Batch 833/938] [D loss: 1.044654, acc: 94%] [G loss: 1.181574]\n",
      "[Epoch 1/200] [Batch 834/938] [D loss: 1.073467, acc: 93%] [G loss: 1.169154]\n",
      "[Epoch 1/200] [Batch 835/938] [D loss: 1.064361, acc: 95%] [G loss: 1.145967]\n",
      "[Epoch 1/200] [Batch 836/938] [D loss: 1.093890, acc: 91%] [G loss: 1.212551]\n",
      "[Epoch 1/200] [Batch 837/938] [D loss: 1.124885, acc: 89%] [G loss: 1.228156]\n",
      "[Epoch 1/200] [Batch 838/938] [D loss: 1.108159, acc: 93%] [G loss: 1.206947]\n",
      "[Epoch 1/200] [Batch 839/938] [D loss: 1.065631, acc: 96%] [G loss: 1.218911]\n",
      "[Epoch 1/200] [Batch 840/938] [D loss: 1.096470, acc: 92%] [G loss: 1.179419]\n",
      "[Epoch 1/200] [Batch 841/938] [D loss: 1.092616, acc: 92%] [G loss: 1.209148]\n",
      "[Epoch 1/200] [Batch 842/938] [D loss: 1.087075, acc: 89%] [G loss: 1.245239]\n",
      "[Epoch 1/200] [Batch 843/938] [D loss: 1.114313, acc: 90%] [G loss: 1.158239]\n",
      "[Epoch 1/200] [Batch 844/938] [D loss: 1.060324, acc: 93%] [G loss: 1.204543]\n",
      "[Epoch 1/200] [Batch 845/938] [D loss: 1.062370, acc: 92%] [G loss: 1.247076]\n",
      "[Epoch 1/200] [Batch 846/938] [D loss: 1.078154, acc: 93%] [G loss: 1.259536]\n",
      "[Epoch 1/200] [Batch 847/938] [D loss: 1.104740, acc: 89%] [G loss: 1.130640]\n",
      "[Epoch 1/200] [Batch 848/938] [D loss: 1.086487, acc: 89%] [G loss: 1.140635]\n",
      "[Epoch 1/200] [Batch 849/938] [D loss: 1.059549, acc: 92%] [G loss: 1.209837]\n",
      "[Epoch 1/200] [Batch 850/938] [D loss: 1.106563, acc: 89%] [G loss: 1.167214]\n",
      "[Epoch 1/200] [Batch 851/938] [D loss: 1.061054, acc: 93%] [G loss: 1.219672]\n",
      "[Epoch 1/200] [Batch 852/938] [D loss: 1.092511, acc: 88%] [G loss: 1.174276]\n",
      "[Epoch 1/200] [Batch 853/938] [D loss: 1.135768, acc: 89%] [G loss: 1.161489]\n",
      "[Epoch 1/200] [Batch 854/938] [D loss: 1.085453, acc: 94%] [G loss: 1.156397]\n",
      "[Epoch 1/200] [Batch 855/938] [D loss: 1.066429, acc: 91%] [G loss: 1.207817]\n",
      "[Epoch 1/200] [Batch 856/938] [D loss: 1.100941, acc: 92%] [G loss: 1.241882]\n",
      "[Epoch 1/200] [Batch 857/938] [D loss: 1.083107, acc: 92%] [G loss: 1.309346]\n",
      "[Epoch 1/200] [Batch 858/938] [D loss: 1.100942, acc: 92%] [G loss: 1.231254]\n",
      "[Epoch 1/200] [Batch 859/938] [D loss: 1.116558, acc: 91%] [G loss: 1.161734]\n",
      "[Epoch 1/200] [Batch 860/938] [D loss: 1.098003, acc: 92%] [G loss: 1.114908]\n",
      "[Epoch 1/200] [Batch 861/938] [D loss: 1.108179, acc: 92%] [G loss: 1.122623]\n",
      "[Epoch 1/200] [Batch 862/938] [D loss: 1.100681, acc: 92%] [G loss: 1.239139]\n",
      "[Epoch 1/200] [Batch 863/938] [D loss: 1.046523, acc: 94%] [G loss: 1.209294]\n",
      "[Epoch 1/200] [Batch 864/938] [D loss: 1.088883, acc: 89%] [G loss: 1.210901]\n",
      "[Epoch 1/200] [Batch 865/938] [D loss: 1.125599, acc: 89%] [G loss: 1.198403]\n",
      "[Epoch 1/200] [Batch 866/938] [D loss: 1.108492, acc: 89%] [G loss: 1.236257]\n",
      "[Epoch 1/200] [Batch 867/938] [D loss: 1.098403, acc: 93%] [G loss: 1.217284]\n",
      "[Epoch 1/200] [Batch 868/938] [D loss: 1.065487, acc: 96%] [G loss: 1.163705]\n",
      "[Epoch 1/200] [Batch 869/938] [D loss: 1.093663, acc: 92%] [G loss: 1.122227]\n",
      "[Epoch 1/200] [Batch 870/938] [D loss: 1.087599, acc: 92%] [G loss: 1.138814]\n",
      "[Epoch 1/200] [Batch 871/938] [D loss: 1.118882, acc: 86%] [G loss: 1.195807]\n",
      "[Epoch 1/200] [Batch 872/938] [D loss: 1.064140, acc: 96%] [G loss: 1.237591]\n",
      "[Epoch 1/200] [Batch 873/938] [D loss: 1.105712, acc: 89%] [G loss: 1.215767]\n",
      "[Epoch 1/200] [Batch 874/938] [D loss: 1.099373, acc: 89%] [G loss: 1.311425]\n",
      "[Epoch 1/200] [Batch 875/938] [D loss: 1.080047, acc: 90%] [G loss: 1.148382]\n",
      "[Epoch 1/200] [Batch 876/938] [D loss: 1.097702, acc: 93%] [G loss: 1.171585]\n",
      "[Epoch 1/200] [Batch 877/938] [D loss: 1.077876, acc: 92%] [G loss: 1.173118]\n",
      "[Epoch 1/200] [Batch 878/938] [D loss: 1.087866, acc: 89%] [G loss: 1.225612]\n",
      "[Epoch 1/200] [Batch 879/938] [D loss: 1.083945, acc: 92%] [G loss: 1.215851]\n",
      "[Epoch 1/200] [Batch 880/938] [D loss: 1.092209, acc: 91%] [G loss: 1.185580]\n",
      "[Epoch 1/200] [Batch 881/938] [D loss: 1.058702, acc: 92%] [G loss: 1.176728]\n",
      "[Epoch 1/200] [Batch 882/938] [D loss: 1.112173, acc: 87%] [G loss: 1.189899]\n",
      "[Epoch 1/200] [Batch 883/938] [D loss: 1.087205, acc: 92%] [G loss: 1.186836]\n",
      "[Epoch 1/200] [Batch 884/938] [D loss: 1.087539, acc: 92%] [G loss: 1.191488]\n",
      "[Epoch 1/200] [Batch 885/938] [D loss: 1.062554, acc: 87%] [G loss: 1.218127]\n",
      "[Epoch 1/200] [Batch 886/938] [D loss: 1.061332, acc: 95%] [G loss: 1.186740]\n",
      "[Epoch 1/200] [Batch 887/938] [D loss: 1.047769, acc: 89%] [G loss: 1.213642]\n",
      "[Epoch 1/200] [Batch 888/938] [D loss: 1.075223, acc: 89%] [G loss: 1.225544]\n",
      "[Epoch 1/200] [Batch 889/938] [D loss: 1.106518, acc: 90%] [G loss: 1.190529]\n",
      "[Epoch 1/200] [Batch 890/938] [D loss: 1.088810, acc: 91%] [G loss: 1.243507]\n",
      "[Epoch 1/200] [Batch 891/938] [D loss: 1.080274, acc: 92%] [G loss: 1.194643]\n",
      "[Epoch 1/200] [Batch 892/938] [D loss: 1.097438, acc: 92%] [G loss: 1.169685]\n",
      "[Epoch 1/200] [Batch 893/938] [D loss: 1.085416, acc: 90%] [G loss: 1.192482]\n",
      "[Epoch 1/200] [Batch 894/938] [D loss: 1.070239, acc: 92%] [G loss: 1.181115]\n",
      "[Epoch 1/200] [Batch 895/938] [D loss: 1.091999, acc: 92%] [G loss: 1.149037]\n",
      "[Epoch 1/200] [Batch 896/938] [D loss: 1.067335, acc: 94%] [G loss: 1.160434]\n",
      "[Epoch 1/200] [Batch 897/938] [D loss: 1.102651, acc: 86%] [G loss: 1.225935]\n",
      "[Epoch 1/200] [Batch 898/938] [D loss: 1.097954, acc: 90%] [G loss: 1.182577]\n",
      "[Epoch 1/200] [Batch 899/938] [D loss: 1.085360, acc: 92%] [G loss: 1.151880]\n",
      "[Epoch 1/200] [Batch 900/938] [D loss: 1.061138, acc: 91%] [G loss: 1.187731]\n",
      "[Epoch 1/200] [Batch 901/938] [D loss: 1.087365, acc: 94%] [G loss: 1.214766]\n",
      "[Epoch 1/200] [Batch 902/938] [D loss: 1.089043, acc: 92%] [G loss: 1.159183]\n",
      "[Epoch 1/200] [Batch 903/938] [D loss: 1.041349, acc: 93%] [G loss: 1.150270]\n",
      "[Epoch 1/200] [Batch 904/938] [D loss: 1.091051, acc: 92%] [G loss: 1.170252]\n",
      "[Epoch 1/200] [Batch 905/938] [D loss: 1.089203, acc: 92%] [G loss: 1.261715]\n",
      "[Epoch 1/200] [Batch 906/938] [D loss: 1.081064, acc: 92%] [G loss: 1.192746]\n",
      "[Epoch 1/200] [Batch 907/938] [D loss: 1.101433, acc: 93%] [G loss: 1.201364]\n",
      "[Epoch 1/200] [Batch 908/938] [D loss: 1.102528, acc: 92%] [G loss: 1.251095]\n",
      "[Epoch 1/200] [Batch 909/938] [D loss: 1.098630, acc: 92%] [G loss: 1.183437]\n",
      "[Epoch 1/200] [Batch 910/938] [D loss: 1.104434, acc: 91%] [G loss: 1.203411]\n",
      "[Epoch 1/200] [Batch 911/938] [D loss: 1.087893, acc: 93%] [G loss: 1.139080]\n",
      "[Epoch 1/200] [Batch 912/938] [D loss: 1.083359, acc: 88%] [G loss: 1.163355]\n",
      "[Epoch 1/200] [Batch 913/938] [D loss: 1.085442, acc: 93%] [G loss: 1.192431]\n",
      "[Epoch 1/200] [Batch 914/938] [D loss: 1.061092, acc: 93%] [G loss: 1.260496]\n",
      "[Epoch 1/200] [Batch 915/938] [D loss: 1.061330, acc: 89%] [G loss: 1.210450]\n",
      "[Epoch 1/200] [Batch 916/938] [D loss: 1.053593, acc: 96%] [G loss: 1.151349]\n",
      "[Epoch 1/200] [Batch 917/938] [D loss: 1.095569, acc: 90%] [G loss: 1.179301]\n",
      "[Epoch 1/200] [Batch 918/938] [D loss: 1.087658, acc: 92%] [G loss: 1.214160]\n",
      "[Epoch 1/200] [Batch 919/938] [D loss: 1.096000, acc: 93%] [G loss: 1.130202]\n",
      "[Epoch 1/200] [Batch 920/938] [D loss: 1.078981, acc: 88%] [G loss: 1.255793]\n",
      "[Epoch 1/200] [Batch 921/938] [D loss: 1.086767, acc: 92%] [G loss: 1.250224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/200] [Batch 922/938] [D loss: 1.122261, acc: 88%] [G loss: 1.216249]\n",
      "[Epoch 1/200] [Batch 923/938] [D loss: 1.086200, acc: 92%] [G loss: 1.189352]\n",
      "[Epoch 1/200] [Batch 924/938] [D loss: 1.094879, acc: 92%] [G loss: 1.228883]\n",
      "[Epoch 1/200] [Batch 925/938] [D loss: 1.066792, acc: 90%] [G loss: 1.111062]\n",
      "[Epoch 1/200] [Batch 926/938] [D loss: 1.084761, acc: 96%] [G loss: 1.128876]\n",
      "[Epoch 1/200] [Batch 927/938] [D loss: 1.088872, acc: 89%] [G loss: 1.173633]\n",
      "[Epoch 1/200] [Batch 928/938] [D loss: 1.080836, acc: 92%] [G loss: 1.194518]\n",
      "[Epoch 1/200] [Batch 929/938] [D loss: 1.083026, acc: 92%] [G loss: 1.221855]\n",
      "[Epoch 1/200] [Batch 930/938] [D loss: 1.083198, acc: 94%] [G loss: 1.211684]\n",
      "[Epoch 1/200] [Batch 931/938] [D loss: 1.107079, acc: 92%] [G loss: 1.174461]\n",
      "[Epoch 1/200] [Batch 932/938] [D loss: 1.072057, acc: 92%] [G loss: 1.193222]\n",
      "[Epoch 1/200] [Batch 933/938] [D loss: 1.104802, acc: 89%] [G loss: 1.151647]\n",
      "[Epoch 1/200] [Batch 934/938] [D loss: 1.051595, acc: 93%] [G loss: 1.235244]\n",
      "[Epoch 1/200] [Batch 935/938] [D loss: 1.086586, acc: 88%] [G loss: 1.199861]\n",
      "[Epoch 1/200] [Batch 936/938] [D loss: 1.053353, acc: 92%] [G loss: 1.277921]\n",
      "[Epoch 1/200] [Batch 937/938] [D loss: 1.083555, acc: 96%] [G loss: 1.185326]\n",
      "[Epoch 2/200] [Batch 0/938] [D loss: 1.056063, acc: 93%] [G loss: 1.165731]\n",
      "[Epoch 2/200] [Batch 1/938] [D loss: 1.089391, acc: 93%] [G loss: 1.153816]\n",
      "[Epoch 2/200] [Batch 2/938] [D loss: 1.084973, acc: 88%] [G loss: 1.265423]\n",
      "[Epoch 2/200] [Batch 3/938] [D loss: 1.086483, acc: 93%] [G loss: 1.139187]\n",
      "[Epoch 2/200] [Batch 4/938] [D loss: 1.096876, acc: 92%] [G loss: 1.159223]\n",
      "[Epoch 2/200] [Batch 5/938] [D loss: 1.061046, acc: 93%] [G loss: 1.205915]\n",
      "[Epoch 2/200] [Batch 6/938] [D loss: 1.100917, acc: 92%] [G loss: 1.194399]\n",
      "[Epoch 2/200] [Batch 7/938] [D loss: 1.110258, acc: 92%] [G loss: 1.130667]\n",
      "[Epoch 2/200] [Batch 8/938] [D loss: 1.100372, acc: 92%] [G loss: 1.131947]\n",
      "[Epoch 2/200] [Batch 9/938] [D loss: 1.102590, acc: 90%] [G loss: 1.227721]\n",
      "[Epoch 2/200] [Batch 10/938] [D loss: 1.075794, acc: 90%] [G loss: 1.281461]\n",
      "[Epoch 2/200] [Batch 11/938] [D loss: 1.074899, acc: 92%] [G loss: 1.219079]\n",
      "[Epoch 2/200] [Batch 12/938] [D loss: 1.093557, acc: 91%] [G loss: 1.154516]\n",
      "[Epoch 2/200] [Batch 13/938] [D loss: 1.067845, acc: 91%] [G loss: 1.272949]\n",
      "[Epoch 2/200] [Batch 14/938] [D loss: 1.042841, acc: 92%] [G loss: 1.147845]\n",
      "[Epoch 2/200] [Batch 15/938] [D loss: 1.101303, acc: 90%] [G loss: 1.185519]\n",
      "[Epoch 2/200] [Batch 16/938] [D loss: 1.089545, acc: 92%] [G loss: 1.159049]\n",
      "[Epoch 2/200] [Batch 17/938] [D loss: 1.099351, acc: 92%] [G loss: 1.228292]\n",
      "[Epoch 2/200] [Batch 18/938] [D loss: 1.135702, acc: 88%] [G loss: 1.229472]\n",
      "[Epoch 2/200] [Batch 19/938] [D loss: 1.076756, acc: 92%] [G loss: 1.201934]\n",
      "[Epoch 2/200] [Batch 20/938] [D loss: 1.064608, acc: 92%] [G loss: 1.115413]\n",
      "[Epoch 2/200] [Batch 21/938] [D loss: 1.103171, acc: 88%] [G loss: 1.191743]\n",
      "[Epoch 2/200] [Batch 22/938] [D loss: 1.080553, acc: 95%] [G loss: 1.156874]\n",
      "[Epoch 2/200] [Batch 23/938] [D loss: 1.092876, acc: 93%] [G loss: 1.139440]\n",
      "[Epoch 2/200] [Batch 24/938] [D loss: 1.089237, acc: 92%] [G loss: 1.150836]\n",
      "[Epoch 2/200] [Batch 25/938] [D loss: 1.080886, acc: 92%] [G loss: 1.176166]\n",
      "[Epoch 2/200] [Batch 26/938] [D loss: 1.079201, acc: 90%] [G loss: 1.214432]\n",
      "[Epoch 2/200] [Batch 27/938] [D loss: 1.078663, acc: 93%] [G loss: 1.205984]\n",
      "[Epoch 2/200] [Batch 28/938] [D loss: 1.110010, acc: 91%] [G loss: 1.232632]\n",
      "[Epoch 2/200] [Batch 29/938] [D loss: 1.158619, acc: 90%] [G loss: 1.120978]\n",
      "[Epoch 2/200] [Batch 30/938] [D loss: 1.086889, acc: 88%] [G loss: 1.214269]\n",
      "[Epoch 2/200] [Batch 31/938] [D loss: 1.074713, acc: 98%] [G loss: 1.187905]\n",
      "[Epoch 2/200] [Batch 32/938] [D loss: 1.101867, acc: 90%] [G loss: 1.186896]\n",
      "[Epoch 2/200] [Batch 33/938] [D loss: 1.107000, acc: 92%] [G loss: 1.155402]\n",
      "[Epoch 2/200] [Batch 34/938] [D loss: 1.079223, acc: 93%] [G loss: 1.231460]\n",
      "[Epoch 2/200] [Batch 35/938] [D loss: 1.083898, acc: 94%] [G loss: 1.204086]\n",
      "[Epoch 2/200] [Batch 36/938] [D loss: 1.089589, acc: 92%] [G loss: 1.264803]\n",
      "[Epoch 2/200] [Batch 37/938] [D loss: 1.102235, acc: 93%] [G loss: 1.104697]\n",
      "[Epoch 2/200] [Batch 38/938] [D loss: 1.086478, acc: 92%] [G loss: 1.142789]\n",
      "[Epoch 2/200] [Batch 39/938] [D loss: 1.077151, acc: 92%] [G loss: 1.226306]\n",
      "[Epoch 2/200] [Batch 40/938] [D loss: 1.079476, acc: 96%] [G loss: 1.200920]\n",
      "[Epoch 2/200] [Batch 41/938] [D loss: 1.104580, acc: 92%] [G loss: 1.204463]\n",
      "[Epoch 2/200] [Batch 42/938] [D loss: 1.059404, acc: 95%] [G loss: 1.234018]\n",
      "[Epoch 2/200] [Batch 43/938] [D loss: 1.071412, acc: 94%] [G loss: 1.163625]\n",
      "[Epoch 2/200] [Batch 44/938] [D loss: 1.059096, acc: 93%] [G loss: 1.278652]\n",
      "[Epoch 2/200] [Batch 45/938] [D loss: 1.049089, acc: 93%] [G loss: 1.220772]\n",
      "[Epoch 2/200] [Batch 46/938] [D loss: 1.077340, acc: 92%] [G loss: 1.119285]\n",
      "[Epoch 2/200] [Batch 47/938] [D loss: 1.070175, acc: 92%] [G loss: 1.149060]\n",
      "[Epoch 2/200] [Batch 48/938] [D loss: 1.077628, acc: 95%] [G loss: 1.205211]\n",
      "[Epoch 2/200] [Batch 49/938] [D loss: 1.054421, acc: 92%] [G loss: 1.299035]\n",
      "[Epoch 2/200] [Batch 50/938] [D loss: 1.086250, acc: 93%] [G loss: 1.159281]\n",
      "[Epoch 2/200] [Batch 51/938] [D loss: 1.083314, acc: 96%] [G loss: 1.157813]\n",
      "[Epoch 2/200] [Batch 52/938] [D loss: 1.069196, acc: 95%] [G loss: 1.199431]\n",
      "[Epoch 2/200] [Batch 53/938] [D loss: 1.072357, acc: 93%] [G loss: 1.192390]\n",
      "[Epoch 2/200] [Batch 54/938] [D loss: 1.125103, acc: 89%] [G loss: 1.142500]\n",
      "[Epoch 2/200] [Batch 55/938] [D loss: 1.090448, acc: 96%] [G loss: 1.196301]\n",
      "[Epoch 2/200] [Batch 56/938] [D loss: 1.087434, acc: 89%] [G loss: 1.199569]\n",
      "[Epoch 2/200] [Batch 57/938] [D loss: 1.080200, acc: 94%] [G loss: 1.208393]\n",
      "[Epoch 2/200] [Batch 58/938] [D loss: 1.067595, acc: 94%] [G loss: 1.155127]\n",
      "[Epoch 2/200] [Batch 59/938] [D loss: 1.108094, acc: 92%] [G loss: 1.241553]\n",
      "[Epoch 2/200] [Batch 60/938] [D loss: 1.119400, acc: 94%] [G loss: 1.154501]\n",
      "[Epoch 2/200] [Batch 61/938] [D loss: 1.073285, acc: 95%] [G loss: 1.142405]\n",
      "[Epoch 2/200] [Batch 62/938] [D loss: 1.039165, acc: 95%] [G loss: 1.190841]\n",
      "[Epoch 2/200] [Batch 63/938] [D loss: 1.060718, acc: 98%] [G loss: 1.217389]\n",
      "[Epoch 2/200] [Batch 64/938] [D loss: 1.081321, acc: 89%] [G loss: 1.226487]\n",
      "[Epoch 2/200] [Batch 65/938] [D loss: 1.068819, acc: 95%] [G loss: 1.181017]\n",
      "[Epoch 2/200] [Batch 66/938] [D loss: 1.085618, acc: 95%] [G loss: 1.138414]\n",
      "[Epoch 2/200] [Batch 67/938] [D loss: 1.070103, acc: 94%] [G loss: 1.250997]\n",
      "[Epoch 2/200] [Batch 68/938] [D loss: 1.068851, acc: 93%] [G loss: 1.187823]\n",
      "[Epoch 2/200] [Batch 69/938] [D loss: 1.069348, acc: 94%] [G loss: 1.219731]\n",
      "[Epoch 2/200] [Batch 70/938] [D loss: 1.079489, acc: 96%] [G loss: 1.226357]\n",
      "[Epoch 2/200] [Batch 71/938] [D loss: 1.084301, acc: 93%] [G loss: 1.299017]\n",
      "[Epoch 2/200] [Batch 72/938] [D loss: 1.079589, acc: 94%] [G loss: 1.220927]\n",
      "[Epoch 2/200] [Batch 73/938] [D loss: 1.018436, acc: 96%] [G loss: 1.218377]\n",
      "[Epoch 2/200] [Batch 74/938] [D loss: 1.107377, acc: 92%] [G loss: 1.130264]\n",
      "[Epoch 2/200] [Batch 75/938] [D loss: 1.075422, acc: 89%] [G loss: 1.184695]\n",
      "[Epoch 2/200] [Batch 76/938] [D loss: 1.083433, acc: 89%] [G loss: 1.121771]\n",
      "[Epoch 2/200] [Batch 77/938] [D loss: 1.063874, acc: 92%] [G loss: 1.222904]\n",
      "[Epoch 2/200] [Batch 78/938] [D loss: 1.093972, acc: 92%] [G loss: 1.229629]\n",
      "[Epoch 2/200] [Batch 79/938] [D loss: 1.098663, acc: 92%] [G loss: 1.225205]\n",
      "[Epoch 2/200] [Batch 80/938] [D loss: 1.096398, acc: 92%] [G loss: 1.213174]\n",
      "[Epoch 2/200] [Batch 81/938] [D loss: 1.074366, acc: 92%] [G loss: 1.169654]\n",
      "[Epoch 2/200] [Batch 82/938] [D loss: 1.089432, acc: 92%] [G loss: 1.186669]\n",
      "[Epoch 2/200] [Batch 83/938] [D loss: 1.084764, acc: 87%] [G loss: 1.223126]\n",
      "[Epoch 2/200] [Batch 84/938] [D loss: 1.077562, acc: 90%] [G loss: 1.211622]\n",
      "[Epoch 2/200] [Batch 85/938] [D loss: 1.132308, acc: 88%] [G loss: 1.219022]\n",
      "[Epoch 2/200] [Batch 86/938] [D loss: 1.068273, acc: 91%] [G loss: 1.164473]\n",
      "[Epoch 2/200] [Batch 87/938] [D loss: 1.071574, acc: 90%] [G loss: 1.205463]\n",
      "[Epoch 2/200] [Batch 88/938] [D loss: 1.070560, acc: 93%] [G loss: 1.222562]\n",
      "[Epoch 2/200] [Batch 89/938] [D loss: 1.068531, acc: 93%] [G loss: 1.174224]\n",
      "[Epoch 2/200] [Batch 90/938] [D loss: 1.077443, acc: 92%] [G loss: 1.132817]\n",
      "[Epoch 2/200] [Batch 91/938] [D loss: 1.054139, acc: 93%] [G loss: 1.145801]\n",
      "[Epoch 2/200] [Batch 92/938] [D loss: 1.083992, acc: 93%] [G loss: 1.171464]\n",
      "[Epoch 2/200] [Batch 93/938] [D loss: 1.076806, acc: 91%] [G loss: 1.169971]\n",
      "[Epoch 2/200] [Batch 94/938] [D loss: 1.079257, acc: 93%] [G loss: 1.151543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 95/938] [D loss: 1.099721, acc: 89%] [G loss: 1.134580]\n",
      "[Epoch 2/200] [Batch 96/938] [D loss: 1.096458, acc: 94%] [G loss: 1.168743]\n",
      "[Epoch 2/200] [Batch 97/938] [D loss: 1.083063, acc: 92%] [G loss: 1.192424]\n",
      "[Epoch 2/200] [Batch 98/938] [D loss: 1.106440, acc: 89%] [G loss: 1.235529]\n",
      "[Epoch 2/200] [Batch 99/938] [D loss: 1.112875, acc: 93%] [G loss: 1.158508]\n",
      "[Epoch 2/200] [Batch 100/938] [D loss: 1.072821, acc: 92%] [G loss: 1.249027]\n",
      "[Epoch 2/200] [Batch 101/938] [D loss: 1.110922, acc: 92%] [G loss: 1.178440]\n",
      "[Epoch 2/200] [Batch 102/938] [D loss: 1.085529, acc: 92%] [G loss: 1.199084]\n",
      "[Epoch 2/200] [Batch 103/938] [D loss: 1.077188, acc: 92%] [G loss: 1.242974]\n",
      "[Epoch 2/200] [Batch 104/938] [D loss: 1.096449, acc: 88%] [G loss: 1.198884]\n",
      "[Epoch 2/200] [Batch 105/938] [D loss: 1.067680, acc: 91%] [G loss: 1.172022]\n",
      "[Epoch 2/200] [Batch 106/938] [D loss: 1.062970, acc: 94%] [G loss: 1.151137]\n",
      "[Epoch 2/200] [Batch 107/938] [D loss: 1.109775, acc: 92%] [G loss: 1.189330]\n",
      "[Epoch 2/200] [Batch 108/938] [D loss: 1.093249, acc: 95%] [G loss: 1.197980]\n",
      "[Epoch 2/200] [Batch 109/938] [D loss: 1.086074, acc: 91%] [G loss: 1.188254]\n",
      "[Epoch 2/200] [Batch 110/938] [D loss: 1.085005, acc: 90%] [G loss: 1.244948]\n",
      "[Epoch 2/200] [Batch 111/938] [D loss: 1.096014, acc: 89%] [G loss: 1.250140]\n",
      "[Epoch 2/200] [Batch 112/938] [D loss: 1.085386, acc: 89%] [G loss: 1.165753]\n",
      "[Epoch 2/200] [Batch 113/938] [D loss: 1.065120, acc: 90%] [G loss: 1.156521]\n",
      "[Epoch 2/200] [Batch 114/938] [D loss: 1.076109, acc: 87%] [G loss: 1.167898]\n",
      "[Epoch 2/200] [Batch 115/938] [D loss: 1.100634, acc: 87%] [G loss: 1.259681]\n",
      "[Epoch 2/200] [Batch 116/938] [D loss: 1.069858, acc: 89%] [G loss: 1.203128]\n",
      "[Epoch 2/200] [Batch 117/938] [D loss: 1.098281, acc: 90%] [G loss: 1.223977]\n",
      "[Epoch 2/200] [Batch 118/938] [D loss: 1.086338, acc: 92%] [G loss: 1.192804]\n",
      "[Epoch 2/200] [Batch 119/938] [D loss: 1.055035, acc: 92%] [G loss: 1.226248]\n",
      "[Epoch 2/200] [Batch 120/938] [D loss: 1.085286, acc: 93%] [G loss: 1.213374]\n",
      "[Epoch 2/200] [Batch 121/938] [D loss: 1.087754, acc: 94%] [G loss: 1.266529]\n",
      "[Epoch 2/200] [Batch 122/938] [D loss: 1.072298, acc: 94%] [G loss: 1.253449]\n",
      "[Epoch 2/200] [Batch 123/938] [D loss: 1.069958, acc: 92%] [G loss: 1.214245]\n",
      "[Epoch 2/200] [Batch 124/938] [D loss: 1.047920, acc: 95%] [G loss: 1.102145]\n",
      "[Epoch 2/200] [Batch 125/938] [D loss: 1.077284, acc: 94%] [G loss: 1.158270]\n",
      "[Epoch 2/200] [Batch 126/938] [D loss: 1.049547, acc: 92%] [G loss: 1.265060]\n",
      "[Epoch 2/200] [Batch 127/938] [D loss: 1.076860, acc: 93%] [G loss: 1.167751]\n",
      "[Epoch 2/200] [Batch 128/938] [D loss: 1.079503, acc: 93%] [G loss: 1.177784]\n",
      "[Epoch 2/200] [Batch 129/938] [D loss: 1.079988, acc: 94%] [G loss: 1.175156]\n",
      "[Epoch 2/200] [Batch 130/938] [D loss: 1.099787, acc: 93%] [G loss: 1.228580]\n",
      "[Epoch 2/200] [Batch 131/938] [D loss: 1.129052, acc: 89%] [G loss: 1.278484]\n",
      "[Epoch 2/200] [Batch 132/938] [D loss: 1.064463, acc: 92%] [G loss: 1.198345]\n",
      "[Epoch 2/200] [Batch 133/938] [D loss: 1.047720, acc: 94%] [G loss: 1.197900]\n",
      "[Epoch 2/200] [Batch 134/938] [D loss: 1.075256, acc: 95%] [G loss: 1.115560]\n",
      "[Epoch 2/200] [Batch 135/938] [D loss: 1.071191, acc: 90%] [G loss: 1.152803]\n",
      "[Epoch 2/200] [Batch 136/938] [D loss: 1.063935, acc: 92%] [G loss: 1.212535]\n",
      "[Epoch 2/200] [Batch 137/938] [D loss: 1.071564, acc: 93%] [G loss: 1.196607]\n",
      "[Epoch 2/200] [Batch 138/938] [D loss: 1.060787, acc: 93%] [G loss: 1.208729]\n",
      "[Epoch 2/200] [Batch 139/938] [D loss: 1.090254, acc: 93%] [G loss: 1.154978]\n",
      "[Epoch 2/200] [Batch 140/938] [D loss: 1.092175, acc: 92%] [G loss: 1.177087]\n",
      "[Epoch 2/200] [Batch 141/938] [D loss: 1.053168, acc: 92%] [G loss: 1.239053]\n",
      "[Epoch 2/200] [Batch 142/938] [D loss: 1.106954, acc: 94%] [G loss: 1.203161]\n",
      "[Epoch 2/200] [Batch 143/938] [D loss: 1.075184, acc: 89%] [G loss: 1.232655]\n",
      "[Epoch 2/200] [Batch 144/938] [D loss: 1.098707, acc: 89%] [G loss: 1.188148]\n",
      "[Epoch 2/200] [Batch 145/938] [D loss: 1.051692, acc: 94%] [G loss: 1.230702]\n",
      "[Epoch 2/200] [Batch 146/938] [D loss: 1.068449, acc: 94%] [G loss: 1.180285]\n",
      "[Epoch 2/200] [Batch 147/938] [D loss: 1.061970, acc: 91%] [G loss: 1.237855]\n",
      "[Epoch 2/200] [Batch 148/938] [D loss: 1.082260, acc: 94%] [G loss: 1.214286]\n",
      "[Epoch 2/200] [Batch 149/938] [D loss: 1.076377, acc: 93%] [G loss: 1.192858]\n",
      "[Epoch 2/200] [Batch 150/938] [D loss: 1.071209, acc: 93%] [G loss: 1.219471]\n",
      "[Epoch 2/200] [Batch 151/938] [D loss: 1.103900, acc: 91%] [G loss: 1.165649]\n",
      "[Epoch 2/200] [Batch 152/938] [D loss: 1.094109, acc: 95%] [G loss: 1.134760]\n",
      "[Epoch 2/200] [Batch 153/938] [D loss: 1.079063, acc: 93%] [G loss: 1.280650]\n",
      "[Epoch 2/200] [Batch 154/938] [D loss: 1.090808, acc: 92%] [G loss: 1.187415]\n",
      "[Epoch 2/200] [Batch 155/938] [D loss: 1.064135, acc: 92%] [G loss: 1.208484]\n",
      "[Epoch 2/200] [Batch 156/938] [D loss: 1.046207, acc: 95%] [G loss: 1.142881]\n",
      "[Epoch 2/200] [Batch 157/938] [D loss: 1.095441, acc: 92%] [G loss: 1.182261]\n",
      "[Epoch 2/200] [Batch 158/938] [D loss: 1.057920, acc: 95%] [G loss: 1.169793]\n",
      "[Epoch 2/200] [Batch 159/938] [D loss: 1.099412, acc: 89%] [G loss: 1.273980]\n",
      "[Epoch 2/200] [Batch 160/938] [D loss: 1.075796, acc: 93%] [G loss: 1.238499]\n",
      "[Epoch 2/200] [Batch 161/938] [D loss: 1.055901, acc: 93%] [G loss: 1.197863]\n",
      "[Epoch 2/200] [Batch 162/938] [D loss: 1.074087, acc: 91%] [G loss: 1.217569]\n",
      "[Epoch 2/200] [Batch 163/938] [D loss: 1.068971, acc: 92%] [G loss: 1.177667]\n",
      "[Epoch 2/200] [Batch 164/938] [D loss: 1.088444, acc: 92%] [G loss: 1.225605]\n",
      "[Epoch 2/200] [Batch 165/938] [D loss: 1.109810, acc: 91%] [G loss: 1.190345]\n",
      "[Epoch 2/200] [Batch 166/938] [D loss: 1.049737, acc: 92%] [G loss: 1.303039]\n",
      "[Epoch 2/200] [Batch 167/938] [D loss: 1.079688, acc: 87%] [G loss: 1.226458]\n",
      "[Epoch 2/200] [Batch 168/938] [D loss: 1.091597, acc: 92%] [G loss: 1.191397]\n",
      "[Epoch 2/200] [Batch 169/938] [D loss: 1.063177, acc: 94%] [G loss: 1.217843]\n",
      "[Epoch 2/200] [Batch 170/938] [D loss: 1.089507, acc: 91%] [G loss: 1.159586]\n",
      "[Epoch 2/200] [Batch 171/938] [D loss: 1.076704, acc: 95%] [G loss: 1.120271]\n",
      "[Epoch 2/200] [Batch 172/938] [D loss: 1.032816, acc: 93%] [G loss: 1.204659]\n",
      "[Epoch 2/200] [Batch 173/938] [D loss: 1.107929, acc: 90%] [G loss: 1.249195]\n",
      "[Epoch 2/200] [Batch 174/938] [D loss: 1.071786, acc: 93%] [G loss: 1.202064]\n",
      "[Epoch 2/200] [Batch 175/938] [D loss: 1.081297, acc: 94%] [G loss: 1.174414]\n",
      "[Epoch 2/200] [Batch 176/938] [D loss: 1.087520, acc: 93%] [G loss: 1.183385]\n",
      "[Epoch 2/200] [Batch 177/938] [D loss: 1.053045, acc: 92%] [G loss: 1.190197]\n",
      "[Epoch 2/200] [Batch 178/938] [D loss: 1.051603, acc: 92%] [G loss: 1.260346]\n",
      "[Epoch 2/200] [Batch 179/938] [D loss: 1.080903, acc: 89%] [G loss: 1.167910]\n",
      "[Epoch 2/200] [Batch 180/938] [D loss: 1.116795, acc: 89%] [G loss: 1.185086]\n",
      "[Epoch 2/200] [Batch 181/938] [D loss: 1.088495, acc: 91%] [G loss: 1.167272]\n",
      "[Epoch 2/200] [Batch 182/938] [D loss: 1.077207, acc: 91%] [G loss: 1.210835]\n",
      "[Epoch 2/200] [Batch 183/938] [D loss: 1.033803, acc: 92%] [G loss: 1.173708]\n",
      "[Epoch 2/200] [Batch 184/938] [D loss: 1.083052, acc: 92%] [G loss: 1.296462]\n",
      "[Epoch 2/200] [Batch 185/938] [D loss: 1.046013, acc: 93%] [G loss: 1.274500]\n",
      "[Epoch 2/200] [Batch 186/938] [D loss: 1.109393, acc: 91%] [G loss: 1.199373]\n",
      "[Epoch 2/200] [Batch 187/938] [D loss: 1.087781, acc: 88%] [G loss: 1.183119]\n",
      "[Epoch 2/200] [Batch 188/938] [D loss: 1.089582, acc: 94%] [G loss: 1.116902]\n",
      "[Epoch 2/200] [Batch 189/938] [D loss: 1.077641, acc: 90%] [G loss: 1.227904]\n",
      "[Epoch 2/200] [Batch 190/938] [D loss: 1.087222, acc: 92%] [G loss: 1.179545]\n",
      "[Epoch 2/200] [Batch 191/938] [D loss: 1.081343, acc: 94%] [G loss: 1.162131]\n",
      "[Epoch 2/200] [Batch 192/938] [D loss: 1.077738, acc: 96%] [G loss: 1.157936]\n",
      "[Epoch 2/200] [Batch 193/938] [D loss: 1.086317, acc: 93%] [G loss: 1.248760]\n",
      "[Epoch 2/200] [Batch 194/938] [D loss: 1.109059, acc: 89%] [G loss: 1.251955]\n",
      "[Epoch 2/200] [Batch 195/938] [D loss: 1.088143, acc: 93%] [G loss: 1.120763]\n",
      "[Epoch 2/200] [Batch 196/938] [D loss: 1.118528, acc: 91%] [G loss: 1.087394]\n",
      "[Epoch 2/200] [Batch 197/938] [D loss: 1.109328, acc: 93%] [G loss: 1.173643]\n",
      "[Epoch 2/200] [Batch 198/938] [D loss: 1.132823, acc: 88%] [G loss: 1.160534]\n",
      "[Epoch 2/200] [Batch 199/938] [D loss: 1.062557, acc: 96%] [G loss: 1.151700]\n",
      "[Epoch 2/200] [Batch 200/938] [D loss: 1.066947, acc: 91%] [G loss: 1.161172]\n",
      "[Epoch 2/200] [Batch 201/938] [D loss: 1.113788, acc: 92%] [G loss: 1.096732]\n",
      "[Epoch 2/200] [Batch 202/938] [D loss: 1.101438, acc: 91%] [G loss: 1.176336]\n",
      "[Epoch 2/200] [Batch 203/938] [D loss: 1.118357, acc: 89%] [G loss: 1.231452]\n",
      "[Epoch 2/200] [Batch 204/938] [D loss: 1.093827, acc: 92%] [G loss: 1.182357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 205/938] [D loss: 1.114635, acc: 92%] [G loss: 1.144394]\n",
      "[Epoch 2/200] [Batch 206/938] [D loss: 1.091340, acc: 94%] [G loss: 1.191115]\n",
      "[Epoch 2/200] [Batch 207/938] [D loss: 1.067688, acc: 93%] [G loss: 1.225463]\n",
      "[Epoch 2/200] [Batch 208/938] [D loss: 1.104006, acc: 88%] [G loss: 1.181642]\n",
      "[Epoch 2/200] [Batch 209/938] [D loss: 1.067493, acc: 90%] [G loss: 1.224373]\n",
      "[Epoch 2/200] [Batch 210/938] [D loss: 1.098975, acc: 92%] [G loss: 1.185241]\n",
      "[Epoch 2/200] [Batch 211/938] [D loss: 1.071168, acc: 93%] [G loss: 1.185919]\n",
      "[Epoch 2/200] [Batch 212/938] [D loss: 1.053276, acc: 93%] [G loss: 1.119830]\n",
      "[Epoch 2/200] [Batch 213/938] [D loss: 1.068880, acc: 92%] [G loss: 1.180291]\n",
      "[Epoch 2/200] [Batch 214/938] [D loss: 1.121850, acc: 91%] [G loss: 1.191224]\n",
      "[Epoch 2/200] [Batch 215/938] [D loss: 1.076279, acc: 93%] [G loss: 1.178318]\n",
      "[Epoch 2/200] [Batch 216/938] [D loss: 1.093066, acc: 94%] [G loss: 1.161463]\n",
      "[Epoch 2/200] [Batch 217/938] [D loss: 1.101863, acc: 92%] [G loss: 1.237606]\n",
      "[Epoch 2/200] [Batch 218/938] [D loss: 1.076861, acc: 96%] [G loss: 1.171909]\n",
      "[Epoch 2/200] [Batch 219/938] [D loss: 1.076523, acc: 92%] [G loss: 1.212574]\n",
      "[Epoch 2/200] [Batch 220/938] [D loss: 1.072484, acc: 93%] [G loss: 1.218558]\n",
      "[Epoch 2/200] [Batch 221/938] [D loss: 1.082768, acc: 89%] [G loss: 1.232089]\n",
      "[Epoch 2/200] [Batch 222/938] [D loss: 1.066589, acc: 96%] [G loss: 1.175667]\n",
      "[Epoch 2/200] [Batch 223/938] [D loss: 1.072961, acc: 95%] [G loss: 1.132105]\n",
      "[Epoch 2/200] [Batch 224/938] [D loss: 1.121128, acc: 92%] [G loss: 1.156221]\n",
      "[Epoch 2/200] [Batch 225/938] [D loss: 1.035395, acc: 98%] [G loss: 1.224939]\n",
      "[Epoch 2/200] [Batch 226/938] [D loss: 1.078567, acc: 96%] [G loss: 1.186574]\n",
      "[Epoch 2/200] [Batch 227/938] [D loss: 1.070692, acc: 93%] [G loss: 1.207615]\n",
      "[Epoch 2/200] [Batch 228/938] [D loss: 1.081989, acc: 93%] [G loss: 1.123174]\n",
      "[Epoch 2/200] [Batch 229/938] [D loss: 1.058438, acc: 93%] [G loss: 1.155166]\n",
      "[Epoch 2/200] [Batch 230/938] [D loss: 1.074052, acc: 92%] [G loss: 1.173090]\n",
      "[Epoch 2/200] [Batch 231/938] [D loss: 1.104066, acc: 91%] [G loss: 1.182132]\n",
      "[Epoch 2/200] [Batch 232/938] [D loss: 1.070869, acc: 90%] [G loss: 1.203426]\n",
      "[Epoch 2/200] [Batch 233/938] [D loss: 1.092121, acc: 95%] [G loss: 1.131722]\n",
      "[Epoch 2/200] [Batch 234/938] [D loss: 1.079394, acc: 92%] [G loss: 1.167989]\n",
      "[Epoch 2/200] [Batch 235/938] [D loss: 1.077656, acc: 96%] [G loss: 1.218555]\n",
      "[Epoch 2/200] [Batch 236/938] [D loss: 1.054174, acc: 96%] [G loss: 1.163221]\n",
      "[Epoch 2/200] [Batch 237/938] [D loss: 1.080332, acc: 92%] [G loss: 1.119207]\n",
      "[Epoch 2/200] [Batch 238/938] [D loss: 1.107786, acc: 93%] [G loss: 1.153021]\n",
      "[Epoch 2/200] [Batch 239/938] [D loss: 1.070395, acc: 92%] [G loss: 1.142764]\n",
      "[Epoch 2/200] [Batch 240/938] [D loss: 1.128842, acc: 88%] [G loss: 1.218735]\n",
      "[Epoch 2/200] [Batch 241/938] [D loss: 1.047319, acc: 95%] [G loss: 1.273859]\n",
      "[Epoch 2/200] [Batch 242/938] [D loss: 1.090423, acc: 96%] [G loss: 1.172214]\n",
      "[Epoch 2/200] [Batch 243/938] [D loss: 1.088798, acc: 91%] [G loss: 1.183771]\n",
      "[Epoch 2/200] [Batch 244/938] [D loss: 1.082286, acc: 89%] [G loss: 1.203161]\n",
      "[Epoch 2/200] [Batch 245/938] [D loss: 1.091789, acc: 89%] [G loss: 1.215743]\n",
      "[Epoch 2/200] [Batch 246/938] [D loss: 1.116789, acc: 92%] [G loss: 1.121376]\n",
      "[Epoch 2/200] [Batch 247/938] [D loss: 1.072773, acc: 92%] [G loss: 1.170401]\n",
      "[Epoch 2/200] [Batch 248/938] [D loss: 1.069381, acc: 95%] [G loss: 1.176777]\n",
      "[Epoch 2/200] [Batch 249/938] [D loss: 1.087793, acc: 91%] [G loss: 1.142462]\n",
      "[Epoch 2/200] [Batch 250/938] [D loss: 1.086413, acc: 92%] [G loss: 1.135532]\n",
      "[Epoch 2/200] [Batch 251/938] [D loss: 1.074440, acc: 94%] [G loss: 1.149677]\n",
      "[Epoch 2/200] [Batch 252/938] [D loss: 1.121366, acc: 92%] [G loss: 1.200882]\n",
      "[Epoch 2/200] [Batch 253/938] [D loss: 1.125293, acc: 93%] [G loss: 1.241015]\n",
      "[Epoch 2/200] [Batch 254/938] [D loss: 1.068671, acc: 91%] [G loss: 1.159111]\n",
      "[Epoch 2/200] [Batch 255/938] [D loss: 1.043050, acc: 96%] [G loss: 1.170815]\n",
      "[Epoch 2/200] [Batch 256/938] [D loss: 1.120333, acc: 96%] [G loss: 1.158980]\n",
      "[Epoch 2/200] [Batch 257/938] [D loss: 1.098165, acc: 91%] [G loss: 1.179706]\n",
      "[Epoch 2/200] [Batch 258/938] [D loss: 1.058755, acc: 94%] [G loss: 1.196933]\n",
      "[Epoch 2/200] [Batch 259/938] [D loss: 1.060498, acc: 89%] [G loss: 1.254498]\n",
      "[Epoch 2/200] [Batch 260/938] [D loss: 1.072217, acc: 92%] [G loss: 1.188973]\n",
      "[Epoch 2/200] [Batch 261/938] [D loss: 1.120206, acc: 89%] [G loss: 1.103035]\n",
      "[Epoch 2/200] [Batch 262/938] [D loss: 1.081973, acc: 95%] [G loss: 1.078178]\n",
      "[Epoch 2/200] [Batch 263/938] [D loss: 1.045332, acc: 93%] [G loss: 1.150659]\n",
      "[Epoch 2/200] [Batch 264/938] [D loss: 1.056310, acc: 92%] [G loss: 1.291058]\n",
      "[Epoch 2/200] [Batch 265/938] [D loss: 1.081809, acc: 91%] [G loss: 1.241256]\n",
      "[Epoch 2/200] [Batch 266/938] [D loss: 1.078107, acc: 95%] [G loss: 1.230655]\n",
      "[Epoch 2/200] [Batch 267/938] [D loss: 1.082942, acc: 92%] [G loss: 1.186987]\n",
      "[Epoch 2/200] [Batch 268/938] [D loss: 1.080788, acc: 92%] [G loss: 1.196554]\n",
      "[Epoch 2/200] [Batch 269/938] [D loss: 1.055873, acc: 93%] [G loss: 1.233590]\n",
      "[Epoch 2/200] [Batch 270/938] [D loss: 1.071794, acc: 92%] [G loss: 1.187084]\n",
      "[Epoch 2/200] [Batch 271/938] [D loss: 1.083079, acc: 94%] [G loss: 1.251545]\n",
      "[Epoch 2/200] [Batch 272/938] [D loss: 1.127882, acc: 91%] [G loss: 1.106961]\n",
      "[Epoch 2/200] [Batch 273/938] [D loss: 1.062488, acc: 93%] [G loss: 1.099669]\n",
      "[Epoch 2/200] [Batch 274/938] [D loss: 1.132941, acc: 89%] [G loss: 1.194573]\n",
      "[Epoch 2/200] [Batch 275/938] [D loss: 1.067708, acc: 92%] [G loss: 1.283771]\n",
      "[Epoch 2/200] [Batch 276/938] [D loss: 1.100068, acc: 93%] [G loss: 1.106276]\n",
      "[Epoch 2/200] [Batch 277/938] [D loss: 1.059454, acc: 93%] [G loss: 1.197841]\n",
      "[Epoch 2/200] [Batch 278/938] [D loss: 1.070225, acc: 94%] [G loss: 1.278382]\n",
      "[Epoch 2/200] [Batch 279/938] [D loss: 1.070418, acc: 90%] [G loss: 1.222949]\n",
      "[Epoch 2/200] [Batch 280/938] [D loss: 1.124406, acc: 91%] [G loss: 1.120768]\n",
      "[Epoch 2/200] [Batch 281/938] [D loss: 1.060406, acc: 92%] [G loss: 1.194649]\n",
      "[Epoch 2/200] [Batch 282/938] [D loss: 1.066048, acc: 94%] [G loss: 1.206976]\n",
      "[Epoch 2/200] [Batch 283/938] [D loss: 1.078349, acc: 93%] [G loss: 1.168442]\n",
      "[Epoch 2/200] [Batch 284/938] [D loss: 1.059479, acc: 94%] [G loss: 1.177867]\n",
      "[Epoch 2/200] [Batch 285/938] [D loss: 1.066764, acc: 95%] [G loss: 1.186492]\n",
      "[Epoch 2/200] [Batch 286/938] [D loss: 1.094016, acc: 89%] [G loss: 1.158128]\n",
      "[Epoch 2/200] [Batch 287/938] [D loss: 1.065228, acc: 94%] [G loss: 1.195956]\n",
      "[Epoch 2/200] [Batch 288/938] [D loss: 1.065244, acc: 92%] [G loss: 1.203599]\n",
      "[Epoch 2/200] [Batch 289/938] [D loss: 1.092618, acc: 92%] [G loss: 1.197200]\n",
      "[Epoch 2/200] [Batch 290/938] [D loss: 1.044022, acc: 98%] [G loss: 1.136954]\n",
      "[Epoch 2/200] [Batch 291/938] [D loss: 1.106349, acc: 91%] [G loss: 1.272496]\n",
      "[Epoch 2/200] [Batch 292/938] [D loss: 1.086462, acc: 89%] [G loss: 1.277116]\n",
      "[Epoch 2/200] [Batch 293/938] [D loss: 1.136856, acc: 92%] [G loss: 1.160889]\n",
      "[Epoch 2/200] [Batch 294/938] [D loss: 1.162810, acc: 86%] [G loss: 1.212914]\n",
      "[Epoch 2/200] [Batch 295/938] [D loss: 1.107342, acc: 93%] [G loss: 1.178146]\n",
      "[Epoch 2/200] [Batch 296/938] [D loss: 1.064970, acc: 90%] [G loss: 1.252841]\n",
      "[Epoch 2/200] [Batch 297/938] [D loss: 1.104769, acc: 91%] [G loss: 1.257041]\n",
      "[Epoch 2/200] [Batch 298/938] [D loss: 1.119770, acc: 89%] [G loss: 1.244342]\n",
      "[Epoch 2/200] [Batch 299/938] [D loss: 1.089259, acc: 92%] [G loss: 1.186895]\n",
      "[Epoch 2/200] [Batch 300/938] [D loss: 1.106058, acc: 90%] [G loss: 1.188686]\n",
      "[Epoch 2/200] [Batch 301/938] [D loss: 1.087971, acc: 91%] [G loss: 1.205959]\n",
      "[Epoch 2/200] [Batch 302/938] [D loss: 1.092298, acc: 93%] [G loss: 1.107805]\n",
      "[Epoch 2/200] [Batch 303/938] [D loss: 1.103920, acc: 96%] [G loss: 1.133102]\n",
      "[Epoch 2/200] [Batch 304/938] [D loss: 1.108938, acc: 89%] [G loss: 1.240880]\n",
      "[Epoch 2/200] [Batch 305/938] [D loss: 1.084991, acc: 93%] [G loss: 1.203869]\n",
      "[Epoch 2/200] [Batch 306/938] [D loss: 1.063396, acc: 96%] [G loss: 1.207911]\n",
      "[Epoch 2/200] [Batch 307/938] [D loss: 1.108649, acc: 89%] [G loss: 1.217346]\n",
      "[Epoch 2/200] [Batch 308/938] [D loss: 1.054313, acc: 92%] [G loss: 1.185580]\n",
      "[Epoch 2/200] [Batch 309/938] [D loss: 1.065955, acc: 92%] [G loss: 1.180622]\n",
      "[Epoch 2/200] [Batch 310/938] [D loss: 1.088747, acc: 96%] [G loss: 1.124109]\n",
      "[Epoch 2/200] [Batch 311/938] [D loss: 1.096359, acc: 92%] [G loss: 1.140484]\n",
      "[Epoch 2/200] [Batch 312/938] [D loss: 1.051886, acc: 96%] [G loss: 1.200464]\n",
      "[Epoch 2/200] [Batch 313/938] [D loss: 1.097978, acc: 92%] [G loss: 1.250745]\n",
      "[Epoch 2/200] [Batch 314/938] [D loss: 1.087148, acc: 92%] [G loss: 1.209404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 315/938] [D loss: 1.060146, acc: 94%] [G loss: 1.198997]\n",
      "[Epoch 2/200] [Batch 316/938] [D loss: 1.084623, acc: 92%] [G loss: 1.179557]\n",
      "[Epoch 2/200] [Batch 317/938] [D loss: 1.055157, acc: 95%] [G loss: 1.264243]\n",
      "[Epoch 2/200] [Batch 318/938] [D loss: 1.106948, acc: 88%] [G loss: 1.130669]\n",
      "[Epoch 2/200] [Batch 319/938] [D loss: 1.091624, acc: 91%] [G loss: 1.260419]\n",
      "[Epoch 2/200] [Batch 320/938] [D loss: 1.099101, acc: 93%] [G loss: 1.180871]\n",
      "[Epoch 2/200] [Batch 321/938] [D loss: 1.073837, acc: 94%] [G loss: 1.166230]\n",
      "[Epoch 2/200] [Batch 322/938] [D loss: 1.115457, acc: 89%] [G loss: 1.165266]\n",
      "[Epoch 2/200] [Batch 323/938] [D loss: 1.079817, acc: 93%] [G loss: 1.187714]\n",
      "[Epoch 2/200] [Batch 324/938] [D loss: 1.050968, acc: 96%] [G loss: 1.228397]\n",
      "[Epoch 2/200] [Batch 325/938] [D loss: 1.090573, acc: 88%] [G loss: 1.311706]\n",
      "[Epoch 2/200] [Batch 326/938] [D loss: 1.110425, acc: 89%] [G loss: 1.159781]\n",
      "[Epoch 2/200] [Batch 327/938] [D loss: 1.067007, acc: 90%] [G loss: 1.135835]\n",
      "[Epoch 2/200] [Batch 328/938] [D loss: 1.045335, acc: 92%] [G loss: 1.251699]\n",
      "[Epoch 2/200] [Batch 329/938] [D loss: 1.130452, acc: 89%] [G loss: 1.131395]\n",
      "[Epoch 2/200] [Batch 330/938] [D loss: 1.084548, acc: 91%] [G loss: 1.212633]\n",
      "[Epoch 2/200] [Batch 331/938] [D loss: 1.086817, acc: 92%] [G loss: 1.219016]\n",
      "[Epoch 2/200] [Batch 332/938] [D loss: 1.085676, acc: 91%] [G loss: 1.169122]\n",
      "[Epoch 2/200] [Batch 333/938] [D loss: 1.111421, acc: 92%] [G loss: 1.213785]\n",
      "[Epoch 2/200] [Batch 334/938] [D loss: 1.091138, acc: 96%] [G loss: 1.136075]\n",
      "[Epoch 2/200] [Batch 335/938] [D loss: 1.119134, acc: 92%] [G loss: 1.253700]\n",
      "[Epoch 2/200] [Batch 336/938] [D loss: 1.046590, acc: 98%] [G loss: 1.258087]\n",
      "[Epoch 2/200] [Batch 337/938] [D loss: 1.099704, acc: 93%] [G loss: 1.250507]\n",
      "[Epoch 2/200] [Batch 338/938] [D loss: 1.095084, acc: 89%] [G loss: 1.123602]\n",
      "[Epoch 2/200] [Batch 339/938] [D loss: 1.041705, acc: 96%] [G loss: 1.080853]\n",
      "[Epoch 2/200] [Batch 340/938] [D loss: 1.096828, acc: 92%] [G loss: 1.135785]\n",
      "[Epoch 2/200] [Batch 341/938] [D loss: 1.064908, acc: 93%] [G loss: 1.268472]\n",
      "[Epoch 2/200] [Batch 342/938] [D loss: 1.063163, acc: 90%] [G loss: 1.257586]\n",
      "[Epoch 2/200] [Batch 343/938] [D loss: 1.078667, acc: 92%] [G loss: 1.223633]\n",
      "[Epoch 2/200] [Batch 344/938] [D loss: 1.160542, acc: 92%] [G loss: 1.149628]\n",
      "[Epoch 2/200] [Batch 345/938] [D loss: 1.081143, acc: 92%] [G loss: 1.186216]\n",
      "[Epoch 2/200] [Batch 346/938] [D loss: 1.105511, acc: 89%] [G loss: 1.168352]\n",
      "[Epoch 2/200] [Batch 347/938] [D loss: 1.102954, acc: 91%] [G loss: 1.208394]\n",
      "[Epoch 2/200] [Batch 348/938] [D loss: 1.077790, acc: 93%] [G loss: 1.200712]\n",
      "[Epoch 2/200] [Batch 349/938] [D loss: 1.067699, acc: 95%] [G loss: 1.251289]\n",
      "[Epoch 2/200] [Batch 350/938] [D loss: 1.077004, acc: 94%] [G loss: 1.208392]\n",
      "[Epoch 2/200] [Batch 351/938] [D loss: 1.120505, acc: 91%] [G loss: 1.203502]\n",
      "[Epoch 2/200] [Batch 352/938] [D loss: 1.096006, acc: 89%] [G loss: 1.180891]\n",
      "[Epoch 2/200] [Batch 353/938] [D loss: 1.128734, acc: 91%] [G loss: 1.172153]\n",
      "[Epoch 2/200] [Batch 354/938] [D loss: 1.095384, acc: 92%] [G loss: 1.144724]\n",
      "[Epoch 2/200] [Batch 355/938] [D loss: 1.091372, acc: 94%] [G loss: 1.125887]\n",
      "[Epoch 2/200] [Batch 356/938] [D loss: 1.056583, acc: 96%] [G loss: 1.200870]\n",
      "[Epoch 2/200] [Batch 357/938] [D loss: 1.075541, acc: 90%] [G loss: 1.203821]\n",
      "[Epoch 2/200] [Batch 358/938] [D loss: 1.081188, acc: 96%] [G loss: 1.230424]\n",
      "[Epoch 2/200] [Batch 359/938] [D loss: 1.103926, acc: 91%] [G loss: 1.085894]\n",
      "[Epoch 2/200] [Batch 360/938] [D loss: 1.091112, acc: 94%] [G loss: 1.159171]\n",
      "[Epoch 2/200] [Batch 361/938] [D loss: 1.111541, acc: 92%] [G loss: 1.184621]\n",
      "[Epoch 2/200] [Batch 362/938] [D loss: 1.060340, acc: 92%] [G loss: 1.329142]\n",
      "[Epoch 2/200] [Batch 363/938] [D loss: 1.042798, acc: 94%] [G loss: 1.208823]\n",
      "[Epoch 2/200] [Batch 364/938] [D loss: 1.075851, acc: 95%] [G loss: 1.205889]\n",
      "[Epoch 2/200] [Batch 365/938] [D loss: 1.094763, acc: 93%] [G loss: 1.219213]\n",
      "[Epoch 2/200] [Batch 366/938] [D loss: 1.061849, acc: 92%] [G loss: 1.206586]\n",
      "[Epoch 2/200] [Batch 367/938] [D loss: 1.076051, acc: 94%] [G loss: 1.181240]\n",
      "[Epoch 2/200] [Batch 368/938] [D loss: 1.086643, acc: 93%] [G loss: 1.162376]\n",
      "[Epoch 2/200] [Batch 369/938] [D loss: 1.109992, acc: 91%] [G loss: 1.200318]\n",
      "[Epoch 2/200] [Batch 370/938] [D loss: 1.073275, acc: 93%] [G loss: 1.255173]\n",
      "[Epoch 2/200] [Batch 371/938] [D loss: 1.042093, acc: 89%] [G loss: 1.207891]\n",
      "[Epoch 2/200] [Batch 372/938] [D loss: 1.122955, acc: 92%] [G loss: 1.119413]\n",
      "[Epoch 2/200] [Batch 373/938] [D loss: 1.018347, acc: 95%] [G loss: 1.228674]\n",
      "[Epoch 2/200] [Batch 374/938] [D loss: 1.089460, acc: 93%] [G loss: 1.192388]\n",
      "[Epoch 2/200] [Batch 375/938] [D loss: 1.096814, acc: 95%] [G loss: 1.227394]\n",
      "[Epoch 2/200] [Batch 376/938] [D loss: 1.096694, acc: 92%] [G loss: 1.145260]\n",
      "[Epoch 2/200] [Batch 377/938] [D loss: 1.071988, acc: 93%] [G loss: 1.192693]\n",
      "[Epoch 2/200] [Batch 378/938] [D loss: 1.070744, acc: 94%] [G loss: 1.210404]\n",
      "[Epoch 2/200] [Batch 379/938] [D loss: 1.073759, acc: 92%] [G loss: 1.198156]\n",
      "[Epoch 2/200] [Batch 380/938] [D loss: 1.105498, acc: 92%] [G loss: 1.163836]\n",
      "[Epoch 2/200] [Batch 381/938] [D loss: 1.070444, acc: 93%] [G loss: 1.192422]\n",
      "[Epoch 2/200] [Batch 382/938] [D loss: 1.075583, acc: 94%] [G loss: 1.236006]\n",
      "[Epoch 2/200] [Batch 383/938] [D loss: 1.097271, acc: 95%] [G loss: 1.171088]\n",
      "[Epoch 2/200] [Batch 384/938] [D loss: 1.034186, acc: 93%] [G loss: 1.239745]\n",
      "[Epoch 2/200] [Batch 385/938] [D loss: 1.086020, acc: 91%] [G loss: 1.164456]\n",
      "[Epoch 2/200] [Batch 386/938] [D loss: 1.049842, acc: 96%] [G loss: 1.266917]\n",
      "[Epoch 2/200] [Batch 387/938] [D loss: 1.065550, acc: 94%] [G loss: 1.201142]\n",
      "[Epoch 2/200] [Batch 388/938] [D loss: 1.090187, acc: 89%] [G loss: 1.276966]\n",
      "[Epoch 2/200] [Batch 389/938] [D loss: 1.071006, acc: 93%] [G loss: 1.221654]\n",
      "[Epoch 2/200] [Batch 390/938] [D loss: 1.084679, acc: 93%] [G loss: 1.194872]\n",
      "[Epoch 2/200] [Batch 391/938] [D loss: 1.029004, acc: 94%] [G loss: 1.219934]\n",
      "[Epoch 2/200] [Batch 392/938] [D loss: 1.043340, acc: 95%] [G loss: 1.206389]\n",
      "[Epoch 2/200] [Batch 393/938] [D loss: 1.096535, acc: 92%] [G loss: 1.258730]\n",
      "[Epoch 2/200] [Batch 394/938] [D loss: 1.102477, acc: 93%] [G loss: 1.216539]\n",
      "[Epoch 2/200] [Batch 395/938] [D loss: 1.084256, acc: 94%] [G loss: 1.207078]\n",
      "[Epoch 2/200] [Batch 396/938] [D loss: 1.058096, acc: 91%] [G loss: 1.216800]\n",
      "[Epoch 2/200] [Batch 397/938] [D loss: 1.072314, acc: 88%] [G loss: 1.209850]\n",
      "[Epoch 2/200] [Batch 398/938] [D loss: 1.094830, acc: 96%] [G loss: 1.157819]\n",
      "[Epoch 2/200] [Batch 399/938] [D loss: 1.083024, acc: 92%] [G loss: 1.087791]\n",
      "[Epoch 2/200] [Batch 400/938] [D loss: 1.067489, acc: 91%] [G loss: 1.227910]\n",
      "[Epoch 2/200] [Batch 401/938] [D loss: 1.062807, acc: 94%] [G loss: 1.173901]\n",
      "[Epoch 2/200] [Batch 402/938] [D loss: 1.085113, acc: 89%] [G loss: 1.270875]\n",
      "[Epoch 2/200] [Batch 403/938] [D loss: 1.055157, acc: 91%] [G loss: 1.173540]\n",
      "[Epoch 2/200] [Batch 404/938] [D loss: 1.062376, acc: 92%] [G loss: 1.197836]\n",
      "[Epoch 2/200] [Batch 405/938] [D loss: 1.105053, acc: 89%] [G loss: 1.182739]\n",
      "[Epoch 2/200] [Batch 406/938] [D loss: 1.100020, acc: 92%] [G loss: 1.154231]\n",
      "[Epoch 2/200] [Batch 407/938] [D loss: 1.104858, acc: 94%] [G loss: 1.132195]\n",
      "[Epoch 2/200] [Batch 408/938] [D loss: 1.109090, acc: 94%] [G loss: 1.176876]\n",
      "[Epoch 2/200] [Batch 409/938] [D loss: 1.110384, acc: 93%] [G loss: 1.262245]\n",
      "[Epoch 2/200] [Batch 410/938] [D loss: 1.064573, acc: 93%] [G loss: 1.222890]\n",
      "[Epoch 2/200] [Batch 411/938] [D loss: 1.141343, acc: 89%] [G loss: 1.178465]\n",
      "[Epoch 2/200] [Batch 412/938] [D loss: 1.085843, acc: 92%] [G loss: 1.156548]\n",
      "[Epoch 2/200] [Batch 413/938] [D loss: 1.063252, acc: 96%] [G loss: 1.191202]\n",
      "[Epoch 2/200] [Batch 414/938] [D loss: 1.063408, acc: 94%] [G loss: 1.196123]\n",
      "[Epoch 2/200] [Batch 415/938] [D loss: 1.067275, acc: 91%] [G loss: 1.227299]\n",
      "[Epoch 2/200] [Batch 416/938] [D loss: 1.105537, acc: 87%] [G loss: 1.139131]\n",
      "[Epoch 2/200] [Batch 417/938] [D loss: 1.101923, acc: 94%] [G loss: 1.240333]\n",
      "[Epoch 2/200] [Batch 418/938] [D loss: 1.083280, acc: 94%] [G loss: 1.148736]\n",
      "[Epoch 2/200] [Batch 419/938] [D loss: 1.030588, acc: 95%] [G loss: 1.254857]\n",
      "[Epoch 2/200] [Batch 420/938] [D loss: 1.043297, acc: 97%] [G loss: 1.182393]\n",
      "[Epoch 2/200] [Batch 421/938] [D loss: 1.110885, acc: 89%] [G loss: 1.224859]\n",
      "[Epoch 2/200] [Batch 422/938] [D loss: 1.054896, acc: 94%] [G loss: 1.189049]\n",
      "[Epoch 2/200] [Batch 423/938] [D loss: 1.089045, acc: 90%] [G loss: 1.169581]\n",
      "[Epoch 2/200] [Batch 424/938] [D loss: 1.112463, acc: 92%] [G loss: 1.144934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 425/938] [D loss: 1.064701, acc: 93%] [G loss: 1.127127]\n",
      "[Epoch 2/200] [Batch 426/938] [D loss: 1.079777, acc: 93%] [G loss: 1.226150]\n",
      "[Epoch 2/200] [Batch 427/938] [D loss: 1.094013, acc: 92%] [G loss: 1.083466]\n",
      "[Epoch 2/200] [Batch 428/938] [D loss: 1.144729, acc: 88%] [G loss: 1.118112]\n",
      "[Epoch 2/200] [Batch 429/938] [D loss: 1.067827, acc: 96%] [G loss: 1.220395]\n",
      "[Epoch 2/200] [Batch 430/938] [D loss: 1.059908, acc: 97%] [G loss: 1.198222]\n",
      "[Epoch 2/200] [Batch 431/938] [D loss: 1.065694, acc: 93%] [G loss: 1.156103]\n",
      "[Epoch 2/200] [Batch 432/938] [D loss: 1.064098, acc: 92%] [G loss: 1.193037]\n",
      "[Epoch 2/200] [Batch 433/938] [D loss: 1.083421, acc: 92%] [G loss: 1.101379]\n",
      "[Epoch 2/200] [Batch 434/938] [D loss: 1.096543, acc: 89%] [G loss: 1.178864]\n",
      "[Epoch 2/200] [Batch 435/938] [D loss: 1.108967, acc: 92%] [G loss: 1.119145]\n",
      "[Epoch 2/200] [Batch 436/938] [D loss: 1.134067, acc: 91%] [G loss: 1.143264]\n",
      "[Epoch 2/200] [Batch 437/938] [D loss: 1.100291, acc: 92%] [G loss: 1.119264]\n",
      "[Epoch 2/200] [Batch 438/938] [D loss: 1.074488, acc: 93%] [G loss: 1.136302]\n",
      "[Epoch 2/200] [Batch 439/938] [D loss: 1.091752, acc: 95%] [G loss: 1.108874]\n",
      "[Epoch 2/200] [Batch 440/938] [D loss: 1.061175, acc: 95%] [G loss: 1.142473]\n",
      "[Epoch 2/200] [Batch 441/938] [D loss: 1.103139, acc: 94%] [G loss: 1.241219]\n",
      "[Epoch 2/200] [Batch 442/938] [D loss: 1.078325, acc: 92%] [G loss: 1.190789]\n",
      "[Epoch 2/200] [Batch 443/938] [D loss: 1.060919, acc: 92%] [G loss: 1.119313]\n",
      "[Epoch 2/200] [Batch 444/938] [D loss: 1.099581, acc: 88%] [G loss: 1.200902]\n",
      "[Epoch 2/200] [Batch 445/938] [D loss: 1.088118, acc: 91%] [G loss: 1.173115]\n",
      "[Epoch 2/200] [Batch 446/938] [D loss: 1.117545, acc: 93%] [G loss: 1.280890]\n",
      "[Epoch 2/200] [Batch 447/938] [D loss: 1.082518, acc: 93%] [G loss: 1.149223]\n",
      "[Epoch 2/200] [Batch 448/938] [D loss: 1.076380, acc: 93%] [G loss: 1.174701]\n",
      "[Epoch 2/200] [Batch 449/938] [D loss: 1.050056, acc: 94%] [G loss: 1.219119]\n",
      "[Epoch 2/200] [Batch 450/938] [D loss: 1.099464, acc: 92%] [G loss: 1.197181]\n",
      "[Epoch 2/200] [Batch 451/938] [D loss: 1.105039, acc: 90%] [G loss: 1.254371]\n",
      "[Epoch 2/200] [Batch 452/938] [D loss: 1.084628, acc: 95%] [G loss: 1.161570]\n",
      "[Epoch 2/200] [Batch 453/938] [D loss: 1.103096, acc: 93%] [G loss: 1.123435]\n",
      "[Epoch 2/200] [Batch 454/938] [D loss: 1.068832, acc: 96%] [G loss: 1.273914]\n",
      "[Epoch 2/200] [Batch 455/938] [D loss: 1.076918, acc: 88%] [G loss: 1.194103]\n",
      "[Epoch 2/200] [Batch 456/938] [D loss: 1.085992, acc: 92%] [G loss: 1.167438]\n",
      "[Epoch 2/200] [Batch 457/938] [D loss: 1.111383, acc: 92%] [G loss: 1.161893]\n",
      "[Epoch 2/200] [Batch 458/938] [D loss: 1.054258, acc: 93%] [G loss: 1.187895]\n",
      "[Epoch 2/200] [Batch 459/938] [D loss: 1.089537, acc: 89%] [G loss: 1.159730]\n",
      "[Epoch 2/200] [Batch 460/938] [D loss: 1.067896, acc: 94%] [G loss: 1.203954]\n",
      "[Epoch 2/200] [Batch 461/938] [D loss: 1.096832, acc: 89%] [G loss: 1.257922]\n",
      "[Epoch 2/200] [Batch 462/938] [D loss: 1.083705, acc: 92%] [G loss: 1.177171]\n",
      "[Epoch 2/200] [Batch 463/938] [D loss: 1.102550, acc: 93%] [G loss: 1.203640]\n",
      "[Epoch 2/200] [Batch 464/938] [D loss: 1.095024, acc: 95%] [G loss: 1.165803]\n",
      "[Epoch 2/200] [Batch 465/938] [D loss: 1.082146, acc: 92%] [G loss: 1.186319]\n",
      "[Epoch 2/200] [Batch 466/938] [D loss: 1.105628, acc: 92%] [G loss: 1.140218]\n",
      "[Epoch 2/200] [Batch 467/938] [D loss: 1.033302, acc: 92%] [G loss: 1.236376]\n",
      "[Epoch 2/200] [Batch 468/938] [D loss: 1.062452, acc: 95%] [G loss: 1.250691]\n",
      "[Epoch 2/200] [Batch 469/938] [D loss: 1.116246, acc: 94%] [G loss: 1.157700]\n",
      "[Epoch 2/200] [Batch 470/938] [D loss: 1.080663, acc: 94%] [G loss: 1.165848]\n",
      "[Epoch 2/200] [Batch 471/938] [D loss: 1.110786, acc: 91%] [G loss: 1.108379]\n",
      "[Epoch 2/200] [Batch 472/938] [D loss: 1.081183, acc: 94%] [G loss: 1.146234]\n",
      "[Epoch 2/200] [Batch 473/938] [D loss: 1.082230, acc: 91%] [G loss: 1.193079]\n",
      "[Epoch 2/200] [Batch 474/938] [D loss: 1.050931, acc: 96%] [G loss: 1.179642]\n",
      "[Epoch 2/200] [Batch 475/938] [D loss: 1.081996, acc: 96%] [G loss: 1.187132]\n",
      "[Epoch 2/200] [Batch 476/938] [D loss: 1.082456, acc: 93%] [G loss: 1.203553]\n",
      "[Epoch 2/200] [Batch 477/938] [D loss: 1.112012, acc: 91%] [G loss: 1.102420]\n",
      "[Epoch 2/200] [Batch 478/938] [D loss: 1.082634, acc: 95%] [G loss: 1.224548]\n",
      "[Epoch 2/200] [Batch 479/938] [D loss: 1.096127, acc: 89%] [G loss: 1.243620]\n",
      "[Epoch 2/200] [Batch 480/938] [D loss: 1.103440, acc: 94%] [G loss: 1.210908]\n",
      "[Epoch 2/200] [Batch 481/938] [D loss: 1.043682, acc: 96%] [G loss: 1.220878]\n",
      "[Epoch 2/200] [Batch 482/938] [D loss: 1.049368, acc: 96%] [G loss: 1.152211]\n",
      "[Epoch 2/200] [Batch 483/938] [D loss: 1.107896, acc: 95%] [G loss: 1.130931]\n",
      "[Epoch 2/200] [Batch 484/938] [D loss: 1.108359, acc: 92%] [G loss: 1.190171]\n",
      "[Epoch 2/200] [Batch 485/938] [D loss: 1.050306, acc: 96%] [G loss: 1.166770]\n",
      "[Epoch 2/200] [Batch 486/938] [D loss: 1.055298, acc: 92%] [G loss: 1.177464]\n",
      "[Epoch 2/200] [Batch 487/938] [D loss: 1.077184, acc: 93%] [G loss: 1.181926]\n",
      "[Epoch 2/200] [Batch 488/938] [D loss: 1.085738, acc: 95%] [G loss: 1.152782]\n",
      "[Epoch 2/200] [Batch 489/938] [D loss: 1.073196, acc: 95%] [G loss: 1.198267]\n",
      "[Epoch 2/200] [Batch 490/938] [D loss: 1.052407, acc: 96%] [G loss: 1.193090]\n",
      "[Epoch 2/200] [Batch 491/938] [D loss: 1.088590, acc: 94%] [G loss: 1.175766]\n",
      "[Epoch 2/200] [Batch 492/938] [D loss: 1.097494, acc: 87%] [G loss: 1.186618]\n",
      "[Epoch 2/200] [Batch 493/938] [D loss: 1.035978, acc: 96%] [G loss: 1.218886]\n",
      "[Epoch 2/200] [Batch 494/938] [D loss: 1.125333, acc: 85%] [G loss: 1.308636]\n",
      "[Epoch 2/200] [Batch 495/938] [D loss: 1.102947, acc: 93%] [G loss: 1.268261]\n",
      "[Epoch 2/200] [Batch 496/938] [D loss: 1.060081, acc: 95%] [G loss: 1.257459]\n",
      "[Epoch 2/200] [Batch 497/938] [D loss: 1.067867, acc: 92%] [G loss: 1.081904]\n",
      "[Epoch 2/200] [Batch 498/938] [D loss: 1.056752, acc: 95%] [G loss: 1.129590]\n",
      "[Epoch 2/200] [Batch 499/938] [D loss: 1.080827, acc: 92%] [G loss: 1.149585]\n",
      "[Epoch 2/200] [Batch 500/938] [D loss: 1.077091, acc: 93%] [G loss: 1.211018]\n",
      "[Epoch 2/200] [Batch 501/938] [D loss: 1.092511, acc: 92%] [G loss: 1.252037]\n",
      "[Epoch 2/200] [Batch 502/938] [D loss: 1.093016, acc: 92%] [G loss: 1.298669]\n",
      "[Epoch 2/200] [Batch 503/938] [D loss: 1.126666, acc: 89%] [G loss: 1.264578]\n",
      "[Epoch 2/200] [Batch 504/938] [D loss: 1.106615, acc: 92%] [G loss: 1.104861]\n",
      "[Epoch 2/200] [Batch 505/938] [D loss: 1.078077, acc: 89%] [G loss: 1.191367]\n",
      "[Epoch 2/200] [Batch 506/938] [D loss: 1.068115, acc: 95%] [G loss: 1.185443]\n",
      "[Epoch 2/200] [Batch 507/938] [D loss: 1.042115, acc: 96%] [G loss: 1.130125]\n",
      "[Epoch 2/200] [Batch 508/938] [D loss: 1.112197, acc: 89%] [G loss: 1.149158]\n",
      "[Epoch 2/200] [Batch 509/938] [D loss: 1.055790, acc: 95%] [G loss: 1.210490]\n",
      "[Epoch 2/200] [Batch 510/938] [D loss: 1.085039, acc: 90%] [G loss: 1.179609]\n",
      "[Epoch 2/200] [Batch 511/938] [D loss: 1.078742, acc: 94%] [G loss: 1.182012]\n",
      "[Epoch 2/200] [Batch 512/938] [D loss: 1.067420, acc: 96%] [G loss: 1.086861]\n",
      "[Epoch 2/200] [Batch 513/938] [D loss: 1.061115, acc: 96%] [G loss: 1.187440]\n",
      "[Epoch 2/200] [Batch 514/938] [D loss: 1.108111, acc: 92%] [G loss: 1.154436]\n",
      "[Epoch 2/200] [Batch 515/938] [D loss: 1.060086, acc: 95%] [G loss: 1.128156]\n",
      "[Epoch 2/200] [Batch 516/938] [D loss: 1.100040, acc: 93%] [G loss: 1.184777]\n",
      "[Epoch 2/200] [Batch 517/938] [D loss: 1.082034, acc: 93%] [G loss: 1.153620]\n",
      "[Epoch 2/200] [Batch 518/938] [D loss: 1.083377, acc: 91%] [G loss: 1.256378]\n",
      "[Epoch 2/200] [Batch 519/938] [D loss: 1.094432, acc: 93%] [G loss: 1.145998]\n",
      "[Epoch 2/200] [Batch 520/938] [D loss: 1.072382, acc: 96%] [G loss: 1.134133]\n",
      "[Epoch 2/200] [Batch 521/938] [D loss: 1.090043, acc: 92%] [G loss: 1.153940]\n",
      "[Epoch 2/200] [Batch 522/938] [D loss: 1.059904, acc: 95%] [G loss: 1.199368]\n",
      "[Epoch 2/200] [Batch 523/938] [D loss: 1.080792, acc: 94%] [G loss: 1.114849]\n",
      "[Epoch 2/200] [Batch 524/938] [D loss: 1.092963, acc: 92%] [G loss: 1.154628]\n",
      "[Epoch 2/200] [Batch 525/938] [D loss: 1.093115, acc: 91%] [G loss: 1.186836]\n",
      "[Epoch 2/200] [Batch 526/938] [D loss: 1.067711, acc: 95%] [G loss: 1.170101]\n",
      "[Epoch 2/200] [Batch 527/938] [D loss: 1.065208, acc: 90%] [G loss: 1.146891]\n",
      "[Epoch 2/200] [Batch 528/938] [D loss: 1.086071, acc: 91%] [G loss: 1.166256]\n",
      "[Epoch 2/200] [Batch 529/938] [D loss: 1.053666, acc: 94%] [G loss: 1.129265]\n",
      "[Epoch 2/200] [Batch 530/938] [D loss: 1.071204, acc: 92%] [G loss: 1.268431]\n",
      "[Epoch 2/200] [Batch 531/938] [D loss: 1.122864, acc: 85%] [G loss: 1.241261]\n",
      "[Epoch 2/200] [Batch 532/938] [D loss: 1.089468, acc: 85%] [G loss: 1.212791]\n",
      "[Epoch 2/200] [Batch 533/938] [D loss: 1.075187, acc: 91%] [G loss: 1.212193]\n",
      "[Epoch 2/200] [Batch 534/938] [D loss: 1.053364, acc: 94%] [G loss: 1.222469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 535/938] [D loss: 1.096104, acc: 93%] [G loss: 1.130553]\n",
      "[Epoch 2/200] [Batch 536/938] [D loss: 1.034669, acc: 97%] [G loss: 1.139191]\n",
      "[Epoch 2/200] [Batch 537/938] [D loss: 1.115477, acc: 96%] [G loss: 1.172587]\n",
      "[Epoch 2/200] [Batch 538/938] [D loss: 1.064327, acc: 92%] [G loss: 1.232131]\n",
      "[Epoch 2/200] [Batch 539/938] [D loss: 1.086008, acc: 93%] [G loss: 1.212531]\n",
      "[Epoch 2/200] [Batch 540/938] [D loss: 1.074396, acc: 92%] [G loss: 1.157345]\n",
      "[Epoch 2/200] [Batch 541/938] [D loss: 1.064232, acc: 92%] [G loss: 1.181989]\n",
      "[Epoch 2/200] [Batch 542/938] [D loss: 1.091074, acc: 92%] [G loss: 1.046247]\n",
      "[Epoch 2/200] [Batch 543/938] [D loss: 1.105286, acc: 94%] [G loss: 1.124206]\n",
      "[Epoch 2/200] [Batch 544/938] [D loss: 1.070411, acc: 95%] [G loss: 1.231027]\n",
      "[Epoch 2/200] [Batch 545/938] [D loss: 1.136706, acc: 94%] [G loss: 1.194424]\n",
      "[Epoch 2/200] [Batch 546/938] [D loss: 1.074384, acc: 95%] [G loss: 1.191586]\n",
      "[Epoch 2/200] [Batch 547/938] [D loss: 1.073390, acc: 96%] [G loss: 1.148330]\n",
      "[Epoch 2/200] [Batch 548/938] [D loss: 1.089883, acc: 92%] [G loss: 1.087726]\n",
      "[Epoch 2/200] [Batch 549/938] [D loss: 1.099824, acc: 94%] [G loss: 1.118096]\n",
      "[Epoch 2/200] [Batch 550/938] [D loss: 1.032500, acc: 94%] [G loss: 1.160438]\n",
      "[Epoch 2/200] [Batch 551/938] [D loss: 1.064152, acc: 93%] [G loss: 1.242063]\n",
      "[Epoch 2/200] [Batch 552/938] [D loss: 1.092626, acc: 92%] [G loss: 1.224855]\n",
      "[Epoch 2/200] [Batch 553/938] [D loss: 1.089799, acc: 90%] [G loss: 1.142821]\n",
      "[Epoch 2/200] [Batch 554/938] [D loss: 1.095619, acc: 92%] [G loss: 1.195899]\n",
      "[Epoch 2/200] [Batch 555/938] [D loss: 1.073820, acc: 97%] [G loss: 1.185431]\n",
      "[Epoch 2/200] [Batch 556/938] [D loss: 1.077765, acc: 92%] [G loss: 1.195257]\n",
      "[Epoch 2/200] [Batch 557/938] [D loss: 1.052140, acc: 95%] [G loss: 1.134469]\n",
      "[Epoch 2/200] [Batch 558/938] [D loss: 1.073876, acc: 95%] [G loss: 1.110579]\n",
      "[Epoch 2/200] [Batch 559/938] [D loss: 1.124638, acc: 92%] [G loss: 1.159875]\n",
      "[Epoch 2/200] [Batch 560/938] [D loss: 1.085281, acc: 90%] [G loss: 1.223289]\n",
      "[Epoch 2/200] [Batch 561/938] [D loss: 1.120019, acc: 87%] [G loss: 1.195858]\n",
      "[Epoch 2/200] [Batch 562/938] [D loss: 1.080379, acc: 90%] [G loss: 1.223799]\n",
      "[Epoch 2/200] [Batch 563/938] [D loss: 1.091346, acc: 91%] [G loss: 1.248532]\n",
      "[Epoch 2/200] [Batch 564/938] [D loss: 1.073982, acc: 91%] [G loss: 1.182077]\n",
      "[Epoch 2/200] [Batch 565/938] [D loss: 1.128454, acc: 94%] [G loss: 1.191672]\n",
      "[Epoch 2/200] [Batch 566/938] [D loss: 1.071214, acc: 92%] [G loss: 1.249551]\n",
      "[Epoch 2/200] [Batch 567/938] [D loss: 1.089098, acc: 93%] [G loss: 1.199015]\n",
      "[Epoch 2/200] [Batch 568/938] [D loss: 1.108709, acc: 96%] [G loss: 1.138819]\n",
      "[Epoch 2/200] [Batch 569/938] [D loss: 1.100525, acc: 93%] [G loss: 1.172867]\n",
      "[Epoch 2/200] [Batch 570/938] [D loss: 1.089567, acc: 96%] [G loss: 1.150467]\n",
      "[Epoch 2/200] [Batch 571/938] [D loss: 1.105706, acc: 93%] [G loss: 1.174718]\n",
      "[Epoch 2/200] [Batch 572/938] [D loss: 1.102370, acc: 94%] [G loss: 1.220890]\n",
      "[Epoch 2/200] [Batch 573/938] [D loss: 1.078144, acc: 94%] [G loss: 1.210483]\n",
      "[Epoch 2/200] [Batch 574/938] [D loss: 1.081412, acc: 93%] [G loss: 1.202744]\n",
      "[Epoch 2/200] [Batch 575/938] [D loss: 1.062455, acc: 96%] [G loss: 1.135524]\n",
      "[Epoch 2/200] [Batch 576/938] [D loss: 1.086214, acc: 92%] [G loss: 1.133527]\n",
      "[Epoch 2/200] [Batch 577/938] [D loss: 1.068635, acc: 94%] [G loss: 1.186278]\n",
      "[Epoch 2/200] [Batch 578/938] [D loss: 1.097590, acc: 95%] [G loss: 1.138779]\n",
      "[Epoch 2/200] [Batch 579/938] [D loss: 1.073014, acc: 95%] [G loss: 1.211449]\n",
      "[Epoch 2/200] [Batch 580/938] [D loss: 1.074236, acc: 93%] [G loss: 1.262610]\n",
      "[Epoch 2/200] [Batch 581/938] [D loss: 1.080919, acc: 89%] [G loss: 1.226299]\n",
      "[Epoch 2/200] [Batch 582/938] [D loss: 1.093131, acc: 92%] [G loss: 1.145621]\n",
      "[Epoch 2/200] [Batch 583/938] [D loss: 1.087298, acc: 92%] [G loss: 1.183625]\n",
      "[Epoch 2/200] [Batch 584/938] [D loss: 1.056052, acc: 92%] [G loss: 1.128147]\n",
      "[Epoch 2/200] [Batch 585/938] [D loss: 1.075346, acc: 94%] [G loss: 1.133423]\n",
      "[Epoch 2/200] [Batch 586/938] [D loss: 1.076332, acc: 91%] [G loss: 1.246407]\n",
      "[Epoch 2/200] [Batch 587/938] [D loss: 1.092826, acc: 97%] [G loss: 1.178627]\n",
      "[Epoch 2/200] [Batch 588/938] [D loss: 1.132215, acc: 92%] [G loss: 1.178133]\n",
      "[Epoch 2/200] [Batch 589/938] [D loss: 1.045165, acc: 96%] [G loss: 1.156642]\n",
      "[Epoch 2/200] [Batch 590/938] [D loss: 1.094764, acc: 92%] [G loss: 1.190361]\n",
      "[Epoch 2/200] [Batch 591/938] [D loss: 1.078388, acc: 95%] [G loss: 1.259490]\n",
      "[Epoch 2/200] [Batch 592/938] [D loss: 1.119922, acc: 92%] [G loss: 1.220137]\n",
      "[Epoch 2/200] [Batch 593/938] [D loss: 1.089112, acc: 96%] [G loss: 1.217410]\n",
      "[Epoch 2/200] [Batch 594/938] [D loss: 1.094095, acc: 92%] [G loss: 1.223230]\n",
      "[Epoch 2/200] [Batch 595/938] [D loss: 1.089702, acc: 92%] [G loss: 1.165856]\n",
      "[Epoch 2/200] [Batch 596/938] [D loss: 1.125009, acc: 89%] [G loss: 1.136100]\n",
      "[Epoch 2/200] [Batch 597/938] [D loss: 1.084337, acc: 94%] [G loss: 1.194251]\n",
      "[Epoch 2/200] [Batch 598/938] [D loss: 1.085096, acc: 96%] [G loss: 1.121112]\n",
      "[Epoch 2/200] [Batch 599/938] [D loss: 1.092534, acc: 93%] [G loss: 1.165951]\n",
      "[Epoch 2/200] [Batch 600/938] [D loss: 1.062859, acc: 96%] [G loss: 1.230713]\n",
      "[Epoch 2/200] [Batch 601/938] [D loss: 1.042053, acc: 95%] [G loss: 1.194147]\n",
      "[Epoch 2/200] [Batch 602/938] [D loss: 1.062329, acc: 93%] [G loss: 1.158164]\n",
      "[Epoch 2/200] [Batch 603/938] [D loss: 1.076246, acc: 96%] [G loss: 1.184244]\n",
      "[Epoch 2/200] [Batch 604/938] [D loss: 1.042092, acc: 94%] [G loss: 1.259187]\n",
      "[Epoch 2/200] [Batch 605/938] [D loss: 1.089582, acc: 94%] [G loss: 1.189237]\n",
      "[Epoch 2/200] [Batch 606/938] [D loss: 1.088071, acc: 94%] [G loss: 1.154540]\n",
      "[Epoch 2/200] [Batch 607/938] [D loss: 1.086059, acc: 92%] [G loss: 1.180169]\n",
      "[Epoch 2/200] [Batch 608/938] [D loss: 1.020245, acc: 92%] [G loss: 1.214395]\n",
      "[Epoch 2/200] [Batch 609/938] [D loss: 1.069833, acc: 95%] [G loss: 1.168318]\n",
      "[Epoch 2/200] [Batch 610/938] [D loss: 1.085042, acc: 93%] [G loss: 1.220278]\n",
      "[Epoch 2/200] [Batch 611/938] [D loss: 1.059011, acc: 97%] [G loss: 1.179068]\n",
      "[Epoch 2/200] [Batch 612/938] [D loss: 1.091596, acc: 92%] [G loss: 1.221714]\n",
      "[Epoch 2/200] [Batch 613/938] [D loss: 1.065341, acc: 98%] [G loss: 1.199880]\n",
      "[Epoch 2/200] [Batch 614/938] [D loss: 1.070673, acc: 92%] [G loss: 1.200364]\n",
      "[Epoch 2/200] [Batch 615/938] [D loss: 1.127653, acc: 93%] [G loss: 1.149961]\n",
      "[Epoch 2/200] [Batch 616/938] [D loss: 1.079324, acc: 96%] [G loss: 1.140460]\n",
      "[Epoch 2/200] [Batch 617/938] [D loss: 1.104141, acc: 95%] [G loss: 1.114541]\n",
      "[Epoch 2/200] [Batch 618/938] [D loss: 1.060018, acc: 98%] [G loss: 1.160759]\n",
      "[Epoch 2/200] [Batch 619/938] [D loss: 1.057514, acc: 96%] [G loss: 1.160298]\n",
      "[Epoch 2/200] [Batch 620/938] [D loss: 1.076007, acc: 96%] [G loss: 1.149066]\n",
      "[Epoch 2/200] [Batch 621/938] [D loss: 1.085279, acc: 92%] [G loss: 1.159583]\n",
      "[Epoch 2/200] [Batch 622/938] [D loss: 1.079536, acc: 95%] [G loss: 1.182748]\n",
      "[Epoch 2/200] [Batch 623/938] [D loss: 1.113362, acc: 91%] [G loss: 1.173760]\n",
      "[Epoch 2/200] [Batch 624/938] [D loss: 1.119610, acc: 90%] [G loss: 1.155165]\n",
      "[Epoch 2/200] [Batch 625/938] [D loss: 1.064823, acc: 89%] [G loss: 1.217245]\n",
      "[Epoch 2/200] [Batch 626/938] [D loss: 1.058150, acc: 95%] [G loss: 1.154267]\n",
      "[Epoch 2/200] [Batch 627/938] [D loss: 1.090401, acc: 87%] [G loss: 1.199813]\n",
      "[Epoch 2/200] [Batch 628/938] [D loss: 1.084356, acc: 92%] [G loss: 1.120173]\n",
      "[Epoch 2/200] [Batch 629/938] [D loss: 1.079462, acc: 96%] [G loss: 1.133748]\n",
      "[Epoch 2/200] [Batch 630/938] [D loss: 1.071618, acc: 93%] [G loss: 1.089476]\n",
      "[Epoch 2/200] [Batch 631/938] [D loss: 1.076053, acc: 92%] [G loss: 1.163007]\n",
      "[Epoch 2/200] [Batch 632/938] [D loss: 1.101765, acc: 91%] [G loss: 1.131288]\n",
      "[Epoch 2/200] [Batch 633/938] [D loss: 1.076621, acc: 96%] [G loss: 1.113085]\n",
      "[Epoch 2/200] [Batch 634/938] [D loss: 1.048740, acc: 98%] [G loss: 1.157362]\n",
      "[Epoch 2/200] [Batch 635/938] [D loss: 1.075074, acc: 92%] [G loss: 1.169151]\n",
      "[Epoch 2/200] [Batch 636/938] [D loss: 1.085907, acc: 93%] [G loss: 1.224132]\n",
      "[Epoch 2/200] [Batch 637/938] [D loss: 1.099684, acc: 91%] [G loss: 1.148523]\n",
      "[Epoch 2/200] [Batch 638/938] [D loss: 1.079014, acc: 92%] [G loss: 1.216947]\n",
      "[Epoch 2/200] [Batch 639/938] [D loss: 1.154100, acc: 91%] [G loss: 1.231383]\n",
      "[Epoch 2/200] [Batch 640/938] [D loss: 1.062074, acc: 90%] [G loss: 1.286870]\n",
      "[Epoch 2/200] [Batch 641/938] [D loss: 1.060396, acc: 93%] [G loss: 1.273908]\n",
      "[Epoch 2/200] [Batch 642/938] [D loss: 1.089140, acc: 96%] [G loss: 1.162567]\n",
      "[Epoch 2/200] [Batch 643/938] [D loss: 1.072958, acc: 95%] [G loss: 1.263096]\n",
      "[Epoch 2/200] [Batch 644/938] [D loss: 1.125090, acc: 96%] [G loss: 1.129689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 645/938] [D loss: 1.088665, acc: 91%] [G loss: 1.182233]\n",
      "[Epoch 2/200] [Batch 646/938] [D loss: 1.120825, acc: 92%] [G loss: 1.250535]\n",
      "[Epoch 2/200] [Batch 647/938] [D loss: 1.073578, acc: 94%] [G loss: 1.199863]\n",
      "[Epoch 2/200] [Batch 648/938] [D loss: 1.097303, acc: 92%] [G loss: 1.174894]\n",
      "[Epoch 2/200] [Batch 649/938] [D loss: 1.081557, acc: 94%] [G loss: 1.217644]\n",
      "[Epoch 2/200] [Batch 650/938] [D loss: 1.080415, acc: 94%] [G loss: 1.134684]\n",
      "[Epoch 2/200] [Batch 651/938] [D loss: 1.099898, acc: 96%] [G loss: 1.183183]\n",
      "[Epoch 2/200] [Batch 652/938] [D loss: 1.073124, acc: 93%] [G loss: 1.178734]\n",
      "[Epoch 2/200] [Batch 653/938] [D loss: 1.081884, acc: 92%] [G loss: 1.255960]\n",
      "[Epoch 2/200] [Batch 654/938] [D loss: 1.085436, acc: 92%] [G loss: 1.212186]\n",
      "[Epoch 2/200] [Batch 655/938] [D loss: 1.093692, acc: 92%] [G loss: 1.195392]\n",
      "[Epoch 2/200] [Batch 656/938] [D loss: 1.090428, acc: 90%] [G loss: 1.259055]\n",
      "[Epoch 2/200] [Batch 657/938] [D loss: 1.063553, acc: 92%] [G loss: 1.207798]\n",
      "[Epoch 2/200] [Batch 658/938] [D loss: 1.080223, acc: 92%] [G loss: 1.254498]\n",
      "[Epoch 2/200] [Batch 659/938] [D loss: 1.061569, acc: 96%] [G loss: 1.225376]\n",
      "[Epoch 2/200] [Batch 660/938] [D loss: 1.089041, acc: 94%] [G loss: 1.251337]\n",
      "[Epoch 2/200] [Batch 661/938] [D loss: 1.084760, acc: 92%] [G loss: 1.154896]\n",
      "[Epoch 2/200] [Batch 662/938] [D loss: 1.061937, acc: 98%] [G loss: 1.121764]\n",
      "[Epoch 2/200] [Batch 663/938] [D loss: 1.093673, acc: 95%] [G loss: 1.126173]\n",
      "[Epoch 2/200] [Batch 664/938] [D loss: 1.107417, acc: 94%] [G loss: 1.141974]\n",
      "[Epoch 2/200] [Batch 665/938] [D loss: 1.096476, acc: 92%] [G loss: 1.180704]\n",
      "[Epoch 2/200] [Batch 666/938] [D loss: 1.101982, acc: 92%] [G loss: 1.150203]\n",
      "[Epoch 2/200] [Batch 667/938] [D loss: 1.085363, acc: 93%] [G loss: 1.270864]\n",
      "[Epoch 2/200] [Batch 668/938] [D loss: 1.092679, acc: 91%] [G loss: 1.200274]\n",
      "[Epoch 2/200] [Batch 669/938] [D loss: 1.078203, acc: 92%] [G loss: 1.110861]\n",
      "[Epoch 2/200] [Batch 670/938] [D loss: 1.063800, acc: 92%] [G loss: 1.136791]\n",
      "[Epoch 2/200] [Batch 671/938] [D loss: 1.061084, acc: 94%] [G loss: 1.142206]\n",
      "[Epoch 2/200] [Batch 672/938] [D loss: 1.107711, acc: 92%] [G loss: 1.124202]\n",
      "[Epoch 2/200] [Batch 673/938] [D loss: 1.090010, acc: 94%] [G loss: 1.244185]\n",
      "[Epoch 2/200] [Batch 674/938] [D loss: 1.077133, acc: 95%] [G loss: 1.212479]\n",
      "[Epoch 2/200] [Batch 675/938] [D loss: 1.079923, acc: 95%] [G loss: 1.093892]\n",
      "[Epoch 2/200] [Batch 676/938] [D loss: 1.075508, acc: 93%] [G loss: 1.156306]\n",
      "[Epoch 2/200] [Batch 677/938] [D loss: 1.050319, acc: 92%] [G loss: 1.160197]\n",
      "[Epoch 2/200] [Batch 678/938] [D loss: 1.095057, acc: 96%] [G loss: 1.196189]\n",
      "[Epoch 2/200] [Batch 679/938] [D loss: 1.085363, acc: 92%] [G loss: 1.135022]\n",
      "[Epoch 2/200] [Batch 680/938] [D loss: 1.040220, acc: 95%] [G loss: 1.177422]\n",
      "[Epoch 2/200] [Batch 681/938] [D loss: 1.118217, acc: 94%] [G loss: 1.143835]\n",
      "[Epoch 2/200] [Batch 682/938] [D loss: 1.113597, acc: 96%] [G loss: 1.135296]\n",
      "[Epoch 2/200] [Batch 683/938] [D loss: 1.080441, acc: 96%] [G loss: 1.170732]\n",
      "[Epoch 2/200] [Batch 684/938] [D loss: 1.090991, acc: 92%] [G loss: 1.182387]\n",
      "[Epoch 2/200] [Batch 685/938] [D loss: 1.062219, acc: 94%] [G loss: 1.246164]\n",
      "[Epoch 2/200] [Batch 686/938] [D loss: 1.085006, acc: 96%] [G loss: 1.214121]\n",
      "[Epoch 2/200] [Batch 687/938] [D loss: 1.048252, acc: 93%] [G loss: 1.110746]\n",
      "[Epoch 2/200] [Batch 688/938] [D loss: 1.072160, acc: 91%] [G loss: 1.176219]\n",
      "[Epoch 2/200] [Batch 689/938] [D loss: 1.091779, acc: 92%] [G loss: 1.177772]\n",
      "[Epoch 2/200] [Batch 690/938] [D loss: 1.080175, acc: 90%] [G loss: 1.169370]\n",
      "[Epoch 2/200] [Batch 691/938] [D loss: 1.065231, acc: 93%] [G loss: 1.137321]\n",
      "[Epoch 2/200] [Batch 692/938] [D loss: 1.085450, acc: 92%] [G loss: 1.175390]\n",
      "[Epoch 2/200] [Batch 693/938] [D loss: 1.089635, acc: 93%] [G loss: 1.177048]\n",
      "[Epoch 2/200] [Batch 694/938] [D loss: 1.076217, acc: 90%] [G loss: 1.261715]\n",
      "[Epoch 2/200] [Batch 695/938] [D loss: 1.049153, acc: 93%] [G loss: 1.197682]\n",
      "[Epoch 2/200] [Batch 696/938] [D loss: 1.092101, acc: 92%] [G loss: 1.172813]\n",
      "[Epoch 2/200] [Batch 697/938] [D loss: 1.061898, acc: 95%] [G loss: 1.125404]\n",
      "[Epoch 2/200] [Batch 698/938] [D loss: 1.040380, acc: 93%] [G loss: 1.189836]\n",
      "[Epoch 2/200] [Batch 699/938] [D loss: 1.075522, acc: 96%] [G loss: 1.297234]\n",
      "[Epoch 2/200] [Batch 700/938] [D loss: 1.055254, acc: 95%] [G loss: 1.215053]\n",
      "[Epoch 2/200] [Batch 701/938] [D loss: 1.079584, acc: 92%] [G loss: 1.227818]\n",
      "[Epoch 2/200] [Batch 702/938] [D loss: 1.097951, acc: 91%] [G loss: 1.183912]\n",
      "[Epoch 2/200] [Batch 703/938] [D loss: 1.107744, acc: 92%] [G loss: 1.152782]\n",
      "[Epoch 2/200] [Batch 704/938] [D loss: 1.090640, acc: 89%] [G loss: 1.202275]\n",
      "[Epoch 2/200] [Batch 705/938] [D loss: 1.097204, acc: 94%] [G loss: 1.143136]\n",
      "[Epoch 2/200] [Batch 706/938] [D loss: 1.087656, acc: 93%] [G loss: 1.097194]\n",
      "[Epoch 2/200] [Batch 707/938] [D loss: 1.106046, acc: 96%] [G loss: 1.229940]\n",
      "[Epoch 2/200] [Batch 708/938] [D loss: 1.067885, acc: 89%] [G loss: 1.218523]\n",
      "[Epoch 2/200] [Batch 709/938] [D loss: 1.066303, acc: 95%] [G loss: 1.223396]\n",
      "[Epoch 2/200] [Batch 710/938] [D loss: 1.084580, acc: 95%] [G loss: 1.160858]\n",
      "[Epoch 2/200] [Batch 711/938] [D loss: 1.056566, acc: 92%] [G loss: 1.178970]\n",
      "[Epoch 2/200] [Batch 712/938] [D loss: 1.079772, acc: 93%] [G loss: 1.162492]\n",
      "[Epoch 2/200] [Batch 713/938] [D loss: 1.087840, acc: 92%] [G loss: 1.091847]\n",
      "[Epoch 2/200] [Batch 714/938] [D loss: 1.111833, acc: 96%] [G loss: 1.111766]\n",
      "[Epoch 2/200] [Batch 715/938] [D loss: 1.070649, acc: 95%] [G loss: 1.153598]\n",
      "[Epoch 2/200] [Batch 716/938] [D loss: 1.105514, acc: 92%] [G loss: 1.165867]\n",
      "[Epoch 2/200] [Batch 717/938] [D loss: 1.077152, acc: 92%] [G loss: 1.259013]\n",
      "[Epoch 2/200] [Batch 718/938] [D loss: 1.086832, acc: 95%] [G loss: 1.146406]\n",
      "[Epoch 2/200] [Batch 719/938] [D loss: 1.094647, acc: 93%] [G loss: 1.187127]\n",
      "[Epoch 2/200] [Batch 720/938] [D loss: 1.073493, acc: 93%] [G loss: 1.210057]\n",
      "[Epoch 2/200] [Batch 721/938] [D loss: 1.070435, acc: 95%] [G loss: 1.184324]\n",
      "[Epoch 2/200] [Batch 722/938] [D loss: 1.064829, acc: 94%] [G loss: 1.151373]\n",
      "[Epoch 2/200] [Batch 723/938] [D loss: 1.094298, acc: 92%] [G loss: 1.317461]\n",
      "[Epoch 2/200] [Batch 724/938] [D loss: 1.127103, acc: 92%] [G loss: 1.166051]\n",
      "[Epoch 2/200] [Batch 725/938] [D loss: 1.041220, acc: 97%] [G loss: 1.195227]\n",
      "[Epoch 2/200] [Batch 726/938] [D loss: 1.074972, acc: 93%] [G loss: 1.158927]\n",
      "[Epoch 2/200] [Batch 727/938] [D loss: 1.098961, acc: 94%] [G loss: 1.149282]\n",
      "[Epoch 2/200] [Batch 728/938] [D loss: 1.096117, acc: 95%] [G loss: 1.150151]\n",
      "[Epoch 2/200] [Batch 729/938] [D loss: 1.060067, acc: 96%] [G loss: 1.171169]\n",
      "[Epoch 2/200] [Batch 730/938] [D loss: 1.083918, acc: 94%] [G loss: 1.214093]\n",
      "[Epoch 2/200] [Batch 731/938] [D loss: 1.125235, acc: 89%] [G loss: 1.147629]\n",
      "[Epoch 2/200] [Batch 732/938] [D loss: 1.135196, acc: 90%] [G loss: 1.176191]\n",
      "[Epoch 2/200] [Batch 733/938] [D loss: 1.078195, acc: 92%] [G loss: 1.167092]\n",
      "[Epoch 2/200] [Batch 734/938] [D loss: 1.137101, acc: 93%] [G loss: 1.075249]\n",
      "[Epoch 2/200] [Batch 735/938] [D loss: 1.102032, acc: 91%] [G loss: 1.189770]\n",
      "[Epoch 2/200] [Batch 736/938] [D loss: 1.126282, acc: 92%] [G loss: 1.192871]\n",
      "[Epoch 2/200] [Batch 737/938] [D loss: 1.092891, acc: 94%] [G loss: 1.189531]\n",
      "[Epoch 2/200] [Batch 738/938] [D loss: 1.051716, acc: 92%] [G loss: 1.205247]\n",
      "[Epoch 2/200] [Batch 739/938] [D loss: 1.091482, acc: 92%] [G loss: 1.220608]\n",
      "[Epoch 2/200] [Batch 740/938] [D loss: 1.063603, acc: 92%] [G loss: 1.239595]\n",
      "[Epoch 2/200] [Batch 741/938] [D loss: 1.127528, acc: 94%] [G loss: 1.140645]\n",
      "[Epoch 2/200] [Batch 742/938] [D loss: 1.114375, acc: 93%] [G loss: 1.107733]\n",
      "[Epoch 2/200] [Batch 743/938] [D loss: 1.077880, acc: 94%] [G loss: 1.134668]\n",
      "[Epoch 2/200] [Batch 744/938] [D loss: 1.066053, acc: 94%] [G loss: 1.124095]\n",
      "[Epoch 2/200] [Batch 745/938] [D loss: 1.076360, acc: 96%] [G loss: 1.156494]\n",
      "[Epoch 2/200] [Batch 746/938] [D loss: 1.066836, acc: 95%] [G loss: 1.231482]\n",
      "[Epoch 2/200] [Batch 747/938] [D loss: 1.058457, acc: 95%] [G loss: 1.217774]\n",
      "[Epoch 2/200] [Batch 748/938] [D loss: 1.094316, acc: 93%] [G loss: 1.236132]\n",
      "[Epoch 2/200] [Batch 749/938] [D loss: 1.110922, acc: 92%] [G loss: 1.139571]\n",
      "[Epoch 2/200] [Batch 750/938] [D loss: 1.095682, acc: 94%] [G loss: 1.204756]\n",
      "[Epoch 2/200] [Batch 751/938] [D loss: 1.090395, acc: 95%] [G loss: 1.144160]\n",
      "[Epoch 2/200] [Batch 752/938] [D loss: 1.091678, acc: 92%] [G loss: 1.162060]\n",
      "[Epoch 2/200] [Batch 753/938] [D loss: 1.127701, acc: 89%] [G loss: 1.170216]\n",
      "[Epoch 2/200] [Batch 754/938] [D loss: 1.101565, acc: 91%] [G loss: 1.175287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 755/938] [D loss: 1.097547, acc: 92%] [G loss: 1.251269]\n",
      "[Epoch 2/200] [Batch 756/938] [D loss: 1.092470, acc: 96%] [G loss: 1.174052]\n",
      "[Epoch 2/200] [Batch 757/938] [D loss: 1.093257, acc: 92%] [G loss: 1.215753]\n",
      "[Epoch 2/200] [Batch 758/938] [D loss: 1.074497, acc: 93%] [G loss: 1.156945]\n",
      "[Epoch 2/200] [Batch 759/938] [D loss: 1.093252, acc: 87%] [G loss: 1.158090]\n",
      "[Epoch 2/200] [Batch 760/938] [D loss: 1.136382, acc: 90%] [G loss: 1.211167]\n",
      "[Epoch 2/200] [Batch 761/938] [D loss: 1.106766, acc: 92%] [G loss: 1.107170]\n",
      "[Epoch 2/200] [Batch 762/938] [D loss: 1.106020, acc: 92%] [G loss: 1.158613]\n",
      "[Epoch 2/200] [Batch 763/938] [D loss: 1.083695, acc: 96%] [G loss: 1.146366]\n",
      "[Epoch 2/200] [Batch 764/938] [D loss: 1.081847, acc: 96%] [G loss: 1.223036]\n",
      "[Epoch 2/200] [Batch 765/938] [D loss: 1.072252, acc: 94%] [G loss: 1.126250]\n",
      "[Epoch 2/200] [Batch 766/938] [D loss: 1.109077, acc: 93%] [G loss: 1.179695]\n",
      "[Epoch 2/200] [Batch 767/938] [D loss: 1.081050, acc: 91%] [G loss: 1.149138]\n",
      "[Epoch 2/200] [Batch 768/938] [D loss: 1.098768, acc: 91%] [G loss: 1.164469]\n",
      "[Epoch 2/200] [Batch 769/938] [D loss: 1.090645, acc: 92%] [G loss: 1.183776]\n",
      "[Epoch 2/200] [Batch 770/938] [D loss: 1.085258, acc: 89%] [G loss: 1.189270]\n",
      "[Epoch 2/200] [Batch 771/938] [D loss: 1.065238, acc: 94%] [G loss: 1.227458]\n",
      "[Epoch 2/200] [Batch 772/938] [D loss: 1.112550, acc: 92%] [G loss: 1.196970]\n",
      "[Epoch 2/200] [Batch 773/938] [D loss: 1.056381, acc: 94%] [G loss: 1.257902]\n",
      "[Epoch 2/200] [Batch 774/938] [D loss: 1.077339, acc: 93%] [G loss: 1.207206]\n",
      "[Epoch 2/200] [Batch 775/938] [D loss: 1.113014, acc: 93%] [G loss: 1.238295]\n",
      "[Epoch 2/200] [Batch 776/938] [D loss: 1.072184, acc: 95%] [G loss: 1.232983]\n",
      "[Epoch 2/200] [Batch 777/938] [D loss: 1.069409, acc: 92%] [G loss: 1.128992]\n",
      "[Epoch 2/200] [Batch 778/938] [D loss: 1.129807, acc: 89%] [G loss: 1.121565]\n",
      "[Epoch 2/200] [Batch 779/938] [D loss: 1.079828, acc: 93%] [G loss: 1.195869]\n",
      "[Epoch 2/200] [Batch 780/938] [D loss: 1.161167, acc: 87%] [G loss: 1.190204]\n",
      "[Epoch 2/200] [Batch 781/938] [D loss: 1.114249, acc: 87%] [G loss: 1.161077]\n",
      "[Epoch 2/200] [Batch 782/938] [D loss: 1.071327, acc: 95%] [G loss: 1.110749]\n",
      "[Epoch 2/200] [Batch 783/938] [D loss: 1.072826, acc: 91%] [G loss: 1.183725]\n",
      "[Epoch 2/200] [Batch 784/938] [D loss: 1.064133, acc: 96%] [G loss: 1.158782]\n",
      "[Epoch 2/200] [Batch 785/938] [D loss: 1.078041, acc: 93%] [G loss: 1.083797]\n",
      "[Epoch 2/200] [Batch 786/938] [D loss: 1.083528, acc: 94%] [G loss: 1.180706]\n",
      "[Epoch 2/200] [Batch 787/938] [D loss: 1.058696, acc: 92%] [G loss: 1.240182]\n",
      "[Epoch 2/200] [Batch 788/938] [D loss: 1.048558, acc: 97%] [G loss: 1.161068]\n",
      "[Epoch 2/200] [Batch 789/938] [D loss: 1.076028, acc: 89%] [G loss: 1.195639]\n",
      "[Epoch 2/200] [Batch 790/938] [D loss: 1.093491, acc: 98%] [G loss: 1.112770]\n",
      "[Epoch 2/200] [Batch 791/938] [D loss: 1.098407, acc: 96%] [G loss: 1.149169]\n",
      "[Epoch 2/200] [Batch 792/938] [D loss: 1.041211, acc: 94%] [G loss: 1.155009]\n",
      "[Epoch 2/200] [Batch 793/938] [D loss: 1.103544, acc: 94%] [G loss: 1.138907]\n",
      "[Epoch 2/200] [Batch 794/938] [D loss: 1.086612, acc: 95%] [G loss: 1.124377]\n",
      "[Epoch 2/200] [Batch 795/938] [D loss: 1.090389, acc: 91%] [G loss: 1.213138]\n",
      "[Epoch 2/200] [Batch 796/938] [D loss: 1.059824, acc: 95%] [G loss: 1.196981]\n",
      "[Epoch 2/200] [Batch 797/938] [D loss: 1.053273, acc: 92%] [G loss: 1.246358]\n",
      "[Epoch 2/200] [Batch 798/938] [D loss: 1.074061, acc: 92%] [G loss: 1.158683]\n",
      "[Epoch 2/200] [Batch 799/938] [D loss: 1.067185, acc: 92%] [G loss: 1.153467]\n",
      "[Epoch 2/200] [Batch 800/938] [D loss: 1.062354, acc: 96%] [G loss: 1.131870]\n",
      "[Epoch 2/200] [Batch 801/938] [D loss: 1.082579, acc: 93%] [G loss: 1.164652]\n",
      "[Epoch 2/200] [Batch 802/938] [D loss: 1.057063, acc: 95%] [G loss: 1.223171]\n",
      "[Epoch 2/200] [Batch 803/938] [D loss: 1.118862, acc: 92%] [G loss: 1.174043]\n",
      "[Epoch 2/200] [Batch 804/938] [D loss: 1.100107, acc: 92%] [G loss: 1.218765]\n",
      "[Epoch 2/200] [Batch 805/938] [D loss: 1.061763, acc: 94%] [G loss: 1.245606]\n",
      "[Epoch 2/200] [Batch 806/938] [D loss: 1.055047, acc: 97%] [G loss: 1.235543]\n",
      "[Epoch 2/200] [Batch 807/938] [D loss: 1.046868, acc: 96%] [G loss: 1.236926]\n",
      "[Epoch 2/200] [Batch 808/938] [D loss: 1.068592, acc: 95%] [G loss: 1.279588]\n",
      "[Epoch 2/200] [Batch 809/938] [D loss: 1.092029, acc: 92%] [G loss: 1.189628]\n",
      "[Epoch 2/200] [Batch 810/938] [D loss: 1.085274, acc: 93%] [G loss: 1.121887]\n",
      "[Epoch 2/200] [Batch 811/938] [D loss: 1.137122, acc: 90%] [G loss: 1.117594]\n",
      "[Epoch 2/200] [Batch 812/938] [D loss: 1.051548, acc: 94%] [G loss: 1.219981]\n",
      "[Epoch 2/200] [Batch 813/938] [D loss: 1.082291, acc: 94%] [G loss: 1.257837]\n",
      "[Epoch 2/200] [Batch 814/938] [D loss: 1.076440, acc: 92%] [G loss: 1.185771]\n",
      "[Epoch 2/200] [Batch 815/938] [D loss: 1.071091, acc: 91%] [G loss: 1.244715]\n",
      "[Epoch 2/200] [Batch 816/938] [D loss: 1.083390, acc: 94%] [G loss: 1.225214]\n",
      "[Epoch 2/200] [Batch 817/938] [D loss: 1.063394, acc: 92%] [G loss: 1.194360]\n",
      "[Epoch 2/200] [Batch 818/938] [D loss: 1.110342, acc: 93%] [G loss: 1.197528]\n",
      "[Epoch 2/200] [Batch 819/938] [D loss: 1.082965, acc: 92%] [G loss: 1.182593]\n",
      "[Epoch 2/200] [Batch 820/938] [D loss: 1.050670, acc: 90%] [G loss: 1.190113]\n",
      "[Epoch 2/200] [Batch 821/938] [D loss: 1.071070, acc: 93%] [G loss: 1.222186]\n",
      "[Epoch 2/200] [Batch 822/938] [D loss: 1.079864, acc: 92%] [G loss: 1.229763]\n",
      "[Epoch 2/200] [Batch 823/938] [D loss: 1.079043, acc: 90%] [G loss: 1.118258]\n",
      "[Epoch 2/200] [Batch 824/938] [D loss: 1.073267, acc: 92%] [G loss: 1.162993]\n",
      "[Epoch 2/200] [Batch 825/938] [D loss: 1.055897, acc: 95%] [G loss: 1.127957]\n",
      "[Epoch 2/200] [Batch 826/938] [D loss: 1.072492, acc: 92%] [G loss: 1.195309]\n",
      "[Epoch 2/200] [Batch 827/938] [D loss: 1.087993, acc: 92%] [G loss: 1.168349]\n",
      "[Epoch 2/200] [Batch 828/938] [D loss: 1.072372, acc: 92%] [G loss: 1.181109]\n",
      "[Epoch 2/200] [Batch 829/938] [D loss: 1.063883, acc: 91%] [G loss: 1.159482]\n",
      "[Epoch 2/200] [Batch 830/938] [D loss: 1.079123, acc: 94%] [G loss: 1.149335]\n",
      "[Epoch 2/200] [Batch 831/938] [D loss: 1.095335, acc: 89%] [G loss: 1.130311]\n",
      "[Epoch 2/200] [Batch 832/938] [D loss: 1.087494, acc: 92%] [G loss: 1.185716]\n",
      "[Epoch 2/200] [Batch 833/938] [D loss: 1.110085, acc: 92%] [G loss: 1.143429]\n",
      "[Epoch 2/200] [Batch 834/938] [D loss: 1.107052, acc: 92%] [G loss: 1.142511]\n",
      "[Epoch 2/200] [Batch 835/938] [D loss: 1.057983, acc: 94%] [G loss: 1.164202]\n",
      "[Epoch 2/200] [Batch 836/938] [D loss: 1.066162, acc: 92%] [G loss: 1.181385]\n",
      "[Epoch 2/200] [Batch 837/938] [D loss: 1.099028, acc: 89%] [G loss: 1.213807]\n",
      "[Epoch 2/200] [Batch 838/938] [D loss: 1.115416, acc: 96%] [G loss: 1.190080]\n",
      "[Epoch 2/200] [Batch 839/938] [D loss: 1.124226, acc: 92%] [G loss: 1.171519]\n",
      "[Epoch 2/200] [Batch 840/938] [D loss: 1.047807, acc: 96%] [G loss: 1.155425]\n",
      "[Epoch 2/200] [Batch 841/938] [D loss: 1.073791, acc: 93%] [G loss: 1.159592]\n",
      "[Epoch 2/200] [Batch 842/938] [D loss: 1.116657, acc: 92%] [G loss: 1.139193]\n",
      "[Epoch 2/200] [Batch 843/938] [D loss: 1.084167, acc: 94%] [G loss: 1.232294]\n",
      "[Epoch 2/200] [Batch 844/938] [D loss: 1.034661, acc: 93%] [G loss: 1.143203]\n",
      "[Epoch 2/200] [Batch 845/938] [D loss: 1.069014, acc: 92%] [G loss: 1.194559]\n",
      "[Epoch 2/200] [Batch 846/938] [D loss: 1.069051, acc: 95%] [G loss: 1.233268]\n",
      "[Epoch 2/200] [Batch 847/938] [D loss: 1.161919, acc: 91%] [G loss: 1.100670]\n",
      "[Epoch 2/200] [Batch 848/938] [D loss: 1.082296, acc: 92%] [G loss: 1.168383]\n",
      "[Epoch 2/200] [Batch 849/938] [D loss: 1.088178, acc: 94%] [G loss: 1.193443]\n",
      "[Epoch 2/200] [Batch 850/938] [D loss: 1.033181, acc: 94%] [G loss: 1.217636]\n",
      "[Epoch 2/200] [Batch 851/938] [D loss: 1.090626, acc: 93%] [G loss: 1.137723]\n",
      "[Epoch 2/200] [Batch 852/938] [D loss: 1.121515, acc: 89%] [G loss: 1.101952]\n",
      "[Epoch 2/200] [Batch 853/938] [D loss: 1.087218, acc: 93%] [G loss: 1.109594]\n",
      "[Epoch 2/200] [Batch 854/938] [D loss: 1.097141, acc: 92%] [G loss: 1.171566]\n",
      "[Epoch 2/200] [Batch 855/938] [D loss: 1.070946, acc: 95%] [G loss: 1.231120]\n",
      "[Epoch 2/200] [Batch 856/938] [D loss: 1.090401, acc: 94%] [G loss: 1.167875]\n",
      "[Epoch 2/200] [Batch 857/938] [D loss: 1.102943, acc: 91%] [G loss: 1.193241]\n",
      "[Epoch 2/200] [Batch 858/938] [D loss: 1.085530, acc: 90%] [G loss: 1.177944]\n",
      "[Epoch 2/200] [Batch 859/938] [D loss: 1.101744, acc: 91%] [G loss: 1.136716]\n",
      "[Epoch 2/200] [Batch 860/938] [D loss: 1.095492, acc: 91%] [G loss: 1.151729]\n",
      "[Epoch 2/200] [Batch 861/938] [D loss: 1.059315, acc: 94%] [G loss: 1.160556]\n",
      "[Epoch 2/200] [Batch 862/938] [D loss: 1.110392, acc: 94%] [G loss: 1.291703]\n",
      "[Epoch 2/200] [Batch 863/938] [D loss: 1.095005, acc: 94%] [G loss: 1.143127]\n",
      "[Epoch 2/200] [Batch 864/938] [D loss: 1.052843, acc: 93%] [G loss: 1.192995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/200] [Batch 865/938] [D loss: 1.083179, acc: 88%] [G loss: 1.167492]\n",
      "[Epoch 2/200] [Batch 866/938] [D loss: 1.101185, acc: 94%] [G loss: 1.100901]\n",
      "[Epoch 2/200] [Batch 867/938] [D loss: 1.116814, acc: 92%] [G loss: 1.225600]\n",
      "[Epoch 2/200] [Batch 868/938] [D loss: 1.127104, acc: 92%] [G loss: 1.198086]\n",
      "[Epoch 2/200] [Batch 869/938] [D loss: 1.120974, acc: 93%] [G loss: 1.210764]\n",
      "[Epoch 2/200] [Batch 870/938] [D loss: 1.099733, acc: 90%] [G loss: 1.147428]\n",
      "[Epoch 2/200] [Batch 871/938] [D loss: 1.088521, acc: 93%] [G loss: 1.152330]\n",
      "[Epoch 2/200] [Batch 872/938] [D loss: 1.074975, acc: 90%] [G loss: 1.148944]\n",
      "[Epoch 2/200] [Batch 873/938] [D loss: 1.088922, acc: 89%] [G loss: 1.125945]\n",
      "[Epoch 2/200] [Batch 874/938] [D loss: 1.041527, acc: 94%] [G loss: 1.154549]\n",
      "[Epoch 2/200] [Batch 875/938] [D loss: 1.072597, acc: 92%] [G loss: 1.155357]\n",
      "[Epoch 2/200] [Batch 876/938] [D loss: 1.139612, acc: 91%] [G loss: 1.181078]\n",
      "[Epoch 2/200] [Batch 877/938] [D loss: 1.041285, acc: 97%] [G loss: 1.183662]\n",
      "[Epoch 2/200] [Batch 878/938] [D loss: 1.080110, acc: 94%] [G loss: 1.137552]\n",
      "[Epoch 2/200] [Batch 879/938] [D loss: 1.134101, acc: 89%] [G loss: 1.200954]\n",
      "[Epoch 2/200] [Batch 880/938] [D loss: 1.085566, acc: 91%] [G loss: 1.269013]\n",
      "[Epoch 2/200] [Batch 881/938] [D loss: 1.084064, acc: 96%] [G loss: 1.175204]\n",
      "[Epoch 2/200] [Batch 882/938] [D loss: 1.122935, acc: 92%] [G loss: 1.135275]\n",
      "[Epoch 2/200] [Batch 883/938] [D loss: 1.081769, acc: 92%] [G loss: 1.101661]\n",
      "[Epoch 2/200] [Batch 884/938] [D loss: 1.066611, acc: 94%] [G loss: 1.144233]\n",
      "[Epoch 2/200] [Batch 885/938] [D loss: 1.048863, acc: 96%] [G loss: 1.205941]\n",
      "[Epoch 2/200] [Batch 886/938] [D loss: 1.054824, acc: 96%] [G loss: 1.171180]\n",
      "[Epoch 2/200] [Batch 887/938] [D loss: 1.059012, acc: 94%] [G loss: 1.216821]\n",
      "[Epoch 2/200] [Batch 888/938] [D loss: 1.082931, acc: 93%] [G loss: 1.123199]\n",
      "[Epoch 2/200] [Batch 889/938] [D loss: 1.048108, acc: 96%] [G loss: 1.182069]\n",
      "[Epoch 2/200] [Batch 890/938] [D loss: 1.065995, acc: 95%] [G loss: 1.257118]\n",
      "[Epoch 2/200] [Batch 891/938] [D loss: 1.058423, acc: 93%] [G loss: 1.086659]\n",
      "[Epoch 2/200] [Batch 892/938] [D loss: 1.077673, acc: 94%] [G loss: 1.144082]\n",
      "[Epoch 2/200] [Batch 893/938] [D loss: 1.073091, acc: 92%] [G loss: 1.197329]\n",
      "[Epoch 2/200] [Batch 894/938] [D loss: 1.086578, acc: 93%] [G loss: 1.104925]\n",
      "[Epoch 2/200] [Batch 895/938] [D loss: 1.086821, acc: 95%] [G loss: 1.153839]\n",
      "[Epoch 2/200] [Batch 896/938] [D loss: 1.079264, acc: 92%] [G loss: 1.108451]\n",
      "[Epoch 2/200] [Batch 897/938] [D loss: 1.080601, acc: 95%] [G loss: 1.077695]\n",
      "[Epoch 2/200] [Batch 898/938] [D loss: 1.095905, acc: 96%] [G loss: 1.162583]\n",
      "[Epoch 2/200] [Batch 899/938] [D loss: 1.120967, acc: 90%] [G loss: 1.141167]\n",
      "[Epoch 2/200] [Batch 900/938] [D loss: 1.116281, acc: 91%] [G loss: 1.157749]\n",
      "[Epoch 2/200] [Batch 901/938] [D loss: 1.084255, acc: 94%] [G loss: 1.218515]\n",
      "[Epoch 2/200] [Batch 902/938] [D loss: 1.066500, acc: 93%] [G loss: 1.170130]\n",
      "[Epoch 2/200] [Batch 903/938] [D loss: 1.101643, acc: 92%] [G loss: 1.221876]\n",
      "[Epoch 2/200] [Batch 904/938] [D loss: 1.076012, acc: 94%] [G loss: 1.199619]\n",
      "[Epoch 2/200] [Batch 905/938] [D loss: 1.109953, acc: 91%] [G loss: 1.100478]\n",
      "[Epoch 2/200] [Batch 906/938] [D loss: 1.078044, acc: 92%] [G loss: 1.159178]\n",
      "[Epoch 2/200] [Batch 907/938] [D loss: 1.101837, acc: 92%] [G loss: 1.198519]\n",
      "[Epoch 2/200] [Batch 908/938] [D loss: 1.061130, acc: 96%] [G loss: 1.172524]\n",
      "[Epoch 2/200] [Batch 909/938] [D loss: 1.111530, acc: 95%] [G loss: 1.184229]\n",
      "[Epoch 2/200] [Batch 910/938] [D loss: 1.092332, acc: 96%] [G loss: 1.212735]\n",
      "[Epoch 2/200] [Batch 911/938] [D loss: 1.087030, acc: 94%] [G loss: 1.092688]\n",
      "[Epoch 2/200] [Batch 912/938] [D loss: 1.056965, acc: 92%] [G loss: 1.179351]\n",
      "[Epoch 2/200] [Batch 913/938] [D loss: 1.097718, acc: 92%] [G loss: 1.192637]\n",
      "[Epoch 2/200] [Batch 914/938] [D loss: 1.111815, acc: 92%] [G loss: 1.159008]\n",
      "[Epoch 2/200] [Batch 915/938] [D loss: 1.104405, acc: 96%] [G loss: 1.149199]\n",
      "[Epoch 2/200] [Batch 916/938] [D loss: 1.088220, acc: 95%] [G loss: 1.234519]\n",
      "[Epoch 2/200] [Batch 917/938] [D loss: 1.055724, acc: 94%] [G loss: 1.143704]\n",
      "[Epoch 2/200] [Batch 918/938] [D loss: 1.026300, acc: 97%] [G loss: 1.188227]\n",
      "[Epoch 2/200] [Batch 919/938] [D loss: 1.081020, acc: 96%] [G loss: 1.166334]\n",
      "[Epoch 2/200] [Batch 920/938] [D loss: 1.075770, acc: 92%] [G loss: 1.198375]\n",
      "[Epoch 2/200] [Batch 921/938] [D loss: 1.076018, acc: 93%] [G loss: 1.192680]\n",
      "[Epoch 2/200] [Batch 922/938] [D loss: 1.105622, acc: 90%] [G loss: 1.093010]\n",
      "[Epoch 2/200] [Batch 923/938] [D loss: 1.110297, acc: 92%] [G loss: 1.053036]\n",
      "[Epoch 2/200] [Batch 924/938] [D loss: 1.095947, acc: 94%] [G loss: 1.113353]\n",
      "[Epoch 2/200] [Batch 925/938] [D loss: 1.071835, acc: 93%] [G loss: 1.181951]\n",
      "[Epoch 2/200] [Batch 926/938] [D loss: 1.096742, acc: 93%] [G loss: 1.178347]\n",
      "[Epoch 2/200] [Batch 927/938] [D loss: 1.075249, acc: 96%] [G loss: 1.192370]\n",
      "[Epoch 2/200] [Batch 928/938] [D loss: 1.047981, acc: 96%] [G loss: 1.177668]\n",
      "[Epoch 2/200] [Batch 929/938] [D loss: 1.102219, acc: 96%] [G loss: 1.164860]\n",
      "[Epoch 2/200] [Batch 930/938] [D loss: 1.067497, acc: 93%] [G loss: 1.158283]\n",
      "[Epoch 2/200] [Batch 931/938] [D loss: 1.100333, acc: 91%] [G loss: 1.155715]\n",
      "[Epoch 2/200] [Batch 932/938] [D loss: 1.070075, acc: 93%] [G loss: 1.141439]\n",
      "[Epoch 2/200] [Batch 933/938] [D loss: 1.070168, acc: 92%] [G loss: 1.266223]\n",
      "[Epoch 2/200] [Batch 934/938] [D loss: 1.140634, acc: 92%] [G loss: 1.267809]\n",
      "[Epoch 2/200] [Batch 935/938] [D loss: 1.106172, acc: 95%] [G loss: 1.268661]\n",
      "[Epoch 2/200] [Batch 936/938] [D loss: 1.110729, acc: 92%] [G loss: 1.172434]\n",
      "[Epoch 2/200] [Batch 937/938] [D loss: 1.055113, acc: 95%] [G loss: 1.171050]\n",
      "[Epoch 3/200] [Batch 0/938] [D loss: 1.052101, acc: 95%] [G loss: 1.160041]\n",
      "[Epoch 3/200] [Batch 1/938] [D loss: 1.080524, acc: 91%] [G loss: 1.123278]\n",
      "[Epoch 3/200] [Batch 2/938] [D loss: 1.085902, acc: 90%] [G loss: 1.068093]\n",
      "[Epoch 3/200] [Batch 3/938] [D loss: 1.101355, acc: 92%] [G loss: 1.222205]\n",
      "[Epoch 3/200] [Batch 4/938] [D loss: 1.076913, acc: 92%] [G loss: 1.109174]\n",
      "[Epoch 3/200] [Batch 5/938] [D loss: 1.098823, acc: 89%] [G loss: 1.163421]\n",
      "[Epoch 3/200] [Batch 6/938] [D loss: 1.041492, acc: 94%] [G loss: 1.232527]\n",
      "[Epoch 3/200] [Batch 7/938] [D loss: 1.108974, acc: 93%] [G loss: 1.104161]\n",
      "[Epoch 3/200] [Batch 8/938] [D loss: 1.071864, acc: 93%] [G loss: 1.186941]\n",
      "[Epoch 3/200] [Batch 9/938] [D loss: 1.084670, acc: 95%] [G loss: 1.163906]\n",
      "[Epoch 3/200] [Batch 10/938] [D loss: 1.089851, acc: 95%] [G loss: 1.128062]\n",
      "[Epoch 3/200] [Batch 11/938] [D loss: 1.065183, acc: 91%] [G loss: 1.168725]\n",
      "[Epoch 3/200] [Batch 12/938] [D loss: 1.055441, acc: 95%] [G loss: 1.178457]\n",
      "[Epoch 3/200] [Batch 13/938] [D loss: 1.074722, acc: 96%] [G loss: 1.182838]\n",
      "[Epoch 3/200] [Batch 14/938] [D loss: 1.083600, acc: 95%] [G loss: 1.209910]\n",
      "[Epoch 3/200] [Batch 15/938] [D loss: 1.073874, acc: 94%] [G loss: 1.212195]\n",
      "[Epoch 3/200] [Batch 16/938] [D loss: 1.093372, acc: 92%] [G loss: 1.166246]\n",
      "[Epoch 3/200] [Batch 17/938] [D loss: 1.084165, acc: 92%] [G loss: 1.211916]\n",
      "[Epoch 3/200] [Batch 18/938] [D loss: 1.082333, acc: 92%] [G loss: 1.221031]\n",
      "[Epoch 3/200] [Batch 19/938] [D loss: 1.070523, acc: 95%] [G loss: 1.131568]\n",
      "[Epoch 3/200] [Batch 20/938] [D loss: 1.106141, acc: 92%] [G loss: 1.102747]\n",
      "[Epoch 3/200] [Batch 21/938] [D loss: 1.074760, acc: 94%] [G loss: 1.101231]\n",
      "[Epoch 3/200] [Batch 22/938] [D loss: 1.070230, acc: 96%] [G loss: 1.204641]\n",
      "[Epoch 3/200] [Batch 23/938] [D loss: 1.101479, acc: 94%] [G loss: 1.208521]\n",
      "[Epoch 3/200] [Batch 24/938] [D loss: 1.139698, acc: 86%] [G loss: 1.217180]\n",
      "[Epoch 3/200] [Batch 25/938] [D loss: 1.150784, acc: 92%] [G loss: 1.120434]\n",
      "[Epoch 3/200] [Batch 26/938] [D loss: 1.077360, acc: 92%] [G loss: 1.144182]\n",
      "[Epoch 3/200] [Batch 27/938] [D loss: 1.079249, acc: 94%] [G loss: 1.179819]\n",
      "[Epoch 3/200] [Batch 28/938] [D loss: 1.105139, acc: 91%] [G loss: 1.136940]\n",
      "[Epoch 3/200] [Batch 29/938] [D loss: 1.091364, acc: 95%] [G loss: 1.164968]\n",
      "[Epoch 3/200] [Batch 30/938] [D loss: 1.093950, acc: 93%] [G loss: 1.148365]\n",
      "[Epoch 3/200] [Batch 31/938] [D loss: 1.105837, acc: 90%] [G loss: 1.226018]\n",
      "[Epoch 3/200] [Batch 32/938] [D loss: 1.088082, acc: 94%] [G loss: 1.232887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 33/938] [D loss: 1.071771, acc: 93%] [G loss: 1.219233]\n",
      "[Epoch 3/200] [Batch 34/938] [D loss: 1.112147, acc: 92%] [G loss: 1.146870]\n",
      "[Epoch 3/200] [Batch 35/938] [D loss: 1.082703, acc: 92%] [G loss: 1.150861]\n",
      "[Epoch 3/200] [Batch 36/938] [D loss: 1.053120, acc: 96%] [G loss: 1.100040]\n",
      "[Epoch 3/200] [Batch 37/938] [D loss: 1.086322, acc: 93%] [G loss: 1.149877]\n",
      "[Epoch 3/200] [Batch 38/938] [D loss: 1.096394, acc: 92%] [G loss: 1.194260]\n",
      "[Epoch 3/200] [Batch 39/938] [D loss: 1.099772, acc: 92%] [G loss: 1.201044]\n",
      "[Epoch 3/200] [Batch 40/938] [D loss: 1.074557, acc: 92%] [G loss: 1.149586]\n",
      "[Epoch 3/200] [Batch 41/938] [D loss: 1.067694, acc: 96%] [G loss: 1.152303]\n",
      "[Epoch 3/200] [Batch 42/938] [D loss: 1.098766, acc: 92%] [G loss: 1.184595]\n",
      "[Epoch 3/200] [Batch 43/938] [D loss: 1.127635, acc: 93%] [G loss: 1.202217]\n",
      "[Epoch 3/200] [Batch 44/938] [D loss: 1.132491, acc: 90%] [G loss: 1.164436]\n",
      "[Epoch 3/200] [Batch 45/938] [D loss: 1.074950, acc: 92%] [G loss: 1.230521]\n",
      "[Epoch 3/200] [Batch 46/938] [D loss: 1.033079, acc: 96%] [G loss: 1.125321]\n",
      "[Epoch 3/200] [Batch 47/938] [D loss: 1.076150, acc: 95%] [G loss: 1.112415]\n",
      "[Epoch 3/200] [Batch 48/938] [D loss: 1.076473, acc: 93%] [G loss: 1.138243]\n",
      "[Epoch 3/200] [Batch 49/938] [D loss: 1.069551, acc: 93%] [G loss: 1.144119]\n",
      "[Epoch 3/200] [Batch 50/938] [D loss: 1.101253, acc: 92%] [G loss: 1.147662]\n",
      "[Epoch 3/200] [Batch 51/938] [D loss: 1.076687, acc: 90%] [G loss: 1.140958]\n",
      "[Epoch 3/200] [Batch 52/938] [D loss: 1.075964, acc: 96%] [G loss: 1.134838]\n",
      "[Epoch 3/200] [Batch 53/938] [D loss: 1.040491, acc: 96%] [G loss: 1.289134]\n",
      "[Epoch 3/200] [Batch 54/938] [D loss: 1.105403, acc: 93%] [G loss: 1.127667]\n",
      "[Epoch 3/200] [Batch 55/938] [D loss: 1.103674, acc: 92%] [G loss: 1.107090]\n",
      "[Epoch 3/200] [Batch 56/938] [D loss: 1.080514, acc: 97%] [G loss: 1.179094]\n",
      "[Epoch 3/200] [Batch 57/938] [D loss: 1.048899, acc: 96%] [G loss: 1.140708]\n",
      "[Epoch 3/200] [Batch 58/938] [D loss: 1.095155, acc: 92%] [G loss: 1.141749]\n",
      "[Epoch 3/200] [Batch 59/938] [D loss: 1.115643, acc: 90%] [G loss: 1.222241]\n",
      "[Epoch 3/200] [Batch 60/938] [D loss: 1.071170, acc: 95%] [G loss: 1.173348]\n",
      "[Epoch 3/200] [Batch 61/938] [D loss: 1.072074, acc: 92%] [G loss: 1.197112]\n",
      "[Epoch 3/200] [Batch 62/938] [D loss: 1.113879, acc: 95%] [G loss: 1.191867]\n",
      "[Epoch 3/200] [Batch 63/938] [D loss: 1.123425, acc: 89%] [G loss: 1.219414]\n",
      "[Epoch 3/200] [Batch 64/938] [D loss: 1.100863, acc: 91%] [G loss: 1.239563]\n",
      "[Epoch 3/200] [Batch 65/938] [D loss: 1.088414, acc: 94%] [G loss: 1.175404]\n",
      "[Epoch 3/200] [Batch 66/938] [D loss: 1.080750, acc: 95%] [G loss: 1.127383]\n",
      "[Epoch 3/200] [Batch 67/938] [D loss: 1.058252, acc: 93%] [G loss: 1.192600]\n",
      "[Epoch 3/200] [Batch 68/938] [D loss: 1.070871, acc: 94%] [G loss: 1.193095]\n",
      "[Epoch 3/200] [Batch 69/938] [D loss: 1.047017, acc: 94%] [G loss: 1.228776]\n",
      "[Epoch 3/200] [Batch 70/938] [D loss: 1.078026, acc: 93%] [G loss: 1.207731]\n",
      "[Epoch 3/200] [Batch 71/938] [D loss: 1.060817, acc: 94%] [G loss: 1.209680]\n",
      "[Epoch 3/200] [Batch 72/938] [D loss: 1.061897, acc: 95%] [G loss: 1.108373]\n",
      "[Epoch 3/200] [Batch 73/938] [D loss: 1.082891, acc: 97%] [G loss: 1.123410]\n",
      "[Epoch 3/200] [Batch 74/938] [D loss: 1.069600, acc: 95%] [G loss: 1.204889]\n",
      "[Epoch 3/200] [Batch 75/938] [D loss: 1.082132, acc: 93%] [G loss: 1.138176]\n",
      "[Epoch 3/200] [Batch 76/938] [D loss: 1.068066, acc: 97%] [G loss: 1.153036]\n",
      "[Epoch 3/200] [Batch 77/938] [D loss: 1.072543, acc: 96%] [G loss: 1.191308]\n",
      "[Epoch 3/200] [Batch 78/938] [D loss: 1.053006, acc: 91%] [G loss: 1.249316]\n",
      "[Epoch 3/200] [Batch 79/938] [D loss: 1.095790, acc: 91%] [G loss: 1.214653]\n",
      "[Epoch 3/200] [Batch 80/938] [D loss: 1.094028, acc: 91%] [G loss: 1.181364]\n",
      "[Epoch 3/200] [Batch 81/938] [D loss: 1.082104, acc: 90%] [G loss: 1.235895]\n",
      "[Epoch 3/200] [Batch 82/938] [D loss: 1.077571, acc: 94%] [G loss: 1.173326]\n",
      "[Epoch 3/200] [Batch 83/938] [D loss: 1.067274, acc: 96%] [G loss: 1.161063]\n",
      "[Epoch 3/200] [Batch 84/938] [D loss: 1.083249, acc: 92%] [G loss: 1.161289]\n",
      "[Epoch 3/200] [Batch 85/938] [D loss: 1.070668, acc: 92%] [G loss: 1.163620]\n",
      "[Epoch 3/200] [Batch 86/938] [D loss: 1.068847, acc: 97%] [G loss: 1.119328]\n",
      "[Epoch 3/200] [Batch 87/938] [D loss: 1.102879, acc: 96%] [G loss: 1.150702]\n",
      "[Epoch 3/200] [Batch 88/938] [D loss: 1.089024, acc: 96%] [G loss: 1.151001]\n",
      "[Epoch 3/200] [Batch 89/938] [D loss: 1.068327, acc: 95%] [G loss: 1.154537]\n",
      "[Epoch 3/200] [Batch 90/938] [D loss: 1.073239, acc: 96%] [G loss: 1.236781]\n",
      "[Epoch 3/200] [Batch 91/938] [D loss: 1.106603, acc: 92%] [G loss: 1.166236]\n",
      "[Epoch 3/200] [Batch 92/938] [D loss: 1.077825, acc: 92%] [G loss: 1.202067]\n",
      "[Epoch 3/200] [Batch 93/938] [D loss: 1.093549, acc: 91%] [G loss: 1.178647]\n",
      "[Epoch 3/200] [Batch 94/938] [D loss: 1.097079, acc: 91%] [G loss: 1.163760]\n",
      "[Epoch 3/200] [Batch 95/938] [D loss: 1.089320, acc: 96%] [G loss: 1.193849]\n",
      "[Epoch 3/200] [Batch 96/938] [D loss: 1.057790, acc: 92%] [G loss: 1.202505]\n",
      "[Epoch 3/200] [Batch 97/938] [D loss: 1.107242, acc: 94%] [G loss: 1.095102]\n",
      "[Epoch 3/200] [Batch 98/938] [D loss: 1.116032, acc: 93%] [G loss: 1.156469]\n",
      "[Epoch 3/200] [Batch 99/938] [D loss: 1.074657, acc: 92%] [G loss: 1.220313]\n",
      "[Epoch 3/200] [Batch 100/938] [D loss: 1.067254, acc: 92%] [G loss: 1.170244]\n",
      "[Epoch 3/200] [Batch 101/938] [D loss: 1.055110, acc: 89%] [G loss: 1.254695]\n",
      "[Epoch 3/200] [Batch 102/938] [D loss: 1.083905, acc: 94%] [G loss: 1.079544]\n",
      "[Epoch 3/200] [Batch 103/938] [D loss: 1.093636, acc: 93%] [G loss: 1.257367]\n",
      "[Epoch 3/200] [Batch 104/938] [D loss: 1.142733, acc: 94%] [G loss: 1.164646]\n",
      "[Epoch 3/200] [Batch 105/938] [D loss: 1.083750, acc: 94%] [G loss: 1.068430]\n",
      "[Epoch 3/200] [Batch 106/938] [D loss: 1.072365, acc: 91%] [G loss: 1.101126]\n",
      "[Epoch 3/200] [Batch 107/938] [D loss: 1.102938, acc: 90%] [G loss: 1.175095]\n",
      "[Epoch 3/200] [Batch 108/938] [D loss: 1.115428, acc: 93%] [G loss: 1.162323]\n",
      "[Epoch 3/200] [Batch 109/938] [D loss: 1.109600, acc: 93%] [G loss: 1.117787]\n",
      "[Epoch 3/200] [Batch 110/938] [D loss: 1.087564, acc: 88%] [G loss: 1.185311]\n",
      "[Epoch 3/200] [Batch 111/938] [D loss: 1.113570, acc: 96%] [G loss: 1.140708]\n",
      "[Epoch 3/200] [Batch 112/938] [D loss: 1.088134, acc: 94%] [G loss: 1.161055]\n",
      "[Epoch 3/200] [Batch 113/938] [D loss: 1.082812, acc: 93%] [G loss: 1.113744]\n",
      "[Epoch 3/200] [Batch 114/938] [D loss: 1.101620, acc: 93%] [G loss: 1.192163]\n",
      "[Epoch 3/200] [Batch 115/938] [D loss: 1.075614, acc: 93%] [G loss: 1.186999]\n",
      "[Epoch 3/200] [Batch 116/938] [D loss: 1.105639, acc: 91%] [G loss: 1.192210]\n",
      "[Epoch 3/200] [Batch 117/938] [D loss: 1.107120, acc: 92%] [G loss: 1.159387]\n",
      "[Epoch 3/200] [Batch 118/938] [D loss: 1.102260, acc: 93%] [G loss: 1.104300]\n",
      "[Epoch 3/200] [Batch 119/938] [D loss: 1.090591, acc: 92%] [G loss: 1.130033]\n",
      "[Epoch 3/200] [Batch 120/938] [D loss: 1.078197, acc: 91%] [G loss: 1.168211]\n",
      "[Epoch 3/200] [Batch 121/938] [D loss: 1.105842, acc: 96%] [G loss: 1.196313]\n",
      "[Epoch 3/200] [Batch 122/938] [D loss: 1.108818, acc: 92%] [G loss: 1.177652]\n",
      "[Epoch 3/200] [Batch 123/938] [D loss: 1.109689, acc: 93%] [G loss: 1.133609]\n",
      "[Epoch 3/200] [Batch 124/938] [D loss: 1.089840, acc: 92%] [G loss: 1.154195]\n",
      "[Epoch 3/200] [Batch 125/938] [D loss: 1.071146, acc: 93%] [G loss: 1.185175]\n",
      "[Epoch 3/200] [Batch 126/938] [D loss: 1.083382, acc: 92%] [G loss: 1.197713]\n",
      "[Epoch 3/200] [Batch 127/938] [D loss: 1.116113, acc: 94%] [G loss: 1.221925]\n",
      "[Epoch 3/200] [Batch 128/938] [D loss: 1.086223, acc: 92%] [G loss: 1.109886]\n",
      "[Epoch 3/200] [Batch 129/938] [D loss: 1.112275, acc: 93%] [G loss: 1.114516]\n",
      "[Epoch 3/200] [Batch 130/938] [D loss: 1.099369, acc: 89%] [G loss: 1.134604]\n",
      "[Epoch 3/200] [Batch 131/938] [D loss: 1.115069, acc: 89%] [G loss: 1.212289]\n",
      "[Epoch 3/200] [Batch 132/938] [D loss: 1.061131, acc: 94%] [G loss: 1.179036]\n",
      "[Epoch 3/200] [Batch 133/938] [D loss: 1.064803, acc: 95%] [G loss: 1.099995]\n",
      "[Epoch 3/200] [Batch 134/938] [D loss: 1.041295, acc: 96%] [G loss: 1.108073]\n",
      "[Epoch 3/200] [Batch 135/938] [D loss: 1.080361, acc: 95%] [G loss: 1.083749]\n",
      "[Epoch 3/200] [Batch 136/938] [D loss: 1.085475, acc: 97%] [G loss: 1.104636]\n",
      "[Epoch 3/200] [Batch 137/938] [D loss: 1.060460, acc: 91%] [G loss: 1.214948]\n",
      "[Epoch 3/200] [Batch 138/938] [D loss: 1.046040, acc: 95%] [G loss: 1.206707]\n",
      "[Epoch 3/200] [Batch 139/938] [D loss: 1.075014, acc: 94%] [G loss: 1.289065]\n",
      "[Epoch 3/200] [Batch 140/938] [D loss: 1.077452, acc: 95%] [G loss: 1.176162]\n",
      "[Epoch 3/200] [Batch 141/938] [D loss: 1.091479, acc: 96%] [G loss: 1.151205]\n",
      "[Epoch 3/200] [Batch 142/938] [D loss: 1.079774, acc: 92%] [G loss: 1.161951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 143/938] [D loss: 1.109738, acc: 92%] [G loss: 1.184252]\n",
      "[Epoch 3/200] [Batch 144/938] [D loss: 1.096192, acc: 93%] [G loss: 1.217033]\n",
      "[Epoch 3/200] [Batch 145/938] [D loss: 1.051581, acc: 94%] [G loss: 1.211025]\n",
      "[Epoch 3/200] [Batch 146/938] [D loss: 1.067431, acc: 95%] [G loss: 1.092660]\n",
      "[Epoch 3/200] [Batch 147/938] [D loss: 1.107379, acc: 90%] [G loss: 1.154376]\n",
      "[Epoch 3/200] [Batch 148/938] [D loss: 1.043398, acc: 95%] [G loss: 1.206010]\n",
      "[Epoch 3/200] [Batch 149/938] [D loss: 1.124242, acc: 92%] [G loss: 1.161776]\n",
      "[Epoch 3/200] [Batch 150/938] [D loss: 1.100689, acc: 92%] [G loss: 1.137474]\n",
      "[Epoch 3/200] [Batch 151/938] [D loss: 1.100619, acc: 94%] [G loss: 1.193736]\n",
      "[Epoch 3/200] [Batch 152/938] [D loss: 1.081184, acc: 100%] [G loss: 1.089350]\n",
      "[Epoch 3/200] [Batch 153/938] [D loss: 1.095640, acc: 93%] [G loss: 1.132599]\n",
      "[Epoch 3/200] [Batch 154/938] [D loss: 1.088845, acc: 91%] [G loss: 1.266808]\n",
      "[Epoch 3/200] [Batch 155/938] [D loss: 1.097898, acc: 94%] [G loss: 1.120622]\n",
      "[Epoch 3/200] [Batch 156/938] [D loss: 1.100484, acc: 93%] [G loss: 1.123845]\n",
      "[Epoch 3/200] [Batch 157/938] [D loss: 1.065606, acc: 94%] [G loss: 1.055888]\n",
      "[Epoch 3/200] [Batch 158/938] [D loss: 1.089236, acc: 90%] [G loss: 1.145076]\n",
      "[Epoch 3/200] [Batch 159/938] [D loss: 1.070189, acc: 94%] [G loss: 1.120102]\n",
      "[Epoch 3/200] [Batch 160/938] [D loss: 1.078245, acc: 92%] [G loss: 1.225700]\n",
      "[Epoch 3/200] [Batch 161/938] [D loss: 1.113615, acc: 92%] [G loss: 1.223988]\n",
      "[Epoch 3/200] [Batch 162/938] [D loss: 1.071512, acc: 94%] [G loss: 1.143229]\n",
      "[Epoch 3/200] [Batch 163/938] [D loss: 1.084495, acc: 93%] [G loss: 1.199816]\n",
      "[Epoch 3/200] [Batch 164/938] [D loss: 1.123622, acc: 92%] [G loss: 1.210003]\n",
      "[Epoch 3/200] [Batch 165/938] [D loss: 1.033971, acc: 94%] [G loss: 1.212247]\n",
      "[Epoch 3/200] [Batch 166/938] [D loss: 1.097861, acc: 92%] [G loss: 1.210697]\n",
      "[Epoch 3/200] [Batch 167/938] [D loss: 1.052737, acc: 94%] [G loss: 1.157905]\n",
      "[Epoch 3/200] [Batch 168/938] [D loss: 1.115475, acc: 91%] [G loss: 1.198118]\n",
      "[Epoch 3/200] [Batch 169/938] [D loss: 1.071125, acc: 94%] [G loss: 1.149175]\n",
      "[Epoch 3/200] [Batch 170/938] [D loss: 1.042619, acc: 96%] [G loss: 1.159604]\n",
      "[Epoch 3/200] [Batch 171/938] [D loss: 1.097474, acc: 95%] [G loss: 1.104547]\n",
      "[Epoch 3/200] [Batch 172/938] [D loss: 1.061503, acc: 94%] [G loss: 1.162927]\n",
      "[Epoch 3/200] [Batch 173/938] [D loss: 1.097638, acc: 91%] [G loss: 1.107726]\n",
      "[Epoch 3/200] [Batch 174/938] [D loss: 1.079774, acc: 96%] [G loss: 1.237182]\n",
      "[Epoch 3/200] [Batch 175/938] [D loss: 1.081149, acc: 94%] [G loss: 1.153213]\n",
      "[Epoch 3/200] [Batch 176/938] [D loss: 1.082474, acc: 95%] [G loss: 1.145999]\n",
      "[Epoch 3/200] [Batch 177/938] [D loss: 1.104020, acc: 92%] [G loss: 1.118754]\n",
      "[Epoch 3/200] [Batch 178/938] [D loss: 1.113108, acc: 91%] [G loss: 1.224297]\n",
      "[Epoch 3/200] [Batch 179/938] [D loss: 1.052692, acc: 95%] [G loss: 1.157793]\n",
      "[Epoch 3/200] [Batch 180/938] [D loss: 1.092487, acc: 94%] [G loss: 1.120388]\n",
      "[Epoch 3/200] [Batch 181/938] [D loss: 1.079845, acc: 94%] [G loss: 1.140285]\n",
      "[Epoch 3/200] [Batch 182/938] [D loss: 1.089343, acc: 92%] [G loss: 1.150000]\n",
      "[Epoch 3/200] [Batch 183/938] [D loss: 1.094311, acc: 96%] [G loss: 1.185858]\n",
      "[Epoch 3/200] [Batch 184/938] [D loss: 1.098688, acc: 92%] [G loss: 1.187233]\n",
      "[Epoch 3/200] [Batch 185/938] [D loss: 1.063951, acc: 94%] [G loss: 1.105377]\n",
      "[Epoch 3/200] [Batch 186/938] [D loss: 1.103462, acc: 93%] [G loss: 1.163571]\n",
      "[Epoch 3/200] [Batch 187/938] [D loss: 1.093020, acc: 94%] [G loss: 1.169523]\n",
      "[Epoch 3/200] [Batch 188/938] [D loss: 1.046407, acc: 92%] [G loss: 1.157516]\n",
      "[Epoch 3/200] [Batch 189/938] [D loss: 1.082897, acc: 94%] [G loss: 1.129871]\n",
      "[Epoch 3/200] [Batch 190/938] [D loss: 1.077229, acc: 92%] [G loss: 1.245391]\n",
      "[Epoch 3/200] [Batch 191/938] [D loss: 1.085885, acc: 92%] [G loss: 1.169582]\n",
      "[Epoch 3/200] [Batch 192/938] [D loss: 1.089099, acc: 92%] [G loss: 1.157922]\n",
      "[Epoch 3/200] [Batch 193/938] [D loss: 1.081269, acc: 92%] [G loss: 1.132450]\n",
      "[Epoch 3/200] [Batch 194/938] [D loss: 1.091470, acc: 92%] [G loss: 1.182237]\n",
      "[Epoch 3/200] [Batch 195/938] [D loss: 1.076936, acc: 96%] [G loss: 1.121796]\n",
      "[Epoch 3/200] [Batch 196/938] [D loss: 1.050086, acc: 92%] [G loss: 1.217467]\n",
      "[Epoch 3/200] [Batch 197/938] [D loss: 1.055779, acc: 98%] [G loss: 1.187414]\n",
      "[Epoch 3/200] [Batch 198/938] [D loss: 1.038229, acc: 96%] [G loss: 1.188435]\n",
      "[Epoch 3/200] [Batch 199/938] [D loss: 1.087756, acc: 95%] [G loss: 1.151997]\n",
      "[Epoch 3/200] [Batch 200/938] [D loss: 1.098464, acc: 92%] [G loss: 1.193328]\n",
      "[Epoch 3/200] [Batch 201/938] [D loss: 1.078522, acc: 97%] [G loss: 1.188779]\n",
      "[Epoch 3/200] [Batch 202/938] [D loss: 1.088875, acc: 93%] [G loss: 1.133553]\n",
      "[Epoch 3/200] [Batch 203/938] [D loss: 1.044398, acc: 96%] [G loss: 1.132970]\n",
      "[Epoch 3/200] [Batch 204/938] [D loss: 1.080785, acc: 90%] [G loss: 1.162436]\n",
      "[Epoch 3/200] [Batch 205/938] [D loss: 1.110727, acc: 96%] [G loss: 1.153969]\n",
      "[Epoch 3/200] [Batch 206/938] [D loss: 1.065537, acc: 93%] [G loss: 1.147139]\n",
      "[Epoch 3/200] [Batch 207/938] [D loss: 1.113000, acc: 91%] [G loss: 1.176810]\n",
      "[Epoch 3/200] [Batch 208/938] [D loss: 1.078537, acc: 95%] [G loss: 1.203564]\n",
      "[Epoch 3/200] [Batch 209/938] [D loss: 1.080663, acc: 96%] [G loss: 1.052661]\n",
      "[Epoch 3/200] [Batch 210/938] [D loss: 1.049801, acc: 96%] [G loss: 1.194369]\n",
      "[Epoch 3/200] [Batch 211/938] [D loss: 1.074322, acc: 92%] [G loss: 1.164440]\n",
      "[Epoch 3/200] [Batch 212/938] [D loss: 1.090232, acc: 94%] [G loss: 1.162423]\n",
      "[Epoch 3/200] [Batch 213/938] [D loss: 1.099827, acc: 89%] [G loss: 1.178067]\n",
      "[Epoch 3/200] [Batch 214/938] [D loss: 1.082325, acc: 89%] [G loss: 1.245653]\n",
      "[Epoch 3/200] [Batch 215/938] [D loss: 1.057693, acc: 94%] [G loss: 1.182471]\n",
      "[Epoch 3/200] [Batch 216/938] [D loss: 1.048398, acc: 94%] [G loss: 1.133896]\n",
      "[Epoch 3/200] [Batch 217/938] [D loss: 1.075844, acc: 93%] [G loss: 1.139494]\n",
      "[Epoch 3/200] [Batch 218/938] [D loss: 1.023838, acc: 94%] [G loss: 1.213848]\n",
      "[Epoch 3/200] [Batch 219/938] [D loss: 1.138228, acc: 92%] [G loss: 1.194753]\n",
      "[Epoch 3/200] [Batch 220/938] [D loss: 1.063079, acc: 92%] [G loss: 1.159875]\n",
      "[Epoch 3/200] [Batch 221/938] [D loss: 1.050001, acc: 96%] [G loss: 1.117296]\n",
      "[Epoch 3/200] [Batch 222/938] [D loss: 1.069700, acc: 92%] [G loss: 1.094611]\n",
      "[Epoch 3/200] [Batch 223/938] [D loss: 1.088333, acc: 92%] [G loss: 1.208700]\n",
      "[Epoch 3/200] [Batch 224/938] [D loss: 1.121002, acc: 90%] [G loss: 1.120276]\n",
      "[Epoch 3/200] [Batch 225/938] [D loss: 1.091182, acc: 92%] [G loss: 1.130385]\n",
      "[Epoch 3/200] [Batch 226/938] [D loss: 1.097824, acc: 93%] [G loss: 1.193670]\n",
      "[Epoch 3/200] [Batch 227/938] [D loss: 1.074284, acc: 92%] [G loss: 1.132717]\n",
      "[Epoch 3/200] [Batch 228/938] [D loss: 1.072929, acc: 93%] [G loss: 1.225528]\n",
      "[Epoch 3/200] [Batch 229/938] [D loss: 1.094063, acc: 93%] [G loss: 1.149794]\n",
      "[Epoch 3/200] [Batch 230/938] [D loss: 1.090044, acc: 96%] [G loss: 1.204741]\n",
      "[Epoch 3/200] [Batch 231/938] [D loss: 1.097858, acc: 92%] [G loss: 1.234287]\n",
      "[Epoch 3/200] [Batch 232/938] [D loss: 1.099483, acc: 94%] [G loss: 1.196883]\n",
      "[Epoch 3/200] [Batch 233/938] [D loss: 1.049111, acc: 93%] [G loss: 1.220605]\n",
      "[Epoch 3/200] [Batch 234/938] [D loss: 1.094036, acc: 92%] [G loss: 1.229154]\n",
      "[Epoch 3/200] [Batch 235/938] [D loss: 1.063931, acc: 92%] [G loss: 1.229544]\n",
      "[Epoch 3/200] [Batch 236/938] [D loss: 1.042599, acc: 95%] [G loss: 1.139192]\n",
      "[Epoch 3/200] [Batch 237/938] [D loss: 1.131774, acc: 93%] [G loss: 1.126713]\n",
      "[Epoch 3/200] [Batch 238/938] [D loss: 1.068977, acc: 95%] [G loss: 1.151321]\n",
      "[Epoch 3/200] [Batch 239/938] [D loss: 1.082287, acc: 91%] [G loss: 1.173429]\n",
      "[Epoch 3/200] [Batch 240/938] [D loss: 1.074043, acc: 96%] [G loss: 1.098686]\n",
      "[Epoch 3/200] [Batch 241/938] [D loss: 1.084325, acc: 92%] [G loss: 1.167114]\n",
      "[Epoch 3/200] [Batch 242/938] [D loss: 1.068513, acc: 89%] [G loss: 1.235879]\n",
      "[Epoch 3/200] [Batch 243/938] [D loss: 1.061712, acc: 90%] [G loss: 1.255532]\n",
      "[Epoch 3/200] [Batch 244/938] [D loss: 1.100072, acc: 96%] [G loss: 1.125735]\n",
      "[Epoch 3/200] [Batch 245/938] [D loss: 1.067298, acc: 93%] [G loss: 1.239913]\n",
      "[Epoch 3/200] [Batch 246/938] [D loss: 1.090286, acc: 96%] [G loss: 1.199536]\n",
      "[Epoch 3/200] [Batch 247/938] [D loss: 1.092212, acc: 88%] [G loss: 1.256017]\n",
      "[Epoch 3/200] [Batch 248/938] [D loss: 1.073300, acc: 89%] [G loss: 1.081898]\n",
      "[Epoch 3/200] [Batch 249/938] [D loss: 1.075918, acc: 92%] [G loss: 1.159889]\n",
      "[Epoch 3/200] [Batch 250/938] [D loss: 1.070865, acc: 92%] [G loss: 1.196566]\n",
      "[Epoch 3/200] [Batch 251/938] [D loss: 1.107502, acc: 87%] [G loss: 1.163455]\n",
      "[Epoch 3/200] [Batch 252/938] [D loss: 1.086020, acc: 94%] [G loss: 1.168022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 253/938] [D loss: 1.051760, acc: 99%] [G loss: 1.205324]\n",
      "[Epoch 3/200] [Batch 254/938] [D loss: 1.104836, acc: 93%] [G loss: 1.134017]\n",
      "[Epoch 3/200] [Batch 255/938] [D loss: 1.023259, acc: 93%] [G loss: 1.190653]\n",
      "[Epoch 3/200] [Batch 256/938] [D loss: 1.046726, acc: 96%] [G loss: 1.173296]\n",
      "[Epoch 3/200] [Batch 257/938] [D loss: 1.073990, acc: 96%] [G loss: 1.193008]\n",
      "[Epoch 3/200] [Batch 258/938] [D loss: 1.109483, acc: 94%] [G loss: 1.114485]\n",
      "[Epoch 3/200] [Batch 259/938] [D loss: 1.071306, acc: 91%] [G loss: 1.159171]\n",
      "[Epoch 3/200] [Batch 260/938] [D loss: 1.091944, acc: 94%] [G loss: 1.130890]\n",
      "[Epoch 3/200] [Batch 261/938] [D loss: 1.085888, acc: 96%] [G loss: 1.125350]\n",
      "[Epoch 3/200] [Batch 262/938] [D loss: 1.068191, acc: 92%] [G loss: 1.239465]\n",
      "[Epoch 3/200] [Batch 263/938] [D loss: 1.101826, acc: 89%] [G loss: 1.143079]\n",
      "[Epoch 3/200] [Batch 264/938] [D loss: 1.068292, acc: 92%] [G loss: 1.107374]\n",
      "[Epoch 3/200] [Batch 265/938] [D loss: 1.112307, acc: 91%] [G loss: 1.152188]\n",
      "[Epoch 3/200] [Batch 266/938] [D loss: 1.062958, acc: 94%] [G loss: 1.143638]\n",
      "[Epoch 3/200] [Batch 267/938] [D loss: 1.083674, acc: 94%] [G loss: 1.086839]\n",
      "[Epoch 3/200] [Batch 268/938] [D loss: 1.082457, acc: 89%] [G loss: 1.194388]\n",
      "[Epoch 3/200] [Batch 269/938] [D loss: 1.053165, acc: 94%] [G loss: 1.155978]\n",
      "[Epoch 3/200] [Batch 270/938] [D loss: 1.101231, acc: 94%] [G loss: 1.216577]\n",
      "[Epoch 3/200] [Batch 271/938] [D loss: 1.052168, acc: 94%] [G loss: 1.063733]\n",
      "[Epoch 3/200] [Batch 272/938] [D loss: 1.084179, acc: 94%] [G loss: 1.059384]\n",
      "[Epoch 3/200] [Batch 273/938] [D loss: 1.085650, acc: 92%] [G loss: 1.123562]\n",
      "[Epoch 3/200] [Batch 274/938] [D loss: 1.043084, acc: 93%] [G loss: 1.182368]\n",
      "[Epoch 3/200] [Batch 275/938] [D loss: 1.076529, acc: 96%] [G loss: 1.225160]\n",
      "[Epoch 3/200] [Batch 276/938] [D loss: 1.110087, acc: 92%] [G loss: 1.198369]\n",
      "[Epoch 3/200] [Batch 277/938] [D loss: 1.103335, acc: 96%] [G loss: 1.218225]\n",
      "[Epoch 3/200] [Batch 278/938] [D loss: 1.073596, acc: 92%] [G loss: 1.087880]\n",
      "[Epoch 3/200] [Batch 279/938] [D loss: 1.078764, acc: 89%] [G loss: 1.146866]\n",
      "[Epoch 3/200] [Batch 280/938] [D loss: 1.094887, acc: 92%] [G loss: 1.129829]\n",
      "[Epoch 3/200] [Batch 281/938] [D loss: 1.101966, acc: 94%] [G loss: 1.126872]\n",
      "[Epoch 3/200] [Batch 282/938] [D loss: 1.107267, acc: 94%] [G loss: 1.097070]\n",
      "[Epoch 3/200] [Batch 283/938] [D loss: 1.103440, acc: 92%] [G loss: 1.159027]\n",
      "[Epoch 3/200] [Batch 284/938] [D loss: 1.085936, acc: 95%] [G loss: 1.111822]\n",
      "[Epoch 3/200] [Batch 285/938] [D loss: 1.062987, acc: 96%] [G loss: 1.122562]\n",
      "[Epoch 3/200] [Batch 286/938] [D loss: 1.083665, acc: 93%] [G loss: 1.202076]\n",
      "[Epoch 3/200] [Batch 287/938] [D loss: 1.095402, acc: 93%] [G loss: 1.194435]\n",
      "[Epoch 3/200] [Batch 288/938] [D loss: 1.088074, acc: 93%] [G loss: 1.124184]\n",
      "[Epoch 3/200] [Batch 289/938] [D loss: 1.069545, acc: 96%] [G loss: 1.165043]\n",
      "[Epoch 3/200] [Batch 290/938] [D loss: 1.107410, acc: 91%] [G loss: 1.138553]\n",
      "[Epoch 3/200] [Batch 291/938] [D loss: 1.102220, acc: 95%] [G loss: 1.101582]\n",
      "[Epoch 3/200] [Batch 292/938] [D loss: 1.101288, acc: 94%] [G loss: 1.177269]\n",
      "[Epoch 3/200] [Batch 293/938] [D loss: 1.041135, acc: 98%] [G loss: 1.279532]\n",
      "[Epoch 3/200] [Batch 294/938] [D loss: 1.111167, acc: 91%] [G loss: 1.247006]\n",
      "[Epoch 3/200] [Batch 295/938] [D loss: 1.088305, acc: 94%] [G loss: 1.229046]\n",
      "[Epoch 3/200] [Batch 296/938] [D loss: 1.087460, acc: 93%] [G loss: 1.169288]\n",
      "[Epoch 3/200] [Batch 297/938] [D loss: 1.076524, acc: 96%] [G loss: 1.127925]\n",
      "[Epoch 3/200] [Batch 298/938] [D loss: 1.136352, acc: 89%] [G loss: 1.100547]\n",
      "[Epoch 3/200] [Batch 299/938] [D loss: 1.054386, acc: 96%] [G loss: 1.230702]\n",
      "[Epoch 3/200] [Batch 300/938] [D loss: 1.105379, acc: 92%] [G loss: 1.243990]\n",
      "[Epoch 3/200] [Batch 301/938] [D loss: 1.159637, acc: 93%] [G loss: 1.198087]\n",
      "[Epoch 3/200] [Batch 302/938] [D loss: 1.130827, acc: 92%] [G loss: 1.056750]\n",
      "[Epoch 3/200] [Batch 303/938] [D loss: 1.071591, acc: 93%] [G loss: 1.101454]\n",
      "[Epoch 3/200] [Batch 304/938] [D loss: 1.107980, acc: 99%] [G loss: 1.148109]\n",
      "[Epoch 3/200] [Batch 305/938] [D loss: 1.100504, acc: 92%] [G loss: 1.126627]\n",
      "[Epoch 3/200] [Batch 306/938] [D loss: 1.097677, acc: 92%] [G loss: 1.188641]\n",
      "[Epoch 3/200] [Batch 307/938] [D loss: 1.098055, acc: 94%] [G loss: 1.157653]\n",
      "[Epoch 3/200] [Batch 308/938] [D loss: 1.084697, acc: 91%] [G loss: 1.148714]\n",
      "[Epoch 3/200] [Batch 309/938] [D loss: 1.095745, acc: 91%] [G loss: 1.222958]\n",
      "[Epoch 3/200] [Batch 310/938] [D loss: 1.048350, acc: 95%] [G loss: 1.213462]\n",
      "[Epoch 3/200] [Batch 311/938] [D loss: 1.042594, acc: 94%] [G loss: 1.237423]\n",
      "[Epoch 3/200] [Batch 312/938] [D loss: 1.080139, acc: 95%] [G loss: 1.173000]\n",
      "[Epoch 3/200] [Batch 313/938] [D loss: 1.089548, acc: 95%] [G loss: 1.141499]\n",
      "[Epoch 3/200] [Batch 314/938] [D loss: 1.077216, acc: 93%] [G loss: 1.206101]\n",
      "[Epoch 3/200] [Batch 315/938] [D loss: 1.079572, acc: 91%] [G loss: 1.136197]\n",
      "[Epoch 3/200] [Batch 316/938] [D loss: 1.103436, acc: 88%] [G loss: 1.187076]\n",
      "[Epoch 3/200] [Batch 317/938] [D loss: 1.101244, acc: 94%] [G loss: 1.160507]\n",
      "[Epoch 3/200] [Batch 318/938] [D loss: 1.086004, acc: 95%] [G loss: 1.171094]\n",
      "[Epoch 3/200] [Batch 319/938] [D loss: 1.082691, acc: 93%] [G loss: 1.280120]\n",
      "[Epoch 3/200] [Batch 320/938] [D loss: 1.122652, acc: 92%] [G loss: 1.138084]\n",
      "[Epoch 3/200] [Batch 321/938] [D loss: 1.086577, acc: 89%] [G loss: 1.309606]\n",
      "[Epoch 3/200] [Batch 322/938] [D loss: 1.060294, acc: 93%] [G loss: 1.248819]\n",
      "[Epoch 3/200] [Batch 323/938] [D loss: 1.066579, acc: 96%] [G loss: 1.187463]\n",
      "[Epoch 3/200] [Batch 324/938] [D loss: 1.054614, acc: 96%] [G loss: 1.140786]\n",
      "[Epoch 3/200] [Batch 325/938] [D loss: 1.086755, acc: 96%] [G loss: 1.215436]\n",
      "[Epoch 3/200] [Batch 326/938] [D loss: 1.056407, acc: 96%] [G loss: 1.212443]\n",
      "[Epoch 3/200] [Batch 327/938] [D loss: 1.105992, acc: 92%] [G loss: 1.144242]\n",
      "[Epoch 3/200] [Batch 328/938] [D loss: 1.096193, acc: 96%] [G loss: 1.147744]\n",
      "[Epoch 3/200] [Batch 329/938] [D loss: 1.088340, acc: 93%] [G loss: 1.230235]\n",
      "[Epoch 3/200] [Batch 330/938] [D loss: 1.079318, acc: 95%] [G loss: 1.176811]\n",
      "[Epoch 3/200] [Batch 331/938] [D loss: 1.092824, acc: 92%] [G loss: 1.163213]\n",
      "[Epoch 3/200] [Batch 332/938] [D loss: 1.105597, acc: 89%] [G loss: 1.178447]\n",
      "[Epoch 3/200] [Batch 333/938] [D loss: 1.110042, acc: 94%] [G loss: 1.141557]\n",
      "[Epoch 3/200] [Batch 334/938] [D loss: 1.061710, acc: 96%] [G loss: 1.206905]\n",
      "[Epoch 3/200] [Batch 335/938] [D loss: 1.066774, acc: 93%] [G loss: 1.192814]\n",
      "[Epoch 3/200] [Batch 336/938] [D loss: 1.109458, acc: 94%] [G loss: 1.137511]\n",
      "[Epoch 3/200] [Batch 337/938] [D loss: 1.071578, acc: 94%] [G loss: 1.119820]\n",
      "[Epoch 3/200] [Batch 338/938] [D loss: 1.124232, acc: 92%] [G loss: 1.123675]\n",
      "[Epoch 3/200] [Batch 339/938] [D loss: 1.066904, acc: 92%] [G loss: 1.152552]\n",
      "[Epoch 3/200] [Batch 340/938] [D loss: 1.070635, acc: 91%] [G loss: 1.144837]\n",
      "[Epoch 3/200] [Batch 341/938] [D loss: 1.099949, acc: 96%] [G loss: 1.144025]\n",
      "[Epoch 3/200] [Batch 342/938] [D loss: 1.101427, acc: 93%] [G loss: 1.216938]\n",
      "[Epoch 3/200] [Batch 343/938] [D loss: 1.098559, acc: 94%] [G loss: 1.155979]\n",
      "[Epoch 3/200] [Batch 344/938] [D loss: 1.048057, acc: 95%] [G loss: 1.150761]\n",
      "[Epoch 3/200] [Batch 345/938] [D loss: 1.036590, acc: 96%] [G loss: 1.148683]\n",
      "[Epoch 3/200] [Batch 346/938] [D loss: 1.084252, acc: 92%] [G loss: 1.216583]\n",
      "[Epoch 3/200] [Batch 347/938] [D loss: 1.098934, acc: 92%] [G loss: 1.117466]\n",
      "[Epoch 3/200] [Batch 348/938] [D loss: 1.051930, acc: 96%] [G loss: 1.132966]\n",
      "[Epoch 3/200] [Batch 349/938] [D loss: 1.066082, acc: 96%] [G loss: 1.195503]\n",
      "[Epoch 3/200] [Batch 350/938] [D loss: 1.089415, acc: 93%] [G loss: 1.132855]\n",
      "[Epoch 3/200] [Batch 351/938] [D loss: 1.075302, acc: 95%] [G loss: 1.145507]\n",
      "[Epoch 3/200] [Batch 352/938] [D loss: 1.077317, acc: 94%] [G loss: 1.122023]\n",
      "[Epoch 3/200] [Batch 353/938] [D loss: 1.084032, acc: 95%] [G loss: 1.178661]\n",
      "[Epoch 3/200] [Batch 354/938] [D loss: 1.046041, acc: 94%] [G loss: 1.243456]\n",
      "[Epoch 3/200] [Batch 355/938] [D loss: 1.053555, acc: 93%] [G loss: 1.212085]\n",
      "[Epoch 3/200] [Batch 356/938] [D loss: 1.078578, acc: 93%] [G loss: 1.102220]\n",
      "[Epoch 3/200] [Batch 357/938] [D loss: 1.102293, acc: 94%] [G loss: 1.152753]\n",
      "[Epoch 3/200] [Batch 358/938] [D loss: 1.102490, acc: 92%] [G loss: 1.157077]\n",
      "[Epoch 3/200] [Batch 359/938] [D loss: 1.080000, acc: 96%] [G loss: 1.174923]\n",
      "[Epoch 3/200] [Batch 360/938] [D loss: 1.065838, acc: 93%] [G loss: 1.097999]\n",
      "[Epoch 3/200] [Batch 361/938] [D loss: 1.090835, acc: 96%] [G loss: 1.166412]\n",
      "[Epoch 3/200] [Batch 362/938] [D loss: 1.082392, acc: 92%] [G loss: 1.145874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 363/938] [D loss: 1.095529, acc: 94%] [G loss: 1.144712]\n",
      "[Epoch 3/200] [Batch 364/938] [D loss: 1.130938, acc: 92%] [G loss: 1.169670]\n",
      "[Epoch 3/200] [Batch 365/938] [D loss: 1.082346, acc: 95%] [G loss: 1.130473]\n",
      "[Epoch 3/200] [Batch 366/938] [D loss: 1.115170, acc: 94%] [G loss: 1.181007]\n",
      "[Epoch 3/200] [Batch 367/938] [D loss: 1.080416, acc: 95%] [G loss: 1.138143]\n",
      "[Epoch 3/200] [Batch 368/938] [D loss: 1.079653, acc: 95%] [G loss: 1.176809]\n",
      "[Epoch 3/200] [Batch 369/938] [D loss: 1.058981, acc: 92%] [G loss: 1.197694]\n",
      "[Epoch 3/200] [Batch 370/938] [D loss: 1.065958, acc: 96%] [G loss: 1.161582]\n",
      "[Epoch 3/200] [Batch 371/938] [D loss: 1.111785, acc: 93%] [G loss: 1.147504]\n",
      "[Epoch 3/200] [Batch 372/938] [D loss: 1.091883, acc: 96%] [G loss: 1.115982]\n",
      "[Epoch 3/200] [Batch 373/938] [D loss: 1.095355, acc: 92%] [G loss: 1.183944]\n",
      "[Epoch 3/200] [Batch 374/938] [D loss: 1.135275, acc: 94%] [G loss: 1.245187]\n",
      "[Epoch 3/200] [Batch 375/938] [D loss: 1.049198, acc: 95%] [G loss: 1.175195]\n",
      "[Epoch 3/200] [Batch 376/938] [D loss: 1.118007, acc: 93%] [G loss: 1.067768]\n",
      "[Epoch 3/200] [Batch 377/938] [D loss: 1.063923, acc: 92%] [G loss: 1.170379]\n",
      "[Epoch 3/200] [Batch 378/938] [D loss: 1.069472, acc: 93%] [G loss: 1.156691]\n",
      "[Epoch 3/200] [Batch 379/938] [D loss: 1.094848, acc: 93%] [G loss: 1.110862]\n",
      "[Epoch 3/200] [Batch 380/938] [D loss: 1.075953, acc: 93%] [G loss: 1.172925]\n",
      "[Epoch 3/200] [Batch 381/938] [D loss: 1.077863, acc: 91%] [G loss: 1.104531]\n",
      "[Epoch 3/200] [Batch 382/938] [D loss: 1.099466, acc: 92%] [G loss: 1.158235]\n",
      "[Epoch 3/200] [Batch 383/938] [D loss: 1.090785, acc: 94%] [G loss: 1.160389]\n",
      "[Epoch 3/200] [Batch 384/938] [D loss: 1.087020, acc: 96%] [G loss: 1.161036]\n",
      "[Epoch 3/200] [Batch 385/938] [D loss: 1.034916, acc: 96%] [G loss: 1.242799]\n",
      "[Epoch 3/200] [Batch 386/938] [D loss: 1.103785, acc: 92%] [G loss: 1.166487]\n",
      "[Epoch 3/200] [Batch 387/938] [D loss: 1.081908, acc: 92%] [G loss: 1.118859]\n",
      "[Epoch 3/200] [Batch 388/938] [D loss: 1.070204, acc: 96%] [G loss: 1.063190]\n",
      "[Epoch 3/200] [Batch 389/938] [D loss: 1.098712, acc: 97%] [G loss: 1.140025]\n",
      "[Epoch 3/200] [Batch 390/938] [D loss: 1.059929, acc: 95%] [G loss: 1.163314]\n",
      "[Epoch 3/200] [Batch 391/938] [D loss: 1.090681, acc: 95%] [G loss: 1.156588]\n",
      "[Epoch 3/200] [Batch 392/938] [D loss: 1.086740, acc: 94%] [G loss: 1.229815]\n",
      "[Epoch 3/200] [Batch 393/938] [D loss: 1.039359, acc: 96%] [G loss: 1.206042]\n",
      "[Epoch 3/200] [Batch 394/938] [D loss: 1.097288, acc: 92%] [G loss: 1.220311]\n",
      "[Epoch 3/200] [Batch 395/938] [D loss: 1.115630, acc: 96%] [G loss: 1.096428]\n",
      "[Epoch 3/200] [Batch 396/938] [D loss: 1.097710, acc: 89%] [G loss: 1.218926]\n",
      "[Epoch 3/200] [Batch 397/938] [D loss: 1.082917, acc: 95%] [G loss: 1.125043]\n",
      "[Epoch 3/200] [Batch 398/938] [D loss: 1.103769, acc: 93%] [G loss: 1.185657]\n",
      "[Epoch 3/200] [Batch 399/938] [D loss: 1.080844, acc: 92%] [G loss: 1.162057]\n",
      "[Epoch 3/200] [Batch 400/938] [D loss: 1.086351, acc: 89%] [G loss: 1.157047]\n",
      "[Epoch 3/200] [Batch 401/938] [D loss: 1.081571, acc: 94%] [G loss: 1.132234]\n",
      "[Epoch 3/200] [Batch 402/938] [D loss: 1.096874, acc: 92%] [G loss: 1.112795]\n",
      "[Epoch 3/200] [Batch 403/938] [D loss: 1.061404, acc: 96%] [G loss: 1.183721]\n",
      "[Epoch 3/200] [Batch 404/938] [D loss: 1.060629, acc: 89%] [G loss: 1.268461]\n",
      "[Epoch 3/200] [Batch 405/938] [D loss: 1.147233, acc: 89%] [G loss: 1.157594]\n",
      "[Epoch 3/200] [Batch 406/938] [D loss: 1.099058, acc: 93%] [G loss: 1.175897]\n",
      "[Epoch 3/200] [Batch 407/938] [D loss: 1.121694, acc: 92%] [G loss: 1.149764]\n",
      "[Epoch 3/200] [Batch 408/938] [D loss: 1.092814, acc: 93%] [G loss: 1.173963]\n",
      "[Epoch 3/200] [Batch 409/938] [D loss: 1.109940, acc: 94%] [G loss: 1.195353]\n",
      "[Epoch 3/200] [Batch 410/938] [D loss: 1.111358, acc: 85%] [G loss: 1.212468]\n",
      "[Epoch 3/200] [Batch 411/938] [D loss: 1.108146, acc: 89%] [G loss: 1.213748]\n",
      "[Epoch 3/200] [Batch 412/938] [D loss: 1.088979, acc: 93%] [G loss: 1.201515]\n",
      "[Epoch 3/200] [Batch 413/938] [D loss: 1.066866, acc: 92%] [G loss: 1.138323]\n",
      "[Epoch 3/200] [Batch 414/938] [D loss: 1.077353, acc: 92%] [G loss: 1.189732]\n",
      "[Epoch 3/200] [Batch 415/938] [D loss: 1.071275, acc: 97%] [G loss: 1.162523]\n",
      "[Epoch 3/200] [Batch 416/938] [D loss: 1.131791, acc: 92%] [G loss: 1.136311]\n",
      "[Epoch 3/200] [Batch 417/938] [D loss: 1.114341, acc: 96%] [G loss: 1.130752]\n",
      "[Epoch 3/200] [Batch 418/938] [D loss: 1.069092, acc: 95%] [G loss: 1.156721]\n",
      "[Epoch 3/200] [Batch 419/938] [D loss: 1.113973, acc: 92%] [G loss: 1.183936]\n",
      "[Epoch 3/200] [Batch 420/938] [D loss: 1.083448, acc: 96%] [G loss: 1.176100]\n",
      "[Epoch 3/200] [Batch 421/938] [D loss: 1.092818, acc: 93%] [G loss: 1.159935]\n",
      "[Epoch 3/200] [Batch 422/938] [D loss: 1.082370, acc: 96%] [G loss: 1.147384]\n",
      "[Epoch 3/200] [Batch 423/938] [D loss: 1.095677, acc: 93%] [G loss: 1.063016]\n",
      "[Epoch 3/200] [Batch 424/938] [D loss: 1.114152, acc: 94%] [G loss: 1.121192]\n",
      "[Epoch 3/200] [Batch 425/938] [D loss: 1.097640, acc: 96%] [G loss: 1.161488]\n",
      "[Epoch 3/200] [Batch 426/938] [D loss: 1.066445, acc: 92%] [G loss: 1.226436]\n",
      "[Epoch 3/200] [Batch 427/938] [D loss: 1.095486, acc: 92%] [G loss: 1.175559]\n",
      "[Epoch 3/200] [Batch 428/938] [D loss: 1.138871, acc: 93%] [G loss: 1.139936]\n",
      "[Epoch 3/200] [Batch 429/938] [D loss: 1.051875, acc: 96%] [G loss: 1.150604]\n",
      "[Epoch 3/200] [Batch 430/938] [D loss: 1.055924, acc: 95%] [G loss: 1.188322]\n",
      "[Epoch 3/200] [Batch 431/938] [D loss: 1.082764, acc: 95%] [G loss: 1.240752]\n",
      "[Epoch 3/200] [Batch 432/938] [D loss: 1.093438, acc: 94%] [G loss: 1.092310]\n",
      "[Epoch 3/200] [Batch 433/938] [D loss: 1.082391, acc: 93%] [G loss: 1.176694]\n",
      "[Epoch 3/200] [Batch 434/938] [D loss: 1.095839, acc: 93%] [G loss: 1.126285]\n",
      "[Epoch 3/200] [Batch 435/938] [D loss: 1.087385, acc: 94%] [G loss: 1.201458]\n",
      "[Epoch 3/200] [Batch 436/938] [D loss: 1.094480, acc: 90%] [G loss: 1.099228]\n",
      "[Epoch 3/200] [Batch 437/938] [D loss: 1.090773, acc: 92%] [G loss: 1.124512]\n",
      "[Epoch 3/200] [Batch 438/938] [D loss: 1.066490, acc: 95%] [G loss: 1.181153]\n",
      "[Epoch 3/200] [Batch 439/938] [D loss: 1.091089, acc: 96%] [G loss: 1.135905]\n",
      "[Epoch 3/200] [Batch 440/938] [D loss: 1.105857, acc: 92%] [G loss: 1.187431]\n",
      "[Epoch 3/200] [Batch 441/938] [D loss: 1.126589, acc: 94%] [G loss: 1.093081]\n",
      "[Epoch 3/200] [Batch 442/938] [D loss: 1.121446, acc: 90%] [G loss: 1.106485]\n",
      "[Epoch 3/200] [Batch 443/938] [D loss: 1.103572, acc: 92%] [G loss: 1.128362]\n",
      "[Epoch 3/200] [Batch 444/938] [D loss: 1.090542, acc: 92%] [G loss: 1.251517]\n",
      "[Epoch 3/200] [Batch 445/938] [D loss: 1.077781, acc: 95%] [G loss: 1.175969]\n",
      "[Epoch 3/200] [Batch 446/938] [D loss: 1.069250, acc: 92%] [G loss: 1.195017]\n",
      "[Epoch 3/200] [Batch 447/938] [D loss: 1.099455, acc: 96%] [G loss: 1.147502]\n",
      "[Epoch 3/200] [Batch 448/938] [D loss: 1.076637, acc: 92%] [G loss: 1.166192]\n",
      "[Epoch 3/200] [Batch 449/938] [D loss: 1.111018, acc: 94%] [G loss: 1.127294]\n",
      "[Epoch 3/200] [Batch 450/938] [D loss: 1.051101, acc: 93%] [G loss: 1.248120]\n",
      "[Epoch 3/200] [Batch 451/938] [D loss: 1.072188, acc: 96%] [G loss: 1.140642]\n",
      "[Epoch 3/200] [Batch 452/938] [D loss: 1.132913, acc: 93%] [G loss: 1.152889]\n",
      "[Epoch 3/200] [Batch 453/938] [D loss: 1.089301, acc: 92%] [G loss: 1.168860]\n",
      "[Epoch 3/200] [Batch 454/938] [D loss: 1.092521, acc: 93%] [G loss: 1.160508]\n",
      "[Epoch 3/200] [Batch 455/938] [D loss: 1.087223, acc: 95%] [G loss: 1.171562]\n",
      "[Epoch 3/200] [Batch 456/938] [D loss: 1.080500, acc: 94%] [G loss: 1.190258]\n",
      "[Epoch 3/200] [Batch 457/938] [D loss: 1.071957, acc: 97%] [G loss: 1.125669]\n",
      "[Epoch 3/200] [Batch 458/938] [D loss: 1.080046, acc: 93%] [G loss: 1.091662]\n",
      "[Epoch 3/200] [Batch 459/938] [D loss: 1.080439, acc: 96%] [G loss: 1.153121]\n",
      "[Epoch 3/200] [Batch 460/938] [D loss: 1.092557, acc: 93%] [G loss: 1.242291]\n",
      "[Epoch 3/200] [Batch 461/938] [D loss: 1.075655, acc: 92%] [G loss: 1.296899]\n",
      "[Epoch 3/200] [Batch 462/938] [D loss: 1.080863, acc: 89%] [G loss: 1.112868]\n",
      "[Epoch 3/200] [Batch 463/938] [D loss: 1.123425, acc: 92%] [G loss: 1.071668]\n",
      "[Epoch 3/200] [Batch 464/938] [D loss: 1.055278, acc: 96%] [G loss: 1.161650]\n",
      "[Epoch 3/200] [Batch 465/938] [D loss: 1.076210, acc: 92%] [G loss: 1.172659]\n",
      "[Epoch 3/200] [Batch 466/938] [D loss: 1.092955, acc: 97%] [G loss: 1.146357]\n",
      "[Epoch 3/200] [Batch 467/938] [D loss: 1.087480, acc: 94%] [G loss: 1.197795]\n",
      "[Epoch 3/200] [Batch 468/938] [D loss: 1.055419, acc: 93%] [G loss: 1.152161]\n",
      "[Epoch 3/200] [Batch 469/938] [D loss: 1.094334, acc: 92%] [G loss: 1.195936]\n",
      "[Epoch 3/200] [Batch 470/938] [D loss: 1.087168, acc: 91%] [G loss: 1.095434]\n",
      "[Epoch 3/200] [Batch 471/938] [D loss: 1.076122, acc: 94%] [G loss: 1.121764]\n",
      "[Epoch 3/200] [Batch 472/938] [D loss: 1.083181, acc: 96%] [G loss: 1.163943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 473/938] [D loss: 1.098716, acc: 91%] [G loss: 1.169340]\n",
      "[Epoch 3/200] [Batch 474/938] [D loss: 1.098806, acc: 96%] [G loss: 1.142594]\n",
      "[Epoch 3/200] [Batch 475/938] [D loss: 1.094457, acc: 95%] [G loss: 1.204918]\n",
      "[Epoch 3/200] [Batch 476/938] [D loss: 1.072693, acc: 94%] [G loss: 1.276917]\n",
      "[Epoch 3/200] [Batch 477/938] [D loss: 1.085483, acc: 93%] [G loss: 1.171042]\n",
      "[Epoch 3/200] [Batch 478/938] [D loss: 1.104298, acc: 90%] [G loss: 1.136243]\n",
      "[Epoch 3/200] [Batch 479/938] [D loss: 1.065694, acc: 94%] [G loss: 1.136227]\n",
      "[Epoch 3/200] [Batch 480/938] [D loss: 1.070301, acc: 93%] [G loss: 1.126110]\n",
      "[Epoch 3/200] [Batch 481/938] [D loss: 1.100004, acc: 92%] [G loss: 1.125143]\n",
      "[Epoch 3/200] [Batch 482/938] [D loss: 1.057020, acc: 95%] [G loss: 1.087550]\n",
      "[Epoch 3/200] [Batch 483/938] [D loss: 1.095902, acc: 92%] [G loss: 1.156975]\n",
      "[Epoch 3/200] [Batch 484/938] [D loss: 1.094064, acc: 93%] [G loss: 1.113193]\n",
      "[Epoch 3/200] [Batch 485/938] [D loss: 1.107633, acc: 92%] [G loss: 1.175750]\n",
      "[Epoch 3/200] [Batch 486/938] [D loss: 1.063796, acc: 93%] [G loss: 1.212033]\n",
      "[Epoch 3/200] [Batch 487/938] [D loss: 1.105572, acc: 91%] [G loss: 1.149111]\n",
      "[Epoch 3/200] [Batch 488/938] [D loss: 1.091526, acc: 95%] [G loss: 1.187100]\n",
      "[Epoch 3/200] [Batch 489/938] [D loss: 1.132307, acc: 91%] [G loss: 1.154271]\n",
      "[Epoch 3/200] [Batch 490/938] [D loss: 1.073873, acc: 95%] [G loss: 1.196909]\n",
      "[Epoch 3/200] [Batch 491/938] [D loss: 1.078528, acc: 94%] [G loss: 1.245096]\n",
      "[Epoch 3/200] [Batch 492/938] [D loss: 1.090207, acc: 96%] [G loss: 1.189433]\n",
      "[Epoch 3/200] [Batch 493/938] [D loss: 1.097750, acc: 91%] [G loss: 1.102414]\n",
      "[Epoch 3/200] [Batch 494/938] [D loss: 1.080902, acc: 98%] [G loss: 1.107172]\n",
      "[Epoch 3/200] [Batch 495/938] [D loss: 1.082258, acc: 94%] [G loss: 1.124780]\n",
      "[Epoch 3/200] [Batch 496/938] [D loss: 1.096088, acc: 92%] [G loss: 1.169910]\n",
      "[Epoch 3/200] [Batch 497/938] [D loss: 1.109308, acc: 93%] [G loss: 1.199114]\n",
      "[Epoch 3/200] [Batch 498/938] [D loss: 1.091228, acc: 94%] [G loss: 1.178977]\n",
      "[Epoch 3/200] [Batch 499/938] [D loss: 1.117785, acc: 93%] [G loss: 1.100583]\n",
      "[Epoch 3/200] [Batch 500/938] [D loss: 1.150704, acc: 95%] [G loss: 1.000500]\n",
      "[Epoch 3/200] [Batch 501/938] [D loss: 1.133600, acc: 93%] [G loss: 1.157292]\n",
      "[Epoch 3/200] [Batch 502/938] [D loss: 1.054564, acc: 94%] [G loss: 1.209571]\n",
      "[Epoch 3/200] [Batch 503/938] [D loss: 1.102588, acc: 93%] [G loss: 1.235687]\n",
      "[Epoch 3/200] [Batch 504/938] [D loss: 1.104344, acc: 92%] [G loss: 1.122146]\n",
      "[Epoch 3/200] [Batch 505/938] [D loss: 1.088163, acc: 96%] [G loss: 1.167814]\n",
      "[Epoch 3/200] [Batch 506/938] [D loss: 1.096317, acc: 92%] [G loss: 1.167793]\n",
      "[Epoch 3/200] [Batch 507/938] [D loss: 1.082979, acc: 95%] [G loss: 1.152468]\n",
      "[Epoch 3/200] [Batch 508/938] [D loss: 1.083869, acc: 94%] [G loss: 1.121483]\n",
      "[Epoch 3/200] [Batch 509/938] [D loss: 1.096194, acc: 93%] [G loss: 1.113456]\n",
      "[Epoch 3/200] [Batch 510/938] [D loss: 1.102523, acc: 93%] [G loss: 1.202874]\n",
      "[Epoch 3/200] [Batch 511/938] [D loss: 1.138695, acc: 90%] [G loss: 1.207147]\n",
      "[Epoch 3/200] [Batch 512/938] [D loss: 1.067752, acc: 96%] [G loss: 1.204220]\n",
      "[Epoch 3/200] [Batch 513/938] [D loss: 1.083386, acc: 95%] [G loss: 1.144549]\n",
      "[Epoch 3/200] [Batch 514/938] [D loss: 1.122618, acc: 92%] [G loss: 1.149563]\n",
      "[Epoch 3/200] [Batch 515/938] [D loss: 1.041239, acc: 96%] [G loss: 1.146647]\n",
      "[Epoch 3/200] [Batch 516/938] [D loss: 1.073498, acc: 94%] [G loss: 1.149915]\n",
      "[Epoch 3/200] [Batch 517/938] [D loss: 1.133013, acc: 89%] [G loss: 1.108389]\n",
      "[Epoch 3/200] [Batch 518/938] [D loss: 1.098590, acc: 96%] [G loss: 1.143051]\n",
      "[Epoch 3/200] [Batch 519/938] [D loss: 1.076199, acc: 90%] [G loss: 1.175464]\n",
      "[Epoch 3/200] [Batch 520/938] [D loss: 1.084976, acc: 92%] [G loss: 1.187296]\n",
      "[Epoch 3/200] [Batch 521/938] [D loss: 1.088399, acc: 95%] [G loss: 1.150694]\n",
      "[Epoch 3/200] [Batch 522/938] [D loss: 1.077173, acc: 93%] [G loss: 1.212735]\n",
      "[Epoch 3/200] [Batch 523/938] [D loss: 1.125045, acc: 93%] [G loss: 1.176873]\n",
      "[Epoch 3/200] [Batch 524/938] [D loss: 1.106908, acc: 94%] [G loss: 1.195568]\n",
      "[Epoch 3/200] [Batch 525/938] [D loss: 1.115697, acc: 90%] [G loss: 1.187417]\n",
      "[Epoch 3/200] [Batch 526/938] [D loss: 1.082045, acc: 93%] [G loss: 1.121392]\n",
      "[Epoch 3/200] [Batch 527/938] [D loss: 1.083171, acc: 95%] [G loss: 1.103597]\n",
      "[Epoch 3/200] [Batch 528/938] [D loss: 1.088030, acc: 93%] [G loss: 1.094486]\n",
      "[Epoch 3/200] [Batch 529/938] [D loss: 1.128783, acc: 89%] [G loss: 1.189611]\n",
      "[Epoch 3/200] [Batch 530/938] [D loss: 1.053126, acc: 96%] [G loss: 1.172042]\n",
      "[Epoch 3/200] [Batch 531/938] [D loss: 1.076930, acc: 96%] [G loss: 1.180331]\n",
      "[Epoch 3/200] [Batch 532/938] [D loss: 1.046660, acc: 93%] [G loss: 1.194141]\n",
      "[Epoch 3/200] [Batch 533/938] [D loss: 1.099882, acc: 96%] [G loss: 1.188104]\n",
      "[Epoch 3/200] [Batch 534/938] [D loss: 1.115062, acc: 93%] [G loss: 1.124824]\n",
      "[Epoch 3/200] [Batch 535/938] [D loss: 1.028761, acc: 96%] [G loss: 1.134830]\n",
      "[Epoch 3/200] [Batch 536/938] [D loss: 1.106958, acc: 95%] [G loss: 1.030168]\n",
      "[Epoch 3/200] [Batch 537/938] [D loss: 1.072501, acc: 94%] [G loss: 1.132233]\n",
      "[Epoch 3/200] [Batch 538/938] [D loss: 1.063033, acc: 95%] [G loss: 1.165639]\n",
      "[Epoch 3/200] [Batch 539/938] [D loss: 1.084127, acc: 92%] [G loss: 1.157754]\n",
      "[Epoch 3/200] [Batch 540/938] [D loss: 1.100656, acc: 97%] [G loss: 1.150710]\n",
      "[Epoch 3/200] [Batch 541/938] [D loss: 1.084311, acc: 93%] [G loss: 1.160604]\n",
      "[Epoch 3/200] [Batch 542/938] [D loss: 1.118869, acc: 93%] [G loss: 1.193803]\n",
      "[Epoch 3/200] [Batch 543/938] [D loss: 1.094601, acc: 90%] [G loss: 1.238204]\n",
      "[Epoch 3/200] [Batch 544/938] [D loss: 1.090587, acc: 94%] [G loss: 1.141235]\n",
      "[Epoch 3/200] [Batch 545/938] [D loss: 1.069137, acc: 94%] [G loss: 1.112729]\n",
      "[Epoch 3/200] [Batch 546/938] [D loss: 1.081529, acc: 96%] [G loss: 1.177604]\n",
      "[Epoch 3/200] [Batch 547/938] [D loss: 1.068242, acc: 95%] [G loss: 1.174243]\n",
      "[Epoch 3/200] [Batch 548/938] [D loss: 1.102428, acc: 93%] [G loss: 1.138051]\n",
      "[Epoch 3/200] [Batch 549/938] [D loss: 1.152335, acc: 90%] [G loss: 1.121540]\n",
      "[Epoch 3/200] [Batch 550/938] [D loss: 1.075524, acc: 94%] [G loss: 1.152268]\n",
      "[Epoch 3/200] [Batch 551/938] [D loss: 1.103051, acc: 92%] [G loss: 1.171165]\n",
      "[Epoch 3/200] [Batch 552/938] [D loss: 1.116799, acc: 92%] [G loss: 1.089892]\n",
      "[Epoch 3/200] [Batch 553/938] [D loss: 1.052806, acc: 96%] [G loss: 1.095023]\n",
      "[Epoch 3/200] [Batch 554/938] [D loss: 1.112952, acc: 90%] [G loss: 1.180168]\n",
      "[Epoch 3/200] [Batch 555/938] [D loss: 1.078857, acc: 90%] [G loss: 1.201350]\n",
      "[Epoch 3/200] [Batch 556/938] [D loss: 1.064431, acc: 95%] [G loss: 1.235139]\n",
      "[Epoch 3/200] [Batch 557/938] [D loss: 1.103478, acc: 95%] [G loss: 1.256980]\n",
      "[Epoch 3/200] [Batch 558/938] [D loss: 1.131964, acc: 92%] [G loss: 1.163908]\n",
      "[Epoch 3/200] [Batch 559/938] [D loss: 1.051846, acc: 91%] [G loss: 1.185295]\n",
      "[Epoch 3/200] [Batch 560/938] [D loss: 1.079398, acc: 93%] [G loss: 1.214715]\n",
      "[Epoch 3/200] [Batch 561/938] [D loss: 1.092372, acc: 93%] [G loss: 1.128449]\n",
      "[Epoch 3/200] [Batch 562/938] [D loss: 1.072294, acc: 92%] [G loss: 1.200334]\n",
      "[Epoch 3/200] [Batch 563/938] [D loss: 1.072605, acc: 96%] [G loss: 1.162008]\n",
      "[Epoch 3/200] [Batch 564/938] [D loss: 1.062444, acc: 91%] [G loss: 1.290232]\n",
      "[Epoch 3/200] [Batch 565/938] [D loss: 1.076078, acc: 89%] [G loss: 1.207848]\n",
      "[Epoch 3/200] [Batch 566/938] [D loss: 1.062613, acc: 94%] [G loss: 1.216547]\n",
      "[Epoch 3/200] [Batch 567/938] [D loss: 1.087885, acc: 97%] [G loss: 1.155192]\n",
      "[Epoch 3/200] [Batch 568/938] [D loss: 1.077561, acc: 93%] [G loss: 1.072127]\n",
      "[Epoch 3/200] [Batch 569/938] [D loss: 1.066138, acc: 94%] [G loss: 1.167360]\n",
      "[Epoch 3/200] [Batch 570/938] [D loss: 1.081083, acc: 94%] [G loss: 1.174354]\n",
      "[Epoch 3/200] [Batch 571/938] [D loss: 1.088491, acc: 96%] [G loss: 1.153875]\n",
      "[Epoch 3/200] [Batch 572/938] [D loss: 1.086700, acc: 93%] [G loss: 1.192652]\n",
      "[Epoch 3/200] [Batch 573/938] [D loss: 1.060204, acc: 94%] [G loss: 1.054942]\n",
      "[Epoch 3/200] [Batch 574/938] [D loss: 1.103767, acc: 95%] [G loss: 1.105424]\n",
      "[Epoch 3/200] [Batch 575/938] [D loss: 1.086827, acc: 94%] [G loss: 1.171949]\n",
      "[Epoch 3/200] [Batch 576/938] [D loss: 1.075958, acc: 95%] [G loss: 1.140343]\n",
      "[Epoch 3/200] [Batch 577/938] [D loss: 1.057314, acc: 95%] [G loss: 1.222695]\n",
      "[Epoch 3/200] [Batch 578/938] [D loss: 1.134876, acc: 92%] [G loss: 1.133894]\n",
      "[Epoch 3/200] [Batch 579/938] [D loss: 1.093406, acc: 95%] [G loss: 1.216904]\n",
      "[Epoch 3/200] [Batch 580/938] [D loss: 1.088104, acc: 91%] [G loss: 1.179351]\n",
      "[Epoch 3/200] [Batch 581/938] [D loss: 1.116944, acc: 95%] [G loss: 1.158464]\n",
      "[Epoch 3/200] [Batch 582/938] [D loss: 1.081769, acc: 93%] [G loss: 1.076830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 583/938] [D loss: 1.092330, acc: 96%] [G loss: 1.079735]\n",
      "[Epoch 3/200] [Batch 584/938] [D loss: 1.028676, acc: 97%] [G loss: 1.227720]\n",
      "[Epoch 3/200] [Batch 585/938] [D loss: 1.069515, acc: 94%] [G loss: 1.123244]\n",
      "[Epoch 3/200] [Batch 586/938] [D loss: 1.056289, acc: 93%] [G loss: 1.157582]\n",
      "[Epoch 3/200] [Batch 587/938] [D loss: 1.124224, acc: 94%] [G loss: 1.148087]\n",
      "[Epoch 3/200] [Batch 588/938] [D loss: 1.071417, acc: 92%] [G loss: 1.075038]\n",
      "[Epoch 3/200] [Batch 589/938] [D loss: 1.071416, acc: 96%] [G loss: 1.149142]\n",
      "[Epoch 3/200] [Batch 590/938] [D loss: 1.082437, acc: 94%] [G loss: 1.140707]\n",
      "[Epoch 3/200] [Batch 591/938] [D loss: 1.097559, acc: 94%] [G loss: 1.102185]\n",
      "[Epoch 3/200] [Batch 592/938] [D loss: 1.073832, acc: 93%] [G loss: 1.194212]\n",
      "[Epoch 3/200] [Batch 593/938] [D loss: 1.102236, acc: 94%] [G loss: 1.108252]\n",
      "[Epoch 3/200] [Batch 594/938] [D loss: 1.084592, acc: 96%] [G loss: 1.146824]\n",
      "[Epoch 3/200] [Batch 595/938] [D loss: 1.078161, acc: 92%] [G loss: 1.125729]\n",
      "[Epoch 3/200] [Batch 596/938] [D loss: 1.044635, acc: 95%] [G loss: 1.144416]\n",
      "[Epoch 3/200] [Batch 597/938] [D loss: 1.099912, acc: 93%] [G loss: 1.158403]\n",
      "[Epoch 3/200] [Batch 598/938] [D loss: 1.092943, acc: 96%] [G loss: 1.135364]\n",
      "[Epoch 3/200] [Batch 599/938] [D loss: 1.104654, acc: 92%] [G loss: 1.148018]\n",
      "[Epoch 3/200] [Batch 600/938] [D loss: 1.078547, acc: 96%] [G loss: 1.160552]\n",
      "[Epoch 3/200] [Batch 601/938] [D loss: 1.068321, acc: 93%] [G loss: 1.193723]\n",
      "[Epoch 3/200] [Batch 602/938] [D loss: 1.045602, acc: 98%] [G loss: 1.197907]\n",
      "[Epoch 3/200] [Batch 603/938] [D loss: 1.157692, acc: 90%] [G loss: 1.105194]\n",
      "[Epoch 3/200] [Batch 604/938] [D loss: 1.053046, acc: 94%] [G loss: 1.144187]\n",
      "[Epoch 3/200] [Batch 605/938] [D loss: 1.061143, acc: 92%] [G loss: 1.139622]\n",
      "[Epoch 3/200] [Batch 606/938] [D loss: 1.060577, acc: 95%] [G loss: 1.111085]\n",
      "[Epoch 3/200] [Batch 607/938] [D loss: 1.100751, acc: 92%] [G loss: 1.249129]\n",
      "[Epoch 3/200] [Batch 608/938] [D loss: 1.106059, acc: 92%] [G loss: 1.166569]\n",
      "[Epoch 3/200] [Batch 609/938] [D loss: 1.094444, acc: 96%] [G loss: 1.140742]\n",
      "[Epoch 3/200] [Batch 610/938] [D loss: 1.097208, acc: 94%] [G loss: 1.080503]\n",
      "[Epoch 3/200] [Batch 611/938] [D loss: 1.098185, acc: 92%] [G loss: 1.113239]\n",
      "[Epoch 3/200] [Batch 612/938] [D loss: 1.100924, acc: 97%] [G loss: 1.112470]\n",
      "[Epoch 3/200] [Batch 613/938] [D loss: 1.100544, acc: 96%] [G loss: 1.101494]\n",
      "[Epoch 3/200] [Batch 614/938] [D loss: 1.066938, acc: 96%] [G loss: 1.174596]\n",
      "[Epoch 3/200] [Batch 615/938] [D loss: 1.069326, acc: 91%] [G loss: 1.127911]\n",
      "[Epoch 3/200] [Batch 616/938] [D loss: 1.070177, acc: 96%] [G loss: 1.141990]\n",
      "[Epoch 3/200] [Batch 617/938] [D loss: 1.099884, acc: 96%] [G loss: 1.144346]\n",
      "[Epoch 3/200] [Batch 618/938] [D loss: 1.080662, acc: 94%] [G loss: 1.217506]\n",
      "[Epoch 3/200] [Batch 619/938] [D loss: 1.087848, acc: 96%] [G loss: 1.106276]\n",
      "[Epoch 3/200] [Batch 620/938] [D loss: 1.105633, acc: 92%] [G loss: 1.164428]\n",
      "[Epoch 3/200] [Batch 621/938] [D loss: 1.063789, acc: 96%] [G loss: 1.138269]\n",
      "[Epoch 3/200] [Batch 622/938] [D loss: 1.117529, acc: 91%] [G loss: 1.157438]\n",
      "[Epoch 3/200] [Batch 623/938] [D loss: 1.068087, acc: 89%] [G loss: 1.124505]\n",
      "[Epoch 3/200] [Batch 624/938] [D loss: 1.051728, acc: 95%] [G loss: 1.202788]\n",
      "[Epoch 3/200] [Batch 625/938] [D loss: 1.105710, acc: 96%] [G loss: 1.233585]\n",
      "[Epoch 3/200] [Batch 626/938] [D loss: 1.077483, acc: 95%] [G loss: 1.235892]\n",
      "[Epoch 3/200] [Batch 627/938] [D loss: 1.072278, acc: 96%] [G loss: 1.154199]\n",
      "[Epoch 3/200] [Batch 628/938] [D loss: 1.067435, acc: 93%] [G loss: 1.142384]\n",
      "[Epoch 3/200] [Batch 629/938] [D loss: 1.082246, acc: 92%] [G loss: 1.125956]\n",
      "[Epoch 3/200] [Batch 630/938] [D loss: 1.078745, acc: 97%] [G loss: 1.134396]\n",
      "[Epoch 3/200] [Batch 631/938] [D loss: 1.088707, acc: 92%] [G loss: 1.193582]\n",
      "[Epoch 3/200] [Batch 632/938] [D loss: 1.102831, acc: 95%] [G loss: 1.166224]\n",
      "[Epoch 3/200] [Batch 633/938] [D loss: 1.107650, acc: 96%] [G loss: 1.193006]\n",
      "[Epoch 3/200] [Batch 634/938] [D loss: 1.123029, acc: 89%] [G loss: 1.201052]\n",
      "[Epoch 3/200] [Batch 635/938] [D loss: 1.115870, acc: 94%] [G loss: 1.096902]\n",
      "[Epoch 3/200] [Batch 636/938] [D loss: 1.103481, acc: 90%] [G loss: 1.180510]\n",
      "[Epoch 3/200] [Batch 637/938] [D loss: 1.113526, acc: 92%] [G loss: 1.141404]\n",
      "[Epoch 3/200] [Batch 638/938] [D loss: 1.087054, acc: 92%] [G loss: 1.126405]\n",
      "[Epoch 3/200] [Batch 639/938] [D loss: 1.087056, acc: 95%] [G loss: 1.094437]\n",
      "[Epoch 3/200] [Batch 640/938] [D loss: 1.076509, acc: 95%] [G loss: 1.195886]\n",
      "[Epoch 3/200] [Batch 641/938] [D loss: 1.058589, acc: 94%] [G loss: 1.138902]\n",
      "[Epoch 3/200] [Batch 642/938] [D loss: 1.093028, acc: 95%] [G loss: 1.168574]\n",
      "[Epoch 3/200] [Batch 643/938] [D loss: 1.122627, acc: 96%] [G loss: 1.067909]\n",
      "[Epoch 3/200] [Batch 644/938] [D loss: 1.065827, acc: 92%] [G loss: 1.112047]\n",
      "[Epoch 3/200] [Batch 645/938] [D loss: 1.050681, acc: 96%] [G loss: 1.114984]\n",
      "[Epoch 3/200] [Batch 646/938] [D loss: 1.089375, acc: 93%] [G loss: 1.238292]\n",
      "[Epoch 3/200] [Batch 647/938] [D loss: 1.088612, acc: 90%] [G loss: 1.151297]\n",
      "[Epoch 3/200] [Batch 648/938] [D loss: 1.115296, acc: 93%] [G loss: 1.088509]\n",
      "[Epoch 3/200] [Batch 649/938] [D loss: 1.095296, acc: 97%] [G loss: 1.107116]\n",
      "[Epoch 3/200] [Batch 650/938] [D loss: 1.062113, acc: 97%] [G loss: 1.186180]\n",
      "[Epoch 3/200] [Batch 651/938] [D loss: 1.026171, acc: 93%] [G loss: 1.230229]\n",
      "[Epoch 3/200] [Batch 652/938] [D loss: 1.078235, acc: 98%] [G loss: 1.101549]\n",
      "[Epoch 3/200] [Batch 653/938] [D loss: 1.058800, acc: 94%] [G loss: 1.150201]\n",
      "[Epoch 3/200] [Batch 654/938] [D loss: 1.075752, acc: 95%] [G loss: 1.113562]\n",
      "[Epoch 3/200] [Batch 655/938] [D loss: 1.071255, acc: 93%] [G loss: 1.224043]\n",
      "[Epoch 3/200] [Batch 656/938] [D loss: 1.081701, acc: 94%] [G loss: 1.186232]\n",
      "[Epoch 3/200] [Batch 657/938] [D loss: 1.093631, acc: 90%] [G loss: 1.153211]\n",
      "[Epoch 3/200] [Batch 658/938] [D loss: 1.109292, acc: 92%] [G loss: 1.229246]\n",
      "[Epoch 3/200] [Batch 659/938] [D loss: 1.107885, acc: 93%] [G loss: 1.127324]\n",
      "[Epoch 3/200] [Batch 660/938] [D loss: 1.087265, acc: 95%] [G loss: 1.155318]\n",
      "[Epoch 3/200] [Batch 661/938] [D loss: 1.067635, acc: 97%] [G loss: 1.118855]\n",
      "[Epoch 3/200] [Batch 662/938] [D loss: 1.101443, acc: 94%] [G loss: 1.146696]\n",
      "[Epoch 3/200] [Batch 663/938] [D loss: 1.069153, acc: 96%] [G loss: 1.179422]\n",
      "[Epoch 3/200] [Batch 664/938] [D loss: 1.080231, acc: 95%] [G loss: 1.158814]\n",
      "[Epoch 3/200] [Batch 665/938] [D loss: 1.104443, acc: 96%] [G loss: 1.172749]\n",
      "[Epoch 3/200] [Batch 666/938] [D loss: 1.058370, acc: 96%] [G loss: 1.199644]\n",
      "[Epoch 3/200] [Batch 667/938] [D loss: 1.056459, acc: 96%] [G loss: 1.176810]\n",
      "[Epoch 3/200] [Batch 668/938] [D loss: 1.076586, acc: 92%] [G loss: 1.190814]\n",
      "[Epoch 3/200] [Batch 669/938] [D loss: 1.047304, acc: 96%] [G loss: 1.175110]\n",
      "[Epoch 3/200] [Batch 670/938] [D loss: 1.113813, acc: 95%] [G loss: 1.133739]\n",
      "[Epoch 3/200] [Batch 671/938] [D loss: 1.126916, acc: 92%] [G loss: 1.111807]\n",
      "[Epoch 3/200] [Batch 672/938] [D loss: 1.074148, acc: 96%] [G loss: 1.095008]\n",
      "[Epoch 3/200] [Batch 673/938] [D loss: 1.086776, acc: 93%] [G loss: 1.086359]\n",
      "[Epoch 3/200] [Batch 674/938] [D loss: 1.073344, acc: 94%] [G loss: 1.159010]\n",
      "[Epoch 3/200] [Batch 675/938] [D loss: 1.095809, acc: 93%] [G loss: 1.105017]\n",
      "[Epoch 3/200] [Batch 676/938] [D loss: 1.050611, acc: 95%] [G loss: 1.224681]\n",
      "[Epoch 3/200] [Batch 677/938] [D loss: 1.095901, acc: 93%] [G loss: 1.169817]\n",
      "[Epoch 3/200] [Batch 678/938] [D loss: 1.080703, acc: 96%] [G loss: 1.221055]\n",
      "[Epoch 3/200] [Batch 679/938] [D loss: 1.110848, acc: 96%] [G loss: 1.188666]\n",
      "[Epoch 3/200] [Batch 680/938] [D loss: 1.062856, acc: 93%] [G loss: 1.197488]\n",
      "[Epoch 3/200] [Batch 681/938] [D loss: 1.072165, acc: 94%] [G loss: 1.141488]\n",
      "[Epoch 3/200] [Batch 682/938] [D loss: 1.071352, acc: 92%] [G loss: 1.147548]\n",
      "[Epoch 3/200] [Batch 683/938] [D loss: 1.068844, acc: 94%] [G loss: 1.111922]\n",
      "[Epoch 3/200] [Batch 684/938] [D loss: 1.094723, acc: 92%] [G loss: 1.167772]\n",
      "[Epoch 3/200] [Batch 685/938] [D loss: 1.087659, acc: 94%] [G loss: 1.134971]\n",
      "[Epoch 3/200] [Batch 686/938] [D loss: 1.069850, acc: 92%] [G loss: 1.235318]\n",
      "[Epoch 3/200] [Batch 687/938] [D loss: 1.114151, acc: 96%] [G loss: 1.157505]\n",
      "[Epoch 3/200] [Batch 688/938] [D loss: 1.041572, acc: 94%] [G loss: 1.122688]\n",
      "[Epoch 3/200] [Batch 689/938] [D loss: 1.100307, acc: 96%] [G loss: 1.059710]\n",
      "[Epoch 3/200] [Batch 690/938] [D loss: 1.094167, acc: 95%] [G loss: 1.197654]\n",
      "[Epoch 3/200] [Batch 691/938] [D loss: 1.037717, acc: 95%] [G loss: 1.304224]\n",
      "[Epoch 3/200] [Batch 692/938] [D loss: 1.066334, acc: 92%] [G loss: 1.270087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 693/938] [D loss: 1.111915, acc: 92%] [G loss: 1.207521]\n",
      "[Epoch 3/200] [Batch 694/938] [D loss: 1.066635, acc: 92%] [G loss: 1.151371]\n",
      "[Epoch 3/200] [Batch 695/938] [D loss: 1.063208, acc: 94%] [G loss: 1.113328]\n",
      "[Epoch 3/200] [Batch 696/938] [D loss: 1.095771, acc: 94%] [G loss: 1.146296]\n",
      "[Epoch 3/200] [Batch 697/938] [D loss: 1.052762, acc: 95%] [G loss: 1.168419]\n",
      "[Epoch 3/200] [Batch 698/938] [D loss: 1.074504, acc: 94%] [G loss: 1.166368]\n",
      "[Epoch 3/200] [Batch 699/938] [D loss: 1.106484, acc: 96%] [G loss: 1.199977]\n",
      "[Epoch 3/200] [Batch 700/938] [D loss: 1.081788, acc: 95%] [G loss: 1.198015]\n",
      "[Epoch 3/200] [Batch 701/938] [D loss: 1.133608, acc: 95%] [G loss: 1.082170]\n",
      "[Epoch 3/200] [Batch 702/938] [D loss: 1.123057, acc: 88%] [G loss: 1.136194]\n",
      "[Epoch 3/200] [Batch 703/938] [D loss: 1.095631, acc: 93%] [G loss: 1.195679]\n",
      "[Epoch 3/200] [Batch 704/938] [D loss: 1.110847, acc: 89%] [G loss: 1.188830]\n",
      "[Epoch 3/200] [Batch 705/938] [D loss: 1.077944, acc: 95%] [G loss: 1.146970]\n",
      "[Epoch 3/200] [Batch 706/938] [D loss: 1.060539, acc: 96%] [G loss: 1.192173]\n",
      "[Epoch 3/200] [Batch 707/938] [D loss: 1.059482, acc: 99%] [G loss: 1.183111]\n",
      "[Epoch 3/200] [Batch 708/938] [D loss: 1.101653, acc: 92%] [G loss: 1.168025]\n",
      "[Epoch 3/200] [Batch 709/938] [D loss: 1.076404, acc: 91%] [G loss: 1.255445]\n",
      "[Epoch 3/200] [Batch 710/938] [D loss: 1.081531, acc: 96%] [G loss: 1.095660]\n",
      "[Epoch 3/200] [Batch 711/938] [D loss: 1.105762, acc: 93%] [G loss: 1.077447]\n",
      "[Epoch 3/200] [Batch 712/938] [D loss: 1.074223, acc: 97%] [G loss: 1.138159]\n",
      "[Epoch 3/200] [Batch 713/938] [D loss: 1.086433, acc: 93%] [G loss: 1.103707]\n",
      "[Epoch 3/200] [Batch 714/938] [D loss: 1.085508, acc: 96%] [G loss: 1.296131]\n",
      "[Epoch 3/200] [Batch 715/938] [D loss: 1.076811, acc: 95%] [G loss: 1.164187]\n",
      "[Epoch 3/200] [Batch 716/938] [D loss: 1.099213, acc: 95%] [G loss: 1.101257]\n",
      "[Epoch 3/200] [Batch 717/938] [D loss: 1.104534, acc: 92%] [G loss: 1.126199]\n",
      "[Epoch 3/200] [Batch 718/938] [D loss: 1.054374, acc: 93%] [G loss: 1.229847]\n",
      "[Epoch 3/200] [Batch 719/938] [D loss: 1.129109, acc: 92%] [G loss: 1.105708]\n",
      "[Epoch 3/200] [Batch 720/938] [D loss: 1.105010, acc: 93%] [G loss: 1.159543]\n",
      "[Epoch 3/200] [Batch 721/938] [D loss: 1.055962, acc: 93%] [G loss: 1.111465]\n",
      "[Epoch 3/200] [Batch 722/938] [D loss: 1.053092, acc: 93%] [G loss: 1.202763]\n",
      "[Epoch 3/200] [Batch 723/938] [D loss: 1.098328, acc: 95%] [G loss: 1.131530]\n",
      "[Epoch 3/200] [Batch 724/938] [D loss: 1.069854, acc: 95%] [G loss: 1.108135]\n",
      "[Epoch 3/200] [Batch 725/938] [D loss: 1.085407, acc: 94%] [G loss: 1.171141]\n",
      "[Epoch 3/200] [Batch 726/938] [D loss: 1.066255, acc: 96%] [G loss: 1.159455]\n",
      "[Epoch 3/200] [Batch 727/938] [D loss: 1.081033, acc: 97%] [G loss: 1.120738]\n",
      "[Epoch 3/200] [Batch 728/938] [D loss: 1.103053, acc: 90%] [G loss: 1.082618]\n",
      "[Epoch 3/200] [Batch 729/938] [D loss: 1.073018, acc: 95%] [G loss: 1.200046]\n",
      "[Epoch 3/200] [Batch 730/938] [D loss: 1.123687, acc: 92%] [G loss: 1.130828]\n",
      "[Epoch 3/200] [Batch 731/938] [D loss: 1.109835, acc: 94%] [G loss: 1.102824]\n",
      "[Epoch 3/200] [Batch 732/938] [D loss: 1.109396, acc: 91%] [G loss: 1.070854]\n",
      "[Epoch 3/200] [Batch 733/938] [D loss: 1.076635, acc: 95%] [G loss: 1.083883]\n",
      "[Epoch 3/200] [Batch 734/938] [D loss: 1.088681, acc: 94%] [G loss: 1.151845]\n",
      "[Epoch 3/200] [Batch 735/938] [D loss: 1.090981, acc: 94%] [G loss: 1.152001]\n",
      "[Epoch 3/200] [Batch 736/938] [D loss: 1.097069, acc: 91%] [G loss: 1.144399]\n",
      "[Epoch 3/200] [Batch 737/938] [D loss: 1.111088, acc: 93%] [G loss: 1.150727]\n",
      "[Epoch 3/200] [Batch 738/938] [D loss: 1.062999, acc: 94%] [G loss: 1.204527]\n",
      "[Epoch 3/200] [Batch 739/938] [D loss: 1.111405, acc: 94%] [G loss: 1.202326]\n",
      "[Epoch 3/200] [Batch 740/938] [D loss: 1.094636, acc: 89%] [G loss: 1.164324]\n",
      "[Epoch 3/200] [Batch 741/938] [D loss: 1.107858, acc: 91%] [G loss: 1.187651]\n",
      "[Epoch 3/200] [Batch 742/938] [D loss: 1.097935, acc: 92%] [G loss: 1.219980]\n",
      "[Epoch 3/200] [Batch 743/938] [D loss: 1.067432, acc: 91%] [G loss: 1.120727]\n",
      "[Epoch 3/200] [Batch 744/938] [D loss: 1.071710, acc: 95%] [G loss: 1.106634]\n",
      "[Epoch 3/200] [Batch 745/938] [D loss: 1.058558, acc: 95%] [G loss: 1.111178]\n",
      "[Epoch 3/200] [Batch 746/938] [D loss: 1.054300, acc: 96%] [G loss: 1.157182]\n",
      "[Epoch 3/200] [Batch 747/938] [D loss: 1.069704, acc: 95%] [G loss: 1.096807]\n",
      "[Epoch 3/200] [Batch 748/938] [D loss: 1.092576, acc: 92%] [G loss: 1.174946]\n",
      "[Epoch 3/200] [Batch 749/938] [D loss: 1.091482, acc: 96%] [G loss: 1.130941]\n",
      "[Epoch 3/200] [Batch 750/938] [D loss: 1.111460, acc: 95%] [G loss: 1.185393]\n",
      "[Epoch 3/200] [Batch 751/938] [D loss: 1.084323, acc: 90%] [G loss: 1.203736]\n",
      "[Epoch 3/200] [Batch 752/938] [D loss: 1.089871, acc: 97%] [G loss: 1.171738]\n",
      "[Epoch 3/200] [Batch 753/938] [D loss: 1.082471, acc: 95%] [G loss: 1.113231]\n",
      "[Epoch 3/200] [Batch 754/938] [D loss: 1.096885, acc: 94%] [G loss: 1.103347]\n",
      "[Epoch 3/200] [Batch 755/938] [D loss: 1.080281, acc: 96%] [G loss: 1.133475]\n",
      "[Epoch 3/200] [Batch 756/938] [D loss: 1.118497, acc: 96%] [G loss: 1.134714]\n",
      "[Epoch 3/200] [Batch 757/938] [D loss: 1.073419, acc: 92%] [G loss: 1.142425]\n",
      "[Epoch 3/200] [Batch 758/938] [D loss: 1.084764, acc: 96%] [G loss: 1.175864]\n",
      "[Epoch 3/200] [Batch 759/938] [D loss: 1.069769, acc: 97%] [G loss: 1.237525]\n",
      "[Epoch 3/200] [Batch 760/938] [D loss: 1.120883, acc: 94%] [G loss: 1.149979]\n",
      "[Epoch 3/200] [Batch 761/938] [D loss: 1.068529, acc: 93%] [G loss: 1.163413]\n",
      "[Epoch 3/200] [Batch 762/938] [D loss: 1.055218, acc: 96%] [G loss: 1.129315]\n",
      "[Epoch 3/200] [Batch 763/938] [D loss: 1.063907, acc: 94%] [G loss: 1.110312]\n",
      "[Epoch 3/200] [Batch 764/938] [D loss: 1.128359, acc: 91%] [G loss: 1.097683]\n",
      "[Epoch 3/200] [Batch 765/938] [D loss: 1.084986, acc: 96%] [G loss: 1.132164]\n",
      "[Epoch 3/200] [Batch 766/938] [D loss: 1.113475, acc: 92%] [G loss: 1.143379]\n",
      "[Epoch 3/200] [Batch 767/938] [D loss: 1.065234, acc: 95%] [G loss: 1.126926]\n",
      "[Epoch 3/200] [Batch 768/938] [D loss: 1.084734, acc: 94%] [G loss: 1.092346]\n",
      "[Epoch 3/200] [Batch 769/938] [D loss: 1.069843, acc: 95%] [G loss: 1.134578]\n",
      "[Epoch 3/200] [Batch 770/938] [D loss: 1.116351, acc: 91%] [G loss: 1.112763]\n",
      "[Epoch 3/200] [Batch 771/938] [D loss: 1.120044, acc: 96%] [G loss: 1.179491]\n",
      "[Epoch 3/200] [Batch 772/938] [D loss: 1.084244, acc: 93%] [G loss: 1.117398]\n",
      "[Epoch 3/200] [Batch 773/938] [D loss: 1.040731, acc: 94%] [G loss: 1.096567]\n",
      "[Epoch 3/200] [Batch 774/938] [D loss: 1.086947, acc: 96%] [G loss: 1.067715]\n",
      "[Epoch 3/200] [Batch 775/938] [D loss: 1.047509, acc: 97%] [G loss: 1.199656]\n",
      "[Epoch 3/200] [Batch 776/938] [D loss: 1.070846, acc: 93%] [G loss: 1.182878]\n",
      "[Epoch 3/200] [Batch 777/938] [D loss: 1.085270, acc: 92%] [G loss: 1.192565]\n",
      "[Epoch 3/200] [Batch 778/938] [D loss: 1.095396, acc: 96%] [G loss: 1.120531]\n",
      "[Epoch 3/200] [Batch 779/938] [D loss: 1.083502, acc: 97%] [G loss: 1.155633]\n",
      "[Epoch 3/200] [Batch 780/938] [D loss: 1.080943, acc: 93%] [G loss: 1.078069]\n",
      "[Epoch 3/200] [Batch 781/938] [D loss: 1.083073, acc: 96%] [G loss: 1.093480]\n",
      "[Epoch 3/200] [Batch 782/938] [D loss: 1.049289, acc: 96%] [G loss: 1.215158]\n",
      "[Epoch 3/200] [Batch 783/938] [D loss: 1.099159, acc: 97%] [G loss: 1.128665]\n",
      "[Epoch 3/200] [Batch 784/938] [D loss: 1.106429, acc: 92%] [G loss: 1.173204]\n",
      "[Epoch 3/200] [Batch 785/938] [D loss: 1.112142, acc: 98%] [G loss: 1.154748]\n",
      "[Epoch 3/200] [Batch 786/938] [D loss: 1.068115, acc: 95%] [G loss: 1.157794]\n",
      "[Epoch 3/200] [Batch 787/938] [D loss: 1.095310, acc: 93%] [G loss: 1.123630]\n",
      "[Epoch 3/200] [Batch 788/938] [D loss: 1.087367, acc: 92%] [G loss: 1.094707]\n",
      "[Epoch 3/200] [Batch 789/938] [D loss: 1.043594, acc: 95%] [G loss: 1.097297]\n",
      "[Epoch 3/200] [Batch 790/938] [D loss: 1.072361, acc: 96%] [G loss: 1.129492]\n",
      "[Epoch 3/200] [Batch 791/938] [D loss: 1.104430, acc: 94%] [G loss: 1.200819]\n",
      "[Epoch 3/200] [Batch 792/938] [D loss: 1.081929, acc: 92%] [G loss: 1.179893]\n",
      "[Epoch 3/200] [Batch 793/938] [D loss: 1.093869, acc: 93%] [G loss: 1.213945]\n",
      "[Epoch 3/200] [Batch 794/938] [D loss: 1.083309, acc: 96%] [G loss: 1.098593]\n",
      "[Epoch 3/200] [Batch 795/938] [D loss: 1.085111, acc: 92%] [G loss: 1.116756]\n",
      "[Epoch 3/200] [Batch 796/938] [D loss: 1.117429, acc: 95%] [G loss: 1.098338]\n",
      "[Epoch 3/200] [Batch 797/938] [D loss: 1.096454, acc: 95%] [G loss: 1.105869]\n",
      "[Epoch 3/200] [Batch 798/938] [D loss: 1.085730, acc: 94%] [G loss: 1.235608]\n",
      "[Epoch 3/200] [Batch 799/938] [D loss: 1.068257, acc: 95%] [G loss: 1.104418]\n",
      "[Epoch 3/200] [Batch 800/938] [D loss: 1.103551, acc: 93%] [G loss: 1.130016]\n",
      "[Epoch 3/200] [Batch 801/938] [D loss: 1.073528, acc: 89%] [G loss: 1.196441]\n",
      "[Epoch 3/200] [Batch 802/938] [D loss: 1.090218, acc: 95%] [G loss: 1.219234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 803/938] [D loss: 1.092223, acc: 96%] [G loss: 1.161411]\n",
      "[Epoch 3/200] [Batch 804/938] [D loss: 1.068719, acc: 94%] [G loss: 1.178503]\n",
      "[Epoch 3/200] [Batch 805/938] [D loss: 1.067663, acc: 93%] [G loss: 1.232665]\n",
      "[Epoch 3/200] [Batch 806/938] [D loss: 1.086103, acc: 92%] [G loss: 1.114779]\n",
      "[Epoch 3/200] [Batch 807/938] [D loss: 1.104657, acc: 96%] [G loss: 1.214093]\n",
      "[Epoch 3/200] [Batch 808/938] [D loss: 1.092882, acc: 92%] [G loss: 1.184251]\n",
      "[Epoch 3/200] [Batch 809/938] [D loss: 1.076572, acc: 96%] [G loss: 1.126842]\n",
      "[Epoch 3/200] [Batch 810/938] [D loss: 1.070591, acc: 91%] [G loss: 1.184902]\n",
      "[Epoch 3/200] [Batch 811/938] [D loss: 1.061415, acc: 93%] [G loss: 1.225473]\n",
      "[Epoch 3/200] [Batch 812/938] [D loss: 1.076958, acc: 93%] [G loss: 1.221610]\n",
      "[Epoch 3/200] [Batch 813/938] [D loss: 1.050273, acc: 91%] [G loss: 1.244044]\n",
      "[Epoch 3/200] [Batch 814/938] [D loss: 1.104098, acc: 96%] [G loss: 1.146278]\n",
      "[Epoch 3/200] [Batch 815/938] [D loss: 1.109265, acc: 98%] [G loss: 1.100715]\n",
      "[Epoch 3/200] [Batch 816/938] [D loss: 1.076754, acc: 97%] [G loss: 1.062071]\n",
      "[Epoch 3/200] [Batch 817/938] [D loss: 1.094867, acc: 96%] [G loss: 1.111760]\n",
      "[Epoch 3/200] [Batch 818/938] [D loss: 1.114201, acc: 95%] [G loss: 1.189089]\n",
      "[Epoch 3/200] [Batch 819/938] [D loss: 1.088634, acc: 94%] [G loss: 1.143474]\n",
      "[Epoch 3/200] [Batch 820/938] [D loss: 1.106617, acc: 91%] [G loss: 1.183854]\n",
      "[Epoch 3/200] [Batch 821/938] [D loss: 1.110743, acc: 93%] [G loss: 1.129665]\n",
      "[Epoch 3/200] [Batch 822/938] [D loss: 1.060436, acc: 97%] [G loss: 1.156423]\n",
      "[Epoch 3/200] [Batch 823/938] [D loss: 1.140680, acc: 91%] [G loss: 1.080614]\n",
      "[Epoch 3/200] [Batch 824/938] [D loss: 1.120033, acc: 91%] [G loss: 1.193392]\n",
      "[Epoch 3/200] [Batch 825/938] [D loss: 1.103453, acc: 95%] [G loss: 1.192937]\n",
      "[Epoch 3/200] [Batch 826/938] [D loss: 1.071585, acc: 95%] [G loss: 1.145564]\n",
      "[Epoch 3/200] [Batch 827/938] [D loss: 1.108751, acc: 94%] [G loss: 1.094873]\n",
      "[Epoch 3/200] [Batch 828/938] [D loss: 1.091023, acc: 93%] [G loss: 1.122676]\n",
      "[Epoch 3/200] [Batch 829/938] [D loss: 1.075812, acc: 96%] [G loss: 1.126225]\n",
      "[Epoch 3/200] [Batch 830/938] [D loss: 1.090491, acc: 92%] [G loss: 1.127092]\n",
      "[Epoch 3/200] [Batch 831/938] [D loss: 1.056135, acc: 97%] [G loss: 1.156528]\n",
      "[Epoch 3/200] [Batch 832/938] [D loss: 1.104062, acc: 94%] [G loss: 1.071867]\n",
      "[Epoch 3/200] [Batch 833/938] [D loss: 1.084488, acc: 91%] [G loss: 1.162040]\n",
      "[Epoch 3/200] [Batch 834/938] [D loss: 1.077450, acc: 92%] [G loss: 1.150808]\n",
      "[Epoch 3/200] [Batch 835/938] [D loss: 1.092669, acc: 92%] [G loss: 1.158112]\n",
      "[Epoch 3/200] [Batch 836/938] [D loss: 1.128902, acc: 89%] [G loss: 1.172164]\n",
      "[Epoch 3/200] [Batch 837/938] [D loss: 1.065170, acc: 92%] [G loss: 1.164897]\n",
      "[Epoch 3/200] [Batch 838/938] [D loss: 1.111971, acc: 95%] [G loss: 1.107598]\n",
      "[Epoch 3/200] [Batch 839/938] [D loss: 1.097863, acc: 96%] [G loss: 1.131900]\n",
      "[Epoch 3/200] [Batch 840/938] [D loss: 1.096628, acc: 96%] [G loss: 1.130703]\n",
      "[Epoch 3/200] [Batch 841/938] [D loss: 1.045017, acc: 94%] [G loss: 1.091731]\n",
      "[Epoch 3/200] [Batch 842/938] [D loss: 1.057544, acc: 96%] [G loss: 1.107115]\n",
      "[Epoch 3/200] [Batch 843/938] [D loss: 1.099453, acc: 97%] [G loss: 1.095423]\n",
      "[Epoch 3/200] [Batch 844/938] [D loss: 1.051962, acc: 94%] [G loss: 1.183645]\n",
      "[Epoch 3/200] [Batch 845/938] [D loss: 1.058909, acc: 94%] [G loss: 1.100683]\n",
      "[Epoch 3/200] [Batch 846/938] [D loss: 1.090916, acc: 96%] [G loss: 1.161206]\n",
      "[Epoch 3/200] [Batch 847/938] [D loss: 1.091275, acc: 93%] [G loss: 1.099441]\n",
      "[Epoch 3/200] [Batch 848/938] [D loss: 1.090846, acc: 94%] [G loss: 1.064219]\n",
      "[Epoch 3/200] [Batch 849/938] [D loss: 1.090050, acc: 94%] [G loss: 1.074151]\n",
      "[Epoch 3/200] [Batch 850/938] [D loss: 1.085495, acc: 92%] [G loss: 1.143948]\n",
      "[Epoch 3/200] [Batch 851/938] [D loss: 1.045532, acc: 96%] [G loss: 1.139133]\n",
      "[Epoch 3/200] [Batch 852/938] [D loss: 1.083044, acc: 96%] [G loss: 1.075155]\n",
      "[Epoch 3/200] [Batch 853/938] [D loss: 1.089215, acc: 94%] [G loss: 1.159895]\n",
      "[Epoch 3/200] [Batch 854/938] [D loss: 1.048175, acc: 97%] [G loss: 1.172728]\n",
      "[Epoch 3/200] [Batch 855/938] [D loss: 1.089864, acc: 94%] [G loss: 1.163204]\n",
      "[Epoch 3/200] [Batch 856/938] [D loss: 1.109143, acc: 92%] [G loss: 1.093738]\n",
      "[Epoch 3/200] [Batch 857/938] [D loss: 1.111219, acc: 93%] [G loss: 1.111158]\n",
      "[Epoch 3/200] [Batch 858/938] [D loss: 1.103285, acc: 91%] [G loss: 1.129480]\n",
      "[Epoch 3/200] [Batch 859/938] [D loss: 1.047881, acc: 92%] [G loss: 1.145491]\n",
      "[Epoch 3/200] [Batch 860/938] [D loss: 1.063604, acc: 96%] [G loss: 1.141371]\n",
      "[Epoch 3/200] [Batch 861/938] [D loss: 1.125023, acc: 89%] [G loss: 1.143407]\n",
      "[Epoch 3/200] [Batch 862/938] [D loss: 1.103447, acc: 96%] [G loss: 1.160387]\n",
      "[Epoch 3/200] [Batch 863/938] [D loss: 1.108729, acc: 91%] [G loss: 1.079253]\n",
      "[Epoch 3/200] [Batch 864/938] [D loss: 1.068669, acc: 95%] [G loss: 1.154742]\n",
      "[Epoch 3/200] [Batch 865/938] [D loss: 1.116861, acc: 91%] [G loss: 1.117821]\n",
      "[Epoch 3/200] [Batch 866/938] [D loss: 1.054971, acc: 96%] [G loss: 1.179768]\n",
      "[Epoch 3/200] [Batch 867/938] [D loss: 1.097192, acc: 93%] [G loss: 1.067920]\n",
      "[Epoch 3/200] [Batch 868/938] [D loss: 1.116490, acc: 95%] [G loss: 1.080317]\n",
      "[Epoch 3/200] [Batch 869/938] [D loss: 1.078710, acc: 96%] [G loss: 1.145902]\n",
      "[Epoch 3/200] [Batch 870/938] [D loss: 1.099459, acc: 93%] [G loss: 1.161678]\n",
      "[Epoch 3/200] [Batch 871/938] [D loss: 1.070847, acc: 94%] [G loss: 1.168278]\n",
      "[Epoch 3/200] [Batch 872/938] [D loss: 1.072551, acc: 95%] [G loss: 1.134340]\n",
      "[Epoch 3/200] [Batch 873/938] [D loss: 1.118837, acc: 92%] [G loss: 1.233176]\n",
      "[Epoch 3/200] [Batch 874/938] [D loss: 1.068110, acc: 89%] [G loss: 1.185219]\n",
      "[Epoch 3/200] [Batch 875/938] [D loss: 1.113797, acc: 90%] [G loss: 1.152783]\n",
      "[Epoch 3/200] [Batch 876/938] [D loss: 1.091977, acc: 92%] [G loss: 1.204462]\n",
      "[Epoch 3/200] [Batch 877/938] [D loss: 1.067351, acc: 95%] [G loss: 1.144464]\n",
      "[Epoch 3/200] [Batch 878/938] [D loss: 1.077486, acc: 96%] [G loss: 1.091456]\n",
      "[Epoch 3/200] [Batch 879/938] [D loss: 1.076240, acc: 94%] [G loss: 1.112627]\n",
      "[Epoch 3/200] [Batch 880/938] [D loss: 1.077145, acc: 96%] [G loss: 1.092182]\n",
      "[Epoch 3/200] [Batch 881/938] [D loss: 1.089774, acc: 91%] [G loss: 1.127367]\n",
      "[Epoch 3/200] [Batch 882/938] [D loss: 1.069974, acc: 92%] [G loss: 1.195930]\n",
      "[Epoch 3/200] [Batch 883/938] [D loss: 1.104373, acc: 96%] [G loss: 1.165637]\n",
      "[Epoch 3/200] [Batch 884/938] [D loss: 1.067546, acc: 96%] [G loss: 1.145811]\n",
      "[Epoch 3/200] [Batch 885/938] [D loss: 1.071390, acc: 94%] [G loss: 1.114774]\n",
      "[Epoch 3/200] [Batch 886/938] [D loss: 1.033833, acc: 96%] [G loss: 1.118394]\n",
      "[Epoch 3/200] [Batch 887/938] [D loss: 1.099143, acc: 95%] [G loss: 1.184322]\n",
      "[Epoch 3/200] [Batch 888/938] [D loss: 1.051153, acc: 97%] [G loss: 1.129533]\n",
      "[Epoch 3/200] [Batch 889/938] [D loss: 1.093753, acc: 94%] [G loss: 1.071890]\n",
      "[Epoch 3/200] [Batch 890/938] [D loss: 1.075194, acc: 95%] [G loss: 1.209566]\n",
      "[Epoch 3/200] [Batch 891/938] [D loss: 1.068939, acc: 95%] [G loss: 1.193581]\n",
      "[Epoch 3/200] [Batch 892/938] [D loss: 1.100518, acc: 92%] [G loss: 1.083172]\n",
      "[Epoch 3/200] [Batch 893/938] [D loss: 1.075454, acc: 92%] [G loss: 1.192896]\n",
      "[Epoch 3/200] [Batch 894/938] [D loss: 1.100624, acc: 91%] [G loss: 1.207665]\n",
      "[Epoch 3/200] [Batch 895/938] [D loss: 1.072428, acc: 93%] [G loss: 1.114214]\n",
      "[Epoch 3/200] [Batch 896/938] [D loss: 1.091776, acc: 94%] [G loss: 1.138711]\n",
      "[Epoch 3/200] [Batch 897/938] [D loss: 1.147508, acc: 86%] [G loss: 1.115946]\n",
      "[Epoch 3/200] [Batch 898/938] [D loss: 1.117654, acc: 89%] [G loss: 1.125984]\n",
      "[Epoch 3/200] [Batch 899/938] [D loss: 1.079375, acc: 95%] [G loss: 1.190938]\n",
      "[Epoch 3/200] [Batch 900/938] [D loss: 1.087530, acc: 93%] [G loss: 1.192487]\n",
      "[Epoch 3/200] [Batch 901/938] [D loss: 1.083527, acc: 91%] [G loss: 1.160467]\n",
      "[Epoch 3/200] [Batch 902/938] [D loss: 1.072666, acc: 93%] [G loss: 1.235057]\n",
      "[Epoch 3/200] [Batch 903/938] [D loss: 1.061920, acc: 96%] [G loss: 1.188908]\n",
      "[Epoch 3/200] [Batch 904/938] [D loss: 1.071858, acc: 95%] [G loss: 1.121247]\n",
      "[Epoch 3/200] [Batch 905/938] [D loss: 1.072689, acc: 97%] [G loss: 1.187225]\n",
      "[Epoch 3/200] [Batch 906/938] [D loss: 1.031856, acc: 96%] [G loss: 1.284132]\n",
      "[Epoch 3/200] [Batch 907/938] [D loss: 1.060897, acc: 93%] [G loss: 1.112172]\n",
      "[Epoch 3/200] [Batch 908/938] [D loss: 1.087172, acc: 95%] [G loss: 1.089333]\n",
      "[Epoch 3/200] [Batch 909/938] [D loss: 1.124218, acc: 94%] [G loss: 1.108209]\n",
      "[Epoch 3/200] [Batch 910/938] [D loss: 1.070561, acc: 95%] [G loss: 1.177425]\n",
      "[Epoch 3/200] [Batch 911/938] [D loss: 1.071291, acc: 92%] [G loss: 1.176360]\n",
      "[Epoch 3/200] [Batch 912/938] [D loss: 1.098660, acc: 96%] [G loss: 1.168355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/200] [Batch 913/938] [D loss: 1.095525, acc: 92%] [G loss: 1.191963]\n",
      "[Epoch 3/200] [Batch 914/938] [D loss: 1.030285, acc: 99%] [G loss: 1.220940]\n",
      "[Epoch 3/200] [Batch 915/938] [D loss: 1.120520, acc: 91%] [G loss: 1.183813]\n",
      "[Epoch 3/200] [Batch 916/938] [D loss: 1.071552, acc: 97%] [G loss: 1.103582]\n",
      "[Epoch 3/200] [Batch 917/938] [D loss: 1.091654, acc: 93%] [G loss: 1.079575]\n",
      "[Epoch 3/200] [Batch 918/938] [D loss: 1.124453, acc: 94%] [G loss: 1.158800]\n",
      "[Epoch 3/200] [Batch 919/938] [D loss: 1.126995, acc: 96%] [G loss: 1.127074]\n",
      "[Epoch 3/200] [Batch 920/938] [D loss: 1.076422, acc: 97%] [G loss: 1.110181]\n",
      "[Epoch 3/200] [Batch 921/938] [D loss: 1.087872, acc: 94%] [G loss: 1.164559]\n",
      "[Epoch 3/200] [Batch 922/938] [D loss: 1.108274, acc: 93%] [G loss: 1.163412]\n",
      "[Epoch 3/200] [Batch 923/938] [D loss: 1.090213, acc: 95%] [G loss: 1.177438]\n",
      "[Epoch 3/200] [Batch 924/938] [D loss: 1.058430, acc: 95%] [G loss: 1.192788]\n",
      "[Epoch 3/200] [Batch 925/938] [D loss: 1.089360, acc: 95%] [G loss: 1.183510]\n",
      "[Epoch 3/200] [Batch 926/938] [D loss: 1.074465, acc: 94%] [G loss: 1.206602]\n",
      "[Epoch 3/200] [Batch 927/938] [D loss: 1.118477, acc: 90%] [G loss: 1.196008]\n",
      "[Epoch 3/200] [Batch 928/938] [D loss: 1.085762, acc: 93%] [G loss: 1.225965]\n",
      "[Epoch 3/200] [Batch 929/938] [D loss: 1.101722, acc: 93%] [G loss: 1.213704]\n",
      "[Epoch 3/200] [Batch 930/938] [D loss: 1.089209, acc: 93%] [G loss: 1.171956]\n",
      "[Epoch 3/200] [Batch 931/938] [D loss: 1.074277, acc: 96%] [G loss: 1.126012]\n",
      "[Epoch 3/200] [Batch 932/938] [D loss: 1.064770, acc: 95%] [G loss: 1.173172]\n",
      "[Epoch 3/200] [Batch 933/938] [D loss: 1.068789, acc: 96%] [G loss: 1.263718]\n",
      "[Epoch 3/200] [Batch 934/938] [D loss: 1.082453, acc: 96%] [G loss: 1.186684]\n",
      "[Epoch 3/200] [Batch 935/938] [D loss: 1.096696, acc: 95%] [G loss: 1.150522]\n",
      "[Epoch 3/200] [Batch 936/938] [D loss: 1.084952, acc: 91%] [G loss: 1.134611]\n",
      "[Epoch 3/200] [Batch 937/938] [D loss: 1.069117, acc: 98%] [G loss: 1.111582]\n",
      "[Epoch 4/200] [Batch 0/938] [D loss: 1.062838, acc: 92%] [G loss: 1.212331]\n",
      "[Epoch 4/200] [Batch 1/938] [D loss: 1.089655, acc: 91%] [G loss: 1.260149]\n",
      "[Epoch 4/200] [Batch 2/938] [D loss: 1.064941, acc: 95%] [G loss: 1.146641]\n",
      "[Epoch 4/200] [Batch 3/938] [D loss: 1.133796, acc: 94%] [G loss: 1.122877]\n",
      "[Epoch 4/200] [Batch 4/938] [D loss: 1.107898, acc: 95%] [G loss: 1.092559]\n",
      "[Epoch 4/200] [Batch 5/938] [D loss: 1.082964, acc: 96%] [G loss: 1.195512]\n",
      "[Epoch 4/200] [Batch 6/938] [D loss: 1.081567, acc: 95%] [G loss: 1.171588]\n",
      "[Epoch 4/200] [Batch 7/938] [D loss: 1.079751, acc: 95%] [G loss: 1.281788]\n",
      "[Epoch 4/200] [Batch 8/938] [D loss: 1.083493, acc: 97%] [G loss: 1.140768]\n",
      "[Epoch 4/200] [Batch 9/938] [D loss: 1.084048, acc: 97%] [G loss: 1.081134]\n",
      "[Epoch 4/200] [Batch 10/938] [D loss: 1.053420, acc: 95%] [G loss: 1.093758]\n",
      "[Epoch 4/200] [Batch 11/938] [D loss: 1.079053, acc: 93%] [G loss: 1.119085]\n",
      "[Epoch 4/200] [Batch 12/938] [D loss: 1.123642, acc: 94%] [G loss: 1.146268]\n",
      "[Epoch 4/200] [Batch 13/938] [D loss: 1.077848, acc: 95%] [G loss: 1.166154]\n",
      "[Epoch 4/200] [Batch 14/938] [D loss: 1.085555, acc: 97%] [G loss: 1.109273]\n",
      "[Epoch 4/200] [Batch 15/938] [D loss: 1.090509, acc: 96%] [G loss: 1.200724]\n",
      "[Epoch 4/200] [Batch 16/938] [D loss: 1.082521, acc: 95%] [G loss: 1.061911]\n",
      "[Epoch 4/200] [Batch 17/938] [D loss: 1.094700, acc: 96%] [G loss: 1.182113]\n",
      "[Epoch 4/200] [Batch 18/938] [D loss: 1.044240, acc: 96%] [G loss: 1.168315]\n",
      "[Epoch 4/200] [Batch 19/938] [D loss: 1.045383, acc: 96%] [G loss: 1.142619]\n",
      "[Epoch 4/200] [Batch 20/938] [D loss: 1.059566, acc: 95%] [G loss: 1.168528]\n",
      "[Epoch 4/200] [Batch 21/938] [D loss: 1.088224, acc: 91%] [G loss: 1.139277]\n",
      "[Epoch 4/200] [Batch 22/938] [D loss: 1.089700, acc: 95%] [G loss: 1.051539]\n",
      "[Epoch 4/200] [Batch 23/938] [D loss: 1.068006, acc: 97%] [G loss: 1.105043]\n",
      "[Epoch 4/200] [Batch 24/938] [D loss: 1.100126, acc: 96%] [G loss: 1.079729]\n",
      "[Epoch 4/200] [Batch 25/938] [D loss: 1.097955, acc: 92%] [G loss: 1.170338]\n",
      "[Epoch 4/200] [Batch 26/938] [D loss: 1.081698, acc: 90%] [G loss: 1.174933]\n",
      "[Epoch 4/200] [Batch 27/938] [D loss: 1.063660, acc: 96%] [G loss: 1.140382]\n",
      "[Epoch 4/200] [Batch 28/938] [D loss: 1.151027, acc: 92%] [G loss: 1.091453]\n",
      "[Epoch 4/200] [Batch 29/938] [D loss: 1.080698, acc: 95%] [G loss: 1.175553]\n",
      "[Epoch 4/200] [Batch 30/938] [D loss: 1.074116, acc: 93%] [G loss: 1.120539]\n",
      "[Epoch 4/200] [Batch 31/938] [D loss: 1.093928, acc: 95%] [G loss: 1.083570]\n",
      "[Epoch 4/200] [Batch 32/938] [D loss: 1.078858, acc: 96%] [G loss: 1.094785]\n",
      "[Epoch 4/200] [Batch 33/938] [D loss: 1.059336, acc: 96%] [G loss: 1.150379]\n",
      "[Epoch 4/200] [Batch 34/938] [D loss: 1.071059, acc: 95%] [G loss: 1.222258]\n",
      "[Epoch 4/200] [Batch 35/938] [D loss: 1.073521, acc: 96%] [G loss: 1.128616]\n",
      "[Epoch 4/200] [Batch 36/938] [D loss: 1.099957, acc: 94%] [G loss: 1.165169]\n",
      "[Epoch 4/200] [Batch 37/938] [D loss: 1.107105, acc: 96%] [G loss: 1.105199]\n",
      "[Epoch 4/200] [Batch 38/938] [D loss: 1.065001, acc: 95%] [G loss: 1.134136]\n",
      "[Epoch 4/200] [Batch 39/938] [D loss: 1.072564, acc: 96%] [G loss: 1.097105]\n",
      "[Epoch 4/200] [Batch 40/938] [D loss: 1.118186, acc: 92%] [G loss: 1.131223]\n",
      "[Epoch 4/200] [Batch 41/938] [D loss: 1.088831, acc: 96%] [G loss: 1.174418]\n",
      "[Epoch 4/200] [Batch 42/938] [D loss: 1.074091, acc: 91%] [G loss: 1.146446]\n",
      "[Epoch 4/200] [Batch 43/938] [D loss: 1.076208, acc: 92%] [G loss: 1.092980]\n",
      "[Epoch 4/200] [Batch 44/938] [D loss: 1.111024, acc: 89%] [G loss: 1.125597]\n",
      "[Epoch 4/200] [Batch 45/938] [D loss: 1.076968, acc: 94%] [G loss: 1.148578]\n",
      "[Epoch 4/200] [Batch 46/938] [D loss: 1.073441, acc: 96%] [G loss: 1.100789]\n",
      "[Epoch 4/200] [Batch 47/938] [D loss: 1.082265, acc: 93%] [G loss: 1.078561]\n",
      "[Epoch 4/200] [Batch 48/938] [D loss: 1.068501, acc: 96%] [G loss: 1.157249]\n",
      "[Epoch 4/200] [Batch 49/938] [D loss: 1.161434, acc: 93%] [G loss: 1.131040]\n",
      "[Epoch 4/200] [Batch 50/938] [D loss: 1.086766, acc: 95%] [G loss: 1.168476]\n",
      "[Epoch 4/200] [Batch 51/938] [D loss: 1.070077, acc: 96%] [G loss: 1.119103]\n",
      "[Epoch 4/200] [Batch 52/938] [D loss: 1.059764, acc: 95%] [G loss: 1.204315]\n",
      "[Epoch 4/200] [Batch 53/938] [D loss: 1.112890, acc: 94%] [G loss: 1.144964]\n",
      "[Epoch 4/200] [Batch 54/938] [D loss: 1.096432, acc: 96%] [G loss: 1.087324]\n",
      "[Epoch 4/200] [Batch 55/938] [D loss: 1.092196, acc: 97%] [G loss: 1.156918]\n",
      "[Epoch 4/200] [Batch 56/938] [D loss: 1.063695, acc: 92%] [G loss: 1.208643]\n",
      "[Epoch 4/200] [Batch 57/938] [D loss: 1.061328, acc: 90%] [G loss: 1.218790]\n",
      "[Epoch 4/200] [Batch 58/938] [D loss: 1.076862, acc: 92%] [G loss: 1.283005]\n",
      "[Epoch 4/200] [Batch 59/938] [D loss: 1.089716, acc: 92%] [G loss: 1.110888]\n",
      "[Epoch 4/200] [Batch 60/938] [D loss: 1.045632, acc: 96%] [G loss: 1.094236]\n",
      "[Epoch 4/200] [Batch 61/938] [D loss: 1.091206, acc: 95%] [G loss: 1.145728]\n",
      "[Epoch 4/200] [Batch 62/938] [D loss: 1.065868, acc: 91%] [G loss: 1.154513]\n",
      "[Epoch 4/200] [Batch 63/938] [D loss: 1.100059, acc: 92%] [G loss: 1.159188]\n",
      "[Epoch 4/200] [Batch 64/938] [D loss: 1.056556, acc: 95%] [G loss: 1.254896]\n",
      "[Epoch 4/200] [Batch 65/938] [D loss: 1.088587, acc: 94%] [G loss: 1.258269]\n",
      "[Epoch 4/200] [Batch 66/938] [D loss: 1.021647, acc: 98%] [G loss: 1.136969]\n",
      "[Epoch 4/200] [Batch 67/938] [D loss: 1.058580, acc: 96%] [G loss: 1.076184]\n",
      "[Epoch 4/200] [Batch 68/938] [D loss: 1.122579, acc: 94%] [G loss: 1.158670]\n",
      "[Epoch 4/200] [Batch 69/938] [D loss: 1.089530, acc: 94%] [G loss: 1.119540]\n",
      "[Epoch 4/200] [Batch 70/938] [D loss: 1.091318, acc: 96%] [G loss: 1.112226]\n",
      "[Epoch 4/200] [Batch 71/938] [D loss: 1.095362, acc: 92%] [G loss: 1.145765]\n",
      "[Epoch 4/200] [Batch 72/938] [D loss: 1.125205, acc: 93%] [G loss: 1.110025]\n",
      "[Epoch 4/200] [Batch 73/938] [D loss: 1.104593, acc: 95%] [G loss: 1.149967]\n",
      "[Epoch 4/200] [Batch 74/938] [D loss: 1.092938, acc: 95%] [G loss: 1.085356]\n",
      "[Epoch 4/200] [Batch 75/938] [D loss: 1.110560, acc: 95%] [G loss: 1.126261]\n",
      "[Epoch 4/200] [Batch 76/938] [D loss: 1.094227, acc: 95%] [G loss: 1.106733]\n",
      "[Epoch 4/200] [Batch 77/938] [D loss: 1.112457, acc: 91%] [G loss: 1.138007]\n",
      "[Epoch 4/200] [Batch 78/938] [D loss: 1.064686, acc: 99%] [G loss: 1.158110]\n",
      "[Epoch 4/200] [Batch 79/938] [D loss: 1.092592, acc: 93%] [G loss: 1.167173]\n",
      "[Epoch 4/200] [Batch 80/938] [D loss: 1.114004, acc: 96%] [G loss: 1.185056]\n",
      "[Epoch 4/200] [Batch 81/938] [D loss: 1.059064, acc: 93%] [G loss: 1.081785]\n",
      "[Epoch 4/200] [Batch 82/938] [D loss: 1.068995, acc: 97%] [G loss: 1.173368]\n",
      "[Epoch 4/200] [Batch 83/938] [D loss: 1.052242, acc: 94%] [G loss: 1.115633]\n",
      "[Epoch 4/200] [Batch 84/938] [D loss: 1.084601, acc: 92%] [G loss: 1.153795]\n",
      "[Epoch 4/200] [Batch 85/938] [D loss: 1.049228, acc: 94%] [G loss: 1.177787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 86/938] [D loss: 1.082415, acc: 97%] [G loss: 1.188551]\n",
      "[Epoch 4/200] [Batch 87/938] [D loss: 1.098989, acc: 95%] [G loss: 1.096754]\n",
      "[Epoch 4/200] [Batch 88/938] [D loss: 1.103082, acc: 91%] [G loss: 1.105962]\n",
      "[Epoch 4/200] [Batch 89/938] [D loss: 1.114966, acc: 96%] [G loss: 1.110024]\n",
      "[Epoch 4/200] [Batch 90/938] [D loss: 1.084197, acc: 92%] [G loss: 1.106848]\n",
      "[Epoch 4/200] [Batch 91/938] [D loss: 1.084457, acc: 93%] [G loss: 1.120175]\n",
      "[Epoch 4/200] [Batch 92/938] [D loss: 1.076071, acc: 94%] [G loss: 1.134560]\n",
      "[Epoch 4/200] [Batch 93/938] [D loss: 1.095658, acc: 93%] [G loss: 1.179943]\n",
      "[Epoch 4/200] [Batch 94/938] [D loss: 1.116289, acc: 89%] [G loss: 1.134265]\n",
      "[Epoch 4/200] [Batch 95/938] [D loss: 1.136283, acc: 92%] [G loss: 1.127000]\n",
      "[Epoch 4/200] [Batch 96/938] [D loss: 1.084612, acc: 96%] [G loss: 1.129173]\n",
      "[Epoch 4/200] [Batch 97/938] [D loss: 1.090806, acc: 97%] [G loss: 1.196701]\n",
      "[Epoch 4/200] [Batch 98/938] [D loss: 1.115753, acc: 95%] [G loss: 1.121019]\n",
      "[Epoch 4/200] [Batch 99/938] [D loss: 1.063551, acc: 95%] [G loss: 1.224685]\n",
      "[Epoch 4/200] [Batch 100/938] [D loss: 1.064862, acc: 95%] [G loss: 1.223924]\n",
      "[Epoch 4/200] [Batch 101/938] [D loss: 1.066349, acc: 95%] [G loss: 1.108769]\n",
      "[Epoch 4/200] [Batch 102/938] [D loss: 1.084455, acc: 92%] [G loss: 1.103454]\n",
      "[Epoch 4/200] [Batch 103/938] [D loss: 1.056797, acc: 95%] [G loss: 1.184294]\n",
      "[Epoch 4/200] [Batch 104/938] [D loss: 1.081529, acc: 94%] [G loss: 1.168219]\n",
      "[Epoch 4/200] [Batch 105/938] [D loss: 1.059988, acc: 96%] [G loss: 1.172111]\n",
      "[Epoch 4/200] [Batch 106/938] [D loss: 1.058820, acc: 97%] [G loss: 1.176205]\n",
      "[Epoch 4/200] [Batch 107/938] [D loss: 1.079018, acc: 96%] [G loss: 1.146813]\n",
      "[Epoch 4/200] [Batch 108/938] [D loss: 1.067924, acc: 93%] [G loss: 1.196528]\n",
      "[Epoch 4/200] [Batch 109/938] [D loss: 1.111124, acc: 93%] [G loss: 1.150151]\n",
      "[Epoch 4/200] [Batch 110/938] [D loss: 1.078920, acc: 100%] [G loss: 1.164122]\n",
      "[Epoch 4/200] [Batch 111/938] [D loss: 1.093790, acc: 94%] [G loss: 1.096967]\n",
      "[Epoch 4/200] [Batch 112/938] [D loss: 1.091602, acc: 90%] [G loss: 1.164654]\n",
      "[Epoch 4/200] [Batch 113/938] [D loss: 1.081818, acc: 95%] [G loss: 1.127614]\n",
      "[Epoch 4/200] [Batch 114/938] [D loss: 1.079089, acc: 97%] [G loss: 1.161108]\n",
      "[Epoch 4/200] [Batch 115/938] [D loss: 1.110712, acc: 91%] [G loss: 1.161734]\n",
      "[Epoch 4/200] [Batch 116/938] [D loss: 1.118716, acc: 92%] [G loss: 1.150231]\n",
      "[Epoch 4/200] [Batch 117/938] [D loss: 1.111671, acc: 89%] [G loss: 1.109863]\n",
      "[Epoch 4/200] [Batch 118/938] [D loss: 1.077591, acc: 93%] [G loss: 1.198505]\n",
      "[Epoch 4/200] [Batch 119/938] [D loss: 1.077051, acc: 96%] [G loss: 1.111569]\n",
      "[Epoch 4/200] [Batch 120/938] [D loss: 1.037417, acc: 98%] [G loss: 1.185018]\n",
      "[Epoch 4/200] [Batch 121/938] [D loss: 1.104598, acc: 94%] [G loss: 1.151312]\n",
      "[Epoch 4/200] [Batch 122/938] [D loss: 1.081822, acc: 97%] [G loss: 1.192234]\n",
      "[Epoch 4/200] [Batch 123/938] [D loss: 1.099952, acc: 92%] [G loss: 1.266528]\n",
      "[Epoch 4/200] [Batch 124/938] [D loss: 1.093876, acc: 94%] [G loss: 1.135396]\n",
      "[Epoch 4/200] [Batch 125/938] [D loss: 1.090097, acc: 96%] [G loss: 1.111527]\n",
      "[Epoch 4/200] [Batch 126/938] [D loss: 1.105113, acc: 94%] [G loss: 1.215775]\n",
      "[Epoch 4/200] [Batch 127/938] [D loss: 1.057694, acc: 93%] [G loss: 1.174432]\n",
      "[Epoch 4/200] [Batch 128/938] [D loss: 1.080985, acc: 96%] [G loss: 1.129055]\n",
      "[Epoch 4/200] [Batch 129/938] [D loss: 1.106353, acc: 92%] [G loss: 1.078579]\n",
      "[Epoch 4/200] [Batch 130/938] [D loss: 1.092252, acc: 92%] [G loss: 1.186281]\n",
      "[Epoch 4/200] [Batch 131/938] [D loss: 1.109374, acc: 96%] [G loss: 1.189682]\n",
      "[Epoch 4/200] [Batch 132/938] [D loss: 1.073617, acc: 94%] [G loss: 1.160831]\n",
      "[Epoch 4/200] [Batch 133/938] [D loss: 1.118196, acc: 96%] [G loss: 1.134102]\n",
      "[Epoch 4/200] [Batch 134/938] [D loss: 1.060517, acc: 99%] [G loss: 1.102306]\n",
      "[Epoch 4/200] [Batch 135/938] [D loss: 1.094119, acc: 96%] [G loss: 1.136553]\n",
      "[Epoch 4/200] [Batch 136/938] [D loss: 1.117153, acc: 92%] [G loss: 1.110562]\n",
      "[Epoch 4/200] [Batch 137/938] [D loss: 1.077217, acc: 95%] [G loss: 1.282982]\n",
      "[Epoch 4/200] [Batch 138/938] [D loss: 1.058749, acc: 95%] [G loss: 1.169875]\n",
      "[Epoch 4/200] [Batch 139/938] [D loss: 1.112675, acc: 97%] [G loss: 1.169115]\n",
      "[Epoch 4/200] [Batch 140/938] [D loss: 1.073156, acc: 96%] [G loss: 1.108137]\n",
      "[Epoch 4/200] [Batch 141/938] [D loss: 1.161779, acc: 90%] [G loss: 1.092502]\n",
      "[Epoch 4/200] [Batch 142/938] [D loss: 1.067838, acc: 96%] [G loss: 1.055643]\n",
      "[Epoch 4/200] [Batch 143/938] [D loss: 1.121124, acc: 92%] [G loss: 1.135698]\n",
      "[Epoch 4/200] [Batch 144/938] [D loss: 1.093801, acc: 95%] [G loss: 1.117580]\n",
      "[Epoch 4/200] [Batch 145/938] [D loss: 1.055692, acc: 95%] [G loss: 1.169015]\n",
      "[Epoch 4/200] [Batch 146/938] [D loss: 1.080659, acc: 95%] [G loss: 1.127876]\n",
      "[Epoch 4/200] [Batch 147/938] [D loss: 1.050530, acc: 93%] [G loss: 1.220274]\n",
      "[Epoch 4/200] [Batch 148/938] [D loss: 1.138990, acc: 91%] [G loss: 1.147147]\n",
      "[Epoch 4/200] [Batch 149/938] [D loss: 1.093835, acc: 92%] [G loss: 1.198149]\n",
      "[Epoch 4/200] [Batch 150/938] [D loss: 1.094411, acc: 96%] [G loss: 1.214736]\n",
      "[Epoch 4/200] [Batch 151/938] [D loss: 1.126868, acc: 96%] [G loss: 1.131517]\n",
      "[Epoch 4/200] [Batch 152/938] [D loss: 1.082464, acc: 93%] [G loss: 1.165164]\n",
      "[Epoch 4/200] [Batch 153/938] [D loss: 1.094903, acc: 94%] [G loss: 1.139759]\n",
      "[Epoch 4/200] [Batch 154/938] [D loss: 1.095994, acc: 95%] [G loss: 1.088970]\n",
      "[Epoch 4/200] [Batch 155/938] [D loss: 1.066848, acc: 97%] [G loss: 1.077359]\n",
      "[Epoch 4/200] [Batch 156/938] [D loss: 1.081882, acc: 96%] [G loss: 1.136431]\n",
      "[Epoch 4/200] [Batch 157/938] [D loss: 1.071854, acc: 91%] [G loss: 1.213697]\n",
      "[Epoch 4/200] [Batch 158/938] [D loss: 1.080539, acc: 93%] [G loss: 1.122408]\n",
      "[Epoch 4/200] [Batch 159/938] [D loss: 1.114250, acc: 95%] [G loss: 1.207215]\n",
      "[Epoch 4/200] [Batch 160/938] [D loss: 1.112615, acc: 96%] [G loss: 1.123196]\n",
      "[Epoch 4/200] [Batch 161/938] [D loss: 1.067923, acc: 96%] [G loss: 1.152047]\n",
      "[Epoch 4/200] [Batch 162/938] [D loss: 1.059428, acc: 95%] [G loss: 1.119797]\n",
      "[Epoch 4/200] [Batch 163/938] [D loss: 1.067947, acc: 94%] [G loss: 1.117617]\n",
      "[Epoch 4/200] [Batch 164/938] [D loss: 1.116486, acc: 92%] [G loss: 1.160720]\n",
      "[Epoch 4/200] [Batch 165/938] [D loss: 1.078658, acc: 92%] [G loss: 1.145705]\n",
      "[Epoch 4/200] [Batch 166/938] [D loss: 1.031239, acc: 96%] [G loss: 1.145445]\n",
      "[Epoch 4/200] [Batch 167/938] [D loss: 1.079638, acc: 95%] [G loss: 1.112942]\n",
      "[Epoch 4/200] [Batch 168/938] [D loss: 1.102128, acc: 92%] [G loss: 1.116003]\n",
      "[Epoch 4/200] [Batch 169/938] [D loss: 1.120345, acc: 94%] [G loss: 1.103506]\n",
      "[Epoch 4/200] [Batch 170/938] [D loss: 1.073440, acc: 94%] [G loss: 1.069268]\n",
      "[Epoch 4/200] [Batch 171/938] [D loss: 1.087154, acc: 94%] [G loss: 1.152728]\n",
      "[Epoch 4/200] [Batch 172/938] [D loss: 1.118844, acc: 95%] [G loss: 1.153318]\n",
      "[Epoch 4/200] [Batch 173/938] [D loss: 1.054374, acc: 96%] [G loss: 1.213475]\n",
      "[Epoch 4/200] [Batch 174/938] [D loss: 1.080815, acc: 95%] [G loss: 1.174915]\n",
      "[Epoch 4/200] [Batch 175/938] [D loss: 1.083621, acc: 95%] [G loss: 1.151296]\n",
      "[Epoch 4/200] [Batch 176/938] [D loss: 1.067322, acc: 96%] [G loss: 1.181361]\n",
      "[Epoch 4/200] [Batch 177/938] [D loss: 1.095623, acc: 93%] [G loss: 1.122042]\n",
      "[Epoch 4/200] [Batch 178/938] [D loss: 1.076129, acc: 92%] [G loss: 1.114527]\n",
      "[Epoch 4/200] [Batch 179/938] [D loss: 1.088530, acc: 95%] [G loss: 1.179827]\n",
      "[Epoch 4/200] [Batch 180/938] [D loss: 1.072862, acc: 94%] [G loss: 1.180063]\n",
      "[Epoch 4/200] [Batch 181/938] [D loss: 1.144978, acc: 94%] [G loss: 1.125290]\n",
      "[Epoch 4/200] [Batch 182/938] [D loss: 1.096293, acc: 93%] [G loss: 1.193133]\n",
      "[Epoch 4/200] [Batch 183/938] [D loss: 1.102130, acc: 89%] [G loss: 1.143683]\n",
      "[Epoch 4/200] [Batch 184/938] [D loss: 1.134451, acc: 96%] [G loss: 1.147955]\n",
      "[Epoch 4/200] [Batch 185/938] [D loss: 1.081292, acc: 95%] [G loss: 1.174937]\n",
      "[Epoch 4/200] [Batch 186/938] [D loss: 1.092036, acc: 92%] [G loss: 1.163388]\n",
      "[Epoch 4/200] [Batch 187/938] [D loss: 1.063815, acc: 94%] [G loss: 1.041254]\n",
      "[Epoch 4/200] [Batch 188/938] [D loss: 1.092381, acc: 93%] [G loss: 1.120884]\n",
      "[Epoch 4/200] [Batch 189/938] [D loss: 1.085136, acc: 94%] [G loss: 1.140800]\n",
      "[Epoch 4/200] [Batch 190/938] [D loss: 1.113034, acc: 96%] [G loss: 1.147820]\n",
      "[Epoch 4/200] [Batch 191/938] [D loss: 1.099431, acc: 98%] [G loss: 1.214260]\n",
      "[Epoch 4/200] [Batch 192/938] [D loss: 1.047571, acc: 98%] [G loss: 1.149664]\n",
      "[Epoch 4/200] [Batch 193/938] [D loss: 1.083540, acc: 93%] [G loss: 1.089585]\n",
      "[Epoch 4/200] [Batch 194/938] [D loss: 1.075983, acc: 96%] [G loss: 1.094994]\n",
      "[Epoch 4/200] [Batch 195/938] [D loss: 1.072429, acc: 96%] [G loss: 1.100968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 196/938] [D loss: 1.126092, acc: 93%] [G loss: 1.140024]\n",
      "[Epoch 4/200] [Batch 197/938] [D loss: 1.086427, acc: 97%] [G loss: 1.091540]\n",
      "[Epoch 4/200] [Batch 198/938] [D loss: 1.078305, acc: 96%] [G loss: 1.186670]\n",
      "[Epoch 4/200] [Batch 199/938] [D loss: 1.062848, acc: 96%] [G loss: 1.124041]\n",
      "[Epoch 4/200] [Batch 200/938] [D loss: 1.111568, acc: 92%] [G loss: 1.224388]\n",
      "[Epoch 4/200] [Batch 201/938] [D loss: 1.105756, acc: 96%] [G loss: 1.115315]\n",
      "[Epoch 4/200] [Batch 202/938] [D loss: 1.104776, acc: 92%] [G loss: 1.150556]\n",
      "[Epoch 4/200] [Batch 203/938] [D loss: 1.098961, acc: 95%] [G loss: 1.125800]\n",
      "[Epoch 4/200] [Batch 204/938] [D loss: 1.075900, acc: 96%] [G loss: 1.099066]\n",
      "[Epoch 4/200] [Batch 205/938] [D loss: 1.087940, acc: 97%] [G loss: 1.137041]\n",
      "[Epoch 4/200] [Batch 206/938] [D loss: 1.079534, acc: 94%] [G loss: 1.097175]\n",
      "[Epoch 4/200] [Batch 207/938] [D loss: 1.043005, acc: 97%] [G loss: 1.224607]\n",
      "[Epoch 4/200] [Batch 208/938] [D loss: 1.084680, acc: 95%] [G loss: 1.154348]\n",
      "[Epoch 4/200] [Batch 209/938] [D loss: 1.077749, acc: 94%] [G loss: 1.190964]\n",
      "[Epoch 4/200] [Batch 210/938] [D loss: 1.127257, acc: 92%] [G loss: 1.200257]\n",
      "[Epoch 4/200] [Batch 211/938] [D loss: 1.111681, acc: 91%] [G loss: 1.185591]\n",
      "[Epoch 4/200] [Batch 212/938] [D loss: 1.131277, acc: 96%] [G loss: 1.151204]\n",
      "[Epoch 4/200] [Batch 213/938] [D loss: 1.119733, acc: 92%] [G loss: 1.094247]\n",
      "[Epoch 4/200] [Batch 214/938] [D loss: 1.098534, acc: 95%] [G loss: 1.155417]\n",
      "[Epoch 4/200] [Batch 215/938] [D loss: 1.039665, acc: 96%] [G loss: 1.124862]\n",
      "[Epoch 4/200] [Batch 216/938] [D loss: 1.113354, acc: 94%] [G loss: 1.141567]\n",
      "[Epoch 4/200] [Batch 217/938] [D loss: 1.065106, acc: 96%] [G loss: 1.129928]\n",
      "[Epoch 4/200] [Batch 218/938] [D loss: 1.125192, acc: 96%] [G loss: 1.132009]\n",
      "[Epoch 4/200] [Batch 219/938] [D loss: 1.083464, acc: 97%] [G loss: 1.100297]\n",
      "[Epoch 4/200] [Batch 220/938] [D loss: 1.086811, acc: 92%] [G loss: 1.139249]\n",
      "[Epoch 4/200] [Batch 221/938] [D loss: 1.095485, acc: 95%] [G loss: 1.122832]\n",
      "[Epoch 4/200] [Batch 222/938] [D loss: 1.069979, acc: 95%] [G loss: 1.163089]\n",
      "[Epoch 4/200] [Batch 223/938] [D loss: 1.107203, acc: 92%] [G loss: 1.172307]\n",
      "[Epoch 4/200] [Batch 224/938] [D loss: 1.073742, acc: 94%] [G loss: 1.156237]\n",
      "[Epoch 4/200] [Batch 225/938] [D loss: 1.087771, acc: 96%] [G loss: 1.087633]\n",
      "[Epoch 4/200] [Batch 226/938] [D loss: 1.095170, acc: 93%] [G loss: 1.095055]\n",
      "[Epoch 4/200] [Batch 227/938] [D loss: 1.099656, acc: 92%] [G loss: 1.068933]\n",
      "[Epoch 4/200] [Batch 228/938] [D loss: 1.078041, acc: 95%] [G loss: 1.157057]\n",
      "[Epoch 4/200] [Batch 229/938] [D loss: 1.089243, acc: 97%] [G loss: 1.172014]\n",
      "[Epoch 4/200] [Batch 230/938] [D loss: 1.088401, acc: 92%] [G loss: 1.157692]\n",
      "[Epoch 4/200] [Batch 231/938] [D loss: 1.084189, acc: 95%] [G loss: 1.143696]\n",
      "[Epoch 4/200] [Batch 232/938] [D loss: 1.088560, acc: 92%] [G loss: 1.160756]\n",
      "[Epoch 4/200] [Batch 233/938] [D loss: 1.095444, acc: 96%] [G loss: 1.166422]\n",
      "[Epoch 4/200] [Batch 234/938] [D loss: 1.078176, acc: 93%] [G loss: 1.222001]\n",
      "[Epoch 4/200] [Batch 235/938] [D loss: 1.074956, acc: 96%] [G loss: 1.206281]\n",
      "[Epoch 4/200] [Batch 236/938] [D loss: 1.107572, acc: 92%] [G loss: 1.164283]\n",
      "[Epoch 4/200] [Batch 237/938] [D loss: 1.121356, acc: 95%] [G loss: 1.132143]\n",
      "[Epoch 4/200] [Batch 238/938] [D loss: 1.082858, acc: 96%] [G loss: 1.089520]\n",
      "[Epoch 4/200] [Batch 239/938] [D loss: 1.111012, acc: 93%] [G loss: 1.167714]\n",
      "[Epoch 4/200] [Batch 240/938] [D loss: 1.125411, acc: 93%] [G loss: 1.126422]\n",
      "[Epoch 4/200] [Batch 241/938] [D loss: 1.091790, acc: 90%] [G loss: 1.143694]\n",
      "[Epoch 4/200] [Batch 242/938] [D loss: 1.113342, acc: 95%] [G loss: 1.125143]\n",
      "[Epoch 4/200] [Batch 243/938] [D loss: 1.111256, acc: 93%] [G loss: 1.179805]\n",
      "[Epoch 4/200] [Batch 244/938] [D loss: 1.083440, acc: 95%] [G loss: 1.082896]\n",
      "[Epoch 4/200] [Batch 245/938] [D loss: 1.148610, acc: 96%] [G loss: 1.033627]\n",
      "[Epoch 4/200] [Batch 246/938] [D loss: 1.125159, acc: 92%] [G loss: 1.063214]\n",
      "[Epoch 4/200] [Batch 247/938] [D loss: 1.081541, acc: 96%] [G loss: 1.124763]\n",
      "[Epoch 4/200] [Batch 248/938] [D loss: 1.110471, acc: 92%] [G loss: 1.156561]\n",
      "[Epoch 4/200] [Batch 249/938] [D loss: 1.061445, acc: 97%] [G loss: 1.178877]\n",
      "[Epoch 4/200] [Batch 250/938] [D loss: 1.131424, acc: 92%] [G loss: 1.179537]\n",
      "[Epoch 4/200] [Batch 251/938] [D loss: 1.115138, acc: 94%] [G loss: 1.146665]\n",
      "[Epoch 4/200] [Batch 252/938] [D loss: 1.061330, acc: 99%] [G loss: 1.095068]\n",
      "[Epoch 4/200] [Batch 253/938] [D loss: 1.093376, acc: 96%] [G loss: 1.057218]\n",
      "[Epoch 4/200] [Batch 254/938] [D loss: 1.148040, acc: 95%] [G loss: 1.074266]\n",
      "[Epoch 4/200] [Batch 255/938] [D loss: 1.108001, acc: 96%] [G loss: 1.175453]\n",
      "[Epoch 4/200] [Batch 256/938] [D loss: 1.076976, acc: 96%] [G loss: 1.104421]\n",
      "[Epoch 4/200] [Batch 257/938] [D loss: 1.081233, acc: 96%] [G loss: 1.159528]\n",
      "[Epoch 4/200] [Batch 258/938] [D loss: 1.098484, acc: 93%] [G loss: 1.230229]\n",
      "[Epoch 4/200] [Batch 259/938] [D loss: 1.052565, acc: 95%] [G loss: 1.245624]\n",
      "[Epoch 4/200] [Batch 260/938] [D loss: 1.129638, acc: 91%] [G loss: 1.109470]\n",
      "[Epoch 4/200] [Batch 261/938] [D loss: 1.067077, acc: 94%] [G loss: 1.167158]\n",
      "[Epoch 4/200] [Batch 262/938] [D loss: 1.082518, acc: 95%] [G loss: 1.139000]\n",
      "[Epoch 4/200] [Batch 263/938] [D loss: 1.060759, acc: 96%] [G loss: 1.171442]\n",
      "[Epoch 4/200] [Batch 264/938] [D loss: 1.094888, acc: 96%] [G loss: 1.194079]\n",
      "[Epoch 4/200] [Batch 265/938] [D loss: 1.087211, acc: 97%] [G loss: 1.145805]\n",
      "[Epoch 4/200] [Batch 266/938] [D loss: 1.064126, acc: 94%] [G loss: 1.157629]\n",
      "[Epoch 4/200] [Batch 267/938] [D loss: 1.063815, acc: 99%] [G loss: 1.076275]\n",
      "[Epoch 4/200] [Batch 268/938] [D loss: 1.109307, acc: 91%] [G loss: 1.160329]\n",
      "[Epoch 4/200] [Batch 269/938] [D loss: 1.069727, acc: 93%] [G loss: 1.186423]\n",
      "[Epoch 4/200] [Batch 270/938] [D loss: 1.116212, acc: 95%] [G loss: 1.118194]\n",
      "[Epoch 4/200] [Batch 271/938] [D loss: 1.106587, acc: 93%] [G loss: 1.112665]\n",
      "[Epoch 4/200] [Batch 272/938] [D loss: 1.119122, acc: 92%] [G loss: 1.079020]\n",
      "[Epoch 4/200] [Batch 273/938] [D loss: 1.075635, acc: 91%] [G loss: 1.129010]\n",
      "[Epoch 4/200] [Batch 274/938] [D loss: 1.079847, acc: 94%] [G loss: 1.216632]\n",
      "[Epoch 4/200] [Batch 275/938] [D loss: 1.152153, acc: 91%] [G loss: 1.148382]\n",
      "[Epoch 4/200] [Batch 276/938] [D loss: 1.110278, acc: 96%] [G loss: 1.141843]\n",
      "[Epoch 4/200] [Batch 277/938] [D loss: 1.113713, acc: 94%] [G loss: 1.170306]\n",
      "[Epoch 4/200] [Batch 278/938] [D loss: 1.073870, acc: 96%] [G loss: 1.160683]\n",
      "[Epoch 4/200] [Batch 279/938] [D loss: 1.062996, acc: 94%] [G loss: 1.164402]\n",
      "[Epoch 4/200] [Batch 280/938] [D loss: 1.083773, acc: 96%] [G loss: 1.196801]\n",
      "[Epoch 4/200] [Batch 281/938] [D loss: 1.139846, acc: 96%] [G loss: 1.150066]\n",
      "[Epoch 4/200] [Batch 282/938] [D loss: 1.131724, acc: 92%] [G loss: 1.207582]\n",
      "[Epoch 4/200] [Batch 283/938] [D loss: 1.079900, acc: 94%] [G loss: 1.137594]\n",
      "[Epoch 4/200] [Batch 284/938] [D loss: 1.068274, acc: 96%] [G loss: 1.097159]\n",
      "[Epoch 4/200] [Batch 285/938] [D loss: 1.135643, acc: 96%] [G loss: 1.169543]\n",
      "[Epoch 4/200] [Batch 286/938] [D loss: 1.128670, acc: 93%] [G loss: 1.088457]\n",
      "[Epoch 4/200] [Batch 287/938] [D loss: 1.074511, acc: 96%] [G loss: 1.173448]\n",
      "[Epoch 4/200] [Batch 288/938] [D loss: 1.057866, acc: 93%] [G loss: 1.184397]\n",
      "[Epoch 4/200] [Batch 289/938] [D loss: 1.096319, acc: 92%] [G loss: 1.123882]\n",
      "[Epoch 4/200] [Batch 290/938] [D loss: 1.130479, acc: 96%] [G loss: 1.165438]\n",
      "[Epoch 4/200] [Batch 291/938] [D loss: 1.103063, acc: 96%] [G loss: 1.117631]\n",
      "[Epoch 4/200] [Batch 292/938] [D loss: 1.096285, acc: 95%] [G loss: 1.109822]\n",
      "[Epoch 4/200] [Batch 293/938] [D loss: 1.049477, acc: 93%] [G loss: 1.199315]\n",
      "[Epoch 4/200] [Batch 294/938] [D loss: 1.097985, acc: 93%] [G loss: 1.158163]\n",
      "[Epoch 4/200] [Batch 295/938] [D loss: 1.100308, acc: 93%] [G loss: 1.166070]\n",
      "[Epoch 4/200] [Batch 296/938] [D loss: 1.065732, acc: 93%] [G loss: 1.140026]\n",
      "[Epoch 4/200] [Batch 297/938] [D loss: 1.091465, acc: 95%] [G loss: 1.128649]\n",
      "[Epoch 4/200] [Batch 298/938] [D loss: 1.066967, acc: 95%] [G loss: 1.185097]\n",
      "[Epoch 4/200] [Batch 299/938] [D loss: 1.083540, acc: 96%] [G loss: 1.133078]\n",
      "[Epoch 4/200] [Batch 300/938] [D loss: 1.098431, acc: 96%] [G loss: 1.152864]\n",
      "[Epoch 4/200] [Batch 301/938] [D loss: 1.072552, acc: 95%] [G loss: 1.153267]\n",
      "[Epoch 4/200] [Batch 302/938] [D loss: 1.054298, acc: 95%] [G loss: 1.074467]\n",
      "[Epoch 4/200] [Batch 303/938] [D loss: 1.085651, acc: 96%] [G loss: 1.074287]\n",
      "[Epoch 4/200] [Batch 304/938] [D loss: 1.077625, acc: 96%] [G loss: 1.171384]\n",
      "[Epoch 4/200] [Batch 305/938] [D loss: 1.077434, acc: 92%] [G loss: 1.159029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 306/938] [D loss: 1.083805, acc: 94%] [G loss: 1.141405]\n",
      "[Epoch 4/200] [Batch 307/938] [D loss: 1.080718, acc: 92%] [G loss: 1.119270]\n",
      "[Epoch 4/200] [Batch 308/938] [D loss: 1.110817, acc: 94%] [G loss: 1.149243]\n",
      "[Epoch 4/200] [Batch 309/938] [D loss: 1.064276, acc: 98%] [G loss: 1.106527]\n",
      "[Epoch 4/200] [Batch 310/938] [D loss: 1.129410, acc: 92%] [G loss: 1.103799]\n",
      "[Epoch 4/200] [Batch 311/938] [D loss: 1.102874, acc: 93%] [G loss: 1.077440]\n",
      "[Epoch 4/200] [Batch 312/938] [D loss: 1.096485, acc: 89%] [G loss: 1.119468]\n",
      "[Epoch 4/200] [Batch 313/938] [D loss: 1.098272, acc: 94%] [G loss: 1.212642]\n",
      "[Epoch 4/200] [Batch 314/938] [D loss: 1.105156, acc: 93%] [G loss: 1.090627]\n",
      "[Epoch 4/200] [Batch 315/938] [D loss: 1.085600, acc: 92%] [G loss: 1.145426]\n",
      "[Epoch 4/200] [Batch 316/938] [D loss: 1.102104, acc: 95%] [G loss: 1.095881]\n",
      "[Epoch 4/200] [Batch 317/938] [D loss: 1.115306, acc: 95%] [G loss: 1.062831]\n",
      "[Epoch 4/200] [Batch 318/938] [D loss: 1.087068, acc: 92%] [G loss: 1.187165]\n",
      "[Epoch 4/200] [Batch 319/938] [D loss: 1.095511, acc: 96%] [G loss: 1.134884]\n",
      "[Epoch 4/200] [Batch 320/938] [D loss: 1.126631, acc: 92%] [G loss: 1.107940]\n",
      "[Epoch 4/200] [Batch 321/938] [D loss: 1.086533, acc: 94%] [G loss: 1.190707]\n",
      "[Epoch 4/200] [Batch 322/938] [D loss: 1.087983, acc: 94%] [G loss: 1.151232]\n",
      "[Epoch 4/200] [Batch 323/938] [D loss: 1.089736, acc: 94%] [G loss: 1.113721]\n",
      "[Epoch 4/200] [Batch 324/938] [D loss: 1.102659, acc: 95%] [G loss: 1.054066]\n",
      "[Epoch 4/200] [Batch 325/938] [D loss: 1.078315, acc: 96%] [G loss: 1.108498]\n",
      "[Epoch 4/200] [Batch 326/938] [D loss: 1.106728, acc: 96%] [G loss: 1.164979]\n",
      "[Epoch 4/200] [Batch 327/938] [D loss: 1.116377, acc: 91%] [G loss: 1.219143]\n",
      "[Epoch 4/200] [Batch 328/938] [D loss: 1.050507, acc: 97%] [G loss: 1.143318]\n",
      "[Epoch 4/200] [Batch 329/938] [D loss: 1.104806, acc: 95%] [G loss: 1.166583]\n",
      "[Epoch 4/200] [Batch 330/938] [D loss: 1.099233, acc: 95%] [G loss: 1.093062]\n",
      "[Epoch 4/200] [Batch 331/938] [D loss: 1.058488, acc: 95%] [G loss: 1.163152]\n",
      "[Epoch 4/200] [Batch 332/938] [D loss: 1.097209, acc: 95%] [G loss: 1.214533]\n",
      "[Epoch 4/200] [Batch 333/938] [D loss: 1.034848, acc: 96%] [G loss: 1.309826]\n",
      "[Epoch 4/200] [Batch 334/938] [D loss: 1.109789, acc: 92%] [G loss: 1.120071]\n",
      "[Epoch 4/200] [Batch 335/938] [D loss: 1.078349, acc: 96%] [G loss: 1.082642]\n",
      "[Epoch 4/200] [Batch 336/938] [D loss: 1.048312, acc: 95%] [G loss: 1.159686]\n",
      "[Epoch 4/200] [Batch 337/938] [D loss: 1.119957, acc: 90%] [G loss: 1.124044]\n",
      "[Epoch 4/200] [Batch 338/938] [D loss: 1.051435, acc: 97%] [G loss: 1.190721]\n",
      "[Epoch 4/200] [Batch 339/938] [D loss: 1.052185, acc: 98%] [G loss: 1.095329]\n",
      "[Epoch 4/200] [Batch 340/938] [D loss: 1.068734, acc: 96%] [G loss: 1.079852]\n",
      "[Epoch 4/200] [Batch 341/938] [D loss: 1.089136, acc: 95%] [G loss: 1.103386]\n",
      "[Epoch 4/200] [Batch 342/938] [D loss: 1.098166, acc: 92%] [G loss: 1.193737]\n",
      "[Epoch 4/200] [Batch 343/938] [D loss: 1.104330, acc: 93%] [G loss: 1.066827]\n",
      "[Epoch 4/200] [Batch 344/938] [D loss: 1.074433, acc: 97%] [G loss: 1.109582]\n",
      "[Epoch 4/200] [Batch 345/938] [D loss: 1.104069, acc: 95%] [G loss: 1.168702]\n",
      "[Epoch 4/200] [Batch 346/938] [D loss: 1.068796, acc: 96%] [G loss: 1.096684]\n",
      "[Epoch 4/200] [Batch 347/938] [D loss: 1.095400, acc: 92%] [G loss: 1.098671]\n",
      "[Epoch 4/200] [Batch 348/938] [D loss: 1.088964, acc: 94%] [G loss: 1.166598]\n",
      "[Epoch 4/200] [Batch 349/938] [D loss: 1.089097, acc: 93%] [G loss: 1.165519]\n",
      "[Epoch 4/200] [Batch 350/938] [D loss: 1.118040, acc: 91%] [G loss: 1.159835]\n",
      "[Epoch 4/200] [Batch 351/938] [D loss: 1.113602, acc: 97%] [G loss: 1.144013]\n",
      "[Epoch 4/200] [Batch 352/938] [D loss: 1.098532, acc: 93%] [G loss: 1.101109]\n",
      "[Epoch 4/200] [Batch 353/938] [D loss: 1.093751, acc: 92%] [G loss: 1.121736]\n",
      "[Epoch 4/200] [Batch 354/938] [D loss: 1.078441, acc: 93%] [G loss: 1.200629]\n",
      "[Epoch 4/200] [Batch 355/938] [D loss: 1.060066, acc: 96%] [G loss: 1.208111]\n",
      "[Epoch 4/200] [Batch 356/938] [D loss: 1.083140, acc: 93%] [G loss: 1.113896]\n",
      "[Epoch 4/200] [Batch 357/938] [D loss: 1.084261, acc: 96%] [G loss: 1.129387]\n",
      "[Epoch 4/200] [Batch 358/938] [D loss: 1.093712, acc: 95%] [G loss: 1.134026]\n",
      "[Epoch 4/200] [Batch 359/938] [D loss: 1.090483, acc: 96%] [G loss: 1.156768]\n",
      "[Epoch 4/200] [Batch 360/938] [D loss: 1.092464, acc: 95%] [G loss: 1.146689]\n",
      "[Epoch 4/200] [Batch 361/938] [D loss: 1.095170, acc: 92%] [G loss: 1.190041]\n",
      "[Epoch 4/200] [Batch 362/938] [D loss: 1.106369, acc: 96%] [G loss: 1.123983]\n",
      "[Epoch 4/200] [Batch 363/938] [D loss: 1.100588, acc: 92%] [G loss: 1.194878]\n",
      "[Epoch 4/200] [Batch 364/938] [D loss: 1.093574, acc: 95%] [G loss: 1.120708]\n",
      "[Epoch 4/200] [Batch 365/938] [D loss: 1.084720, acc: 92%] [G loss: 1.134095]\n",
      "[Epoch 4/200] [Batch 366/938] [D loss: 1.093590, acc: 95%] [G loss: 1.103775]\n",
      "[Epoch 4/200] [Batch 367/938] [D loss: 1.070337, acc: 95%] [G loss: 1.090622]\n",
      "[Epoch 4/200] [Batch 368/938] [D loss: 1.104184, acc: 95%] [G loss: 1.101380]\n",
      "[Epoch 4/200] [Batch 369/938] [D loss: 1.071266, acc: 96%] [G loss: 1.143930]\n",
      "[Epoch 4/200] [Batch 370/938] [D loss: 1.097424, acc: 96%] [G loss: 1.117584]\n",
      "[Epoch 4/200] [Batch 371/938] [D loss: 1.042920, acc: 96%] [G loss: 1.127603]\n",
      "[Epoch 4/200] [Batch 372/938] [D loss: 1.087632, acc: 97%] [G loss: 1.172893]\n",
      "[Epoch 4/200] [Batch 373/938] [D loss: 1.075586, acc: 94%] [G loss: 1.336518]\n",
      "[Epoch 4/200] [Batch 374/938] [D loss: 1.059433, acc: 98%] [G loss: 1.209471]\n",
      "[Epoch 4/200] [Batch 375/938] [D loss: 1.047225, acc: 97%] [G loss: 1.122195]\n",
      "[Epoch 4/200] [Batch 376/938] [D loss: 1.101137, acc: 94%] [G loss: 1.099101]\n",
      "[Epoch 4/200] [Batch 377/938] [D loss: 1.101394, acc: 93%] [G loss: 1.170140]\n",
      "[Epoch 4/200] [Batch 378/938] [D loss: 1.075319, acc: 96%] [G loss: 1.145732]\n",
      "[Epoch 4/200] [Batch 379/938] [D loss: 1.086888, acc: 96%] [G loss: 1.117262]\n",
      "[Epoch 4/200] [Batch 380/938] [D loss: 1.110132, acc: 94%] [G loss: 1.115901]\n",
      "[Epoch 4/200] [Batch 381/938] [D loss: 1.103543, acc: 95%] [G loss: 1.133362]\n",
      "[Epoch 4/200] [Batch 382/938] [D loss: 1.120323, acc: 93%] [G loss: 1.109965]\n",
      "[Epoch 4/200] [Batch 383/938] [D loss: 1.093626, acc: 92%] [G loss: 1.134253]\n",
      "[Epoch 4/200] [Batch 384/938] [D loss: 1.071289, acc: 93%] [G loss: 1.115921]\n",
      "[Epoch 4/200] [Batch 385/938] [D loss: 1.097195, acc: 96%] [G loss: 1.213798]\n",
      "[Epoch 4/200] [Batch 386/938] [D loss: 1.111296, acc: 93%] [G loss: 1.256879]\n",
      "[Epoch 4/200] [Batch 387/938] [D loss: 1.118272, acc: 95%] [G loss: 1.076731]\n",
      "[Epoch 4/200] [Batch 388/938] [D loss: 1.096823, acc: 92%] [G loss: 1.063144]\n",
      "[Epoch 4/200] [Batch 389/938] [D loss: 1.102850, acc: 94%] [G loss: 1.065138]\n",
      "[Epoch 4/200] [Batch 390/938] [D loss: 1.091057, acc: 92%] [G loss: 1.140299]\n",
      "[Epoch 4/200] [Batch 391/938] [D loss: 1.155345, acc: 93%] [G loss: 1.218994]\n",
      "[Epoch 4/200] [Batch 392/938] [D loss: 1.068475, acc: 97%] [G loss: 1.201067]\n",
      "[Epoch 4/200] [Batch 393/938] [D loss: 1.084254, acc: 92%] [G loss: 1.166833]\n",
      "[Epoch 4/200] [Batch 394/938] [D loss: 1.113092, acc: 95%] [G loss: 1.120395]\n",
      "[Epoch 4/200] [Batch 395/938] [D loss: 1.106344, acc: 96%] [G loss: 1.119125]\n",
      "[Epoch 4/200] [Batch 396/938] [D loss: 1.101880, acc: 92%] [G loss: 1.180175]\n",
      "[Epoch 4/200] [Batch 397/938] [D loss: 1.095417, acc: 93%] [G loss: 1.192488]\n",
      "[Epoch 4/200] [Batch 398/938] [D loss: 1.088348, acc: 96%] [G loss: 1.148974]\n",
      "[Epoch 4/200] [Batch 399/938] [D loss: 1.105774, acc: 92%] [G loss: 1.095857]\n",
      "[Epoch 4/200] [Batch 400/938] [D loss: 1.098595, acc: 95%] [G loss: 1.168298]\n",
      "[Epoch 4/200] [Batch 401/938] [D loss: 1.098213, acc: 97%] [G loss: 1.157270]\n",
      "[Epoch 4/200] [Batch 402/938] [D loss: 1.088321, acc: 95%] [G loss: 1.259781]\n",
      "[Epoch 4/200] [Batch 403/938] [D loss: 1.097594, acc: 95%] [G loss: 1.142281]\n",
      "[Epoch 4/200] [Batch 404/938] [D loss: 1.120775, acc: 95%] [G loss: 1.153960]\n",
      "[Epoch 4/200] [Batch 405/938] [D loss: 1.062447, acc: 96%] [G loss: 1.159350]\n",
      "[Epoch 4/200] [Batch 406/938] [D loss: 1.089993, acc: 95%] [G loss: 1.170852]\n",
      "[Epoch 4/200] [Batch 407/938] [D loss: 1.108903, acc: 94%] [G loss: 1.139663]\n",
      "[Epoch 4/200] [Batch 408/938] [D loss: 1.119780, acc: 92%] [G loss: 1.100654]\n",
      "[Epoch 4/200] [Batch 409/938] [D loss: 1.076717, acc: 96%] [G loss: 1.093899]\n",
      "[Epoch 4/200] [Batch 410/938] [D loss: 1.074921, acc: 97%] [G loss: 1.095920]\n",
      "[Epoch 4/200] [Batch 411/938] [D loss: 1.089585, acc: 96%] [G loss: 1.072376]\n",
      "[Epoch 4/200] [Batch 412/938] [D loss: 1.117865, acc: 93%] [G loss: 1.101577]\n",
      "[Epoch 4/200] [Batch 413/938] [D loss: 1.053957, acc: 93%] [G loss: 1.154304]\n",
      "[Epoch 4/200] [Batch 414/938] [D loss: 1.072723, acc: 96%] [G loss: 1.138001]\n",
      "[Epoch 4/200] [Batch 415/938] [D loss: 1.114655, acc: 99%] [G loss: 1.104328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 416/938] [D loss: 1.120275, acc: 92%] [G loss: 1.155822]\n",
      "[Epoch 4/200] [Batch 417/938] [D loss: 1.095417, acc: 96%] [G loss: 1.231225]\n",
      "[Epoch 4/200] [Batch 418/938] [D loss: 1.088866, acc: 93%] [G loss: 1.189881]\n",
      "[Epoch 4/200] [Batch 419/938] [D loss: 1.093356, acc: 93%] [G loss: 1.124545]\n",
      "[Epoch 4/200] [Batch 420/938] [D loss: 1.095502, acc: 95%] [G loss: 1.118410]\n",
      "[Epoch 4/200] [Batch 421/938] [D loss: 1.089861, acc: 96%] [G loss: 1.078411]\n",
      "[Epoch 4/200] [Batch 422/938] [D loss: 1.042551, acc: 97%] [G loss: 1.070948]\n",
      "[Epoch 4/200] [Batch 423/938] [D loss: 1.080884, acc: 95%] [G loss: 1.131512]\n",
      "[Epoch 4/200] [Batch 424/938] [D loss: 1.103427, acc: 92%] [G loss: 1.077684]\n",
      "[Epoch 4/200] [Batch 425/938] [D loss: 1.065220, acc: 95%] [G loss: 1.138412]\n",
      "[Epoch 4/200] [Batch 426/938] [D loss: 1.111461, acc: 96%] [G loss: 1.105937]\n",
      "[Epoch 4/200] [Batch 427/938] [D loss: 1.071183, acc: 96%] [G loss: 1.200116]\n",
      "[Epoch 4/200] [Batch 428/938] [D loss: 1.053799, acc: 95%] [G loss: 1.168053]\n",
      "[Epoch 4/200] [Batch 429/938] [D loss: 1.058474, acc: 91%] [G loss: 1.217407]\n",
      "[Epoch 4/200] [Batch 430/938] [D loss: 1.094464, acc: 97%] [G loss: 1.173163]\n",
      "[Epoch 4/200] [Batch 431/938] [D loss: 1.121240, acc: 93%] [G loss: 1.145138]\n",
      "[Epoch 4/200] [Batch 432/938] [D loss: 1.109017, acc: 96%] [G loss: 1.119750]\n",
      "[Epoch 4/200] [Batch 433/938] [D loss: 1.080925, acc: 96%] [G loss: 1.102433]\n",
      "[Epoch 4/200] [Batch 434/938] [D loss: 1.075793, acc: 93%] [G loss: 1.195485]\n",
      "[Epoch 4/200] [Batch 435/938] [D loss: 1.071671, acc: 97%] [G loss: 1.144062]\n",
      "[Epoch 4/200] [Batch 436/938] [D loss: 1.087817, acc: 94%] [G loss: 1.192640]\n",
      "[Epoch 4/200] [Batch 437/938] [D loss: 1.067221, acc: 96%] [G loss: 1.178373]\n",
      "[Epoch 4/200] [Batch 438/938] [D loss: 1.126641, acc: 89%] [G loss: 1.173319]\n",
      "[Epoch 4/200] [Batch 439/938] [D loss: 1.077240, acc: 97%] [G loss: 1.126147]\n",
      "[Epoch 4/200] [Batch 440/938] [D loss: 1.113627, acc: 92%] [G loss: 1.099399]\n",
      "[Epoch 4/200] [Batch 441/938] [D loss: 1.110777, acc: 94%] [G loss: 1.128083]\n",
      "[Epoch 4/200] [Batch 442/938] [D loss: 1.050741, acc: 94%] [G loss: 1.149542]\n",
      "[Epoch 4/200] [Batch 443/938] [D loss: 1.101576, acc: 92%] [G loss: 1.175564]\n",
      "[Epoch 4/200] [Batch 444/938] [D loss: 1.064759, acc: 96%] [G loss: 1.157549]\n",
      "[Epoch 4/200] [Batch 445/938] [D loss: 1.091076, acc: 94%] [G loss: 1.109729]\n",
      "[Epoch 4/200] [Batch 446/938] [D loss: 1.094291, acc: 96%] [G loss: 1.117647]\n",
      "[Epoch 4/200] [Batch 447/938] [D loss: 1.086546, acc: 96%] [G loss: 1.056675]\n",
      "[Epoch 4/200] [Batch 448/938] [D loss: 1.076907, acc: 93%] [G loss: 1.137228]\n",
      "[Epoch 4/200] [Batch 449/938] [D loss: 1.093724, acc: 94%] [G loss: 1.060725]\n",
      "[Epoch 4/200] [Batch 450/938] [D loss: 1.069221, acc: 95%] [G loss: 1.120309]\n",
      "[Epoch 4/200] [Batch 451/938] [D loss: 1.091552, acc: 96%] [G loss: 1.176017]\n",
      "[Epoch 4/200] [Batch 452/938] [D loss: 1.110012, acc: 92%] [G loss: 1.175520]\n",
      "[Epoch 4/200] [Batch 453/938] [D loss: 1.074935, acc: 96%] [G loss: 1.118402]\n",
      "[Epoch 4/200] [Batch 454/938] [D loss: 1.074614, acc: 93%] [G loss: 1.152132]\n",
      "[Epoch 4/200] [Batch 455/938] [D loss: 1.098469, acc: 94%] [G loss: 1.113117]\n",
      "[Epoch 4/200] [Batch 456/938] [D loss: 1.099694, acc: 96%] [G loss: 1.166078]\n",
      "[Epoch 4/200] [Batch 457/938] [D loss: 1.111454, acc: 94%] [G loss: 1.086753]\n",
      "[Epoch 4/200] [Batch 458/938] [D loss: 1.080333, acc: 95%] [G loss: 1.079433]\n",
      "[Epoch 4/200] [Batch 459/938] [D loss: 1.059478, acc: 96%] [G loss: 1.221642]\n",
      "[Epoch 4/200] [Batch 460/938] [D loss: 1.074459, acc: 95%] [G loss: 1.102963]\n",
      "[Epoch 4/200] [Batch 461/938] [D loss: 1.089240, acc: 96%] [G loss: 1.127956]\n",
      "[Epoch 4/200] [Batch 462/938] [D loss: 1.089337, acc: 95%] [G loss: 1.194743]\n",
      "[Epoch 4/200] [Batch 463/938] [D loss: 1.075998, acc: 97%] [G loss: 1.121978]\n",
      "[Epoch 4/200] [Batch 464/938] [D loss: 1.092704, acc: 95%] [G loss: 1.147697]\n",
      "[Epoch 4/200] [Batch 465/938] [D loss: 1.072446, acc: 96%] [G loss: 1.182512]\n",
      "[Epoch 4/200] [Batch 466/938] [D loss: 1.102851, acc: 91%] [G loss: 1.072897]\n",
      "[Epoch 4/200] [Batch 467/938] [D loss: 1.068730, acc: 96%] [G loss: 1.031038]\n",
      "[Epoch 4/200] [Batch 468/938] [D loss: 1.063369, acc: 95%] [G loss: 1.136685]\n",
      "[Epoch 4/200] [Batch 469/938] [D loss: 1.075435, acc: 96%] [G loss: 1.136511]\n",
      "[Epoch 4/200] [Batch 470/938] [D loss: 1.139764, acc: 92%] [G loss: 1.122701]\n",
      "[Epoch 4/200] [Batch 471/938] [D loss: 1.116461, acc: 97%] [G loss: 1.132241]\n",
      "[Epoch 4/200] [Batch 472/938] [D loss: 1.063743, acc: 94%] [G loss: 1.139965]\n",
      "[Epoch 4/200] [Batch 473/938] [D loss: 1.078921, acc: 96%] [G loss: 1.185548]\n",
      "[Epoch 4/200] [Batch 474/938] [D loss: 1.098044, acc: 95%] [G loss: 1.158741]\n",
      "[Epoch 4/200] [Batch 475/938] [D loss: 1.098641, acc: 96%] [G loss: 1.147294]\n",
      "[Epoch 4/200] [Batch 476/938] [D loss: 1.098852, acc: 91%] [G loss: 1.147141]\n",
      "[Epoch 4/200] [Batch 477/938] [D loss: 1.068908, acc: 96%] [G loss: 1.147456]\n",
      "[Epoch 4/200] [Batch 478/938] [D loss: 1.093242, acc: 94%] [G loss: 1.155703]\n",
      "[Epoch 4/200] [Batch 479/938] [D loss: 1.077525, acc: 95%] [G loss: 1.164444]\n",
      "[Epoch 4/200] [Batch 480/938] [D loss: 1.085326, acc: 96%] [G loss: 1.203343]\n",
      "[Epoch 4/200] [Batch 481/938] [D loss: 1.077012, acc: 98%] [G loss: 1.159811]\n",
      "[Epoch 4/200] [Batch 482/938] [D loss: 1.064699, acc: 97%] [G loss: 1.096496]\n",
      "[Epoch 4/200] [Batch 483/938] [D loss: 1.062317, acc: 95%] [G loss: 1.162714]\n",
      "[Epoch 4/200] [Batch 484/938] [D loss: 1.115196, acc: 93%] [G loss: 1.155438]\n",
      "[Epoch 4/200] [Batch 485/938] [D loss: 1.069535, acc: 96%] [G loss: 1.115446]\n",
      "[Epoch 4/200] [Batch 486/938] [D loss: 1.122662, acc: 95%] [G loss: 1.216710]\n",
      "[Epoch 4/200] [Batch 487/938] [D loss: 1.122546, acc: 96%] [G loss: 1.126249]\n",
      "[Epoch 4/200] [Batch 488/938] [D loss: 1.087053, acc: 97%] [G loss: 1.091574]\n",
      "[Epoch 4/200] [Batch 489/938] [D loss: 1.106349, acc: 92%] [G loss: 1.101298]\n",
      "[Epoch 4/200] [Batch 490/938] [D loss: 1.080340, acc: 96%] [G loss: 1.119474]\n",
      "[Epoch 4/200] [Batch 491/938] [D loss: 1.084053, acc: 95%] [G loss: 1.106327]\n",
      "[Epoch 4/200] [Batch 492/938] [D loss: 1.058168, acc: 96%] [G loss: 1.243148]\n",
      "[Epoch 4/200] [Batch 493/938] [D loss: 1.051457, acc: 96%] [G loss: 1.158580]\n",
      "[Epoch 4/200] [Batch 494/938] [D loss: 1.071575, acc: 95%] [G loss: 1.057138]\n",
      "[Epoch 4/200] [Batch 495/938] [D loss: 1.095323, acc: 96%] [G loss: 1.099037]\n",
      "[Epoch 4/200] [Batch 496/938] [D loss: 1.072129, acc: 95%] [G loss: 1.104388]\n",
      "[Epoch 4/200] [Batch 497/938] [D loss: 1.107626, acc: 92%] [G loss: 1.134405]\n",
      "[Epoch 4/200] [Batch 498/938] [D loss: 1.092388, acc: 95%] [G loss: 1.119592]\n",
      "[Epoch 4/200] [Batch 499/938] [D loss: 1.060260, acc: 96%] [G loss: 1.167024]\n",
      "[Epoch 4/200] [Batch 500/938] [D loss: 1.073217, acc: 96%] [G loss: 1.091060]\n",
      "[Epoch 4/200] [Batch 501/938] [D loss: 1.074447, acc: 98%] [G loss: 1.113548]\n",
      "[Epoch 4/200] [Batch 502/938] [D loss: 1.103374, acc: 94%] [G loss: 1.137332]\n",
      "[Epoch 4/200] [Batch 503/938] [D loss: 1.117422, acc: 96%] [G loss: 1.138068]\n",
      "[Epoch 4/200] [Batch 504/938] [D loss: 1.119303, acc: 93%] [G loss: 1.142025]\n",
      "[Epoch 4/200] [Batch 505/938] [D loss: 1.080286, acc: 89%] [G loss: 1.182646]\n",
      "[Epoch 4/200] [Batch 506/938] [D loss: 1.091071, acc: 92%] [G loss: 1.189181]\n",
      "[Epoch 4/200] [Batch 507/938] [D loss: 1.101298, acc: 97%] [G loss: 1.170622]\n",
      "[Epoch 4/200] [Batch 508/938] [D loss: 1.107211, acc: 96%] [G loss: 1.208824]\n",
      "[Epoch 4/200] [Batch 509/938] [D loss: 1.094360, acc: 92%] [G loss: 1.095683]\n",
      "[Epoch 4/200] [Batch 510/938] [D loss: 1.067680, acc: 97%] [G loss: 1.091591]\n",
      "[Epoch 4/200] [Batch 511/938] [D loss: 1.079854, acc: 94%] [G loss: 1.117076]\n",
      "[Epoch 4/200] [Batch 512/938] [D loss: 1.112817, acc: 92%] [G loss: 1.066437]\n",
      "[Epoch 4/200] [Batch 513/938] [D loss: 1.094505, acc: 98%] [G loss: 1.126441]\n",
      "[Epoch 4/200] [Batch 514/938] [D loss: 1.095420, acc: 95%] [G loss: 1.123423]\n",
      "[Epoch 4/200] [Batch 515/938] [D loss: 1.049724, acc: 98%] [G loss: 1.123753]\n",
      "[Epoch 4/200] [Batch 516/938] [D loss: 1.084033, acc: 92%] [G loss: 1.157372]\n",
      "[Epoch 4/200] [Batch 517/938] [D loss: 1.125048, acc: 95%] [G loss: 1.150125]\n",
      "[Epoch 4/200] [Batch 518/938] [D loss: 1.115517, acc: 96%] [G loss: 1.107334]\n",
      "[Epoch 4/200] [Batch 519/938] [D loss: 1.084103, acc: 96%] [G loss: 1.106644]\n",
      "[Epoch 4/200] [Batch 520/938] [D loss: 1.133262, acc: 92%] [G loss: 1.062703]\n",
      "[Epoch 4/200] [Batch 521/938] [D loss: 1.112694, acc: 95%] [G loss: 1.063812]\n",
      "[Epoch 4/200] [Batch 522/938] [D loss: 1.035752, acc: 95%] [G loss: 1.121918]\n",
      "[Epoch 4/200] [Batch 523/938] [D loss: 1.094013, acc: 96%] [G loss: 1.172409]\n",
      "[Epoch 4/200] [Batch 524/938] [D loss: 1.064934, acc: 96%] [G loss: 1.144857]\n",
      "[Epoch 4/200] [Batch 525/938] [D loss: 1.078894, acc: 96%] [G loss: 1.095369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 526/938] [D loss: 1.091056, acc: 96%] [G loss: 1.099910]\n",
      "[Epoch 4/200] [Batch 527/938] [D loss: 1.073450, acc: 96%] [G loss: 1.140638]\n",
      "[Epoch 4/200] [Batch 528/938] [D loss: 1.074288, acc: 94%] [G loss: 1.187752]\n",
      "[Epoch 4/200] [Batch 529/938] [D loss: 1.081609, acc: 96%] [G loss: 1.155181]\n",
      "[Epoch 4/200] [Batch 530/938] [D loss: 1.138594, acc: 90%] [G loss: 1.156648]\n",
      "[Epoch 4/200] [Batch 531/938] [D loss: 1.112039, acc: 94%] [G loss: 1.188872]\n",
      "[Epoch 4/200] [Batch 532/938] [D loss: 1.100934, acc: 93%] [G loss: 1.107963]\n",
      "[Epoch 4/200] [Batch 533/938] [D loss: 1.064229, acc: 91%] [G loss: 1.156426]\n",
      "[Epoch 4/200] [Batch 534/938] [D loss: 1.069812, acc: 94%] [G loss: 1.129032]\n",
      "[Epoch 4/200] [Batch 535/938] [D loss: 1.103470, acc: 96%] [G loss: 1.167587]\n",
      "[Epoch 4/200] [Batch 536/938] [D loss: 1.088055, acc: 96%] [G loss: 1.104209]\n",
      "[Epoch 4/200] [Batch 537/938] [D loss: 1.074867, acc: 91%] [G loss: 1.077871]\n",
      "[Epoch 4/200] [Batch 538/938] [D loss: 1.100061, acc: 92%] [G loss: 1.187769]\n",
      "[Epoch 4/200] [Batch 539/938] [D loss: 1.101172, acc: 94%] [G loss: 1.167474]\n",
      "[Epoch 4/200] [Batch 540/938] [D loss: 1.093158, acc: 96%] [G loss: 1.127245]\n",
      "[Epoch 4/200] [Batch 541/938] [D loss: 1.089828, acc: 94%] [G loss: 1.217244]\n",
      "[Epoch 4/200] [Batch 542/938] [D loss: 1.056674, acc: 96%] [G loss: 1.125893]\n",
      "[Epoch 4/200] [Batch 543/938] [D loss: 1.075836, acc: 98%] [G loss: 1.150155]\n",
      "[Epoch 4/200] [Batch 544/938] [D loss: 1.081880, acc: 92%] [G loss: 1.248018]\n",
      "[Epoch 4/200] [Batch 545/938] [D loss: 1.088121, acc: 91%] [G loss: 1.140287]\n",
      "[Epoch 4/200] [Batch 546/938] [D loss: 1.114574, acc: 95%] [G loss: 1.178881]\n",
      "[Epoch 4/200] [Batch 547/938] [D loss: 1.027156, acc: 96%] [G loss: 1.151665]\n",
      "[Epoch 4/200] [Batch 548/938] [D loss: 1.099708, acc: 94%] [G loss: 1.172615]\n",
      "[Epoch 4/200] [Batch 549/938] [D loss: 1.066200, acc: 96%] [G loss: 1.179984]\n",
      "[Epoch 4/200] [Batch 550/938] [D loss: 1.098824, acc: 96%] [G loss: 1.129489]\n",
      "[Epoch 4/200] [Batch 551/938] [D loss: 1.084081, acc: 96%] [G loss: 1.122763]\n",
      "[Epoch 4/200] [Batch 552/938] [D loss: 1.108819, acc: 92%] [G loss: 1.096899]\n",
      "[Epoch 4/200] [Batch 553/938] [D loss: 1.090885, acc: 92%] [G loss: 1.173251]\n",
      "[Epoch 4/200] [Batch 554/938] [D loss: 1.095207, acc: 94%] [G loss: 1.095909]\n",
      "[Epoch 4/200] [Batch 555/938] [D loss: 1.100182, acc: 94%] [G loss: 1.244586]\n",
      "[Epoch 4/200] [Batch 556/938] [D loss: 1.053644, acc: 95%] [G loss: 1.178192]\n",
      "[Epoch 4/200] [Batch 557/938] [D loss: 1.102273, acc: 94%] [G loss: 1.111503]\n",
      "[Epoch 4/200] [Batch 558/938] [D loss: 1.096201, acc: 95%] [G loss: 1.103821]\n",
      "[Epoch 4/200] [Batch 559/938] [D loss: 1.086133, acc: 93%] [G loss: 1.147590]\n",
      "[Epoch 4/200] [Batch 560/938] [D loss: 1.119294, acc: 96%] [G loss: 1.069655]\n",
      "[Epoch 4/200] [Batch 561/938] [D loss: 1.084040, acc: 97%] [G loss: 1.141241]\n",
      "[Epoch 4/200] [Batch 562/938] [D loss: 1.090712, acc: 96%] [G loss: 1.054446]\n",
      "[Epoch 4/200] [Batch 563/938] [D loss: 1.073809, acc: 93%] [G loss: 1.131628]\n",
      "[Epoch 4/200] [Batch 564/938] [D loss: 1.085202, acc: 91%] [G loss: 1.152593]\n",
      "[Epoch 4/200] [Batch 565/938] [D loss: 1.069546, acc: 95%] [G loss: 1.047440]\n",
      "[Epoch 4/200] [Batch 566/938] [D loss: 1.064335, acc: 96%] [G loss: 1.134746]\n",
      "[Epoch 4/200] [Batch 567/938] [D loss: 1.060590, acc: 97%] [G loss: 1.129612]\n",
      "[Epoch 4/200] [Batch 568/938] [D loss: 1.039188, acc: 95%] [G loss: 1.162590]\n",
      "[Epoch 4/200] [Batch 569/938] [D loss: 1.118639, acc: 93%] [G loss: 1.065627]\n",
      "[Epoch 4/200] [Batch 570/938] [D loss: 1.099501, acc: 96%] [G loss: 1.148488]\n",
      "[Epoch 4/200] [Batch 571/938] [D loss: 1.101905, acc: 96%] [G loss: 1.175341]\n",
      "[Epoch 4/200] [Batch 572/938] [D loss: 1.066281, acc: 96%] [G loss: 1.155324]\n",
      "[Epoch 4/200] [Batch 573/938] [D loss: 1.071082, acc: 96%] [G loss: 1.197794]\n",
      "[Epoch 4/200] [Batch 574/938] [D loss: 1.058446, acc: 95%] [G loss: 1.168318]\n",
      "[Epoch 4/200] [Batch 575/938] [D loss: 1.110698, acc: 89%] [G loss: 1.165302]\n",
      "[Epoch 4/200] [Batch 576/938] [D loss: 1.089899, acc: 94%] [G loss: 1.074173]\n",
      "[Epoch 4/200] [Batch 577/938] [D loss: 1.081941, acc: 97%] [G loss: 1.094389]\n",
      "[Epoch 4/200] [Batch 578/938] [D loss: 1.123116, acc: 90%] [G loss: 1.185766]\n",
      "[Epoch 4/200] [Batch 579/938] [D loss: 1.070296, acc: 92%] [G loss: 1.115981]\n",
      "[Epoch 4/200] [Batch 580/938] [D loss: 1.104291, acc: 94%] [G loss: 1.105212]\n",
      "[Epoch 4/200] [Batch 581/938] [D loss: 1.035319, acc: 97%] [G loss: 1.155937]\n",
      "[Epoch 4/200] [Batch 582/938] [D loss: 1.069598, acc: 93%] [G loss: 1.181072]\n",
      "[Epoch 4/200] [Batch 583/938] [D loss: 1.101410, acc: 96%] [G loss: 1.146829]\n",
      "[Epoch 4/200] [Batch 584/938] [D loss: 1.057858, acc: 96%] [G loss: 1.077538]\n",
      "[Epoch 4/200] [Batch 585/938] [D loss: 1.101520, acc: 92%] [G loss: 1.089325]\n",
      "[Epoch 4/200] [Batch 586/938] [D loss: 1.068516, acc: 96%] [G loss: 1.110679]\n",
      "[Epoch 4/200] [Batch 587/938] [D loss: 1.028572, acc: 98%] [G loss: 1.119318]\n",
      "[Epoch 4/200] [Batch 588/938] [D loss: 1.076217, acc: 96%] [G loss: 1.163119]\n",
      "[Epoch 4/200] [Batch 589/938] [D loss: 1.079961, acc: 95%] [G loss: 1.201216]\n",
      "[Epoch 4/200] [Batch 590/938] [D loss: 1.073096, acc: 92%] [G loss: 1.189024]\n",
      "[Epoch 4/200] [Batch 591/938] [D loss: 1.101781, acc: 95%] [G loss: 1.105242]\n",
      "[Epoch 4/200] [Batch 592/938] [D loss: 1.057756, acc: 95%] [G loss: 1.091772]\n",
      "[Epoch 4/200] [Batch 593/938] [D loss: 1.075768, acc: 94%] [G loss: 1.126619]\n",
      "[Epoch 4/200] [Batch 594/938] [D loss: 1.058323, acc: 95%] [G loss: 1.161161]\n",
      "[Epoch 4/200] [Batch 595/938] [D loss: 1.105524, acc: 97%] [G loss: 1.093385]\n",
      "[Epoch 4/200] [Batch 596/938] [D loss: 1.066375, acc: 93%] [G loss: 1.146599]\n",
      "[Epoch 4/200] [Batch 597/938] [D loss: 1.070446, acc: 98%] [G loss: 1.186708]\n",
      "[Epoch 4/200] [Batch 598/938] [D loss: 1.152377, acc: 93%] [G loss: 1.169756]\n",
      "[Epoch 4/200] [Batch 599/938] [D loss: 1.118885, acc: 92%] [G loss: 1.120714]\n",
      "[Epoch 4/200] [Batch 600/938] [D loss: 1.051717, acc: 96%] [G loss: 1.136965]\n",
      "[Epoch 4/200] [Batch 601/938] [D loss: 1.102350, acc: 95%] [G loss: 1.062746]\n",
      "[Epoch 4/200] [Batch 602/938] [D loss: 1.159499, acc: 94%] [G loss: 1.124109]\n",
      "[Epoch 4/200] [Batch 603/938] [D loss: 1.091546, acc: 99%] [G loss: 1.156968]\n",
      "[Epoch 4/200] [Batch 604/938] [D loss: 1.104913, acc: 92%] [G loss: 1.221490]\n",
      "[Epoch 4/200] [Batch 605/938] [D loss: 1.065950, acc: 94%] [G loss: 1.186066]\n",
      "[Epoch 4/200] [Batch 606/938] [D loss: 1.083709, acc: 94%] [G loss: 1.120930]\n",
      "[Epoch 4/200] [Batch 607/938] [D loss: 1.089747, acc: 96%] [G loss: 1.193183]\n",
      "[Epoch 4/200] [Batch 608/938] [D loss: 1.132756, acc: 96%] [G loss: 1.094603]\n",
      "[Epoch 4/200] [Batch 609/938] [D loss: 1.109921, acc: 92%] [G loss: 1.075542]\n",
      "[Epoch 4/200] [Batch 610/938] [D loss: 1.087118, acc: 94%] [G loss: 1.157298]\n",
      "[Epoch 4/200] [Batch 611/938] [D loss: 1.089070, acc: 96%] [G loss: 1.146237]\n",
      "[Epoch 4/200] [Batch 612/938] [D loss: 1.078431, acc: 96%] [G loss: 1.266027]\n",
      "[Epoch 4/200] [Batch 613/938] [D loss: 1.112568, acc: 92%] [G loss: 1.117727]\n",
      "[Epoch 4/200] [Batch 614/938] [D loss: 1.108960, acc: 91%] [G loss: 1.118537]\n",
      "[Epoch 4/200] [Batch 615/938] [D loss: 1.135586, acc: 92%] [G loss: 1.066818]\n",
      "[Epoch 4/200] [Batch 616/938] [D loss: 1.069255, acc: 94%] [G loss: 1.150541]\n",
      "[Epoch 4/200] [Batch 617/938] [D loss: 1.100468, acc: 93%] [G loss: 1.146890]\n",
      "[Epoch 4/200] [Batch 618/938] [D loss: 1.086264, acc: 96%] [G loss: 1.188690]\n",
      "[Epoch 4/200] [Batch 619/938] [D loss: 1.078503, acc: 96%] [G loss: 1.129236]\n",
      "[Epoch 4/200] [Batch 620/938] [D loss: 1.132950, acc: 92%] [G loss: 1.165971]\n",
      "[Epoch 4/200] [Batch 621/938] [D loss: 1.068084, acc: 95%] [G loss: 1.195243]\n",
      "[Epoch 4/200] [Batch 622/938] [D loss: 1.088791, acc: 94%] [G loss: 1.194134]\n",
      "[Epoch 4/200] [Batch 623/938] [D loss: 1.102619, acc: 94%] [G loss: 1.134747]\n",
      "[Epoch 4/200] [Batch 624/938] [D loss: 1.104406, acc: 93%] [G loss: 1.165618]\n",
      "[Epoch 4/200] [Batch 625/938] [D loss: 1.054753, acc: 95%] [G loss: 1.142790]\n",
      "[Epoch 4/200] [Batch 626/938] [D loss: 1.110391, acc: 92%] [G loss: 1.113205]\n",
      "[Epoch 4/200] [Batch 627/938] [D loss: 1.078690, acc: 95%] [G loss: 1.124873]\n",
      "[Epoch 4/200] [Batch 628/938] [D loss: 1.070825, acc: 95%] [G loss: 1.144440]\n",
      "[Epoch 4/200] [Batch 629/938] [D loss: 1.084513, acc: 95%] [G loss: 1.257719]\n",
      "[Epoch 4/200] [Batch 630/938] [D loss: 1.084291, acc: 96%] [G loss: 1.141390]\n",
      "[Epoch 4/200] [Batch 631/938] [D loss: 1.048405, acc: 97%] [G loss: 1.153717]\n",
      "[Epoch 4/200] [Batch 632/938] [D loss: 1.077908, acc: 96%] [G loss: 1.157577]\n",
      "[Epoch 4/200] [Batch 633/938] [D loss: 1.077568, acc: 97%] [G loss: 1.092847]\n",
      "[Epoch 4/200] [Batch 634/938] [D loss: 1.105588, acc: 96%] [G loss: 1.088148]\n",
      "[Epoch 4/200] [Batch 635/938] [D loss: 1.073080, acc: 96%] [G loss: 1.136678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 636/938] [D loss: 1.073242, acc: 93%] [G loss: 1.139374]\n",
      "[Epoch 4/200] [Batch 637/938] [D loss: 1.098263, acc: 96%] [G loss: 1.190298]\n",
      "[Epoch 4/200] [Batch 638/938] [D loss: 1.058385, acc: 93%] [G loss: 1.159343]\n",
      "[Epoch 4/200] [Batch 639/938] [D loss: 1.082158, acc: 94%] [G loss: 1.126589]\n",
      "[Epoch 4/200] [Batch 640/938] [D loss: 1.119756, acc: 92%] [G loss: 1.162412]\n",
      "[Epoch 4/200] [Batch 641/938] [D loss: 1.098630, acc: 90%] [G loss: 1.104540]\n",
      "[Epoch 4/200] [Batch 642/938] [D loss: 1.096532, acc: 96%] [G loss: 1.129861]\n",
      "[Epoch 4/200] [Batch 643/938] [D loss: 1.059348, acc: 98%] [G loss: 1.167620]\n",
      "[Epoch 4/200] [Batch 644/938] [D loss: 1.081984, acc: 96%] [G loss: 1.148244]\n",
      "[Epoch 4/200] [Batch 645/938] [D loss: 1.099782, acc: 95%] [G loss: 1.133408]\n",
      "[Epoch 4/200] [Batch 646/938] [D loss: 1.070359, acc: 96%] [G loss: 1.101881]\n",
      "[Epoch 4/200] [Batch 647/938] [D loss: 1.093653, acc: 94%] [G loss: 1.111258]\n",
      "[Epoch 4/200] [Batch 648/938] [D loss: 1.075442, acc: 95%] [G loss: 1.175775]\n",
      "[Epoch 4/200] [Batch 649/938] [D loss: 1.074831, acc: 97%] [G loss: 1.095990]\n",
      "[Epoch 4/200] [Batch 650/938] [D loss: 1.083252, acc: 95%] [G loss: 1.125063]\n",
      "[Epoch 4/200] [Batch 651/938] [D loss: 1.119207, acc: 93%] [G loss: 1.108304]\n",
      "[Epoch 4/200] [Batch 652/938] [D loss: 1.074678, acc: 95%] [G loss: 1.108133]\n",
      "[Epoch 4/200] [Batch 653/938] [D loss: 1.075096, acc: 96%] [G loss: 1.105818]\n",
      "[Epoch 4/200] [Batch 654/938] [D loss: 1.118115, acc: 93%] [G loss: 1.140245]\n",
      "[Epoch 4/200] [Batch 655/938] [D loss: 1.076863, acc: 96%] [G loss: 1.119097]\n",
      "[Epoch 4/200] [Batch 656/938] [D loss: 1.117427, acc: 93%] [G loss: 1.130279]\n",
      "[Epoch 4/200] [Batch 657/938] [D loss: 1.084018, acc: 94%] [G loss: 1.203806]\n",
      "[Epoch 4/200] [Batch 658/938] [D loss: 1.060460, acc: 95%] [G loss: 1.141193]\n",
      "[Epoch 4/200] [Batch 659/938] [D loss: 1.088121, acc: 97%] [G loss: 1.068625]\n",
      "[Epoch 4/200] [Batch 660/938] [D loss: 1.125367, acc: 93%] [G loss: 1.152383]\n",
      "[Epoch 4/200] [Batch 661/938] [D loss: 1.110730, acc: 92%] [G loss: 1.118645]\n",
      "[Epoch 4/200] [Batch 662/938] [D loss: 1.069396, acc: 94%] [G loss: 1.180940]\n",
      "[Epoch 4/200] [Batch 663/938] [D loss: 1.049913, acc: 96%] [G loss: 1.179821]\n",
      "[Epoch 4/200] [Batch 664/938] [D loss: 1.038594, acc: 96%] [G loss: 1.160746]\n",
      "[Epoch 4/200] [Batch 665/938] [D loss: 1.088515, acc: 94%] [G loss: 1.137965]\n",
      "[Epoch 4/200] [Batch 666/938] [D loss: 1.110920, acc: 97%] [G loss: 1.133911]\n",
      "[Epoch 4/200] [Batch 667/938] [D loss: 1.145121, acc: 90%] [G loss: 1.188247]\n",
      "[Epoch 4/200] [Batch 668/938] [D loss: 1.122893, acc: 95%] [G loss: 1.139559]\n",
      "[Epoch 4/200] [Batch 669/938] [D loss: 1.066687, acc: 96%] [G loss: 1.160203]\n",
      "[Epoch 4/200] [Batch 670/938] [D loss: 1.087034, acc: 95%] [G loss: 1.120173]\n",
      "[Epoch 4/200] [Batch 671/938] [D loss: 1.098705, acc: 95%] [G loss: 1.137642]\n",
      "[Epoch 4/200] [Batch 672/938] [D loss: 1.115781, acc: 93%] [G loss: 1.122518]\n",
      "[Epoch 4/200] [Batch 673/938] [D loss: 1.067499, acc: 97%] [G loss: 1.096713]\n",
      "[Epoch 4/200] [Batch 674/938] [D loss: 1.099377, acc: 92%] [G loss: 1.078770]\n",
      "[Epoch 4/200] [Batch 675/938] [D loss: 1.054648, acc: 96%] [G loss: 1.233374]\n",
      "[Epoch 4/200] [Batch 676/938] [D loss: 1.066502, acc: 96%] [G loss: 1.229379]\n",
      "[Epoch 4/200] [Batch 677/938] [D loss: 1.094014, acc: 95%] [G loss: 1.151542]\n",
      "[Epoch 4/200] [Batch 678/938] [D loss: 1.098141, acc: 95%] [G loss: 1.185878]\n",
      "[Epoch 4/200] [Batch 679/938] [D loss: 1.102395, acc: 97%] [G loss: 1.181046]\n",
      "[Epoch 4/200] [Batch 680/938] [D loss: 1.080370, acc: 94%] [G loss: 1.222414]\n",
      "[Epoch 4/200] [Batch 681/938] [D loss: 1.093643, acc: 96%] [G loss: 1.043227]\n",
      "[Epoch 4/200] [Batch 682/938] [D loss: 1.108514, acc: 96%] [G loss: 1.104686]\n",
      "[Epoch 4/200] [Batch 683/938] [D loss: 1.090420, acc: 95%] [G loss: 1.140318]\n",
      "[Epoch 4/200] [Batch 684/938] [D loss: 1.075788, acc: 95%] [G loss: 1.132376]\n",
      "[Epoch 4/200] [Batch 685/938] [D loss: 1.077513, acc: 94%] [G loss: 1.152583]\n",
      "[Epoch 4/200] [Batch 686/938] [D loss: 1.105137, acc: 96%] [G loss: 1.268499]\n",
      "[Epoch 4/200] [Batch 687/938] [D loss: 1.056094, acc: 96%] [G loss: 1.151571]\n",
      "[Epoch 4/200] [Batch 688/938] [D loss: 1.053415, acc: 96%] [G loss: 1.144817]\n",
      "[Epoch 4/200] [Batch 689/938] [D loss: 1.057927, acc: 91%] [G loss: 1.051184]\n",
      "[Epoch 4/200] [Batch 690/938] [D loss: 1.093501, acc: 95%] [G loss: 1.056225]\n",
      "[Epoch 4/200] [Batch 691/938] [D loss: 1.087060, acc: 94%] [G loss: 1.149454]\n",
      "[Epoch 4/200] [Batch 692/938] [D loss: 1.069090, acc: 96%] [G loss: 1.134180]\n",
      "[Epoch 4/200] [Batch 693/938] [D loss: 1.127393, acc: 93%] [G loss: 1.180612]\n",
      "[Epoch 4/200] [Batch 694/938] [D loss: 1.065003, acc: 94%] [G loss: 1.093880]\n",
      "[Epoch 4/200] [Batch 695/938] [D loss: 1.099139, acc: 95%] [G loss: 1.091408]\n",
      "[Epoch 4/200] [Batch 696/938] [D loss: 1.093342, acc: 95%] [G loss: 1.147410]\n",
      "[Epoch 4/200] [Batch 697/938] [D loss: 1.101162, acc: 96%] [G loss: 1.155668]\n",
      "[Epoch 4/200] [Batch 698/938] [D loss: 1.035458, acc: 97%] [G loss: 1.083292]\n",
      "[Epoch 4/200] [Batch 699/938] [D loss: 1.123378, acc: 95%] [G loss: 1.089419]\n",
      "[Epoch 4/200] [Batch 700/938] [D loss: 1.102928, acc: 94%] [G loss: 1.062885]\n",
      "[Epoch 4/200] [Batch 701/938] [D loss: 1.079278, acc: 92%] [G loss: 1.200366]\n",
      "[Epoch 4/200] [Batch 702/938] [D loss: 1.091068, acc: 94%] [G loss: 1.227732]\n",
      "[Epoch 4/200] [Batch 703/938] [D loss: 1.093691, acc: 96%] [G loss: 1.128072]\n",
      "[Epoch 4/200] [Batch 704/938] [D loss: 1.066784, acc: 98%] [G loss: 1.143296]\n",
      "[Epoch 4/200] [Batch 705/938] [D loss: 1.083312, acc: 96%] [G loss: 1.121261]\n",
      "[Epoch 4/200] [Batch 706/938] [D loss: 1.093903, acc: 97%] [G loss: 1.125594]\n",
      "[Epoch 4/200] [Batch 707/938] [D loss: 1.086113, acc: 96%] [G loss: 1.147196]\n",
      "[Epoch 4/200] [Batch 708/938] [D loss: 1.086213, acc: 93%] [G loss: 1.106209]\n",
      "[Epoch 4/200] [Batch 709/938] [D loss: 1.078269, acc: 96%] [G loss: 1.162532]\n",
      "[Epoch 4/200] [Batch 710/938] [D loss: 1.085325, acc: 95%] [G loss: 1.142561]\n",
      "[Epoch 4/200] [Batch 711/938] [D loss: 1.124531, acc: 95%] [G loss: 1.085400]\n",
      "[Epoch 4/200] [Batch 712/938] [D loss: 1.100274, acc: 96%] [G loss: 1.087987]\n",
      "[Epoch 4/200] [Batch 713/938] [D loss: 1.077132, acc: 94%] [G loss: 1.070815]\n",
      "[Epoch 4/200] [Batch 714/938] [D loss: 1.093726, acc: 92%] [G loss: 1.150038]\n",
      "[Epoch 4/200] [Batch 715/938] [D loss: 1.066471, acc: 92%] [G loss: 1.077547]\n",
      "[Epoch 4/200] [Batch 716/938] [D loss: 1.077625, acc: 94%] [G loss: 1.163595]\n",
      "[Epoch 4/200] [Batch 717/938] [D loss: 1.108849, acc: 93%] [G loss: 1.143341]\n",
      "[Epoch 4/200] [Batch 718/938] [D loss: 1.054926, acc: 94%] [G loss: 1.104782]\n",
      "[Epoch 4/200] [Batch 719/938] [D loss: 1.122706, acc: 96%] [G loss: 1.090432]\n",
      "[Epoch 4/200] [Batch 720/938] [D loss: 1.066628, acc: 96%] [G loss: 1.198846]\n",
      "[Epoch 4/200] [Batch 721/938] [D loss: 1.105296, acc: 96%] [G loss: 1.145378]\n",
      "[Epoch 4/200] [Batch 722/938] [D loss: 1.072831, acc: 96%] [G loss: 1.163531]\n",
      "[Epoch 4/200] [Batch 723/938] [D loss: 1.076974, acc: 94%] [G loss: 1.144913]\n",
      "[Epoch 4/200] [Batch 724/938] [D loss: 1.105487, acc: 97%] [G loss: 1.117487]\n",
      "[Epoch 4/200] [Batch 725/938] [D loss: 1.081582, acc: 92%] [G loss: 1.151078]\n",
      "[Epoch 4/200] [Batch 726/938] [D loss: 1.073450, acc: 94%] [G loss: 1.070044]\n",
      "[Epoch 4/200] [Batch 727/938] [D loss: 1.095125, acc: 96%] [G loss: 1.080316]\n",
      "[Epoch 4/200] [Batch 728/938] [D loss: 1.094636, acc: 95%] [G loss: 1.130140]\n",
      "[Epoch 4/200] [Batch 729/938] [D loss: 1.084317, acc: 92%] [G loss: 1.160853]\n",
      "[Epoch 4/200] [Batch 730/938] [D loss: 1.078987, acc: 98%] [G loss: 1.168593]\n",
      "[Epoch 4/200] [Batch 731/938] [D loss: 1.140797, acc: 94%] [G loss: 1.129360]\n",
      "[Epoch 4/200] [Batch 732/938] [D loss: 1.085598, acc: 93%] [G loss: 1.110290]\n",
      "[Epoch 4/200] [Batch 733/938] [D loss: 1.055250, acc: 95%] [G loss: 1.115501]\n",
      "[Epoch 4/200] [Batch 734/938] [D loss: 1.061968, acc: 96%] [G loss: 1.100625]\n",
      "[Epoch 4/200] [Batch 735/938] [D loss: 1.081947, acc: 95%] [G loss: 1.130745]\n",
      "[Epoch 4/200] [Batch 736/938] [D loss: 1.093472, acc: 91%] [G loss: 1.170730]\n",
      "[Epoch 4/200] [Batch 737/938] [D loss: 1.065861, acc: 93%] [G loss: 1.185679]\n",
      "[Epoch 4/200] [Batch 738/938] [D loss: 1.141099, acc: 94%] [G loss: 1.136804]\n",
      "[Epoch 4/200] [Batch 739/938] [D loss: 1.112830, acc: 96%] [G loss: 1.172886]\n",
      "[Epoch 4/200] [Batch 740/938] [D loss: 1.123352, acc: 93%] [G loss: 1.107318]\n",
      "[Epoch 4/200] [Batch 741/938] [D loss: 1.092737, acc: 91%] [G loss: 1.106251]\n",
      "[Epoch 4/200] [Batch 742/938] [D loss: 1.084271, acc: 94%] [G loss: 1.156170]\n",
      "[Epoch 4/200] [Batch 743/938] [D loss: 1.073908, acc: 94%] [G loss: 1.202576]\n",
      "[Epoch 4/200] [Batch 744/938] [D loss: 1.036805, acc: 94%] [G loss: 1.160335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 745/938] [D loss: 1.073704, acc: 91%] [G loss: 1.095863]\n",
      "[Epoch 4/200] [Batch 746/938] [D loss: 1.057106, acc: 97%] [G loss: 1.146198]\n",
      "[Epoch 4/200] [Batch 747/938] [D loss: 1.076982, acc: 95%] [G loss: 1.131439]\n",
      "[Epoch 4/200] [Batch 748/938] [D loss: 1.075864, acc: 96%] [G loss: 1.158037]\n",
      "[Epoch 4/200] [Batch 749/938] [D loss: 1.070441, acc: 97%] [G loss: 1.125780]\n",
      "[Epoch 4/200] [Batch 750/938] [D loss: 1.074375, acc: 93%] [G loss: 1.173173]\n",
      "[Epoch 4/200] [Batch 751/938] [D loss: 1.097133, acc: 96%] [G loss: 1.171933]\n",
      "[Epoch 4/200] [Batch 752/938] [D loss: 1.139079, acc: 90%] [G loss: 1.154372]\n",
      "[Epoch 4/200] [Batch 753/938] [D loss: 1.119040, acc: 95%] [G loss: 1.116726]\n",
      "[Epoch 4/200] [Batch 754/938] [D loss: 1.098526, acc: 93%] [G loss: 1.097813]\n",
      "[Epoch 4/200] [Batch 755/938] [D loss: 1.089341, acc: 94%] [G loss: 1.135165]\n",
      "[Epoch 4/200] [Batch 756/938] [D loss: 1.076455, acc: 94%] [G loss: 1.132809]\n",
      "[Epoch 4/200] [Batch 757/938] [D loss: 1.157229, acc: 90%] [G loss: 1.104918]\n",
      "[Epoch 4/200] [Batch 758/938] [D loss: 1.099991, acc: 90%] [G loss: 1.197869]\n",
      "[Epoch 4/200] [Batch 759/938] [D loss: 1.110912, acc: 98%] [G loss: 1.200545]\n",
      "[Epoch 4/200] [Batch 760/938] [D loss: 1.065355, acc: 95%] [G loss: 1.158238]\n",
      "[Epoch 4/200] [Batch 761/938] [D loss: 1.093637, acc: 92%] [G loss: 1.173018]\n",
      "[Epoch 4/200] [Batch 762/938] [D loss: 1.065918, acc: 97%] [G loss: 1.099945]\n",
      "[Epoch 4/200] [Batch 763/938] [D loss: 1.107232, acc: 92%] [G loss: 1.085452]\n",
      "[Epoch 4/200] [Batch 764/938] [D loss: 1.091002, acc: 92%] [G loss: 1.170770]\n",
      "[Epoch 4/200] [Batch 765/938] [D loss: 1.052642, acc: 97%] [G loss: 1.196315]\n",
      "[Epoch 4/200] [Batch 766/938] [D loss: 1.066082, acc: 96%] [G loss: 1.128850]\n",
      "[Epoch 4/200] [Batch 767/938] [D loss: 1.077705, acc: 94%] [G loss: 1.134485]\n",
      "[Epoch 4/200] [Batch 768/938] [D loss: 1.068226, acc: 96%] [G loss: 1.111079]\n",
      "[Epoch 4/200] [Batch 769/938] [D loss: 1.066110, acc: 96%] [G loss: 1.110351]\n",
      "[Epoch 4/200] [Batch 770/938] [D loss: 1.096922, acc: 92%] [G loss: 1.108541]\n",
      "[Epoch 4/200] [Batch 771/938] [D loss: 1.074470, acc: 98%] [G loss: 1.087779]\n",
      "[Epoch 4/200] [Batch 772/938] [D loss: 1.071721, acc: 94%] [G loss: 1.122244]\n",
      "[Epoch 4/200] [Batch 773/938] [D loss: 1.113814, acc: 94%] [G loss: 1.245074]\n",
      "[Epoch 4/200] [Batch 774/938] [D loss: 1.123465, acc: 94%] [G loss: 1.181943]\n",
      "[Epoch 4/200] [Batch 775/938] [D loss: 1.127793, acc: 94%] [G loss: 1.286067]\n",
      "[Epoch 4/200] [Batch 776/938] [D loss: 1.065985, acc: 98%] [G loss: 1.203216]\n",
      "[Epoch 4/200] [Batch 777/938] [D loss: 1.106201, acc: 96%] [G loss: 1.097729]\n",
      "[Epoch 4/200] [Batch 778/938] [D loss: 1.148754, acc: 92%] [G loss: 1.072083]\n",
      "[Epoch 4/200] [Batch 779/938] [D loss: 1.075875, acc: 92%] [G loss: 1.092403]\n",
      "[Epoch 4/200] [Batch 780/938] [D loss: 1.110203, acc: 92%] [G loss: 1.094087]\n",
      "[Epoch 4/200] [Batch 781/938] [D loss: 1.094398, acc: 96%] [G loss: 1.126426]\n",
      "[Epoch 4/200] [Batch 782/938] [D loss: 1.080282, acc: 95%] [G loss: 1.146502]\n",
      "[Epoch 4/200] [Batch 783/938] [D loss: 1.083078, acc: 94%] [G loss: 1.082823]\n",
      "[Epoch 4/200] [Batch 784/938] [D loss: 1.098580, acc: 95%] [G loss: 1.263056]\n",
      "[Epoch 4/200] [Batch 785/938] [D loss: 1.101676, acc: 96%] [G loss: 1.113387]\n",
      "[Epoch 4/200] [Batch 786/938] [D loss: 1.093714, acc: 94%] [G loss: 1.106858]\n",
      "[Epoch 4/200] [Batch 787/938] [D loss: 1.056523, acc: 93%] [G loss: 1.178684]\n",
      "[Epoch 4/200] [Batch 788/938] [D loss: 1.098558, acc: 95%] [G loss: 1.117190]\n",
      "[Epoch 4/200] [Batch 789/938] [D loss: 1.076105, acc: 93%] [G loss: 1.143185]\n",
      "[Epoch 4/200] [Batch 790/938] [D loss: 1.093195, acc: 96%] [G loss: 1.133516]\n",
      "[Epoch 4/200] [Batch 791/938] [D loss: 1.091059, acc: 94%] [G loss: 1.160213]\n",
      "[Epoch 4/200] [Batch 792/938] [D loss: 1.075384, acc: 96%] [G loss: 1.148997]\n",
      "[Epoch 4/200] [Batch 793/938] [D loss: 1.090060, acc: 96%] [G loss: 1.127888]\n",
      "[Epoch 4/200] [Batch 794/938] [D loss: 1.118531, acc: 96%] [G loss: 1.079721]\n",
      "[Epoch 4/200] [Batch 795/938] [D loss: 1.089820, acc: 97%] [G loss: 1.089668]\n",
      "[Epoch 4/200] [Batch 796/938] [D loss: 1.083130, acc: 92%] [G loss: 1.133840]\n",
      "[Epoch 4/200] [Batch 797/938] [D loss: 1.102659, acc: 92%] [G loss: 1.096269]\n",
      "[Epoch 4/200] [Batch 798/938] [D loss: 1.061547, acc: 94%] [G loss: 1.160225]\n",
      "[Epoch 4/200] [Batch 799/938] [D loss: 1.088899, acc: 95%] [G loss: 1.110089]\n",
      "[Epoch 4/200] [Batch 800/938] [D loss: 1.107059, acc: 96%] [G loss: 1.073824]\n",
      "[Epoch 4/200] [Batch 801/938] [D loss: 1.106612, acc: 96%] [G loss: 1.209997]\n",
      "[Epoch 4/200] [Batch 802/938] [D loss: 1.071482, acc: 99%] [G loss: 1.169013]\n",
      "[Epoch 4/200] [Batch 803/938] [D loss: 1.148508, acc: 92%] [G loss: 1.137775]\n",
      "[Epoch 4/200] [Batch 804/938] [D loss: 1.097232, acc: 95%] [G loss: 1.059392]\n",
      "[Epoch 4/200] [Batch 805/938] [D loss: 1.104615, acc: 94%] [G loss: 1.140469]\n",
      "[Epoch 4/200] [Batch 806/938] [D loss: 1.101317, acc: 92%] [G loss: 1.158162]\n",
      "[Epoch 4/200] [Batch 807/938] [D loss: 1.089056, acc: 96%] [G loss: 1.097611]\n",
      "[Epoch 4/200] [Batch 808/938] [D loss: 1.098428, acc: 95%] [G loss: 1.112008]\n",
      "[Epoch 4/200] [Batch 809/938] [D loss: 1.087318, acc: 97%] [G loss: 1.095182]\n",
      "[Epoch 4/200] [Batch 810/938] [D loss: 1.118343, acc: 95%] [G loss: 1.152280]\n",
      "[Epoch 4/200] [Batch 811/938] [D loss: 1.088512, acc: 95%] [G loss: 1.071482]\n",
      "[Epoch 4/200] [Batch 812/938] [D loss: 1.092591, acc: 96%] [G loss: 1.122318]\n",
      "[Epoch 4/200] [Batch 813/938] [D loss: 1.075567, acc: 94%] [G loss: 1.207731]\n",
      "[Epoch 4/200] [Batch 814/938] [D loss: 1.050273, acc: 95%] [G loss: 1.268705]\n",
      "[Epoch 4/200] [Batch 815/938] [D loss: 1.049916, acc: 96%] [G loss: 1.109883]\n",
      "[Epoch 4/200] [Batch 816/938] [D loss: 1.099337, acc: 93%] [G loss: 1.098959]\n",
      "[Epoch 4/200] [Batch 817/938] [D loss: 1.078106, acc: 94%] [G loss: 1.167917]\n",
      "[Epoch 4/200] [Batch 818/938] [D loss: 1.095831, acc: 90%] [G loss: 1.138262]\n",
      "[Epoch 4/200] [Batch 819/938] [D loss: 1.106121, acc: 94%] [G loss: 1.096008]\n",
      "[Epoch 4/200] [Batch 820/938] [D loss: 1.101553, acc: 95%] [G loss: 1.179674]\n",
      "[Epoch 4/200] [Batch 821/938] [D loss: 1.087027, acc: 96%] [G loss: 1.097392]\n",
      "[Epoch 4/200] [Batch 822/938] [D loss: 1.114947, acc: 91%] [G loss: 1.098227]\n",
      "[Epoch 4/200] [Batch 823/938] [D loss: 1.077151, acc: 92%] [G loss: 1.190342]\n",
      "[Epoch 4/200] [Batch 824/938] [D loss: 1.124241, acc: 93%] [G loss: 1.162539]\n",
      "[Epoch 4/200] [Batch 825/938] [D loss: 1.076563, acc: 97%] [G loss: 1.083473]\n",
      "[Epoch 4/200] [Batch 826/938] [D loss: 1.076557, acc: 92%] [G loss: 1.088990]\n",
      "[Epoch 4/200] [Batch 827/938] [D loss: 1.096406, acc: 94%] [G loss: 1.114064]\n",
      "[Epoch 4/200] [Batch 828/938] [D loss: 1.065713, acc: 94%] [G loss: 1.162712]\n",
      "[Epoch 4/200] [Batch 829/938] [D loss: 1.065299, acc: 96%] [G loss: 1.094393]\n",
      "[Epoch 4/200] [Batch 830/938] [D loss: 1.111705, acc: 99%] [G loss: 1.122255]\n",
      "[Epoch 4/200] [Batch 831/938] [D loss: 1.100652, acc: 96%] [G loss: 1.126249]\n",
      "[Epoch 4/200] [Batch 832/938] [D loss: 1.081197, acc: 95%] [G loss: 1.163338]\n",
      "[Epoch 4/200] [Batch 833/938] [D loss: 1.103138, acc: 95%] [G loss: 1.073955]\n",
      "[Epoch 4/200] [Batch 834/938] [D loss: 1.066421, acc: 96%] [G loss: 1.139486]\n",
      "[Epoch 4/200] [Batch 835/938] [D loss: 1.095296, acc: 96%] [G loss: 1.130355]\n",
      "[Epoch 4/200] [Batch 836/938] [D loss: 1.084472, acc: 96%] [G loss: 1.141787]\n",
      "[Epoch 4/200] [Batch 837/938] [D loss: 1.056333, acc: 93%] [G loss: 1.165174]\n",
      "[Epoch 4/200] [Batch 838/938] [D loss: 1.079394, acc: 95%] [G loss: 1.166390]\n",
      "[Epoch 4/200] [Batch 839/938] [D loss: 1.073279, acc: 95%] [G loss: 1.153357]\n",
      "[Epoch 4/200] [Batch 840/938] [D loss: 1.085955, acc: 94%] [G loss: 1.052272]\n",
      "[Epoch 4/200] [Batch 841/938] [D loss: 1.085552, acc: 93%] [G loss: 1.125714]\n",
      "[Epoch 4/200] [Batch 842/938] [D loss: 1.081727, acc: 92%] [G loss: 1.139971]\n",
      "[Epoch 4/200] [Batch 843/938] [D loss: 1.101183, acc: 93%] [G loss: 1.150661]\n",
      "[Epoch 4/200] [Batch 844/938] [D loss: 1.111389, acc: 92%] [G loss: 1.140291]\n",
      "[Epoch 4/200] [Batch 845/938] [D loss: 1.103338, acc: 98%] [G loss: 1.066018]\n",
      "[Epoch 4/200] [Batch 846/938] [D loss: 1.027034, acc: 96%] [G loss: 1.186664]\n",
      "[Epoch 4/200] [Batch 847/938] [D loss: 1.088062, acc: 96%] [G loss: 1.152442]\n",
      "[Epoch 4/200] [Batch 848/938] [D loss: 1.081369, acc: 95%] [G loss: 1.081909]\n",
      "[Epoch 4/200] [Batch 849/938] [D loss: 1.094947, acc: 90%] [G loss: 1.164878]\n",
      "[Epoch 4/200] [Batch 850/938] [D loss: 1.060803, acc: 95%] [G loss: 1.137769]\n",
      "[Epoch 4/200] [Batch 851/938] [D loss: 1.102755, acc: 94%] [G loss: 1.033320]\n",
      "[Epoch 4/200] [Batch 852/938] [D loss: 1.057386, acc: 97%] [G loss: 1.143757]\n",
      "[Epoch 4/200] [Batch 853/938] [D loss: 1.115702, acc: 91%] [G loss: 1.196630]\n",
      "[Epoch 4/200] [Batch 854/938] [D loss: 1.104253, acc: 93%] [G loss: 1.182714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/200] [Batch 855/938] [D loss: 1.156258, acc: 90%] [G loss: 1.186474]\n",
      "[Epoch 4/200] [Batch 856/938] [D loss: 1.087670, acc: 95%] [G loss: 1.097665]\n",
      "[Epoch 4/200] [Batch 857/938] [D loss: 1.108780, acc: 92%] [G loss: 1.072638]\n",
      "[Epoch 4/200] [Batch 858/938] [D loss: 1.081434, acc: 97%] [G loss: 1.114027]\n",
      "[Epoch 4/200] [Batch 859/938] [D loss: 1.082730, acc: 95%] [G loss: 1.205541]\n",
      "[Epoch 4/200] [Batch 860/938] [D loss: 1.043542, acc: 97%] [G loss: 1.152036]\n",
      "[Epoch 4/200] [Batch 861/938] [D loss: 1.084066, acc: 97%] [G loss: 1.161596]\n",
      "[Epoch 4/200] [Batch 862/938] [D loss: 1.067472, acc: 96%] [G loss: 1.139622]\n",
      "[Epoch 4/200] [Batch 863/938] [D loss: 1.122383, acc: 92%] [G loss: 1.215837]\n",
      "[Epoch 4/200] [Batch 864/938] [D loss: 1.102353, acc: 94%] [G loss: 1.110685]\n",
      "[Epoch 4/200] [Batch 865/938] [D loss: 1.089944, acc: 96%] [G loss: 1.141218]\n",
      "[Epoch 4/200] [Batch 866/938] [D loss: 1.082367, acc: 95%] [G loss: 1.078642]\n",
      "[Epoch 4/200] [Batch 867/938] [D loss: 1.079367, acc: 98%] [G loss: 1.064908]\n",
      "[Epoch 4/200] [Batch 868/938] [D loss: 1.083031, acc: 98%] [G loss: 1.114807]\n",
      "[Epoch 4/200] [Batch 869/938] [D loss: 1.093728, acc: 96%] [G loss: 1.133890]\n",
      "[Epoch 4/200] [Batch 870/938] [D loss: 1.061604, acc: 97%] [G loss: 1.218178]\n",
      "[Epoch 4/200] [Batch 871/938] [D loss: 1.077057, acc: 94%] [G loss: 1.187496]\n",
      "[Epoch 4/200] [Batch 872/938] [D loss: 1.094415, acc: 94%] [G loss: 1.157741]\n",
      "[Epoch 4/200] [Batch 873/938] [D loss: 1.111942, acc: 92%] [G loss: 1.105402]\n",
      "[Epoch 4/200] [Batch 874/938] [D loss: 1.087494, acc: 92%] [G loss: 1.126329]\n",
      "[Epoch 4/200] [Batch 875/938] [D loss: 1.120548, acc: 95%] [G loss: 1.059891]\n",
      "[Epoch 4/200] [Batch 876/938] [D loss: 1.128070, acc: 94%] [G loss: 1.133473]\n",
      "[Epoch 4/200] [Batch 877/938] [D loss: 1.093780, acc: 92%] [G loss: 1.095082]\n",
      "[Epoch 4/200] [Batch 878/938] [D loss: 1.050810, acc: 97%] [G loss: 1.067823]\n",
      "[Epoch 4/200] [Batch 879/938] [D loss: 1.071605, acc: 96%] [G loss: 1.087258]\n",
      "[Epoch 4/200] [Batch 880/938] [D loss: 1.084677, acc: 95%] [G loss: 1.103964]\n",
      "[Epoch 4/200] [Batch 881/938] [D loss: 1.096582, acc: 94%] [G loss: 1.108739]\n",
      "[Epoch 4/200] [Batch 882/938] [D loss: 1.110164, acc: 92%] [G loss: 1.165018]\n",
      "[Epoch 4/200] [Batch 883/938] [D loss: 1.117823, acc: 96%] [G loss: 1.200423]\n",
      "[Epoch 4/200] [Batch 884/938] [D loss: 1.091182, acc: 95%] [G loss: 1.119276]\n",
      "[Epoch 4/200] [Batch 885/938] [D loss: 1.099620, acc: 97%] [G loss: 1.063921]\n",
      "[Epoch 4/200] [Batch 886/938] [D loss: 1.085686, acc: 96%] [G loss: 1.108460]\n",
      "[Epoch 4/200] [Batch 887/938] [D loss: 1.135159, acc: 96%] [G loss: 1.056951]\n",
      "[Epoch 4/200] [Batch 888/938] [D loss: 1.115470, acc: 95%] [G loss: 1.088521]\n",
      "[Epoch 4/200] [Batch 889/938] [D loss: 1.099638, acc: 92%] [G loss: 1.165157]\n",
      "[Epoch 4/200] [Batch 890/938] [D loss: 1.056303, acc: 97%] [G loss: 1.221654]\n",
      "[Epoch 4/200] [Batch 891/938] [D loss: 1.081291, acc: 95%] [G loss: 1.181745]\n",
      "[Epoch 4/200] [Batch 892/938] [D loss: 1.062069, acc: 95%] [G loss: 1.182687]\n",
      "[Epoch 4/200] [Batch 893/938] [D loss: 1.086868, acc: 97%] [G loss: 1.141923]\n",
      "[Epoch 4/200] [Batch 894/938] [D loss: 1.099059, acc: 96%] [G loss: 1.137054]\n",
      "[Epoch 4/200] [Batch 895/938] [D loss: 1.104340, acc: 96%] [G loss: 1.129626]\n",
      "[Epoch 4/200] [Batch 896/938] [D loss: 1.079318, acc: 92%] [G loss: 1.154484]\n",
      "[Epoch 4/200] [Batch 897/938] [D loss: 1.105896, acc: 92%] [G loss: 1.162140]\n",
      "[Epoch 4/200] [Batch 898/938] [D loss: 1.077280, acc: 93%] [G loss: 1.154757]\n",
      "[Epoch 4/200] [Batch 899/938] [D loss: 1.118893, acc: 96%] [G loss: 1.090842]\n",
      "[Epoch 4/200] [Batch 900/938] [D loss: 1.071878, acc: 96%] [G loss: 1.092212]\n",
      "[Epoch 4/200] [Batch 901/938] [D loss: 1.121046, acc: 96%] [G loss: 1.144635]\n",
      "[Epoch 4/200] [Batch 902/938] [D loss: 1.095543, acc: 96%] [G loss: 1.130331]\n",
      "[Epoch 4/200] [Batch 903/938] [D loss: 1.071826, acc: 94%] [G loss: 1.145152]\n",
      "[Epoch 4/200] [Batch 904/938] [D loss: 1.070138, acc: 98%] [G loss: 1.176648]\n",
      "[Epoch 4/200] [Batch 905/938] [D loss: 1.090188, acc: 97%] [G loss: 1.173595]\n",
      "[Epoch 4/200] [Batch 906/938] [D loss: 1.099258, acc: 93%] [G loss: 1.088084]\n",
      "[Epoch 4/200] [Batch 907/938] [D loss: 1.070233, acc: 97%] [G loss: 1.169862]\n",
      "[Epoch 4/200] [Batch 908/938] [D loss: 1.074531, acc: 93%] [G loss: 1.092287]\n",
      "[Epoch 4/200] [Batch 909/938] [D loss: 1.073674, acc: 94%] [G loss: 1.063737]\n",
      "[Epoch 4/200] [Batch 910/938] [D loss: 1.113422, acc: 92%] [G loss: 1.121443]\n",
      "[Epoch 4/200] [Batch 911/938] [D loss: 1.097345, acc: 95%] [G loss: 1.225978]\n",
      "[Epoch 4/200] [Batch 912/938] [D loss: 1.071078, acc: 96%] [G loss: 1.153624]\n",
      "[Epoch 4/200] [Batch 913/938] [D loss: 1.081844, acc: 94%] [G loss: 1.182692]\n",
      "[Epoch 4/200] [Batch 914/938] [D loss: 1.090598, acc: 96%] [G loss: 1.103648]\n",
      "[Epoch 4/200] [Batch 915/938] [D loss: 1.121494, acc: 89%] [G loss: 1.159221]\n",
      "[Epoch 4/200] [Batch 916/938] [D loss: 1.093947, acc: 91%] [G loss: 1.114749]\n",
      "[Epoch 4/200] [Batch 917/938] [D loss: 1.087575, acc: 94%] [G loss: 1.089113]\n",
      "[Epoch 4/200] [Batch 918/938] [D loss: 1.072355, acc: 96%] [G loss: 1.120781]\n",
      "[Epoch 4/200] [Batch 919/938] [D loss: 1.101237, acc: 95%] [G loss: 1.108433]\n",
      "[Epoch 4/200] [Batch 920/938] [D loss: 1.046522, acc: 96%] [G loss: 1.118630]\n",
      "[Epoch 4/200] [Batch 921/938] [D loss: 1.149120, acc: 94%] [G loss: 1.111825]\n",
      "[Epoch 4/200] [Batch 922/938] [D loss: 1.061804, acc: 96%] [G loss: 1.163374]\n",
      "[Epoch 4/200] [Batch 923/938] [D loss: 1.105526, acc: 93%] [G loss: 1.205572]\n",
      "[Epoch 4/200] [Batch 924/938] [D loss: 1.099061, acc: 96%] [G loss: 1.134354]\n",
      "[Epoch 4/200] [Batch 925/938] [D loss: 1.128396, acc: 92%] [G loss: 1.208290]\n",
      "[Epoch 4/200] [Batch 926/938] [D loss: 1.105843, acc: 95%] [G loss: 1.150442]\n",
      "[Epoch 4/200] [Batch 927/938] [D loss: 1.077696, acc: 92%] [G loss: 1.170319]\n",
      "[Epoch 4/200] [Batch 928/938] [D loss: 1.059271, acc: 94%] [G loss: 1.175715]\n",
      "[Epoch 4/200] [Batch 929/938] [D loss: 1.052336, acc: 94%] [G loss: 1.190145]\n",
      "[Epoch 4/200] [Batch 930/938] [D loss: 1.123496, acc: 93%] [G loss: 1.147370]\n",
      "[Epoch 4/200] [Batch 931/938] [D loss: 1.069896, acc: 98%] [G loss: 1.135288]\n",
      "[Epoch 4/200] [Batch 932/938] [D loss: 1.092851, acc: 92%] [G loss: 1.087621]\n",
      "[Epoch 4/200] [Batch 933/938] [D loss: 1.105949, acc: 96%] [G loss: 1.103797]\n",
      "[Epoch 4/200] [Batch 934/938] [D loss: 1.082422, acc: 95%] [G loss: 1.128106]\n",
      "[Epoch 4/200] [Batch 935/938] [D loss: 1.087312, acc: 96%] [G loss: 1.187387]\n",
      "[Epoch 4/200] [Batch 936/938] [D loss: 1.107754, acc: 96%] [G loss: 1.176546]\n",
      "[Epoch 4/200] [Batch 937/938] [D loss: 1.132586, acc: 95%] [G loss: 1.105862]\n",
      "[Epoch 5/200] [Batch 0/938] [D loss: 1.064547, acc: 96%] [G loss: 1.134353]\n",
      "[Epoch 5/200] [Batch 1/938] [D loss: 1.137565, acc: 96%] [G loss: 1.058235]\n",
      "[Epoch 5/200] [Batch 2/938] [D loss: 1.089797, acc: 94%] [G loss: 1.110157]\n",
      "[Epoch 5/200] [Batch 3/938] [D loss: 1.094051, acc: 98%] [G loss: 1.200462]\n",
      "[Epoch 5/200] [Batch 4/938] [D loss: 1.045047, acc: 92%] [G loss: 1.153261]\n",
      "[Epoch 5/200] [Batch 5/938] [D loss: 1.058071, acc: 94%] [G loss: 1.139290]\n",
      "[Epoch 5/200] [Batch 6/938] [D loss: 1.113474, acc: 93%] [G loss: 1.082260]\n",
      "[Epoch 5/200] [Batch 7/938] [D loss: 1.130404, acc: 92%] [G loss: 1.146210]\n",
      "[Epoch 5/200] [Batch 8/938] [D loss: 1.091996, acc: 92%] [G loss: 1.164514]\n",
      "[Epoch 5/200] [Batch 9/938] [D loss: 1.046942, acc: 98%] [G loss: 1.144770]\n",
      "[Epoch 5/200] [Batch 10/938] [D loss: 1.126334, acc: 91%] [G loss: 1.099936]\n",
      "[Epoch 5/200] [Batch 11/938] [D loss: 1.103369, acc: 92%] [G loss: 1.112271]\n",
      "[Epoch 5/200] [Batch 12/938] [D loss: 1.081352, acc: 95%] [G loss: 1.108585]\n",
      "[Epoch 5/200] [Batch 13/938] [D loss: 1.083394, acc: 93%] [G loss: 1.139245]\n",
      "[Epoch 5/200] [Batch 14/938] [D loss: 1.083498, acc: 96%] [G loss: 1.160939]\n",
      "[Epoch 5/200] [Batch 15/938] [D loss: 1.050161, acc: 96%] [G loss: 1.168525]\n",
      "[Epoch 5/200] [Batch 16/938] [D loss: 1.102852, acc: 91%] [G loss: 1.135894]\n",
      "[Epoch 5/200] [Batch 17/938] [D loss: 1.090760, acc: 97%] [G loss: 1.149667]\n",
      "[Epoch 5/200] [Batch 18/938] [D loss: 1.054979, acc: 92%] [G loss: 1.113993]\n",
      "[Epoch 5/200] [Batch 19/938] [D loss: 1.043718, acc: 96%] [G loss: 1.108275]\n",
      "[Epoch 5/200] [Batch 20/938] [D loss: 1.085078, acc: 96%] [G loss: 1.209172]\n",
      "[Epoch 5/200] [Batch 21/938] [D loss: 1.088467, acc: 92%] [G loss: 1.234679]\n",
      "[Epoch 5/200] [Batch 22/938] [D loss: 1.109855, acc: 96%] [G loss: 1.123051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 23/938] [D loss: 1.102143, acc: 97%] [G loss: 1.146676]\n",
      "[Epoch 5/200] [Batch 24/938] [D loss: 1.118154, acc: 96%] [G loss: 1.169456]\n",
      "[Epoch 5/200] [Batch 25/938] [D loss: 1.041823, acc: 98%] [G loss: 1.170224]\n",
      "[Epoch 5/200] [Batch 26/938] [D loss: 1.118876, acc: 93%] [G loss: 1.116254]\n",
      "[Epoch 5/200] [Batch 27/938] [D loss: 1.076506, acc: 96%] [G loss: 1.107573]\n",
      "[Epoch 5/200] [Batch 28/938] [D loss: 1.081581, acc: 96%] [G loss: 1.104779]\n",
      "[Epoch 5/200] [Batch 29/938] [D loss: 1.064762, acc: 96%] [G loss: 1.092554]\n",
      "[Epoch 5/200] [Batch 30/938] [D loss: 1.013049, acc: 95%] [G loss: 1.150702]\n",
      "[Epoch 5/200] [Batch 31/938] [D loss: 1.106307, acc: 94%] [G loss: 1.191070]\n",
      "[Epoch 5/200] [Batch 32/938] [D loss: 1.074690, acc: 93%] [G loss: 1.158736]\n",
      "[Epoch 5/200] [Batch 33/938] [D loss: 1.096746, acc: 94%] [G loss: 1.143576]\n",
      "[Epoch 5/200] [Batch 34/938] [D loss: 1.090462, acc: 96%] [G loss: 1.176143]\n",
      "[Epoch 5/200] [Batch 35/938] [D loss: 1.118045, acc: 94%] [G loss: 1.055728]\n",
      "[Epoch 5/200] [Batch 36/938] [D loss: 1.075376, acc: 94%] [G loss: 1.159324]\n",
      "[Epoch 5/200] [Batch 37/938] [D loss: 1.084930, acc: 97%] [G loss: 1.166938]\n",
      "[Epoch 5/200] [Batch 38/938] [D loss: 1.083492, acc: 92%] [G loss: 1.162806]\n",
      "[Epoch 5/200] [Batch 39/938] [D loss: 1.102559, acc: 93%] [G loss: 1.106023]\n",
      "[Epoch 5/200] [Batch 40/938] [D loss: 1.056907, acc: 96%] [G loss: 1.144462]\n",
      "[Epoch 5/200] [Batch 41/938] [D loss: 1.110653, acc: 92%] [G loss: 1.077985]\n",
      "[Epoch 5/200] [Batch 42/938] [D loss: 1.123332, acc: 90%] [G loss: 1.117417]\n",
      "[Epoch 5/200] [Batch 43/938] [D loss: 1.050244, acc: 96%] [G loss: 1.183439]\n",
      "[Epoch 5/200] [Batch 44/938] [D loss: 1.070932, acc: 95%] [G loss: 1.185875]\n",
      "[Epoch 5/200] [Batch 45/938] [D loss: 1.122448, acc: 93%] [G loss: 1.206985]\n",
      "[Epoch 5/200] [Batch 46/938] [D loss: 1.104347, acc: 96%] [G loss: 1.073798]\n",
      "[Epoch 5/200] [Batch 47/938] [D loss: 1.096171, acc: 94%] [G loss: 1.090917]\n",
      "[Epoch 5/200] [Batch 48/938] [D loss: 1.113188, acc: 94%] [G loss: 1.212492]\n",
      "[Epoch 5/200] [Batch 49/938] [D loss: 1.065918, acc: 96%] [G loss: 1.169253]\n",
      "[Epoch 5/200] [Batch 50/938] [D loss: 1.090432, acc: 96%] [G loss: 1.130398]\n",
      "[Epoch 5/200] [Batch 51/938] [D loss: 1.070162, acc: 98%] [G loss: 1.188869]\n",
      "[Epoch 5/200] [Batch 52/938] [D loss: 1.062748, acc: 96%] [G loss: 1.170573]\n",
      "[Epoch 5/200] [Batch 53/938] [D loss: 1.090816, acc: 97%] [G loss: 1.166481]\n",
      "[Epoch 5/200] [Batch 54/938] [D loss: 1.088581, acc: 95%] [G loss: 1.091471]\n",
      "[Epoch 5/200] [Batch 55/938] [D loss: 1.107429, acc: 96%] [G loss: 1.116753]\n",
      "[Epoch 5/200] [Batch 56/938] [D loss: 1.091315, acc: 92%] [G loss: 1.147471]\n",
      "[Epoch 5/200] [Batch 57/938] [D loss: 1.101662, acc: 93%] [G loss: 1.066224]\n",
      "[Epoch 5/200] [Batch 58/938] [D loss: 1.081985, acc: 94%] [G loss: 1.121208]\n",
      "[Epoch 5/200] [Batch 59/938] [D loss: 1.087751, acc: 96%] [G loss: 1.068850]\n",
      "[Epoch 5/200] [Batch 60/938] [D loss: 1.104472, acc: 95%] [G loss: 1.092516]\n",
      "[Epoch 5/200] [Batch 61/938] [D loss: 1.130967, acc: 92%] [G loss: 1.154256]\n",
      "[Epoch 5/200] [Batch 62/938] [D loss: 1.101251, acc: 95%] [G loss: 1.188583]\n",
      "[Epoch 5/200] [Batch 63/938] [D loss: 1.055384, acc: 98%] [G loss: 1.115480]\n",
      "[Epoch 5/200] [Batch 64/938] [D loss: 1.094144, acc: 97%] [G loss: 1.143201]\n",
      "[Epoch 5/200] [Batch 65/938] [D loss: 1.083064, acc: 96%] [G loss: 1.154030]\n",
      "[Epoch 5/200] [Batch 66/938] [D loss: 1.068959, acc: 96%] [G loss: 1.107075]\n",
      "[Epoch 5/200] [Batch 67/938] [D loss: 1.106487, acc: 96%] [G loss: 1.147946]\n",
      "[Epoch 5/200] [Batch 68/938] [D loss: 1.092609, acc: 95%] [G loss: 1.117139]\n",
      "[Epoch 5/200] [Batch 69/938] [D loss: 1.079498, acc: 95%] [G loss: 1.200791]\n",
      "[Epoch 5/200] [Batch 70/938] [D loss: 1.098076, acc: 93%] [G loss: 1.063830]\n",
      "[Epoch 5/200] [Batch 71/938] [D loss: 1.079004, acc: 92%] [G loss: 1.143945]\n",
      "[Epoch 5/200] [Batch 72/938] [D loss: 1.046344, acc: 99%] [G loss: 1.104305]\n",
      "[Epoch 5/200] [Batch 73/938] [D loss: 1.052408, acc: 97%] [G loss: 1.120787]\n",
      "[Epoch 5/200] [Batch 74/938] [D loss: 1.097847, acc: 94%] [G loss: 1.176998]\n",
      "[Epoch 5/200] [Batch 75/938] [D loss: 1.095107, acc: 97%] [G loss: 1.113940]\n",
      "[Epoch 5/200] [Batch 76/938] [D loss: 1.088499, acc: 95%] [G loss: 1.105373]\n",
      "[Epoch 5/200] [Batch 77/938] [D loss: 1.047396, acc: 96%] [G loss: 1.089536]\n",
      "[Epoch 5/200] [Batch 78/938] [D loss: 1.086912, acc: 93%] [G loss: 1.202672]\n",
      "[Epoch 5/200] [Batch 79/938] [D loss: 1.107440, acc: 91%] [G loss: 1.088526]\n",
      "[Epoch 5/200] [Batch 80/938] [D loss: 1.097125, acc: 95%] [G loss: 1.128262]\n",
      "[Epoch 5/200] [Batch 81/938] [D loss: 1.067470, acc: 95%] [G loss: 1.102373]\n",
      "[Epoch 5/200] [Batch 82/938] [D loss: 1.084641, acc: 95%] [G loss: 1.091926]\n",
      "[Epoch 5/200] [Batch 83/938] [D loss: 1.074812, acc: 96%] [G loss: 1.137215]\n",
      "[Epoch 5/200] [Batch 84/938] [D loss: 1.086782, acc: 96%] [G loss: 1.216511]\n",
      "[Epoch 5/200] [Batch 85/938] [D loss: 1.067196, acc: 96%] [G loss: 1.122963]\n",
      "[Epoch 5/200] [Batch 86/938] [D loss: 1.113517, acc: 94%] [G loss: 1.147803]\n",
      "[Epoch 5/200] [Batch 87/938] [D loss: 1.069291, acc: 95%] [G loss: 1.101828]\n",
      "[Epoch 5/200] [Batch 88/938] [D loss: 1.089420, acc: 96%] [G loss: 1.077703]\n",
      "[Epoch 5/200] [Batch 89/938] [D loss: 1.116024, acc: 92%] [G loss: 1.101069]\n",
      "[Epoch 5/200] [Batch 90/938] [D loss: 1.089878, acc: 96%] [G loss: 1.206073]\n",
      "[Epoch 5/200] [Batch 91/938] [D loss: 1.102796, acc: 94%] [G loss: 1.154845]\n",
      "[Epoch 5/200] [Batch 92/938] [D loss: 1.074416, acc: 96%] [G loss: 1.127758]\n",
      "[Epoch 5/200] [Batch 93/938] [D loss: 1.111394, acc: 97%] [G loss: 1.057790]\n",
      "[Epoch 5/200] [Batch 94/938] [D loss: 1.095712, acc: 95%] [G loss: 1.097589]\n",
      "[Epoch 5/200] [Batch 95/938] [D loss: 1.124917, acc: 94%] [G loss: 1.172716]\n",
      "[Epoch 5/200] [Batch 96/938] [D loss: 1.074755, acc: 96%] [G loss: 1.101571]\n",
      "[Epoch 5/200] [Batch 97/938] [D loss: 1.068492, acc: 96%] [G loss: 1.205666]\n",
      "[Epoch 5/200] [Batch 98/938] [D loss: 1.103346, acc: 96%] [G loss: 1.196445]\n",
      "[Epoch 5/200] [Batch 99/938] [D loss: 1.100486, acc: 95%] [G loss: 1.117306]\n",
      "[Epoch 5/200] [Batch 100/938] [D loss: 1.078948, acc: 96%] [G loss: 1.104947]\n",
      "[Epoch 5/200] [Batch 101/938] [D loss: 1.081088, acc: 95%] [G loss: 1.133394]\n",
      "[Epoch 5/200] [Batch 102/938] [D loss: 1.048679, acc: 92%] [G loss: 1.187626]\n",
      "[Epoch 5/200] [Batch 103/938] [D loss: 1.111685, acc: 96%] [G loss: 1.077941]\n",
      "[Epoch 5/200] [Batch 104/938] [D loss: 1.125251, acc: 91%] [G loss: 1.066663]\n",
      "[Epoch 5/200] [Batch 105/938] [D loss: 1.052549, acc: 96%] [G loss: 1.164826]\n",
      "[Epoch 5/200] [Batch 106/938] [D loss: 1.072208, acc: 97%] [G loss: 1.091502]\n",
      "[Epoch 5/200] [Batch 107/938] [D loss: 1.120736, acc: 95%] [G loss: 1.111786]\n",
      "[Epoch 5/200] [Batch 108/938] [D loss: 1.083479, acc: 95%] [G loss: 1.146195]\n",
      "[Epoch 5/200] [Batch 109/938] [D loss: 1.041984, acc: 98%] [G loss: 1.122308]\n",
      "[Epoch 5/200] [Batch 110/938] [D loss: 1.095859, acc: 91%] [G loss: 1.158255]\n",
      "[Epoch 5/200] [Batch 111/938] [D loss: 1.105298, acc: 95%] [G loss: 1.160964]\n",
      "[Epoch 5/200] [Batch 112/938] [D loss: 1.101672, acc: 96%] [G loss: 1.107152]\n",
      "[Epoch 5/200] [Batch 113/938] [D loss: 1.095472, acc: 92%] [G loss: 1.116462]\n",
      "[Epoch 5/200] [Batch 114/938] [D loss: 1.083109, acc: 95%] [G loss: 1.092854]\n",
      "[Epoch 5/200] [Batch 115/938] [D loss: 1.102154, acc: 95%] [G loss: 1.143064]\n",
      "[Epoch 5/200] [Batch 116/938] [D loss: 1.070407, acc: 96%] [G loss: 1.123354]\n",
      "[Epoch 5/200] [Batch 117/938] [D loss: 1.138491, acc: 96%] [G loss: 1.057987]\n",
      "[Epoch 5/200] [Batch 118/938] [D loss: 1.101943, acc: 93%] [G loss: 1.125834]\n",
      "[Epoch 5/200] [Batch 119/938] [D loss: 1.098725, acc: 94%] [G loss: 1.142479]\n",
      "[Epoch 5/200] [Batch 120/938] [D loss: 1.088166, acc: 98%] [G loss: 1.163649]\n",
      "[Epoch 5/200] [Batch 121/938] [D loss: 1.077260, acc: 95%] [G loss: 1.187276]\n",
      "[Epoch 5/200] [Batch 122/938] [D loss: 1.111856, acc: 95%] [G loss: 1.131018]\n",
      "[Epoch 5/200] [Batch 123/938] [D loss: 1.112479, acc: 96%] [G loss: 1.101099]\n",
      "[Epoch 5/200] [Batch 124/938] [D loss: 1.099422, acc: 97%] [G loss: 1.100070]\n",
      "[Epoch 5/200] [Batch 125/938] [D loss: 1.112350, acc: 96%] [G loss: 1.176247]\n",
      "[Epoch 5/200] [Batch 126/938] [D loss: 1.100950, acc: 96%] [G loss: 1.138576]\n",
      "[Epoch 5/200] [Batch 127/938] [D loss: 1.054003, acc: 96%] [G loss: 1.091353]\n",
      "[Epoch 5/200] [Batch 128/938] [D loss: 1.094028, acc: 93%] [G loss: 1.106486]\n",
      "[Epoch 5/200] [Batch 129/938] [D loss: 1.078377, acc: 96%] [G loss: 1.123216]\n",
      "[Epoch 5/200] [Batch 130/938] [D loss: 1.099675, acc: 94%] [G loss: 1.075703]\n",
      "[Epoch 5/200] [Batch 131/938] [D loss: 1.075484, acc: 96%] [G loss: 1.155294]\n",
      "[Epoch 5/200] [Batch 132/938] [D loss: 1.075219, acc: 97%] [G loss: 1.149548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 133/938] [D loss: 1.107122, acc: 92%] [G loss: 1.166830]\n",
      "[Epoch 5/200] [Batch 134/938] [D loss: 1.106977, acc: 93%] [G loss: 1.150036]\n",
      "[Epoch 5/200] [Batch 135/938] [D loss: 1.109687, acc: 95%] [G loss: 1.119356]\n",
      "[Epoch 5/200] [Batch 136/938] [D loss: 1.098011, acc: 93%] [G loss: 1.116447]\n",
      "[Epoch 5/200] [Batch 137/938] [D loss: 1.092420, acc: 93%] [G loss: 1.097775]\n",
      "[Epoch 5/200] [Batch 138/938] [D loss: 1.072641, acc: 97%] [G loss: 1.137417]\n",
      "[Epoch 5/200] [Batch 139/938] [D loss: 1.101424, acc: 96%] [G loss: 1.033597]\n",
      "[Epoch 5/200] [Batch 140/938] [D loss: 1.105310, acc: 96%] [G loss: 1.080719]\n",
      "[Epoch 5/200] [Batch 141/938] [D loss: 1.109853, acc: 92%] [G loss: 1.183019]\n",
      "[Epoch 5/200] [Batch 142/938] [D loss: 1.077282, acc: 99%] [G loss: 1.142359]\n",
      "[Epoch 5/200] [Batch 143/938] [D loss: 1.100960, acc: 96%] [G loss: 1.082968]\n",
      "[Epoch 5/200] [Batch 144/938] [D loss: 1.085620, acc: 91%] [G loss: 1.131708]\n",
      "[Epoch 5/200] [Batch 145/938] [D loss: 1.095426, acc: 93%] [G loss: 1.191197]\n",
      "[Epoch 5/200] [Batch 146/938] [D loss: 1.087336, acc: 95%] [G loss: 1.137476]\n",
      "[Epoch 5/200] [Batch 147/938] [D loss: 1.053120, acc: 96%] [G loss: 1.098076]\n",
      "[Epoch 5/200] [Batch 148/938] [D loss: 1.047685, acc: 98%] [G loss: 1.068790]\n",
      "[Epoch 5/200] [Batch 149/938] [D loss: 1.083035, acc: 96%] [G loss: 1.060387]\n",
      "[Epoch 5/200] [Batch 150/938] [D loss: 1.029255, acc: 92%] [G loss: 1.057697]\n",
      "[Epoch 5/200] [Batch 151/938] [D loss: 1.048962, acc: 96%] [G loss: 1.110480]\n",
      "[Epoch 5/200] [Batch 152/938] [D loss: 1.094768, acc: 94%] [G loss: 1.127137]\n",
      "[Epoch 5/200] [Batch 153/938] [D loss: 1.061697, acc: 97%] [G loss: 1.153117]\n",
      "[Epoch 5/200] [Batch 154/938] [D loss: 1.143464, acc: 92%] [G loss: 1.130991]\n",
      "[Epoch 5/200] [Batch 155/938] [D loss: 1.058417, acc: 97%] [G loss: 1.144576]\n",
      "[Epoch 5/200] [Batch 156/938] [D loss: 1.083139, acc: 95%] [G loss: 1.111718]\n",
      "[Epoch 5/200] [Batch 157/938] [D loss: 1.112073, acc: 95%] [G loss: 1.129167]\n",
      "[Epoch 5/200] [Batch 158/938] [D loss: 1.090021, acc: 98%] [G loss: 1.079046]\n",
      "[Epoch 5/200] [Batch 159/938] [D loss: 1.114463, acc: 94%] [G loss: 1.125517]\n",
      "[Epoch 5/200] [Batch 160/938] [D loss: 1.038363, acc: 98%] [G loss: 1.130430]\n",
      "[Epoch 5/200] [Batch 161/938] [D loss: 1.100536, acc: 94%] [G loss: 1.171708]\n",
      "[Epoch 5/200] [Batch 162/938] [D loss: 1.074995, acc: 97%] [G loss: 1.178307]\n",
      "[Epoch 5/200] [Batch 163/938] [D loss: 1.089885, acc: 94%] [G loss: 1.140321]\n",
      "[Epoch 5/200] [Batch 164/938] [D loss: 1.101980, acc: 94%] [G loss: 1.177390]\n",
      "[Epoch 5/200] [Batch 165/938] [D loss: 1.115469, acc: 93%] [G loss: 1.085787]\n",
      "[Epoch 5/200] [Batch 166/938] [D loss: 1.094560, acc: 96%] [G loss: 1.101422]\n",
      "[Epoch 5/200] [Batch 167/938] [D loss: 1.093220, acc: 95%] [G loss: 1.086950]\n",
      "[Epoch 5/200] [Batch 168/938] [D loss: 1.075938, acc: 96%] [G loss: 1.104634]\n",
      "[Epoch 5/200] [Batch 169/938] [D loss: 1.119972, acc: 95%] [G loss: 1.155510]\n",
      "[Epoch 5/200] [Batch 170/938] [D loss: 1.094442, acc: 93%] [G loss: 1.200035]\n",
      "[Epoch 5/200] [Batch 171/938] [D loss: 1.106035, acc: 94%] [G loss: 1.171011]\n",
      "[Epoch 5/200] [Batch 172/938] [D loss: 1.099244, acc: 96%] [G loss: 1.189748]\n",
      "[Epoch 5/200] [Batch 173/938] [D loss: 1.073602, acc: 92%] [G loss: 1.168964]\n",
      "[Epoch 5/200] [Batch 174/938] [D loss: 1.062513, acc: 95%] [G loss: 1.111036]\n",
      "[Epoch 5/200] [Batch 175/938] [D loss: 1.078858, acc: 94%] [G loss: 1.107460]\n",
      "[Epoch 5/200] [Batch 176/938] [D loss: 1.079698, acc: 92%] [G loss: 1.171691]\n",
      "[Epoch 5/200] [Batch 177/938] [D loss: 1.083349, acc: 94%] [G loss: 1.142943]\n",
      "[Epoch 5/200] [Batch 178/938] [D loss: 1.125398, acc: 96%] [G loss: 1.186730]\n",
      "[Epoch 5/200] [Batch 179/938] [D loss: 1.085206, acc: 95%] [G loss: 1.202602]\n",
      "[Epoch 5/200] [Batch 180/938] [D loss: 1.098817, acc: 97%] [G loss: 1.192274]\n",
      "[Epoch 5/200] [Batch 181/938] [D loss: 1.063129, acc: 96%] [G loss: 1.135021]\n",
      "[Epoch 5/200] [Batch 182/938] [D loss: 1.091596, acc: 94%] [G loss: 1.189488]\n",
      "[Epoch 5/200] [Batch 183/938] [D loss: 1.069250, acc: 95%] [G loss: 1.154035]\n",
      "[Epoch 5/200] [Batch 184/938] [D loss: 1.086865, acc: 92%] [G loss: 1.112265]\n",
      "[Epoch 5/200] [Batch 185/938] [D loss: 1.105812, acc: 96%] [G loss: 1.052953]\n",
      "[Epoch 5/200] [Batch 186/938] [D loss: 1.089654, acc: 94%] [G loss: 1.068963]\n",
      "[Epoch 5/200] [Batch 187/938] [D loss: 1.088524, acc: 96%] [G loss: 1.056699]\n",
      "[Epoch 5/200] [Batch 188/938] [D loss: 1.116979, acc: 94%] [G loss: 1.127259]\n",
      "[Epoch 5/200] [Batch 189/938] [D loss: 1.100656, acc: 99%] [G loss: 1.079843]\n",
      "[Epoch 5/200] [Batch 190/938] [D loss: 1.086293, acc: 96%] [G loss: 1.118689]\n",
      "[Epoch 5/200] [Batch 191/938] [D loss: 1.069905, acc: 93%] [G loss: 1.101302]\n",
      "[Epoch 5/200] [Batch 192/938] [D loss: 1.117239, acc: 95%] [G loss: 1.157798]\n",
      "[Epoch 5/200] [Batch 193/938] [D loss: 1.095208, acc: 96%] [G loss: 1.172758]\n",
      "[Epoch 5/200] [Batch 194/938] [D loss: 1.080123, acc: 96%] [G loss: 1.133621]\n",
      "[Epoch 5/200] [Batch 195/938] [D loss: 1.093670, acc: 95%] [G loss: 1.131896]\n",
      "[Epoch 5/200] [Batch 196/938] [D loss: 1.036179, acc: 97%] [G loss: 1.138056]\n",
      "[Epoch 5/200] [Batch 197/938] [D loss: 1.092522, acc: 95%] [G loss: 1.116847]\n",
      "[Epoch 5/200] [Batch 198/938] [D loss: 1.123768, acc: 91%] [G loss: 1.118405]\n",
      "[Epoch 5/200] [Batch 199/938] [D loss: 1.080782, acc: 93%] [G loss: 1.157815]\n",
      "[Epoch 5/200] [Batch 200/938] [D loss: 1.087845, acc: 96%] [G loss: 1.132737]\n",
      "[Epoch 5/200] [Batch 201/938] [D loss: 1.094491, acc: 92%] [G loss: 1.129358]\n",
      "[Epoch 5/200] [Batch 202/938] [D loss: 1.127121, acc: 95%] [G loss: 1.142601]\n",
      "[Epoch 5/200] [Batch 203/938] [D loss: 1.071512, acc: 96%] [G loss: 1.092606]\n",
      "[Epoch 5/200] [Batch 204/938] [D loss: 1.064861, acc: 96%] [G loss: 1.074160]\n",
      "[Epoch 5/200] [Batch 205/938] [D loss: 1.078228, acc: 94%] [G loss: 1.173422]\n",
      "[Epoch 5/200] [Batch 206/938] [D loss: 1.093468, acc: 96%] [G loss: 1.207764]\n",
      "[Epoch 5/200] [Batch 207/938] [D loss: 1.110671, acc: 91%] [G loss: 1.167052]\n",
      "[Epoch 5/200] [Batch 208/938] [D loss: 1.044962, acc: 97%] [G loss: 1.154900]\n",
      "[Epoch 5/200] [Batch 209/938] [D loss: 1.089520, acc: 96%] [G loss: 1.130961]\n",
      "[Epoch 5/200] [Batch 210/938] [D loss: 1.092004, acc: 96%] [G loss: 1.150101]\n",
      "[Epoch 5/200] [Batch 211/938] [D loss: 1.096712, acc: 94%] [G loss: 1.134047]\n",
      "[Epoch 5/200] [Batch 212/938] [D loss: 1.130303, acc: 89%] [G loss: 1.124621]\n",
      "[Epoch 5/200] [Batch 213/938] [D loss: 1.076229, acc: 96%] [G loss: 1.104696]\n",
      "[Epoch 5/200] [Batch 214/938] [D loss: 1.090116, acc: 96%] [G loss: 1.182501]\n",
      "[Epoch 5/200] [Batch 215/938] [D loss: 1.104379, acc: 96%] [G loss: 1.127842]\n",
      "[Epoch 5/200] [Batch 216/938] [D loss: 1.066629, acc: 95%] [G loss: 1.127335]\n",
      "[Epoch 5/200] [Batch 217/938] [D loss: 1.101878, acc: 92%] [G loss: 1.107256]\n",
      "[Epoch 5/200] [Batch 218/938] [D loss: 1.055196, acc: 98%] [G loss: 1.102861]\n",
      "[Epoch 5/200] [Batch 219/938] [D loss: 1.060910, acc: 97%] [G loss: 1.175471]\n",
      "[Epoch 5/200] [Batch 220/938] [D loss: 1.087964, acc: 96%] [G loss: 1.209975]\n",
      "[Epoch 5/200] [Batch 221/938] [D loss: 1.088629, acc: 95%] [G loss: 1.145260]\n",
      "[Epoch 5/200] [Batch 222/938] [D loss: 1.104958, acc: 93%] [G loss: 1.098220]\n",
      "[Epoch 5/200] [Batch 223/938] [D loss: 1.058052, acc: 96%] [G loss: 1.180848]\n",
      "[Epoch 5/200] [Batch 224/938] [D loss: 1.150637, acc: 92%] [G loss: 1.079338]\n",
      "[Epoch 5/200] [Batch 225/938] [D loss: 1.113173, acc: 96%] [G loss: 1.070016]\n",
      "[Epoch 5/200] [Batch 226/938] [D loss: 1.103408, acc: 96%] [G loss: 1.114946]\n",
      "[Epoch 5/200] [Batch 227/938] [D loss: 1.091705, acc: 92%] [G loss: 1.063934]\n",
      "[Epoch 5/200] [Batch 228/938] [D loss: 1.078593, acc: 94%] [G loss: 1.169436]\n",
      "[Epoch 5/200] [Batch 229/938] [D loss: 1.117570, acc: 88%] [G loss: 1.168983]\n",
      "[Epoch 5/200] [Batch 230/938] [D loss: 1.101979, acc: 99%] [G loss: 1.104449]\n",
      "[Epoch 5/200] [Batch 231/938] [D loss: 1.103022, acc: 93%] [G loss: 1.120314]\n",
      "[Epoch 5/200] [Batch 232/938] [D loss: 1.071678, acc: 96%] [G loss: 1.097603]\n",
      "[Epoch 5/200] [Batch 233/938] [D loss: 1.110679, acc: 91%] [G loss: 1.147745]\n",
      "[Epoch 5/200] [Batch 234/938] [D loss: 1.134356, acc: 92%] [G loss: 1.121202]\n",
      "[Epoch 5/200] [Batch 235/938] [D loss: 1.072881, acc: 97%] [G loss: 1.082109]\n",
      "[Epoch 5/200] [Batch 236/938] [D loss: 1.069940, acc: 92%] [G loss: 1.141786]\n",
      "[Epoch 5/200] [Batch 237/938] [D loss: 1.055757, acc: 96%] [G loss: 1.107972]\n",
      "[Epoch 5/200] [Batch 238/938] [D loss: 1.118840, acc: 92%] [G loss: 1.134098]\n",
      "[Epoch 5/200] [Batch 239/938] [D loss: 1.083474, acc: 96%] [G loss: 1.124634]\n",
      "[Epoch 5/200] [Batch 240/938] [D loss: 1.099375, acc: 95%] [G loss: 1.119500]\n",
      "[Epoch 5/200] [Batch 241/938] [D loss: 1.050807, acc: 98%] [G loss: 1.056811]\n",
      "[Epoch 5/200] [Batch 242/938] [D loss: 1.081701, acc: 96%] [G loss: 1.127797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 243/938] [D loss: 1.061698, acc: 96%] [G loss: 1.124051]\n",
      "[Epoch 5/200] [Batch 244/938] [D loss: 1.091483, acc: 96%] [G loss: 1.152046]\n",
      "[Epoch 5/200] [Batch 245/938] [D loss: 1.087204, acc: 96%] [G loss: 1.171007]\n",
      "[Epoch 5/200] [Batch 246/938] [D loss: 1.100653, acc: 92%] [G loss: 1.154685]\n",
      "[Epoch 5/200] [Batch 247/938] [D loss: 1.095056, acc: 94%] [G loss: 1.083894]\n",
      "[Epoch 5/200] [Batch 248/938] [D loss: 1.107458, acc: 93%] [G loss: 1.088591]\n",
      "[Epoch 5/200] [Batch 249/938] [D loss: 1.085716, acc: 95%] [G loss: 1.122225]\n",
      "[Epoch 5/200] [Batch 250/938] [D loss: 1.138802, acc: 95%] [G loss: 1.092256]\n",
      "[Epoch 5/200] [Batch 251/938] [D loss: 1.091197, acc: 95%] [G loss: 1.176643]\n",
      "[Epoch 5/200] [Batch 252/938] [D loss: 1.105508, acc: 93%] [G loss: 1.116390]\n",
      "[Epoch 5/200] [Batch 253/938] [D loss: 1.079115, acc: 92%] [G loss: 1.207612]\n",
      "[Epoch 5/200] [Batch 254/938] [D loss: 1.118409, acc: 89%] [G loss: 1.179247]\n",
      "[Epoch 5/200] [Batch 255/938] [D loss: 1.114966, acc: 94%] [G loss: 1.076140]\n",
      "[Epoch 5/200] [Batch 256/938] [D loss: 1.056895, acc: 97%] [G loss: 1.125626]\n",
      "[Epoch 5/200] [Batch 257/938] [D loss: 1.081538, acc: 95%] [G loss: 1.106777]\n",
      "[Epoch 5/200] [Batch 258/938] [D loss: 1.074785, acc: 96%] [G loss: 1.085620]\n",
      "[Epoch 5/200] [Batch 259/938] [D loss: 1.094262, acc: 95%] [G loss: 1.121661]\n",
      "[Epoch 5/200] [Batch 260/938] [D loss: 1.076005, acc: 96%] [G loss: 1.131297]\n",
      "[Epoch 5/200] [Batch 261/938] [D loss: 1.092433, acc: 92%] [G loss: 1.188937]\n",
      "[Epoch 5/200] [Batch 262/938] [D loss: 1.086702, acc: 94%] [G loss: 1.112277]\n",
      "[Epoch 5/200] [Batch 263/938] [D loss: 1.040435, acc: 98%] [G loss: 1.084409]\n",
      "[Epoch 5/200] [Batch 264/938] [D loss: 1.066905, acc: 89%] [G loss: 1.161597]\n",
      "[Epoch 5/200] [Batch 265/938] [D loss: 1.088413, acc: 96%] [G loss: 1.106828]\n",
      "[Epoch 5/200] [Batch 266/938] [D loss: 1.070624, acc: 96%] [G loss: 1.154831]\n",
      "[Epoch 5/200] [Batch 267/938] [D loss: 1.107678, acc: 94%] [G loss: 1.143506]\n",
      "[Epoch 5/200] [Batch 268/938] [D loss: 1.126588, acc: 94%] [G loss: 1.067233]\n",
      "[Epoch 5/200] [Batch 269/938] [D loss: 1.088662, acc: 95%] [G loss: 1.168646]\n",
      "[Epoch 5/200] [Batch 270/938] [D loss: 1.050359, acc: 96%] [G loss: 1.185157]\n",
      "[Epoch 5/200] [Batch 271/938] [D loss: 1.080140, acc: 96%] [G loss: 1.112967]\n",
      "[Epoch 5/200] [Batch 272/938] [D loss: 1.081253, acc: 94%] [G loss: 1.096883]\n",
      "[Epoch 5/200] [Batch 273/938] [D loss: 1.060439, acc: 95%] [G loss: 1.069108]\n",
      "[Epoch 5/200] [Batch 274/938] [D loss: 1.095094, acc: 93%] [G loss: 1.164646]\n",
      "[Epoch 5/200] [Batch 275/938] [D loss: 1.094995, acc: 96%] [G loss: 1.068075]\n",
      "[Epoch 5/200] [Batch 276/938] [D loss: 1.071694, acc: 97%] [G loss: 1.116717]\n",
      "[Epoch 5/200] [Batch 277/938] [D loss: 1.065459, acc: 96%] [G loss: 1.162915]\n",
      "[Epoch 5/200] [Batch 278/938] [D loss: 1.091208, acc: 92%] [G loss: 1.105104]\n",
      "[Epoch 5/200] [Batch 279/938] [D loss: 1.107807, acc: 94%] [G loss: 1.124105]\n",
      "[Epoch 5/200] [Batch 280/938] [D loss: 1.097811, acc: 94%] [G loss: 1.066965]\n",
      "[Epoch 5/200] [Batch 281/938] [D loss: 1.052212, acc: 97%] [G loss: 1.166183]\n",
      "[Epoch 5/200] [Batch 282/938] [D loss: 1.068405, acc: 96%] [G loss: 1.108803]\n",
      "[Epoch 5/200] [Batch 283/938] [D loss: 1.099859, acc: 96%] [G loss: 1.135110]\n",
      "[Epoch 5/200] [Batch 284/938] [D loss: 1.073529, acc: 96%] [G loss: 1.142019]\n",
      "[Epoch 5/200] [Batch 285/938] [D loss: 1.043317, acc: 96%] [G loss: 1.134433]\n",
      "[Epoch 5/200] [Batch 286/938] [D loss: 1.078564, acc: 96%] [G loss: 1.140533]\n",
      "[Epoch 5/200] [Batch 287/938] [D loss: 1.090159, acc: 95%] [G loss: 1.128822]\n",
      "[Epoch 5/200] [Batch 288/938] [D loss: 1.087128, acc: 95%] [G loss: 1.099945]\n",
      "[Epoch 5/200] [Batch 289/938] [D loss: 1.075695, acc: 92%] [G loss: 1.139364]\n",
      "[Epoch 5/200] [Batch 290/938] [D loss: 1.083301, acc: 96%] [G loss: 1.125863]\n",
      "[Epoch 5/200] [Batch 291/938] [D loss: 1.121405, acc: 93%] [G loss: 1.055361]\n",
      "[Epoch 5/200] [Batch 292/938] [D loss: 1.106491, acc: 96%] [G loss: 1.121451]\n",
      "[Epoch 5/200] [Batch 293/938] [D loss: 1.087575, acc: 95%] [G loss: 1.103283]\n",
      "[Epoch 5/200] [Batch 294/938] [D loss: 1.104482, acc: 92%] [G loss: 1.145029]\n",
      "[Epoch 5/200] [Batch 295/938] [D loss: 1.093071, acc: 96%] [G loss: 1.190345]\n",
      "[Epoch 5/200] [Batch 296/938] [D loss: 1.093513, acc: 93%] [G loss: 1.128073]\n",
      "[Epoch 5/200] [Batch 297/938] [D loss: 1.093818, acc: 95%] [G loss: 1.124778]\n",
      "[Epoch 5/200] [Batch 298/938] [D loss: 1.093491, acc: 95%] [G loss: 1.109363]\n",
      "[Epoch 5/200] [Batch 299/938] [D loss: 1.104014, acc: 95%] [G loss: 1.101755]\n",
      "[Epoch 5/200] [Batch 300/938] [D loss: 1.091205, acc: 92%] [G loss: 1.145687]\n",
      "[Epoch 5/200] [Batch 301/938] [D loss: 1.067052, acc: 97%] [G loss: 1.169809]\n",
      "[Epoch 5/200] [Batch 302/938] [D loss: 1.113944, acc: 96%] [G loss: 1.082792]\n",
      "[Epoch 5/200] [Batch 303/938] [D loss: 1.087112, acc: 96%] [G loss: 1.082682]\n",
      "[Epoch 5/200] [Batch 304/938] [D loss: 1.103140, acc: 95%] [G loss: 1.034940]\n",
      "[Epoch 5/200] [Batch 305/938] [D loss: 1.137294, acc: 92%] [G loss: 1.153738]\n",
      "[Epoch 5/200] [Batch 306/938] [D loss: 1.064139, acc: 96%] [G loss: 1.122267]\n",
      "[Epoch 5/200] [Batch 307/938] [D loss: 1.095584, acc: 97%] [G loss: 1.183687]\n",
      "[Epoch 5/200] [Batch 308/938] [D loss: 1.068770, acc: 98%] [G loss: 1.233950]\n",
      "[Epoch 5/200] [Batch 309/938] [D loss: 1.077654, acc: 96%] [G loss: 1.145052]\n",
      "[Epoch 5/200] [Batch 310/938] [D loss: 1.100281, acc: 93%] [G loss: 1.067423]\n",
      "[Epoch 5/200] [Batch 311/938] [D loss: 1.078320, acc: 96%] [G loss: 1.053317]\n",
      "[Epoch 5/200] [Batch 312/938] [D loss: 1.051103, acc: 97%] [G loss: 1.071795]\n",
      "[Epoch 5/200] [Batch 313/938] [D loss: 1.081025, acc: 95%] [G loss: 1.155826]\n",
      "[Epoch 5/200] [Batch 314/938] [D loss: 1.108159, acc: 94%] [G loss: 1.220035]\n",
      "[Epoch 5/200] [Batch 315/938] [D loss: 1.097497, acc: 92%] [G loss: 1.115749]\n",
      "[Epoch 5/200] [Batch 316/938] [D loss: 1.051950, acc: 96%] [G loss: 1.122025]\n",
      "[Epoch 5/200] [Batch 317/938] [D loss: 1.055306, acc: 96%] [G loss: 1.080164]\n",
      "[Epoch 5/200] [Batch 318/938] [D loss: 1.041425, acc: 97%] [G loss: 1.161246]\n",
      "[Epoch 5/200] [Batch 319/938] [D loss: 1.096312, acc: 96%] [G loss: 1.129875]\n",
      "[Epoch 5/200] [Batch 320/938] [D loss: 1.131784, acc: 94%] [G loss: 1.112262]\n",
      "[Epoch 5/200] [Batch 321/938] [D loss: 1.103398, acc: 98%] [G loss: 1.123449]\n",
      "[Epoch 5/200] [Batch 322/938] [D loss: 1.043390, acc: 96%] [G loss: 1.125810]\n",
      "[Epoch 5/200] [Batch 323/938] [D loss: 1.096133, acc: 96%] [G loss: 1.142107]\n",
      "[Epoch 5/200] [Batch 324/938] [D loss: 1.027021, acc: 96%] [G loss: 1.118230]\n",
      "[Epoch 5/200] [Batch 325/938] [D loss: 1.076702, acc: 95%] [G loss: 1.072058]\n",
      "[Epoch 5/200] [Batch 326/938] [D loss: 1.104023, acc: 96%] [G loss: 1.101600]\n",
      "[Epoch 5/200] [Batch 327/938] [D loss: 1.095544, acc: 96%] [G loss: 1.072430]\n",
      "[Epoch 5/200] [Batch 328/938] [D loss: 1.053678, acc: 99%] [G loss: 1.090744]\n",
      "[Epoch 5/200] [Batch 329/938] [D loss: 1.072526, acc: 96%] [G loss: 1.153632]\n",
      "[Epoch 5/200] [Batch 330/938] [D loss: 1.060427, acc: 94%] [G loss: 1.105160]\n",
      "[Epoch 5/200] [Batch 331/938] [D loss: 1.070650, acc: 95%] [G loss: 1.083647]\n",
      "[Epoch 5/200] [Batch 332/938] [D loss: 1.071967, acc: 96%] [G loss: 1.123890]\n",
      "[Epoch 5/200] [Batch 333/938] [D loss: 1.111767, acc: 94%] [G loss: 1.159374]\n",
      "[Epoch 5/200] [Batch 334/938] [D loss: 1.112323, acc: 92%] [G loss: 1.250631]\n",
      "[Epoch 5/200] [Batch 335/938] [D loss: 1.092289, acc: 94%] [G loss: 1.137489]\n",
      "[Epoch 5/200] [Batch 336/938] [D loss: 1.092230, acc: 99%] [G loss: 1.122612]\n",
      "[Epoch 5/200] [Batch 337/938] [D loss: 1.114619, acc: 95%] [G loss: 1.100151]\n",
      "[Epoch 5/200] [Batch 338/938] [D loss: 1.082662, acc: 96%] [G loss: 1.133363]\n",
      "[Epoch 5/200] [Batch 339/938] [D loss: 1.048879, acc: 96%] [G loss: 1.124610]\n",
      "[Epoch 5/200] [Batch 340/938] [D loss: 1.150236, acc: 92%] [G loss: 1.058276]\n",
      "[Epoch 5/200] [Batch 341/938] [D loss: 1.108572, acc: 97%] [G loss: 1.192938]\n",
      "[Epoch 5/200] [Batch 342/938] [D loss: 1.050486, acc: 96%] [G loss: 1.094201]\n",
      "[Epoch 5/200] [Batch 343/938] [D loss: 1.099774, acc: 91%] [G loss: 1.096217]\n",
      "[Epoch 5/200] [Batch 344/938] [D loss: 1.079231, acc: 94%] [G loss: 1.098354]\n",
      "[Epoch 5/200] [Batch 345/938] [D loss: 1.061966, acc: 95%] [G loss: 1.189676]\n",
      "[Epoch 5/200] [Batch 346/938] [D loss: 1.085196, acc: 93%] [G loss: 1.125432]\n",
      "[Epoch 5/200] [Batch 347/938] [D loss: 1.067989, acc: 94%] [G loss: 1.128416]\n",
      "[Epoch 5/200] [Batch 348/938] [D loss: 1.071177, acc: 94%] [G loss: 1.066394]\n",
      "[Epoch 5/200] [Batch 349/938] [D loss: 1.065552, acc: 96%] [G loss: 1.131236]\n",
      "[Epoch 5/200] [Batch 350/938] [D loss: 1.058506, acc: 95%] [G loss: 1.119518]\n",
      "[Epoch 5/200] [Batch 351/938] [D loss: 1.084034, acc: 96%] [G loss: 1.108972]\n",
      "[Epoch 5/200] [Batch 352/938] [D loss: 1.125605, acc: 91%] [G loss: 1.213911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 353/938] [D loss: 1.067108, acc: 96%] [G loss: 1.111164]\n",
      "[Epoch 5/200] [Batch 354/938] [D loss: 1.070065, acc: 97%] [G loss: 1.156343]\n",
      "[Epoch 5/200] [Batch 355/938] [D loss: 1.057286, acc: 99%] [G loss: 1.117713]\n",
      "[Epoch 5/200] [Batch 356/938] [D loss: 1.057606, acc: 98%] [G loss: 1.109210]\n",
      "[Epoch 5/200] [Batch 357/938] [D loss: 1.073385, acc: 96%] [G loss: 1.137957]\n",
      "[Epoch 5/200] [Batch 358/938] [D loss: 1.103298, acc: 96%] [G loss: 1.093077]\n",
      "[Epoch 5/200] [Batch 359/938] [D loss: 1.069006, acc: 94%] [G loss: 1.116227]\n",
      "[Epoch 5/200] [Batch 360/938] [D loss: 1.118643, acc: 91%] [G loss: 1.111976]\n",
      "[Epoch 5/200] [Batch 361/938] [D loss: 1.095414, acc: 95%] [G loss: 1.116996]\n",
      "[Epoch 5/200] [Batch 362/938] [D loss: 1.110883, acc: 95%] [G loss: 1.157610]\n",
      "[Epoch 5/200] [Batch 363/938] [D loss: 1.080812, acc: 95%] [G loss: 1.112463]\n",
      "[Epoch 5/200] [Batch 364/938] [D loss: 1.097514, acc: 98%] [G loss: 1.093060]\n",
      "[Epoch 5/200] [Batch 365/938] [D loss: 1.104198, acc: 95%] [G loss: 1.042706]\n",
      "[Epoch 5/200] [Batch 366/938] [D loss: 1.071488, acc: 96%] [G loss: 1.180704]\n",
      "[Epoch 5/200] [Batch 367/938] [D loss: 1.096486, acc: 95%] [G loss: 1.044454]\n",
      "[Epoch 5/200] [Batch 368/938] [D loss: 1.111414, acc: 95%] [G loss: 1.106711]\n",
      "[Epoch 5/200] [Batch 369/938] [D loss: 1.107374, acc: 94%] [G loss: 1.117167]\n",
      "[Epoch 5/200] [Batch 370/938] [D loss: 1.085199, acc: 94%] [G loss: 1.094468]\n",
      "[Epoch 5/200] [Batch 371/938] [D loss: 1.103670, acc: 92%] [G loss: 1.165050]\n",
      "[Epoch 5/200] [Batch 372/938] [D loss: 1.116739, acc: 95%] [G loss: 1.077878]\n",
      "[Epoch 5/200] [Batch 373/938] [D loss: 1.049671, acc: 96%] [G loss: 1.125850]\n",
      "[Epoch 5/200] [Batch 374/938] [D loss: 1.092954, acc: 91%] [G loss: 1.188325]\n",
      "[Epoch 5/200] [Batch 375/938] [D loss: 1.095772, acc: 96%] [G loss: 1.121778]\n",
      "[Epoch 5/200] [Batch 376/938] [D loss: 1.091723, acc: 96%] [G loss: 1.184576]\n",
      "[Epoch 5/200] [Batch 377/938] [D loss: 1.113139, acc: 93%] [G loss: 1.156801]\n",
      "[Epoch 5/200] [Batch 378/938] [D loss: 1.081080, acc: 94%] [G loss: 1.135735]\n",
      "[Epoch 5/200] [Batch 379/938] [D loss: 1.096369, acc: 93%] [G loss: 1.114593]\n",
      "[Epoch 5/200] [Batch 380/938] [D loss: 1.087165, acc: 96%] [G loss: 1.068274]\n",
      "[Epoch 5/200] [Batch 381/938] [D loss: 1.104979, acc: 95%] [G loss: 1.108894]\n",
      "[Epoch 5/200] [Batch 382/938] [D loss: 1.092896, acc: 95%] [G loss: 1.091285]\n",
      "[Epoch 5/200] [Batch 383/938] [D loss: 1.085025, acc: 92%] [G loss: 1.142845]\n",
      "[Epoch 5/200] [Batch 384/938] [D loss: 1.066710, acc: 98%] [G loss: 1.112494]\n",
      "[Epoch 5/200] [Batch 385/938] [D loss: 1.098270, acc: 97%] [G loss: 1.085209]\n",
      "[Epoch 5/200] [Batch 386/938] [D loss: 1.111286, acc: 92%] [G loss: 1.118122]\n",
      "[Epoch 5/200] [Batch 387/938] [D loss: 1.083189, acc: 96%] [G loss: 1.134167]\n",
      "[Epoch 5/200] [Batch 388/938] [D loss: 1.061074, acc: 95%] [G loss: 1.149130]\n",
      "[Epoch 5/200] [Batch 389/938] [D loss: 1.078557, acc: 93%] [G loss: 1.153766]\n",
      "[Epoch 5/200] [Batch 390/938] [D loss: 1.095524, acc: 94%] [G loss: 1.113910]\n",
      "[Epoch 5/200] [Batch 391/938] [D loss: 1.104745, acc: 93%] [G loss: 1.136352]\n",
      "[Epoch 5/200] [Batch 392/938] [D loss: 1.126790, acc: 96%] [G loss: 1.065348]\n",
      "[Epoch 5/200] [Batch 393/938] [D loss: 1.126015, acc: 94%] [G loss: 1.095392]\n",
      "[Epoch 5/200] [Batch 394/938] [D loss: 1.096313, acc: 94%] [G loss: 1.139058]\n",
      "[Epoch 5/200] [Batch 395/938] [D loss: 1.108330, acc: 94%] [G loss: 1.152574]\n",
      "[Epoch 5/200] [Batch 396/938] [D loss: 1.066748, acc: 97%] [G loss: 1.183916]\n",
      "[Epoch 5/200] [Batch 397/938] [D loss: 1.105139, acc: 94%] [G loss: 1.190700]\n",
      "[Epoch 5/200] [Batch 398/938] [D loss: 1.105056, acc: 93%] [G loss: 1.065927]\n",
      "[Epoch 5/200] [Batch 399/938] [D loss: 1.124197, acc: 92%] [G loss: 1.126215]\n",
      "[Epoch 5/200] [Batch 400/938] [D loss: 1.092372, acc: 96%] [G loss: 1.100688]\n",
      "[Epoch 5/200] [Batch 401/938] [D loss: 1.096489, acc: 96%] [G loss: 1.159328]\n",
      "[Epoch 5/200] [Batch 402/938] [D loss: 1.092636, acc: 96%] [G loss: 1.123178]\n",
      "[Epoch 5/200] [Batch 403/938] [D loss: 1.070612, acc: 96%] [G loss: 1.116421]\n",
      "[Epoch 5/200] [Batch 404/938] [D loss: 1.066618, acc: 97%] [G loss: 1.084730]\n",
      "[Epoch 5/200] [Batch 405/938] [D loss: 1.126433, acc: 94%] [G loss: 1.107649]\n",
      "[Epoch 5/200] [Batch 406/938] [D loss: 1.098314, acc: 96%] [G loss: 1.117143]\n",
      "[Epoch 5/200] [Batch 407/938] [D loss: 1.101731, acc: 95%] [G loss: 1.118772]\n",
      "[Epoch 5/200] [Batch 408/938] [D loss: 1.129575, acc: 93%] [G loss: 1.062011]\n",
      "[Epoch 5/200] [Batch 409/938] [D loss: 1.095044, acc: 96%] [G loss: 1.143684]\n",
      "[Epoch 5/200] [Batch 410/938] [D loss: 1.052832, acc: 94%] [G loss: 1.153505]\n",
      "[Epoch 5/200] [Batch 411/938] [D loss: 1.103095, acc: 98%] [G loss: 1.153750]\n",
      "[Epoch 5/200] [Batch 412/938] [D loss: 1.062950, acc: 96%] [G loss: 1.126799]\n",
      "[Epoch 5/200] [Batch 413/938] [D loss: 1.077253, acc: 96%] [G loss: 1.168322]\n",
      "[Epoch 5/200] [Batch 414/938] [D loss: 1.086008, acc: 94%] [G loss: 1.130708]\n",
      "[Epoch 5/200] [Batch 415/938] [D loss: 1.107120, acc: 96%] [G loss: 1.063822]\n",
      "[Epoch 5/200] [Batch 416/938] [D loss: 1.087969, acc: 95%] [G loss: 1.108159]\n",
      "[Epoch 5/200] [Batch 417/938] [D loss: 1.054848, acc: 96%] [G loss: 1.090738]\n",
      "[Epoch 5/200] [Batch 418/938] [D loss: 1.074840, acc: 96%] [G loss: 1.195233]\n",
      "[Epoch 5/200] [Batch 419/938] [D loss: 1.096205, acc: 93%] [G loss: 1.224066]\n",
      "[Epoch 5/200] [Batch 420/938] [D loss: 1.103932, acc: 97%] [G loss: 1.095133]\n",
      "[Epoch 5/200] [Batch 421/938] [D loss: 1.118614, acc: 96%] [G loss: 1.142823]\n",
      "[Epoch 5/200] [Batch 422/938] [D loss: 1.094441, acc: 94%] [G loss: 1.099242]\n",
      "[Epoch 5/200] [Batch 423/938] [D loss: 1.071099, acc: 92%] [G loss: 1.142215]\n",
      "[Epoch 5/200] [Batch 424/938] [D loss: 1.087301, acc: 97%] [G loss: 1.166781]\n",
      "[Epoch 5/200] [Batch 425/938] [D loss: 1.105536, acc: 92%] [G loss: 1.079894]\n",
      "[Epoch 5/200] [Batch 426/938] [D loss: 1.115784, acc: 96%] [G loss: 1.100813]\n",
      "[Epoch 5/200] [Batch 427/938] [D loss: 1.116307, acc: 94%] [G loss: 1.062991]\n",
      "[Epoch 5/200] [Batch 428/938] [D loss: 1.059114, acc: 96%] [G loss: 1.145080]\n",
      "[Epoch 5/200] [Batch 429/938] [D loss: 1.102861, acc: 94%] [G loss: 1.132919]\n",
      "[Epoch 5/200] [Batch 430/938] [D loss: 1.101912, acc: 95%] [G loss: 1.109411]\n",
      "[Epoch 5/200] [Batch 431/938] [D loss: 1.075441, acc: 97%] [G loss: 1.089717]\n",
      "[Epoch 5/200] [Batch 432/938] [D loss: 1.061808, acc: 96%] [G loss: 1.082665]\n",
      "[Epoch 5/200] [Batch 433/938] [D loss: 1.089875, acc: 94%] [G loss: 1.122698]\n",
      "[Epoch 5/200] [Batch 434/938] [D loss: 1.074738, acc: 95%] [G loss: 1.153851]\n",
      "[Epoch 5/200] [Batch 435/938] [D loss: 1.085989, acc: 96%] [G loss: 1.139785]\n",
      "[Epoch 5/200] [Batch 436/938] [D loss: 1.096361, acc: 91%] [G loss: 1.135904]\n",
      "[Epoch 5/200] [Batch 437/938] [D loss: 1.108607, acc: 95%] [G loss: 1.124283]\n",
      "[Epoch 5/200] [Batch 438/938] [D loss: 1.038205, acc: 100%] [G loss: 1.131086]\n",
      "[Epoch 5/200] [Batch 439/938] [D loss: 1.060518, acc: 94%] [G loss: 1.182891]\n",
      "[Epoch 5/200] [Batch 440/938] [D loss: 1.027245, acc: 97%] [G loss: 1.150100]\n",
      "[Epoch 5/200] [Batch 441/938] [D loss: 1.076912, acc: 96%] [G loss: 1.138237]\n",
      "[Epoch 5/200] [Batch 442/938] [D loss: 1.043753, acc: 99%] [G loss: 1.132572]\n",
      "[Epoch 5/200] [Batch 443/938] [D loss: 1.045020, acc: 95%] [G loss: 1.163689]\n",
      "[Epoch 5/200] [Batch 444/938] [D loss: 1.104575, acc: 96%] [G loss: 1.131170]\n",
      "[Epoch 5/200] [Batch 445/938] [D loss: 1.134667, acc: 94%] [G loss: 1.118366]\n",
      "[Epoch 5/200] [Batch 446/938] [D loss: 1.085280, acc: 92%] [G loss: 1.217908]\n",
      "[Epoch 5/200] [Batch 447/938] [D loss: 1.104086, acc: 96%] [G loss: 1.141659]\n",
      "[Epoch 5/200] [Batch 448/938] [D loss: 1.074133, acc: 98%] [G loss: 1.107861]\n",
      "[Epoch 5/200] [Batch 449/938] [D loss: 1.101417, acc: 96%] [G loss: 1.077883]\n",
      "[Epoch 5/200] [Batch 450/938] [D loss: 1.119076, acc: 94%] [G loss: 1.118685]\n",
      "[Epoch 5/200] [Batch 451/938] [D loss: 1.072510, acc: 99%] [G loss: 1.127222]\n",
      "[Epoch 5/200] [Batch 452/938] [D loss: 1.101120, acc: 96%] [G loss: 1.115419]\n",
      "[Epoch 5/200] [Batch 453/938] [D loss: 1.114279, acc: 93%] [G loss: 1.092972]\n",
      "[Epoch 5/200] [Batch 454/938] [D loss: 1.072698, acc: 95%] [G loss: 1.089387]\n",
      "[Epoch 5/200] [Batch 455/938] [D loss: 1.088826, acc: 95%] [G loss: 1.104308]\n",
      "[Epoch 5/200] [Batch 456/938] [D loss: 1.061014, acc: 96%] [G loss: 1.137273]\n",
      "[Epoch 5/200] [Batch 457/938] [D loss: 1.091911, acc: 99%] [G loss: 1.106700]\n",
      "[Epoch 5/200] [Batch 458/938] [D loss: 1.098062, acc: 92%] [G loss: 1.172113]\n",
      "[Epoch 5/200] [Batch 459/938] [D loss: 1.064614, acc: 96%] [G loss: 1.113266]\n",
      "[Epoch 5/200] [Batch 460/938] [D loss: 1.104901, acc: 96%] [G loss: 1.163732]\n",
      "[Epoch 5/200] [Batch 461/938] [D loss: 1.095450, acc: 96%] [G loss: 1.090160]\n",
      "[Epoch 5/200] [Batch 462/938] [D loss: 1.059375, acc: 98%] [G loss: 1.121823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 463/938] [D loss: 1.110716, acc: 94%] [G loss: 1.104604]\n",
      "[Epoch 5/200] [Batch 464/938] [D loss: 1.086601, acc: 94%] [G loss: 1.151833]\n",
      "[Epoch 5/200] [Batch 465/938] [D loss: 1.085400, acc: 96%] [G loss: 1.148015]\n",
      "[Epoch 5/200] [Batch 466/938] [D loss: 1.117262, acc: 95%] [G loss: 1.127201]\n",
      "[Epoch 5/200] [Batch 467/938] [D loss: 1.071914, acc: 96%] [G loss: 1.128803]\n",
      "[Epoch 5/200] [Batch 468/938] [D loss: 1.088331, acc: 94%] [G loss: 1.124055]\n",
      "[Epoch 5/200] [Batch 469/938] [D loss: 1.113719, acc: 96%] [G loss: 1.086184]\n",
      "[Epoch 5/200] [Batch 470/938] [D loss: 1.078542, acc: 96%] [G loss: 1.125180]\n",
      "[Epoch 5/200] [Batch 471/938] [D loss: 1.103208, acc: 98%] [G loss: 1.076709]\n",
      "[Epoch 5/200] [Batch 472/938] [D loss: 1.059417, acc: 95%] [G loss: 1.059226]\n",
      "[Epoch 5/200] [Batch 473/938] [D loss: 1.078051, acc: 98%] [G loss: 1.146833]\n",
      "[Epoch 5/200] [Batch 474/938] [D loss: 1.056361, acc: 97%] [G loss: 1.219391]\n",
      "[Epoch 5/200] [Batch 475/938] [D loss: 1.071213, acc: 97%] [G loss: 1.170367]\n",
      "[Epoch 5/200] [Batch 476/938] [D loss: 1.065087, acc: 96%] [G loss: 1.093548]\n",
      "[Epoch 5/200] [Batch 477/938] [D loss: 1.046743, acc: 98%] [G loss: 1.163144]\n",
      "[Epoch 5/200] [Batch 478/938] [D loss: 1.068810, acc: 94%] [G loss: 1.119452]\n",
      "[Epoch 5/200] [Batch 479/938] [D loss: 1.078302, acc: 96%] [G loss: 1.150836]\n",
      "[Epoch 5/200] [Batch 480/938] [D loss: 1.062714, acc: 97%] [G loss: 1.150576]\n",
      "[Epoch 5/200] [Batch 481/938] [D loss: 1.065750, acc: 94%] [G loss: 1.226753]\n",
      "[Epoch 5/200] [Batch 482/938] [D loss: 1.100382, acc: 93%] [G loss: 1.137806]\n",
      "[Epoch 5/200] [Batch 483/938] [D loss: 1.089060, acc: 92%] [G loss: 1.090110]\n",
      "[Epoch 5/200] [Batch 484/938] [D loss: 1.109977, acc: 93%] [G loss: 1.040080]\n",
      "[Epoch 5/200] [Batch 485/938] [D loss: 1.067200, acc: 96%] [G loss: 1.165485]\n",
      "[Epoch 5/200] [Batch 486/938] [D loss: 1.091672, acc: 92%] [G loss: 1.172519]\n",
      "[Epoch 5/200] [Batch 487/938] [D loss: 1.091215, acc: 94%] [G loss: 1.116083]\n",
      "[Epoch 5/200] [Batch 488/938] [D loss: 1.029892, acc: 97%] [G loss: 1.255222]\n",
      "[Epoch 5/200] [Batch 489/938] [D loss: 1.110328, acc: 96%] [G loss: 1.127818]\n",
      "[Epoch 5/200] [Batch 490/938] [D loss: 1.091573, acc: 92%] [G loss: 1.181916]\n",
      "[Epoch 5/200] [Batch 491/938] [D loss: 1.113873, acc: 91%] [G loss: 1.202124]\n",
      "[Epoch 5/200] [Batch 492/938] [D loss: 1.057246, acc: 97%] [G loss: 1.090722]\n",
      "[Epoch 5/200] [Batch 493/938] [D loss: 1.085085, acc: 97%] [G loss: 1.060560]\n",
      "[Epoch 5/200] [Batch 494/938] [D loss: 1.077574, acc: 96%] [G loss: 1.057203]\n",
      "[Epoch 5/200] [Batch 495/938] [D loss: 1.101107, acc: 95%] [G loss: 1.152038]\n",
      "[Epoch 5/200] [Batch 496/938] [D loss: 1.116565, acc: 96%] [G loss: 1.114663]\n",
      "[Epoch 5/200] [Batch 497/938] [D loss: 1.147102, acc: 92%] [G loss: 1.175578]\n",
      "[Epoch 5/200] [Batch 498/938] [D loss: 1.137234, acc: 94%] [G loss: 1.087392]\n",
      "[Epoch 5/200] [Batch 499/938] [D loss: 1.064515, acc: 97%] [G loss: 1.097056]\n",
      "[Epoch 5/200] [Batch 500/938] [D loss: 1.138267, acc: 93%] [G loss: 1.099223]\n",
      "[Epoch 5/200] [Batch 501/938] [D loss: 1.050106, acc: 96%] [G loss: 1.100066]\n",
      "[Epoch 5/200] [Batch 502/938] [D loss: 1.056987, acc: 96%] [G loss: 1.130017]\n",
      "[Epoch 5/200] [Batch 503/938] [D loss: 1.100808, acc: 96%] [G loss: 1.179398]\n",
      "[Epoch 5/200] [Batch 504/938] [D loss: 1.109963, acc: 94%] [G loss: 1.145036]\n",
      "[Epoch 5/200] [Batch 505/938] [D loss: 1.099975, acc: 96%] [G loss: 1.139734]\n",
      "[Epoch 5/200] [Batch 506/938] [D loss: 1.082367, acc: 98%] [G loss: 1.125264]\n",
      "[Epoch 5/200] [Batch 507/938] [D loss: 1.066957, acc: 97%] [G loss: 1.124908]\n",
      "[Epoch 5/200] [Batch 508/938] [D loss: 1.089691, acc: 94%] [G loss: 1.139897]\n",
      "[Epoch 5/200] [Batch 509/938] [D loss: 1.035037, acc: 95%] [G loss: 1.111121]\n",
      "[Epoch 5/200] [Batch 510/938] [D loss: 1.062613, acc: 98%] [G loss: 1.074305]\n",
      "[Epoch 5/200] [Batch 511/938] [D loss: 1.123931, acc: 93%] [G loss: 1.166326]\n",
      "[Epoch 5/200] [Batch 512/938] [D loss: 1.094176, acc: 96%] [G loss: 1.249016]\n",
      "[Epoch 5/200] [Batch 513/938] [D loss: 1.070250, acc: 96%] [G loss: 1.145722]\n",
      "[Epoch 5/200] [Batch 514/938] [D loss: 1.073524, acc: 96%] [G loss: 1.126161]\n",
      "[Epoch 5/200] [Batch 515/938] [D loss: 1.082555, acc: 95%] [G loss: 1.116920]\n",
      "[Epoch 5/200] [Batch 516/938] [D loss: 1.080976, acc: 96%] [G loss: 1.134812]\n",
      "[Epoch 5/200] [Batch 517/938] [D loss: 1.122668, acc: 96%] [G loss: 1.033743]\n",
      "[Epoch 5/200] [Batch 518/938] [D loss: 1.132054, acc: 94%] [G loss: 1.108027]\n",
      "[Epoch 5/200] [Batch 519/938] [D loss: 1.135262, acc: 94%] [G loss: 1.077554]\n",
      "[Epoch 5/200] [Batch 520/938] [D loss: 1.067865, acc: 96%] [G loss: 1.162686]\n",
      "[Epoch 5/200] [Batch 521/938] [D loss: 1.095066, acc: 94%] [G loss: 1.171960]\n",
      "[Epoch 5/200] [Batch 522/938] [D loss: 1.082472, acc: 99%] [G loss: 1.142224]\n",
      "[Epoch 5/200] [Batch 523/938] [D loss: 1.070564, acc: 100%] [G loss: 1.136956]\n",
      "[Epoch 5/200] [Batch 524/938] [D loss: 1.093819, acc: 95%] [G loss: 1.077787]\n",
      "[Epoch 5/200] [Batch 525/938] [D loss: 1.092184, acc: 98%] [G loss: 1.062393]\n",
      "[Epoch 5/200] [Batch 526/938] [D loss: 1.107657, acc: 96%] [G loss: 1.114896]\n",
      "[Epoch 5/200] [Batch 527/938] [D loss: 1.083126, acc: 92%] [G loss: 1.173109]\n",
      "[Epoch 5/200] [Batch 528/938] [D loss: 1.095193, acc: 96%] [G loss: 1.118954]\n",
      "[Epoch 5/200] [Batch 529/938] [D loss: 1.059291, acc: 99%] [G loss: 1.189993]\n",
      "[Epoch 5/200] [Batch 530/938] [D loss: 1.096600, acc: 95%] [G loss: 1.225403]\n",
      "[Epoch 5/200] [Batch 531/938] [D loss: 1.110715, acc: 97%] [G loss: 1.172240]\n",
      "[Epoch 5/200] [Batch 532/938] [D loss: 1.097618, acc: 92%] [G loss: 1.140944]\n",
      "[Epoch 5/200] [Batch 533/938] [D loss: 1.129226, acc: 94%] [G loss: 1.081322]\n",
      "[Epoch 5/200] [Batch 534/938] [D loss: 1.081891, acc: 96%] [G loss: 1.139572]\n",
      "[Epoch 5/200] [Batch 535/938] [D loss: 1.111543, acc: 96%] [G loss: 1.150379]\n",
      "[Epoch 5/200] [Batch 536/938] [D loss: 1.106266, acc: 95%] [G loss: 1.129855]\n",
      "[Epoch 5/200] [Batch 537/938] [D loss: 1.065528, acc: 96%] [G loss: 1.167409]\n",
      "[Epoch 5/200] [Batch 538/938] [D loss: 1.090977, acc: 92%] [G loss: 1.170845]\n",
      "[Epoch 5/200] [Batch 539/938] [D loss: 1.122014, acc: 95%] [G loss: 1.150432]\n",
      "[Epoch 5/200] [Batch 540/938] [D loss: 1.096226, acc: 91%] [G loss: 1.204851]\n",
      "[Epoch 5/200] [Batch 541/938] [D loss: 1.075860, acc: 96%] [G loss: 1.068894]\n",
      "[Epoch 5/200] [Batch 542/938] [D loss: 1.095959, acc: 95%] [G loss: 1.072259]\n",
      "[Epoch 5/200] [Batch 543/938] [D loss: 1.073675, acc: 92%] [G loss: 1.127377]\n",
      "[Epoch 5/200] [Batch 544/938] [D loss: 1.106843, acc: 96%] [G loss: 1.069339]\n",
      "[Epoch 5/200] [Batch 545/938] [D loss: 1.101323, acc: 94%] [G loss: 1.033731]\n",
      "[Epoch 5/200] [Batch 546/938] [D loss: 1.107088, acc: 92%] [G loss: 1.116019]\n",
      "[Epoch 5/200] [Batch 547/938] [D loss: 1.068425, acc: 97%] [G loss: 1.119410]\n",
      "[Epoch 5/200] [Batch 548/938] [D loss: 1.117137, acc: 97%] [G loss: 1.147956]\n",
      "[Epoch 5/200] [Batch 549/938] [D loss: 1.093582, acc: 94%] [G loss: 1.143263]\n",
      "[Epoch 5/200] [Batch 550/938] [D loss: 1.095686, acc: 95%] [G loss: 1.161158]\n",
      "[Epoch 5/200] [Batch 551/938] [D loss: 1.101641, acc: 96%] [G loss: 1.092932]\n",
      "[Epoch 5/200] [Batch 552/938] [D loss: 1.078754, acc: 96%] [G loss: 1.101224]\n",
      "[Epoch 5/200] [Batch 553/938] [D loss: 1.101888, acc: 99%] [G loss: 1.108004]\n",
      "[Epoch 5/200] [Batch 554/938] [D loss: 1.098187, acc: 96%] [G loss: 1.110949]\n",
      "[Epoch 5/200] [Batch 555/938] [D loss: 1.138995, acc: 93%] [G loss: 1.106512]\n",
      "[Epoch 5/200] [Batch 556/938] [D loss: 1.091676, acc: 92%] [G loss: 1.110758]\n",
      "[Epoch 5/200] [Batch 557/938] [D loss: 1.087157, acc: 98%] [G loss: 1.157918]\n",
      "[Epoch 5/200] [Batch 558/938] [D loss: 1.084138, acc: 93%] [G loss: 1.105502]\n",
      "[Epoch 5/200] [Batch 559/938] [D loss: 1.092698, acc: 95%] [G loss: 1.116686]\n",
      "[Epoch 5/200] [Batch 560/938] [D loss: 1.074695, acc: 93%] [G loss: 1.215665]\n",
      "[Epoch 5/200] [Batch 561/938] [D loss: 1.085057, acc: 93%] [G loss: 1.177079]\n",
      "[Epoch 5/200] [Batch 562/938] [D loss: 1.071712, acc: 98%] [G loss: 1.118201]\n",
      "[Epoch 5/200] [Batch 563/938] [D loss: 1.058572, acc: 97%] [G loss: 1.110654]\n",
      "[Epoch 5/200] [Batch 564/938] [D loss: 1.075659, acc: 93%] [G loss: 1.077537]\n",
      "[Epoch 5/200] [Batch 565/938] [D loss: 1.085491, acc: 96%] [G loss: 1.170060]\n",
      "[Epoch 5/200] [Batch 566/938] [D loss: 1.076885, acc: 96%] [G loss: 1.137785]\n",
      "[Epoch 5/200] [Batch 567/938] [D loss: 1.067567, acc: 96%] [G loss: 1.129821]\n",
      "[Epoch 5/200] [Batch 568/938] [D loss: 1.100050, acc: 97%] [G loss: 1.141175]\n",
      "[Epoch 5/200] [Batch 569/938] [D loss: 1.091263, acc: 95%] [G loss: 1.115382]\n",
      "[Epoch 5/200] [Batch 570/938] [D loss: 1.077621, acc: 98%] [G loss: 1.066729]\n",
      "[Epoch 5/200] [Batch 571/938] [D loss: 1.089888, acc: 94%] [G loss: 1.057548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 572/938] [D loss: 1.050010, acc: 96%] [G loss: 1.128654]\n",
      "[Epoch 5/200] [Batch 573/938] [D loss: 1.061819, acc: 94%] [G loss: 1.111122]\n",
      "[Epoch 5/200] [Batch 574/938] [D loss: 1.111051, acc: 93%] [G loss: 1.130589]\n",
      "[Epoch 5/200] [Batch 575/938] [D loss: 1.076589, acc: 95%] [G loss: 1.088913]\n",
      "[Epoch 5/200] [Batch 576/938] [D loss: 1.124232, acc: 95%] [G loss: 1.110844]\n",
      "[Epoch 5/200] [Batch 577/938] [D loss: 1.082155, acc: 96%] [G loss: 1.126429]\n",
      "[Epoch 5/200] [Batch 578/938] [D loss: 1.111422, acc: 94%] [G loss: 1.125668]\n",
      "[Epoch 5/200] [Batch 579/938] [D loss: 1.096070, acc: 93%] [G loss: 1.043400]\n",
      "[Epoch 5/200] [Batch 580/938] [D loss: 1.111290, acc: 97%] [G loss: 1.146919]\n",
      "[Epoch 5/200] [Batch 581/938] [D loss: 1.098247, acc: 96%] [G loss: 1.122058]\n",
      "[Epoch 5/200] [Batch 582/938] [D loss: 1.076297, acc: 95%] [G loss: 1.136723]\n",
      "[Epoch 5/200] [Batch 583/938] [D loss: 1.084701, acc: 96%] [G loss: 1.166595]\n",
      "[Epoch 5/200] [Batch 584/938] [D loss: 1.102062, acc: 96%] [G loss: 1.125923]\n",
      "[Epoch 5/200] [Batch 585/938] [D loss: 1.159007, acc: 95%] [G loss: 1.042205]\n",
      "[Epoch 5/200] [Batch 586/938] [D loss: 1.097058, acc: 93%] [G loss: 1.088651]\n",
      "[Epoch 5/200] [Batch 587/938] [D loss: 1.094919, acc: 94%] [G loss: 1.204240]\n",
      "[Epoch 5/200] [Batch 588/938] [D loss: 1.092151, acc: 97%] [G loss: 1.084804]\n",
      "[Epoch 5/200] [Batch 589/938] [D loss: 1.090481, acc: 93%] [G loss: 1.186877]\n",
      "[Epoch 5/200] [Batch 590/938] [D loss: 1.066368, acc: 95%] [G loss: 1.099594]\n",
      "[Epoch 5/200] [Batch 591/938] [D loss: 1.069141, acc: 96%] [G loss: 1.110851]\n",
      "[Epoch 5/200] [Batch 592/938] [D loss: 1.060463, acc: 95%] [G loss: 1.107489]\n",
      "[Epoch 5/200] [Batch 593/938] [D loss: 1.111335, acc: 92%] [G loss: 1.227974]\n",
      "[Epoch 5/200] [Batch 594/938] [D loss: 1.099428, acc: 96%] [G loss: 1.106930]\n",
      "[Epoch 5/200] [Batch 595/938] [D loss: 1.074315, acc: 99%] [G loss: 1.083962]\n",
      "[Epoch 5/200] [Batch 596/938] [D loss: 1.093915, acc: 96%] [G loss: 1.083189]\n",
      "[Epoch 5/200] [Batch 597/938] [D loss: 1.091281, acc: 97%] [G loss: 1.059664]\n",
      "[Epoch 5/200] [Batch 598/938] [D loss: 1.082793, acc: 95%] [G loss: 1.118473]\n",
      "[Epoch 5/200] [Batch 599/938] [D loss: 1.083351, acc: 96%] [G loss: 1.175650]\n",
      "[Epoch 5/200] [Batch 600/938] [D loss: 1.127909, acc: 95%] [G loss: 1.056345]\n",
      "[Epoch 5/200] [Batch 601/938] [D loss: 1.034852, acc: 98%] [G loss: 1.135379]\n",
      "[Epoch 5/200] [Batch 602/938] [D loss: 1.159973, acc: 92%] [G loss: 1.136009]\n",
      "[Epoch 5/200] [Batch 603/938] [D loss: 1.102781, acc: 96%] [G loss: 1.201326]\n",
      "[Epoch 5/200] [Batch 604/938] [D loss: 1.078058, acc: 96%] [G loss: 1.111461]\n",
      "[Epoch 5/200] [Batch 605/938] [D loss: 1.091755, acc: 92%] [G loss: 1.122632]\n",
      "[Epoch 5/200] [Batch 606/938] [D loss: 1.092060, acc: 96%] [G loss: 1.039406]\n",
      "[Epoch 5/200] [Batch 607/938] [D loss: 1.079171, acc: 94%] [G loss: 1.123597]\n",
      "[Epoch 5/200] [Batch 608/938] [D loss: 1.090552, acc: 93%] [G loss: 1.153095]\n",
      "[Epoch 5/200] [Batch 609/938] [D loss: 1.116272, acc: 98%] [G loss: 1.167574]\n",
      "[Epoch 5/200] [Batch 610/938] [D loss: 1.089337, acc: 96%] [G loss: 1.096118]\n",
      "[Epoch 5/200] [Batch 611/938] [D loss: 1.057806, acc: 96%] [G loss: 1.150024]\n",
      "[Epoch 5/200] [Batch 612/938] [D loss: 1.079772, acc: 92%] [G loss: 1.151406]\n",
      "[Epoch 5/200] [Batch 613/938] [D loss: 1.090616, acc: 95%] [G loss: 1.151343]\n",
      "[Epoch 5/200] [Batch 614/938] [D loss: 1.078116, acc: 98%] [G loss: 1.161732]\n",
      "[Epoch 5/200] [Batch 615/938] [D loss: 1.134233, acc: 93%] [G loss: 1.155178]\n",
      "[Epoch 5/200] [Batch 616/938] [D loss: 1.095666, acc: 94%] [G loss: 1.073424]\n",
      "[Epoch 5/200] [Batch 617/938] [D loss: 1.088303, acc: 95%] [G loss: 1.126870]\n",
      "[Epoch 5/200] [Batch 618/938] [D loss: 1.087395, acc: 96%] [G loss: 1.064482]\n",
      "[Epoch 5/200] [Batch 619/938] [D loss: 1.088145, acc: 93%] [G loss: 1.158207]\n",
      "[Epoch 5/200] [Batch 620/938] [D loss: 1.072628, acc: 96%] [G loss: 1.131498]\n",
      "[Epoch 5/200] [Batch 621/938] [D loss: 1.142739, acc: 96%] [G loss: 1.117634]\n",
      "[Epoch 5/200] [Batch 622/938] [D loss: 1.077422, acc: 94%] [G loss: 1.121290]\n",
      "[Epoch 5/200] [Batch 623/938] [D loss: 1.071021, acc: 97%] [G loss: 1.107388]\n",
      "[Epoch 5/200] [Batch 624/938] [D loss: 1.088166, acc: 92%] [G loss: 1.074032]\n",
      "[Epoch 5/200] [Batch 625/938] [D loss: 1.069985, acc: 96%] [G loss: 1.166695]\n",
      "[Epoch 5/200] [Batch 626/938] [D loss: 1.082345, acc: 94%] [G loss: 1.087616]\n",
      "[Epoch 5/200] [Batch 627/938] [D loss: 1.077456, acc: 94%] [G loss: 1.117559]\n",
      "[Epoch 5/200] [Batch 628/938] [D loss: 1.149960, acc: 96%] [G loss: 1.145122]\n",
      "[Epoch 5/200] [Batch 629/938] [D loss: 1.085521, acc: 93%] [G loss: 1.152886]\n",
      "[Epoch 5/200] [Batch 630/938] [D loss: 1.104291, acc: 96%] [G loss: 1.142766]\n",
      "[Epoch 5/200] [Batch 631/938] [D loss: 1.080521, acc: 95%] [G loss: 1.120627]\n",
      "[Epoch 5/200] [Batch 632/938] [D loss: 1.105613, acc: 97%] [G loss: 1.088811]\n",
      "[Epoch 5/200] [Batch 633/938] [D loss: 1.095375, acc: 96%] [G loss: 1.092571]\n",
      "[Epoch 5/200] [Batch 634/938] [D loss: 1.102425, acc: 96%] [G loss: 1.167975]\n",
      "[Epoch 5/200] [Batch 635/938] [D loss: 1.130500, acc: 95%] [G loss: 1.046110]\n",
      "[Epoch 5/200] [Batch 636/938] [D loss: 1.101972, acc: 95%] [G loss: 1.163262]\n",
      "[Epoch 5/200] [Batch 637/938] [D loss: 1.105606, acc: 94%] [G loss: 1.148515]\n",
      "[Epoch 5/200] [Batch 638/938] [D loss: 1.082374, acc: 96%] [G loss: 1.053248]\n",
      "[Epoch 5/200] [Batch 639/938] [D loss: 1.100537, acc: 93%] [G loss: 1.129075]\n",
      "[Epoch 5/200] [Batch 640/938] [D loss: 1.049753, acc: 96%] [G loss: 1.125056]\n",
      "[Epoch 5/200] [Batch 641/938] [D loss: 1.114240, acc: 96%] [G loss: 1.131384]\n",
      "[Epoch 5/200] [Batch 642/938] [D loss: 1.126516, acc: 92%] [G loss: 1.158766]\n",
      "[Epoch 5/200] [Batch 643/938] [D loss: 1.086712, acc: 96%] [G loss: 1.082013]\n",
      "[Epoch 5/200] [Batch 644/938] [D loss: 1.092807, acc: 97%] [G loss: 1.154441]\n",
      "[Epoch 5/200] [Batch 645/938] [D loss: 1.099085, acc: 93%] [G loss: 1.114447]\n",
      "[Epoch 5/200] [Batch 646/938] [D loss: 1.106029, acc: 96%] [G loss: 1.103755]\n",
      "[Epoch 5/200] [Batch 647/938] [D loss: 1.106354, acc: 97%] [G loss: 1.207172]\n",
      "[Epoch 5/200] [Batch 648/938] [D loss: 1.048193, acc: 95%] [G loss: 1.147982]\n",
      "[Epoch 5/200] [Batch 649/938] [D loss: 1.081472, acc: 96%] [G loss: 1.152302]\n",
      "[Epoch 5/200] [Batch 650/938] [D loss: 1.096355, acc: 96%] [G loss: 1.149802]\n",
      "[Epoch 5/200] [Batch 651/938] [D loss: 1.045012, acc: 95%] [G loss: 1.110541]\n",
      "[Epoch 5/200] [Batch 652/938] [D loss: 1.069717, acc: 96%] [G loss: 1.124441]\n",
      "[Epoch 5/200] [Batch 653/938] [D loss: 1.052961, acc: 97%] [G loss: 1.138281]\n",
      "[Epoch 5/200] [Batch 654/938] [D loss: 1.088321, acc: 98%] [G loss: 1.118634]\n",
      "[Epoch 5/200] [Batch 655/938] [D loss: 1.102026, acc: 95%] [G loss: 1.106348]\n",
      "[Epoch 5/200] [Batch 656/938] [D loss: 1.069104, acc: 96%] [G loss: 1.129945]\n",
      "[Epoch 5/200] [Batch 657/938] [D loss: 1.087755, acc: 94%] [G loss: 1.137034]\n",
      "[Epoch 5/200] [Batch 658/938] [D loss: 1.133186, acc: 95%] [G loss: 1.095140]\n",
      "[Epoch 5/200] [Batch 659/938] [D loss: 1.103135, acc: 94%] [G loss: 1.127490]\n",
      "[Epoch 5/200] [Batch 660/938] [D loss: 1.105125, acc: 96%] [G loss: 1.105585]\n",
      "[Epoch 5/200] [Batch 661/938] [D loss: 1.079125, acc: 96%] [G loss: 1.113125]\n",
      "[Epoch 5/200] [Batch 662/938] [D loss: 1.090885, acc: 96%] [G loss: 1.100184]\n",
      "[Epoch 5/200] [Batch 663/938] [D loss: 1.086810, acc: 93%] [G loss: 1.113809]\n",
      "[Epoch 5/200] [Batch 664/938] [D loss: 1.073286, acc: 92%] [G loss: 1.168088]\n",
      "[Epoch 5/200] [Batch 665/938] [D loss: 1.096784, acc: 98%] [G loss: 1.125978]\n",
      "[Epoch 5/200] [Batch 666/938] [D loss: 1.079626, acc: 97%] [G loss: 1.170015]\n",
      "[Epoch 5/200] [Batch 667/938] [D loss: 1.101770, acc: 96%] [G loss: 1.067503]\n",
      "[Epoch 5/200] [Batch 668/938] [D loss: 1.116709, acc: 96%] [G loss: 1.070001]\n",
      "[Epoch 5/200] [Batch 669/938] [D loss: 1.085966, acc: 99%] [G loss: 1.138029]\n",
      "[Epoch 5/200] [Batch 670/938] [D loss: 1.125969, acc: 96%] [G loss: 1.188878]\n",
      "[Epoch 5/200] [Batch 671/938] [D loss: 1.124944, acc: 95%] [G loss: 1.105535]\n",
      "[Epoch 5/200] [Batch 672/938] [D loss: 1.032696, acc: 97%] [G loss: 1.172204]\n",
      "[Epoch 5/200] [Batch 673/938] [D loss: 1.082690, acc: 96%] [G loss: 1.106426]\n",
      "[Epoch 5/200] [Batch 674/938] [D loss: 1.128480, acc: 89%] [G loss: 1.159288]\n",
      "[Epoch 5/200] [Batch 675/938] [D loss: 1.097530, acc: 98%] [G loss: 1.143672]\n",
      "[Epoch 5/200] [Batch 676/938] [D loss: 1.091174, acc: 96%] [G loss: 1.168027]\n",
      "[Epoch 5/200] [Batch 677/938] [D loss: 1.101918, acc: 98%] [G loss: 1.196215]\n",
      "[Epoch 5/200] [Batch 678/938] [D loss: 1.062910, acc: 96%] [G loss: 1.084840]\n",
      "[Epoch 5/200] [Batch 679/938] [D loss: 1.135355, acc: 89%] [G loss: 1.243627]\n",
      "[Epoch 5/200] [Batch 680/938] [D loss: 1.094525, acc: 92%] [G loss: 1.134965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 681/938] [D loss: 1.115567, acc: 95%] [G loss: 1.100536]\n",
      "[Epoch 5/200] [Batch 682/938] [D loss: 1.085325, acc: 95%] [G loss: 1.113428]\n",
      "[Epoch 5/200] [Batch 683/938] [D loss: 1.107483, acc: 96%] [G loss: 1.104344]\n",
      "[Epoch 5/200] [Batch 684/938] [D loss: 1.088265, acc: 96%] [G loss: 1.109118]\n",
      "[Epoch 5/200] [Batch 685/938] [D loss: 1.057383, acc: 99%] [G loss: 1.117521]\n",
      "[Epoch 5/200] [Batch 686/938] [D loss: 1.087064, acc: 92%] [G loss: 1.165807]\n",
      "[Epoch 5/200] [Batch 687/938] [D loss: 1.093155, acc: 96%] [G loss: 1.098135]\n",
      "[Epoch 5/200] [Batch 688/938] [D loss: 1.086334, acc: 97%] [G loss: 1.175047]\n",
      "[Epoch 5/200] [Batch 689/938] [D loss: 1.130708, acc: 93%] [G loss: 1.114664]\n",
      "[Epoch 5/200] [Batch 690/938] [D loss: 1.111439, acc: 96%] [G loss: 1.114579]\n",
      "[Epoch 5/200] [Batch 691/938] [D loss: 1.097770, acc: 97%] [G loss: 1.145919]\n",
      "[Epoch 5/200] [Batch 692/938] [D loss: 1.090220, acc: 92%] [G loss: 1.072438]\n",
      "[Epoch 5/200] [Batch 693/938] [D loss: 1.101020, acc: 97%] [G loss: 1.087830]\n",
      "[Epoch 5/200] [Batch 694/938] [D loss: 1.108942, acc: 91%] [G loss: 1.108351]\n",
      "[Epoch 5/200] [Batch 695/938] [D loss: 1.078472, acc: 94%] [G loss: 1.143245]\n",
      "[Epoch 5/200] [Batch 696/938] [D loss: 1.080818, acc: 94%] [G loss: 1.070496]\n",
      "[Epoch 5/200] [Batch 697/938] [D loss: 1.101092, acc: 94%] [G loss: 1.088540]\n",
      "[Epoch 5/200] [Batch 698/938] [D loss: 1.110271, acc: 92%] [G loss: 1.092728]\n",
      "[Epoch 5/200] [Batch 699/938] [D loss: 1.101815, acc: 96%] [G loss: 1.127530]\n",
      "[Epoch 5/200] [Batch 700/938] [D loss: 1.116158, acc: 96%] [G loss: 1.136130]\n",
      "[Epoch 5/200] [Batch 701/938] [D loss: 1.148314, acc: 95%] [G loss: 1.087669]\n",
      "[Epoch 5/200] [Batch 702/938] [D loss: 1.091674, acc: 96%] [G loss: 1.147989]\n",
      "[Epoch 5/200] [Batch 703/938] [D loss: 1.080276, acc: 95%] [G loss: 1.157266]\n",
      "[Epoch 5/200] [Batch 704/938] [D loss: 1.067311, acc: 97%] [G loss: 1.083200]\n",
      "[Epoch 5/200] [Batch 705/938] [D loss: 1.070859, acc: 97%] [G loss: 1.088187]\n",
      "[Epoch 5/200] [Batch 706/938] [D loss: 1.062342, acc: 95%] [G loss: 1.129017]\n",
      "[Epoch 5/200] [Batch 707/938] [D loss: 1.091141, acc: 97%] [G loss: 1.135438]\n",
      "[Epoch 5/200] [Batch 708/938] [D loss: 1.082225, acc: 96%] [G loss: 1.143084]\n",
      "[Epoch 5/200] [Batch 709/938] [D loss: 1.072713, acc: 94%] [G loss: 1.122723]\n",
      "[Epoch 5/200] [Batch 710/938] [D loss: 1.067525, acc: 96%] [G loss: 1.094156]\n",
      "[Epoch 5/200] [Batch 711/938] [D loss: 1.056038, acc: 99%] [G loss: 1.171365]\n",
      "[Epoch 5/200] [Batch 712/938] [D loss: 1.061754, acc: 95%] [G loss: 1.103290]\n",
      "[Epoch 5/200] [Batch 713/938] [D loss: 1.100819, acc: 95%] [G loss: 1.143668]\n",
      "[Epoch 5/200] [Batch 714/938] [D loss: 1.122966, acc: 95%] [G loss: 1.110753]\n",
      "[Epoch 5/200] [Batch 715/938] [D loss: 1.057086, acc: 95%] [G loss: 1.148446]\n",
      "[Epoch 5/200] [Batch 716/938] [D loss: 1.115298, acc: 90%] [G loss: 1.105119]\n",
      "[Epoch 5/200] [Batch 717/938] [D loss: 1.123592, acc: 96%] [G loss: 1.097708]\n",
      "[Epoch 5/200] [Batch 718/938] [D loss: 1.076183, acc: 97%] [G loss: 1.082138]\n",
      "[Epoch 5/200] [Batch 719/938] [D loss: 1.114358, acc: 96%] [G loss: 1.098963]\n",
      "[Epoch 5/200] [Batch 720/938] [D loss: 1.075152, acc: 97%] [G loss: 1.166285]\n",
      "[Epoch 5/200] [Batch 721/938] [D loss: 1.107952, acc: 94%] [G loss: 1.172756]\n",
      "[Epoch 5/200] [Batch 722/938] [D loss: 1.106934, acc: 96%] [G loss: 1.114366]\n",
      "[Epoch 5/200] [Batch 723/938] [D loss: 1.072224, acc: 95%] [G loss: 1.128741]\n",
      "[Epoch 5/200] [Batch 724/938] [D loss: 1.113950, acc: 98%] [G loss: 1.151848]\n",
      "[Epoch 5/200] [Batch 725/938] [D loss: 1.088988, acc: 95%] [G loss: 1.160655]\n",
      "[Epoch 5/200] [Batch 726/938] [D loss: 1.048047, acc: 93%] [G loss: 1.140580]\n",
      "[Epoch 5/200] [Batch 727/938] [D loss: 1.097876, acc: 94%] [G loss: 1.063712]\n",
      "[Epoch 5/200] [Batch 728/938] [D loss: 1.097610, acc: 94%] [G loss: 1.145915]\n",
      "[Epoch 5/200] [Batch 729/938] [D loss: 1.119769, acc: 92%] [G loss: 1.089921]\n",
      "[Epoch 5/200] [Batch 730/938] [D loss: 1.112493, acc: 95%] [G loss: 1.125114]\n",
      "[Epoch 5/200] [Batch 731/938] [D loss: 1.053182, acc: 96%] [G loss: 1.124542]\n",
      "[Epoch 5/200] [Batch 732/938] [D loss: 1.089675, acc: 93%] [G loss: 1.045691]\n",
      "[Epoch 5/200] [Batch 733/938] [D loss: 1.096740, acc: 93%] [G loss: 1.056357]\n",
      "[Epoch 5/200] [Batch 734/938] [D loss: 1.118563, acc: 94%] [G loss: 1.040048]\n",
      "[Epoch 5/200] [Batch 735/938] [D loss: 1.089905, acc: 96%] [G loss: 1.105458]\n",
      "[Epoch 5/200] [Batch 736/938] [D loss: 1.055255, acc: 94%] [G loss: 1.187679]\n",
      "[Epoch 5/200] [Batch 737/938] [D loss: 1.091831, acc: 98%] [G loss: 1.097862]\n",
      "[Epoch 5/200] [Batch 738/938] [D loss: 1.082237, acc: 95%] [G loss: 1.117336]\n",
      "[Epoch 5/200] [Batch 739/938] [D loss: 1.086394, acc: 96%] [G loss: 1.143404]\n",
      "[Epoch 5/200] [Batch 740/938] [D loss: 1.090908, acc: 94%] [G loss: 1.167993]\n",
      "[Epoch 5/200] [Batch 741/938] [D loss: 1.162430, acc: 92%] [G loss: 1.101983]\n",
      "[Epoch 5/200] [Batch 742/938] [D loss: 1.064930, acc: 96%] [G loss: 1.064520]\n",
      "[Epoch 5/200] [Batch 743/938] [D loss: 1.087670, acc: 98%] [G loss: 1.143790]\n",
      "[Epoch 5/200] [Batch 744/938] [D loss: 1.084514, acc: 96%] [G loss: 1.134360]\n",
      "[Epoch 5/200] [Batch 745/938] [D loss: 1.079156, acc: 98%] [G loss: 1.095994]\n",
      "[Epoch 5/200] [Batch 746/938] [D loss: 1.080005, acc: 93%] [G loss: 1.075062]\n",
      "[Epoch 5/200] [Batch 747/938] [D loss: 1.075502, acc: 97%] [G loss: 1.176627]\n",
      "[Epoch 5/200] [Batch 748/938] [D loss: 1.079419, acc: 95%] [G loss: 1.124271]\n",
      "[Epoch 5/200] [Batch 749/938] [D loss: 1.065495, acc: 96%] [G loss: 1.084092]\n",
      "[Epoch 5/200] [Batch 750/938] [D loss: 1.128226, acc: 92%] [G loss: 1.064238]\n",
      "[Epoch 5/200] [Batch 751/938] [D loss: 1.133600, acc: 94%] [G loss: 1.086131]\n",
      "[Epoch 5/200] [Batch 752/938] [D loss: 1.112990, acc: 95%] [G loss: 1.116745]\n",
      "[Epoch 5/200] [Batch 753/938] [D loss: 1.135888, acc: 96%] [G loss: 1.124892]\n",
      "[Epoch 5/200] [Batch 754/938] [D loss: 1.136268, acc: 95%] [G loss: 1.060038]\n",
      "[Epoch 5/200] [Batch 755/938] [D loss: 1.111664, acc: 93%] [G loss: 1.114733]\n",
      "[Epoch 5/200] [Batch 756/938] [D loss: 1.063773, acc: 95%] [G loss: 1.133625]\n",
      "[Epoch 5/200] [Batch 757/938] [D loss: 1.075683, acc: 99%] [G loss: 1.142195]\n",
      "[Epoch 5/200] [Batch 758/938] [D loss: 1.102697, acc: 92%] [G loss: 1.102176]\n",
      "[Epoch 5/200] [Batch 759/938] [D loss: 1.084881, acc: 97%] [G loss: 1.124556]\n",
      "[Epoch 5/200] [Batch 760/938] [D loss: 1.118749, acc: 96%] [G loss: 1.118789]\n",
      "[Epoch 5/200] [Batch 761/938] [D loss: 1.104404, acc: 95%] [G loss: 1.102920]\n",
      "[Epoch 5/200] [Batch 762/938] [D loss: 1.072289, acc: 96%] [G loss: 1.085712]\n",
      "[Epoch 5/200] [Batch 763/938] [D loss: 1.052812, acc: 98%] [G loss: 1.151551]\n",
      "[Epoch 5/200] [Batch 764/938] [D loss: 1.076486, acc: 96%] [G loss: 1.066435]\n",
      "[Epoch 5/200] [Batch 765/938] [D loss: 1.096443, acc: 98%] [G loss: 1.138502]\n",
      "[Epoch 5/200] [Batch 766/938] [D loss: 1.083885, acc: 98%] [G loss: 1.129536]\n",
      "[Epoch 5/200] [Batch 767/938] [D loss: 1.059318, acc: 96%] [G loss: 1.186221]\n",
      "[Epoch 5/200] [Batch 768/938] [D loss: 1.102503, acc: 94%] [G loss: 1.111397]\n",
      "[Epoch 5/200] [Batch 769/938] [D loss: 1.057927, acc: 99%] [G loss: 1.138642]\n",
      "[Epoch 5/200] [Batch 770/938] [D loss: 1.156711, acc: 96%] [G loss: 1.114719]\n",
      "[Epoch 5/200] [Batch 771/938] [D loss: 1.082339, acc: 98%] [G loss: 1.125311]\n",
      "[Epoch 5/200] [Batch 772/938] [D loss: 1.103740, acc: 95%] [G loss: 1.056629]\n",
      "[Epoch 5/200] [Batch 773/938] [D loss: 1.104314, acc: 99%] [G loss: 1.089295]\n",
      "[Epoch 5/200] [Batch 774/938] [D loss: 1.058439, acc: 95%] [G loss: 1.214711]\n",
      "[Epoch 5/200] [Batch 775/938] [D loss: 1.070375, acc: 98%] [G loss: 1.103904]\n",
      "[Epoch 5/200] [Batch 776/938] [D loss: 1.067863, acc: 96%] [G loss: 1.094724]\n",
      "[Epoch 5/200] [Batch 777/938] [D loss: 1.052419, acc: 95%] [G loss: 1.166425]\n",
      "[Epoch 5/200] [Batch 778/938] [D loss: 1.123201, acc: 92%] [G loss: 1.140219]\n",
      "[Epoch 5/200] [Batch 779/938] [D loss: 1.066399, acc: 99%] [G loss: 1.043345]\n",
      "[Epoch 5/200] [Batch 780/938] [D loss: 1.135535, acc: 96%] [G loss: 1.057212]\n",
      "[Epoch 5/200] [Batch 781/938] [D loss: 1.128780, acc: 96%] [G loss: 1.095816]\n",
      "[Epoch 5/200] [Batch 782/938] [D loss: 1.124520, acc: 92%] [G loss: 1.095128]\n",
      "[Epoch 5/200] [Batch 783/938] [D loss: 1.066398, acc: 96%] [G loss: 1.190626]\n",
      "[Epoch 5/200] [Batch 784/938] [D loss: 1.085510, acc: 94%] [G loss: 1.181944]\n",
      "[Epoch 5/200] [Batch 785/938] [D loss: 1.090676, acc: 94%] [G loss: 1.039229]\n",
      "[Epoch 5/200] [Batch 786/938] [D loss: 1.103439, acc: 93%] [G loss: 1.150106]\n",
      "[Epoch 5/200] [Batch 787/938] [D loss: 1.106259, acc: 96%] [G loss: 1.107042]\n",
      "[Epoch 5/200] [Batch 788/938] [D loss: 1.083789, acc: 94%] [G loss: 1.251018]\n",
      "[Epoch 5/200] [Batch 789/938] [D loss: 1.062343, acc: 95%] [G loss: 1.106343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 790/938] [D loss: 1.119496, acc: 96%] [G loss: 1.093693]\n",
      "[Epoch 5/200] [Batch 791/938] [D loss: 1.076275, acc: 97%] [G loss: 1.111811]\n",
      "[Epoch 5/200] [Batch 792/938] [D loss: 1.082219, acc: 95%] [G loss: 1.166676]\n",
      "[Epoch 5/200] [Batch 793/938] [D loss: 1.068669, acc: 95%] [G loss: 1.135880]\n",
      "[Epoch 5/200] [Batch 794/938] [D loss: 1.094845, acc: 96%] [G loss: 1.088062]\n",
      "[Epoch 5/200] [Batch 795/938] [D loss: 1.088094, acc: 96%] [G loss: 1.158674]\n",
      "[Epoch 5/200] [Batch 796/938] [D loss: 1.098011, acc: 94%] [G loss: 1.060049]\n",
      "[Epoch 5/200] [Batch 797/938] [D loss: 1.143725, acc: 96%] [G loss: 1.157055]\n",
      "[Epoch 5/200] [Batch 798/938] [D loss: 1.124739, acc: 95%] [G loss: 1.155410]\n",
      "[Epoch 5/200] [Batch 799/938] [D loss: 1.082531, acc: 98%] [G loss: 1.090461]\n",
      "[Epoch 5/200] [Batch 800/938] [D loss: 1.095983, acc: 94%] [G loss: 1.012870]\n",
      "[Epoch 5/200] [Batch 801/938] [D loss: 1.070065, acc: 95%] [G loss: 1.090949]\n",
      "[Epoch 5/200] [Batch 802/938] [D loss: 1.096390, acc: 97%] [G loss: 1.107764]\n",
      "[Epoch 5/200] [Batch 803/938] [D loss: 1.085307, acc: 96%] [G loss: 1.122382]\n",
      "[Epoch 5/200] [Batch 804/938] [D loss: 1.088597, acc: 98%] [G loss: 1.100381]\n",
      "[Epoch 5/200] [Batch 805/938] [D loss: 1.123762, acc: 96%] [G loss: 1.107913]\n",
      "[Epoch 5/200] [Batch 806/938] [D loss: 1.081902, acc: 92%] [G loss: 1.100751]\n",
      "[Epoch 5/200] [Batch 807/938] [D loss: 1.104216, acc: 96%] [G loss: 1.103183]\n",
      "[Epoch 5/200] [Batch 808/938] [D loss: 1.083513, acc: 96%] [G loss: 1.101441]\n",
      "[Epoch 5/200] [Batch 809/938] [D loss: 1.106404, acc: 96%] [G loss: 1.077757]\n",
      "[Epoch 5/200] [Batch 810/938] [D loss: 1.078275, acc: 97%] [G loss: 1.148221]\n",
      "[Epoch 5/200] [Batch 811/938] [D loss: 1.069521, acc: 96%] [G loss: 1.160995]\n",
      "[Epoch 5/200] [Batch 812/938] [D loss: 1.063017, acc: 96%] [G loss: 1.163037]\n",
      "[Epoch 5/200] [Batch 813/938] [D loss: 1.063636, acc: 99%] [G loss: 1.159043]\n",
      "[Epoch 5/200] [Batch 814/938] [D loss: 1.103579, acc: 91%] [G loss: 1.078043]\n",
      "[Epoch 5/200] [Batch 815/938] [D loss: 1.128252, acc: 96%] [G loss: 1.108441]\n",
      "[Epoch 5/200] [Batch 816/938] [D loss: 1.092420, acc: 96%] [G loss: 1.066009]\n",
      "[Epoch 5/200] [Batch 817/938] [D loss: 1.095535, acc: 95%] [G loss: 1.174826]\n",
      "[Epoch 5/200] [Batch 818/938] [D loss: 1.081352, acc: 97%] [G loss: 1.129033]\n",
      "[Epoch 5/200] [Batch 819/938] [D loss: 1.051687, acc: 95%] [G loss: 1.123203]\n",
      "[Epoch 5/200] [Batch 820/938] [D loss: 1.088249, acc: 93%] [G loss: 1.090091]\n",
      "[Epoch 5/200] [Batch 821/938] [D loss: 1.101663, acc: 94%] [G loss: 1.146145]\n",
      "[Epoch 5/200] [Batch 822/938] [D loss: 1.101582, acc: 96%] [G loss: 1.105887]\n",
      "[Epoch 5/200] [Batch 823/938] [D loss: 1.071904, acc: 97%] [G loss: 1.111987]\n",
      "[Epoch 5/200] [Batch 824/938] [D loss: 1.093365, acc: 97%] [G loss: 1.117393]\n",
      "[Epoch 5/200] [Batch 825/938] [D loss: 1.093441, acc: 95%] [G loss: 1.068873]\n",
      "[Epoch 5/200] [Batch 826/938] [D loss: 1.090497, acc: 94%] [G loss: 1.124779]\n",
      "[Epoch 5/200] [Batch 827/938] [D loss: 1.057684, acc: 96%] [G loss: 1.088694]\n",
      "[Epoch 5/200] [Batch 828/938] [D loss: 1.104280, acc: 92%] [G loss: 1.091394]\n",
      "[Epoch 5/200] [Batch 829/938] [D loss: 1.088266, acc: 93%] [G loss: 1.078569]\n",
      "[Epoch 5/200] [Batch 830/938] [D loss: 1.109015, acc: 92%] [G loss: 1.100513]\n",
      "[Epoch 5/200] [Batch 831/938] [D loss: 1.078417, acc: 94%] [G loss: 1.125548]\n",
      "[Epoch 5/200] [Batch 832/938] [D loss: 1.061062, acc: 96%] [G loss: 1.115821]\n",
      "[Epoch 5/200] [Batch 833/938] [D loss: 1.114602, acc: 96%] [G loss: 1.137891]\n",
      "[Epoch 5/200] [Batch 834/938] [D loss: 1.096769, acc: 98%] [G loss: 1.133850]\n",
      "[Epoch 5/200] [Batch 835/938] [D loss: 1.084815, acc: 95%] [G loss: 1.140185]\n",
      "[Epoch 5/200] [Batch 836/938] [D loss: 1.077154, acc: 94%] [G loss: 1.154460]\n",
      "[Epoch 5/200] [Batch 837/938] [D loss: 1.070829, acc: 96%] [G loss: 1.162828]\n",
      "[Epoch 5/200] [Batch 838/938] [D loss: 1.063831, acc: 95%] [G loss: 1.081196]\n",
      "[Epoch 5/200] [Batch 839/938] [D loss: 1.104755, acc: 97%] [G loss: 1.095384]\n",
      "[Epoch 5/200] [Batch 840/938] [D loss: 1.067682, acc: 92%] [G loss: 1.059708]\n",
      "[Epoch 5/200] [Batch 841/938] [D loss: 1.058793, acc: 96%] [G loss: 1.069960]\n",
      "[Epoch 5/200] [Batch 842/938] [D loss: 1.101112, acc: 95%] [G loss: 1.122034]\n",
      "[Epoch 5/200] [Batch 843/938] [D loss: 1.120848, acc: 93%] [G loss: 1.108970]\n",
      "[Epoch 5/200] [Batch 844/938] [D loss: 1.125202, acc: 93%] [G loss: 1.134883]\n",
      "[Epoch 5/200] [Batch 845/938] [D loss: 1.107109, acc: 94%] [G loss: 1.083848]\n",
      "[Epoch 5/200] [Batch 846/938] [D loss: 1.113022, acc: 94%] [G loss: 1.188278]\n",
      "[Epoch 5/200] [Batch 847/938] [D loss: 1.094906, acc: 96%] [G loss: 1.122793]\n",
      "[Epoch 5/200] [Batch 848/938] [D loss: 1.064794, acc: 93%] [G loss: 1.118967]\n",
      "[Epoch 5/200] [Batch 849/938] [D loss: 1.086879, acc: 93%] [G loss: 1.144641]\n",
      "[Epoch 5/200] [Batch 850/938] [D loss: 1.090828, acc: 95%] [G loss: 1.127039]\n",
      "[Epoch 5/200] [Batch 851/938] [D loss: 1.056490, acc: 97%] [G loss: 1.062810]\n",
      "[Epoch 5/200] [Batch 852/938] [D loss: 1.078003, acc: 96%] [G loss: 1.120806]\n",
      "[Epoch 5/200] [Batch 853/938] [D loss: 1.112030, acc: 97%] [G loss: 1.121262]\n",
      "[Epoch 5/200] [Batch 854/938] [D loss: 1.111963, acc: 92%] [G loss: 1.200602]\n",
      "[Epoch 5/200] [Batch 855/938] [D loss: 1.111188, acc: 93%] [G loss: 1.138860]\n",
      "[Epoch 5/200] [Batch 856/938] [D loss: 1.074124, acc: 96%] [G loss: 1.081784]\n",
      "[Epoch 5/200] [Batch 857/938] [D loss: 1.071529, acc: 97%] [G loss: 1.129143]\n",
      "[Epoch 5/200] [Batch 858/938] [D loss: 1.056903, acc: 96%] [G loss: 1.205510]\n",
      "[Epoch 5/200] [Batch 859/938] [D loss: 1.068568, acc: 97%] [G loss: 1.145540]\n",
      "[Epoch 5/200] [Batch 860/938] [D loss: 1.039149, acc: 97%] [G loss: 1.136544]\n",
      "[Epoch 5/200] [Batch 861/938] [D loss: 1.089160, acc: 96%] [G loss: 1.157619]\n",
      "[Epoch 5/200] [Batch 862/938] [D loss: 1.078082, acc: 96%] [G loss: 1.113361]\n",
      "[Epoch 5/200] [Batch 863/938] [D loss: 1.074920, acc: 97%] [G loss: 1.133498]\n",
      "[Epoch 5/200] [Batch 864/938] [D loss: 1.078461, acc: 96%] [G loss: 1.099802]\n",
      "[Epoch 5/200] [Batch 865/938] [D loss: 1.108499, acc: 96%] [G loss: 1.051434]\n",
      "[Epoch 5/200] [Batch 866/938] [D loss: 1.056138, acc: 94%] [G loss: 1.104243]\n",
      "[Epoch 5/200] [Batch 867/938] [D loss: 1.096189, acc: 95%] [G loss: 1.138214]\n",
      "[Epoch 5/200] [Batch 868/938] [D loss: 1.095638, acc: 93%] [G loss: 1.200555]\n",
      "[Epoch 5/200] [Batch 869/938] [D loss: 1.093795, acc: 96%] [G loss: 1.092705]\n",
      "[Epoch 5/200] [Batch 870/938] [D loss: 1.100002, acc: 95%] [G loss: 1.078572]\n",
      "[Epoch 5/200] [Batch 871/938] [D loss: 1.096782, acc: 96%] [G loss: 1.169950]\n",
      "[Epoch 5/200] [Batch 872/938] [D loss: 1.109164, acc: 98%] [G loss: 1.171395]\n",
      "[Epoch 5/200] [Batch 873/938] [D loss: 1.099299, acc: 94%] [G loss: 1.107521]\n",
      "[Epoch 5/200] [Batch 874/938] [D loss: 1.124162, acc: 92%] [G loss: 1.095882]\n",
      "[Epoch 5/200] [Batch 875/938] [D loss: 1.085354, acc: 94%] [G loss: 1.160491]\n",
      "[Epoch 5/200] [Batch 876/938] [D loss: 1.059758, acc: 99%] [G loss: 1.179512]\n",
      "[Epoch 5/200] [Batch 877/938] [D loss: 1.107227, acc: 94%] [G loss: 1.177831]\n",
      "[Epoch 5/200] [Batch 878/938] [D loss: 1.121689, acc: 96%] [G loss: 1.199890]\n",
      "[Epoch 5/200] [Batch 879/938] [D loss: 1.110449, acc: 92%] [G loss: 1.123063]\n",
      "[Epoch 5/200] [Batch 880/938] [D loss: 1.072708, acc: 96%] [G loss: 1.162081]\n",
      "[Epoch 5/200] [Batch 881/938] [D loss: 1.099734, acc: 96%] [G loss: 1.119708]\n",
      "[Epoch 5/200] [Batch 882/938] [D loss: 1.111459, acc: 95%] [G loss: 1.076480]\n",
      "[Epoch 5/200] [Batch 883/938] [D loss: 1.086907, acc: 94%] [G loss: 1.095735]\n",
      "[Epoch 5/200] [Batch 884/938] [D loss: 1.084383, acc: 95%] [G loss: 1.106851]\n",
      "[Epoch 5/200] [Batch 885/938] [D loss: 1.093757, acc: 97%] [G loss: 1.089927]\n",
      "[Epoch 5/200] [Batch 886/938] [D loss: 1.138750, acc: 96%] [G loss: 1.128466]\n",
      "[Epoch 5/200] [Batch 887/938] [D loss: 1.083248, acc: 92%] [G loss: 1.153318]\n",
      "[Epoch 5/200] [Batch 888/938] [D loss: 1.122984, acc: 96%] [G loss: 1.086207]\n",
      "[Epoch 5/200] [Batch 889/938] [D loss: 1.087050, acc: 96%] [G loss: 1.101658]\n",
      "[Epoch 5/200] [Batch 890/938] [D loss: 1.086879, acc: 97%] [G loss: 1.124237]\n",
      "[Epoch 5/200] [Batch 891/938] [D loss: 1.116577, acc: 93%] [G loss: 1.134477]\n",
      "[Epoch 5/200] [Batch 892/938] [D loss: 1.091927, acc: 96%] [G loss: 1.148558]\n",
      "[Epoch 5/200] [Batch 893/938] [D loss: 1.087950, acc: 94%] [G loss: 1.094725]\n",
      "[Epoch 5/200] [Batch 894/938] [D loss: 1.110862, acc: 95%] [G loss: 1.142957]\n",
      "[Epoch 5/200] [Batch 895/938] [D loss: 1.104069, acc: 95%] [G loss: 1.154657]\n",
      "[Epoch 5/200] [Batch 896/938] [D loss: 1.131813, acc: 96%] [G loss: 1.129154]\n",
      "[Epoch 5/200] [Batch 897/938] [D loss: 1.078364, acc: 99%] [G loss: 1.149676]\n",
      "[Epoch 5/200] [Batch 898/938] [D loss: 1.096144, acc: 95%] [G loss: 1.089581]\n",
      "[Epoch 5/200] [Batch 899/938] [D loss: 1.082200, acc: 93%] [G loss: 1.044766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/200] [Batch 900/938] [D loss: 1.132678, acc: 95%] [G loss: 1.039524]\n",
      "[Epoch 5/200] [Batch 901/938] [D loss: 1.080829, acc: 96%] [G loss: 1.047814]\n",
      "[Epoch 5/200] [Batch 902/938] [D loss: 1.108942, acc: 98%] [G loss: 1.153508]\n",
      "[Epoch 5/200] [Batch 903/938] [D loss: 1.081684, acc: 96%] [G loss: 1.167140]\n",
      "[Epoch 5/200] [Batch 904/938] [D loss: 1.106728, acc: 95%] [G loss: 1.113382]\n",
      "[Epoch 5/200] [Batch 905/938] [D loss: 1.101756, acc: 97%] [G loss: 1.103174]\n",
      "[Epoch 5/200] [Batch 906/938] [D loss: 1.110090, acc: 96%] [G loss: 1.104170]\n",
      "[Epoch 5/200] [Batch 907/938] [D loss: 1.092757, acc: 94%] [G loss: 1.104355]\n",
      "[Epoch 5/200] [Batch 908/938] [D loss: 1.108037, acc: 95%] [G loss: 1.105984]\n",
      "[Epoch 5/200] [Batch 909/938] [D loss: 1.114769, acc: 95%] [G loss: 1.110685]\n",
      "[Epoch 5/200] [Batch 910/938] [D loss: 1.072246, acc: 94%] [G loss: 1.181738]\n",
      "[Epoch 5/200] [Batch 911/938] [D loss: 1.073631, acc: 98%] [G loss: 1.130740]\n",
      "[Epoch 5/200] [Batch 912/938] [D loss: 1.099298, acc: 93%] [G loss: 1.059211]\n",
      "[Epoch 5/200] [Batch 913/938] [D loss: 1.089123, acc: 94%] [G loss: 1.099128]\n",
      "[Epoch 5/200] [Batch 914/938] [D loss: 1.107875, acc: 93%] [G loss: 1.072976]\n",
      "[Epoch 5/200] [Batch 915/938] [D loss: 1.100266, acc: 98%] [G loss: 1.093670]\n",
      "[Epoch 5/200] [Batch 916/938] [D loss: 1.126693, acc: 92%] [G loss: 1.153462]\n",
      "[Epoch 5/200] [Batch 917/938] [D loss: 1.127952, acc: 93%] [G loss: 1.183015]\n",
      "[Epoch 5/200] [Batch 918/938] [D loss: 1.066116, acc: 97%] [G loss: 1.120769]\n",
      "[Epoch 5/200] [Batch 919/938] [D loss: 1.095447, acc: 92%] [G loss: 1.084223]\n",
      "[Epoch 5/200] [Batch 920/938] [D loss: 1.073596, acc: 98%] [G loss: 1.072685]\n",
      "[Epoch 5/200] [Batch 921/938] [D loss: 1.142421, acc: 93%] [G loss: 1.097273]\n",
      "[Epoch 5/200] [Batch 922/938] [D loss: 1.099450, acc: 96%] [G loss: 1.106682]\n",
      "[Epoch 5/200] [Batch 923/938] [D loss: 1.094599, acc: 96%] [G loss: 1.150603]\n",
      "[Epoch 5/200] [Batch 924/938] [D loss: 1.083049, acc: 96%] [G loss: 1.176483]\n",
      "[Epoch 5/200] [Batch 925/938] [D loss: 1.102906, acc: 90%] [G loss: 1.118067]\n",
      "[Epoch 5/200] [Batch 926/938] [D loss: 1.110222, acc: 96%] [G loss: 1.036407]\n",
      "[Epoch 5/200] [Batch 927/938] [D loss: 1.092202, acc: 93%] [G loss: 1.153287]\n",
      "[Epoch 5/200] [Batch 928/938] [D loss: 1.111846, acc: 92%] [G loss: 1.195763]\n",
      "[Epoch 5/200] [Batch 929/938] [D loss: 1.059549, acc: 95%] [G loss: 1.125335]\n",
      "[Epoch 5/200] [Batch 930/938] [D loss: 1.099994, acc: 94%] [G loss: 1.152215]\n",
      "[Epoch 5/200] [Batch 931/938] [D loss: 1.115830, acc: 90%] [G loss: 1.147999]\n",
      "[Epoch 5/200] [Batch 932/938] [D loss: 1.136663, acc: 95%] [G loss: 1.075449]\n",
      "[Epoch 5/200] [Batch 933/938] [D loss: 1.098238, acc: 96%] [G loss: 1.148878]\n",
      "[Epoch 5/200] [Batch 934/938] [D loss: 1.072411, acc: 99%] [G loss: 1.092516]\n",
      "[Epoch 5/200] [Batch 935/938] [D loss: 1.069253, acc: 95%] [G loss: 1.161164]\n",
      "[Epoch 5/200] [Batch 936/938] [D loss: 1.042235, acc: 97%] [G loss: 1.105922]\n",
      "[Epoch 5/200] [Batch 937/938] [D loss: 1.080789, acc: 95%] [G loss: 1.170424]\n",
      "[Epoch 6/200] [Batch 0/938] [D loss: 1.088956, acc: 97%] [G loss: 1.081389]\n",
      "[Epoch 6/200] [Batch 1/938] [D loss: 1.092043, acc: 95%] [G loss: 1.159014]\n",
      "[Epoch 6/200] [Batch 2/938] [D loss: 1.129089, acc: 93%] [G loss: 1.126877]\n",
      "[Epoch 6/200] [Batch 3/938] [D loss: 1.082057, acc: 95%] [G loss: 1.166315]\n",
      "[Epoch 6/200] [Batch 4/938] [D loss: 1.047633, acc: 96%] [G loss: 1.146014]\n",
      "[Epoch 6/200] [Batch 5/938] [D loss: 1.089035, acc: 91%] [G loss: 1.121196]\n",
      "[Epoch 6/200] [Batch 6/938] [D loss: 1.071230, acc: 97%] [G loss: 1.112447]\n",
      "[Epoch 6/200] [Batch 7/938] [D loss: 1.098150, acc: 98%] [G loss: 1.144924]\n",
      "[Epoch 6/200] [Batch 8/938] [D loss: 1.056740, acc: 99%] [G loss: 1.086517]\n",
      "[Epoch 6/200] [Batch 9/938] [D loss: 1.095385, acc: 98%] [G loss: 1.046335]\n",
      "[Epoch 6/200] [Batch 10/938] [D loss: 1.112373, acc: 93%] [G loss: 1.127282]\n",
      "[Epoch 6/200] [Batch 11/938] [D loss: 1.103597, acc: 94%] [G loss: 1.077215]\n",
      "[Epoch 6/200] [Batch 12/938] [D loss: 1.093475, acc: 93%] [G loss: 1.148570]\n",
      "[Epoch 6/200] [Batch 13/938] [D loss: 1.114860, acc: 96%] [G loss: 1.155319]\n",
      "[Epoch 6/200] [Batch 14/938] [D loss: 1.103190, acc: 93%] [G loss: 1.097403]\n",
      "[Epoch 6/200] [Batch 15/938] [D loss: 1.078561, acc: 96%] [G loss: 1.121404]\n",
      "[Epoch 6/200] [Batch 16/938] [D loss: 1.094601, acc: 98%] [G loss: 1.045746]\n",
      "[Epoch 6/200] [Batch 17/938] [D loss: 1.078212, acc: 96%] [G loss: 1.123711]\n",
      "[Epoch 6/200] [Batch 18/938] [D loss: 1.043793, acc: 97%] [G loss: 1.153878]\n",
      "[Epoch 6/200] [Batch 19/938] [D loss: 1.078879, acc: 99%] [G loss: 1.098418]\n",
      "[Epoch 6/200] [Batch 20/938] [D loss: 1.095666, acc: 96%] [G loss: 1.139473]\n",
      "[Epoch 6/200] [Batch 21/938] [D loss: 1.117206, acc: 94%] [G loss: 1.083822]\n",
      "[Epoch 6/200] [Batch 22/938] [D loss: 1.101112, acc: 95%] [G loss: 1.064862]\n",
      "[Epoch 6/200] [Batch 23/938] [D loss: 1.112570, acc: 96%] [G loss: 1.070843]\n",
      "[Epoch 6/200] [Batch 24/938] [D loss: 1.090101, acc: 98%] [G loss: 1.141018]\n",
      "[Epoch 6/200] [Batch 25/938] [D loss: 1.128326, acc: 96%] [G loss: 1.098752]\n",
      "[Epoch 6/200] [Batch 26/938] [D loss: 1.120788, acc: 95%] [G loss: 1.124128]\n",
      "[Epoch 6/200] [Batch 27/938] [D loss: 1.084787, acc: 96%] [G loss: 1.076176]\n",
      "[Epoch 6/200] [Batch 28/938] [D loss: 1.086829, acc: 96%] [G loss: 1.075502]\n",
      "[Epoch 6/200] [Batch 29/938] [D loss: 1.108279, acc: 94%] [G loss: 1.132839]\n",
      "[Epoch 6/200] [Batch 30/938] [D loss: 1.089145, acc: 97%] [G loss: 1.126975]\n",
      "[Epoch 6/200] [Batch 31/938] [D loss: 1.115997, acc: 96%] [G loss: 1.068648]\n",
      "[Epoch 6/200] [Batch 32/938] [D loss: 1.095517, acc: 97%] [G loss: 1.116906]\n",
      "[Epoch 6/200] [Batch 33/938] [D loss: 1.082246, acc: 97%] [G loss: 1.116352]\n",
      "[Epoch 6/200] [Batch 34/938] [D loss: 1.083897, acc: 95%] [G loss: 1.162198]\n",
      "[Epoch 6/200] [Batch 35/938] [D loss: 1.078546, acc: 96%] [G loss: 1.096660]\n",
      "[Epoch 6/200] [Batch 36/938] [D loss: 1.087271, acc: 94%] [G loss: 1.098281]\n",
      "[Epoch 6/200] [Batch 37/938] [D loss: 1.068803, acc: 96%] [G loss: 1.180395]\n",
      "[Epoch 6/200] [Batch 38/938] [D loss: 1.071774, acc: 97%] [G loss: 1.153678]\n",
      "[Epoch 6/200] [Batch 39/938] [D loss: 1.068018, acc: 97%] [G loss: 1.087765]\n",
      "[Epoch 6/200] [Batch 40/938] [D loss: 1.107258, acc: 97%] [G loss: 1.162641]\n",
      "[Epoch 6/200] [Batch 41/938] [D loss: 1.071222, acc: 96%] [G loss: 1.109735]\n",
      "[Epoch 6/200] [Batch 42/938] [D loss: 1.097142, acc: 97%] [G loss: 1.094236]\n",
      "[Epoch 6/200] [Batch 43/938] [D loss: 1.069305, acc: 96%] [G loss: 1.125427]\n",
      "[Epoch 6/200] [Batch 44/938] [D loss: 1.123229, acc: 94%] [G loss: 1.052557]\n",
      "[Epoch 6/200] [Batch 45/938] [D loss: 1.104390, acc: 97%] [G loss: 1.111438]\n",
      "[Epoch 6/200] [Batch 46/938] [D loss: 1.078323, acc: 95%] [G loss: 1.096171]\n",
      "[Epoch 6/200] [Batch 47/938] [D loss: 1.091001, acc: 95%] [G loss: 1.126881]\n",
      "[Epoch 6/200] [Batch 48/938] [D loss: 1.065989, acc: 96%] [G loss: 1.095204]\n",
      "[Epoch 6/200] [Batch 49/938] [D loss: 1.104573, acc: 95%] [G loss: 1.084986]\n",
      "[Epoch 6/200] [Batch 50/938] [D loss: 1.091490, acc: 94%] [G loss: 1.193544]\n",
      "[Epoch 6/200] [Batch 51/938] [D loss: 1.086573, acc: 96%] [G loss: 1.135412]\n",
      "[Epoch 6/200] [Batch 52/938] [D loss: 1.066088, acc: 97%] [G loss: 1.194332]\n",
      "[Epoch 6/200] [Batch 53/938] [D loss: 1.082879, acc: 96%] [G loss: 1.062050]\n",
      "[Epoch 6/200] [Batch 54/938] [D loss: 1.140910, acc: 96%] [G loss: 1.069106]\n",
      "[Epoch 6/200] [Batch 55/938] [D loss: 1.067502, acc: 96%] [G loss: 1.112287]\n",
      "[Epoch 6/200] [Batch 56/938] [D loss: 1.095153, acc: 96%] [G loss: 1.124276]\n",
      "[Epoch 6/200] [Batch 57/938] [D loss: 1.090719, acc: 98%] [G loss: 1.148217]\n",
      "[Epoch 6/200] [Batch 58/938] [D loss: 1.113611, acc: 91%] [G loss: 1.195409]\n",
      "[Epoch 6/200] [Batch 59/938] [D loss: 1.093721, acc: 91%] [G loss: 1.137050]\n",
      "[Epoch 6/200] [Batch 60/938] [D loss: 1.107060, acc: 96%] [G loss: 1.147276]\n",
      "[Epoch 6/200] [Batch 61/938] [D loss: 1.055321, acc: 97%] [G loss: 1.180250]\n",
      "[Epoch 6/200] [Batch 62/938] [D loss: 1.089550, acc: 94%] [G loss: 1.085116]\n",
      "[Epoch 6/200] [Batch 63/938] [D loss: 1.078807, acc: 97%] [G loss: 1.094861]\n",
      "[Epoch 6/200] [Batch 64/938] [D loss: 1.078999, acc: 95%] [G loss: 1.060637]\n",
      "[Epoch 6/200] [Batch 65/938] [D loss: 1.091219, acc: 95%] [G loss: 1.138980]\n",
      "[Epoch 6/200] [Batch 66/938] [D loss: 1.123885, acc: 97%] [G loss: 1.069236]\n",
      "[Epoch 6/200] [Batch 67/938] [D loss: 1.107617, acc: 96%] [G loss: 1.110354]\n",
      "[Epoch 6/200] [Batch 68/938] [D loss: 1.109141, acc: 93%] [G loss: 1.052469]\n",
      "[Epoch 6/200] [Batch 69/938] [D loss: 1.073393, acc: 97%] [G loss: 1.105546]\n",
      "[Epoch 6/200] [Batch 70/938] [D loss: 1.104700, acc: 92%] [G loss: 1.150389]\n",
      "[Epoch 6/200] [Batch 71/938] [D loss: 1.093390, acc: 95%] [G loss: 1.185478]\n",
      "[Epoch 6/200] [Batch 72/938] [D loss: 1.064628, acc: 96%] [G loss: 1.160117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 73/938] [D loss: 1.073718, acc: 98%] [G loss: 1.124260]\n",
      "[Epoch 6/200] [Batch 74/938] [D loss: 1.099044, acc: 96%] [G loss: 1.137979]\n",
      "[Epoch 6/200] [Batch 75/938] [D loss: 1.109619, acc: 93%] [G loss: 1.143846]\n",
      "[Epoch 6/200] [Batch 76/938] [D loss: 1.100657, acc: 96%] [G loss: 1.145452]\n",
      "[Epoch 6/200] [Batch 77/938] [D loss: 1.099951, acc: 96%] [G loss: 1.058550]\n",
      "[Epoch 6/200] [Batch 78/938] [D loss: 1.096977, acc: 93%] [G loss: 1.067571]\n",
      "[Epoch 6/200] [Batch 79/938] [D loss: 1.097245, acc: 96%] [G loss: 1.098457]\n",
      "[Epoch 6/200] [Batch 80/938] [D loss: 1.096800, acc: 97%] [G loss: 1.041076]\n",
      "[Epoch 6/200] [Batch 81/938] [D loss: 1.089216, acc: 98%] [G loss: 1.161584]\n",
      "[Epoch 6/200] [Batch 82/938] [D loss: 1.073483, acc: 95%] [G loss: 1.140707]\n",
      "[Epoch 6/200] [Batch 83/938] [D loss: 1.082380, acc: 96%] [G loss: 1.142975]\n",
      "[Epoch 6/200] [Batch 84/938] [D loss: 1.133652, acc: 94%] [G loss: 1.056169]\n",
      "[Epoch 6/200] [Batch 85/938] [D loss: 1.091365, acc: 92%] [G loss: 1.153236]\n",
      "[Epoch 6/200] [Batch 86/938] [D loss: 1.138711, acc: 94%] [G loss: 1.071734]\n",
      "[Epoch 6/200] [Batch 87/938] [D loss: 1.083198, acc: 92%] [G loss: 1.140584]\n",
      "[Epoch 6/200] [Batch 88/938] [D loss: 1.103937, acc: 95%] [G loss: 1.155601]\n",
      "[Epoch 6/200] [Batch 89/938] [D loss: 1.107821, acc: 97%] [G loss: 1.133025]\n",
      "[Epoch 6/200] [Batch 90/938] [D loss: 1.088394, acc: 93%] [G loss: 1.147048]\n",
      "[Epoch 6/200] [Batch 91/938] [D loss: 1.112836, acc: 97%] [G loss: 1.095615]\n",
      "[Epoch 6/200] [Batch 92/938] [D loss: 1.089549, acc: 98%] [G loss: 1.088953]\n",
      "[Epoch 6/200] [Batch 93/938] [D loss: 1.097048, acc: 95%] [G loss: 1.113636]\n",
      "[Epoch 6/200] [Batch 94/938] [D loss: 1.094269, acc: 96%] [G loss: 1.150966]\n",
      "[Epoch 6/200] [Batch 95/938] [D loss: 1.074863, acc: 99%] [G loss: 1.182874]\n",
      "[Epoch 6/200] [Batch 96/938] [D loss: 1.086157, acc: 94%] [G loss: 1.121434]\n",
      "[Epoch 6/200] [Batch 97/938] [D loss: 1.091443, acc: 97%] [G loss: 1.155668]\n",
      "[Epoch 6/200] [Batch 98/938] [D loss: 1.086095, acc: 94%] [G loss: 1.067489]\n",
      "[Epoch 6/200] [Batch 99/938] [D loss: 1.071856, acc: 97%] [G loss: 1.105683]\n",
      "[Epoch 6/200] [Batch 100/938] [D loss: 1.101505, acc: 95%] [G loss: 1.099458]\n",
      "[Epoch 6/200] [Batch 101/938] [D loss: 1.079749, acc: 96%] [G loss: 1.035561]\n",
      "[Epoch 6/200] [Batch 102/938] [D loss: 1.066987, acc: 96%] [G loss: 1.162547]\n",
      "[Epoch 6/200] [Batch 103/938] [D loss: 1.084887, acc: 96%] [G loss: 1.096571]\n",
      "[Epoch 6/200] [Batch 104/938] [D loss: 1.086107, acc: 93%] [G loss: 1.110880]\n",
      "[Epoch 6/200] [Batch 105/938] [D loss: 1.072118, acc: 95%] [G loss: 1.125656]\n",
      "[Epoch 6/200] [Batch 106/938] [D loss: 1.087841, acc: 98%] [G loss: 1.062981]\n",
      "[Epoch 6/200] [Batch 107/938] [D loss: 1.092910, acc: 95%] [G loss: 1.116489]\n",
      "[Epoch 6/200] [Batch 108/938] [D loss: 1.086929, acc: 94%] [G loss: 1.140345]\n",
      "[Epoch 6/200] [Batch 109/938] [D loss: 1.073504, acc: 95%] [G loss: 1.130163]\n",
      "[Epoch 6/200] [Batch 110/938] [D loss: 1.108846, acc: 95%] [G loss: 1.150704]\n",
      "[Epoch 6/200] [Batch 111/938] [D loss: 1.099124, acc: 96%] [G loss: 1.161781]\n",
      "[Epoch 6/200] [Batch 112/938] [D loss: 1.053452, acc: 97%] [G loss: 1.127367]\n",
      "[Epoch 6/200] [Batch 113/938] [D loss: 1.069691, acc: 96%] [G loss: 1.101069]\n",
      "[Epoch 6/200] [Batch 114/938] [D loss: 1.076959, acc: 97%] [G loss: 1.122206]\n",
      "[Epoch 6/200] [Batch 115/938] [D loss: 1.116420, acc: 92%] [G loss: 1.113158]\n",
      "[Epoch 6/200] [Batch 116/938] [D loss: 1.079794, acc: 93%] [G loss: 1.074438]\n",
      "[Epoch 6/200] [Batch 117/938] [D loss: 1.090388, acc: 99%] [G loss: 1.120121]\n",
      "[Epoch 6/200] [Batch 118/938] [D loss: 1.094821, acc: 93%] [G loss: 1.104811]\n",
      "[Epoch 6/200] [Batch 119/938] [D loss: 1.080560, acc: 96%] [G loss: 1.189700]\n",
      "[Epoch 6/200] [Batch 120/938] [D loss: 1.064163, acc: 99%] [G loss: 1.181006]\n",
      "[Epoch 6/200] [Batch 121/938] [D loss: 1.050176, acc: 97%] [G loss: 1.136652]\n",
      "[Epoch 6/200] [Batch 122/938] [D loss: 1.124420, acc: 96%] [G loss: 1.042788]\n",
      "[Epoch 6/200] [Batch 123/938] [D loss: 1.105312, acc: 91%] [G loss: 1.154241]\n",
      "[Epoch 6/200] [Batch 124/938] [D loss: 1.100636, acc: 96%] [G loss: 1.164865]\n",
      "[Epoch 6/200] [Batch 125/938] [D loss: 1.078562, acc: 95%] [G loss: 1.124120]\n",
      "[Epoch 6/200] [Batch 126/938] [D loss: 1.091585, acc: 98%] [G loss: 1.148561]\n",
      "[Epoch 6/200] [Batch 127/938] [D loss: 1.072792, acc: 97%] [G loss: 1.092863]\n",
      "[Epoch 6/200] [Batch 128/938] [D loss: 1.070590, acc: 94%] [G loss: 1.097186]\n",
      "[Epoch 6/200] [Batch 129/938] [D loss: 1.065001, acc: 96%] [G loss: 1.162216]\n",
      "[Epoch 6/200] [Batch 130/938] [D loss: 1.092877, acc: 94%] [G loss: 1.110786]\n",
      "[Epoch 6/200] [Batch 131/938] [D loss: 1.105865, acc: 94%] [G loss: 1.210376]\n",
      "[Epoch 6/200] [Batch 132/938] [D loss: 1.089100, acc: 98%] [G loss: 1.147518]\n",
      "[Epoch 6/200] [Batch 133/938] [D loss: 1.079184, acc: 95%] [G loss: 1.109242]\n",
      "[Epoch 6/200] [Batch 134/938] [D loss: 1.076308, acc: 96%] [G loss: 1.174126]\n",
      "[Epoch 6/200] [Batch 135/938] [D loss: 1.089619, acc: 95%] [G loss: 1.076699]\n",
      "[Epoch 6/200] [Batch 136/938] [D loss: 1.116775, acc: 95%] [G loss: 1.138658]\n",
      "[Epoch 6/200] [Batch 137/938] [D loss: 1.106845, acc: 95%] [G loss: 1.144108]\n",
      "[Epoch 6/200] [Batch 138/938] [D loss: 1.076803, acc: 99%] [G loss: 1.086577]\n",
      "[Epoch 6/200] [Batch 139/938] [D loss: 1.086379, acc: 97%] [G loss: 1.067371]\n",
      "[Epoch 6/200] [Batch 140/938] [D loss: 1.082346, acc: 98%] [G loss: 1.176079]\n",
      "[Epoch 6/200] [Batch 141/938] [D loss: 1.091117, acc: 97%] [G loss: 1.141069]\n",
      "[Epoch 6/200] [Batch 142/938] [D loss: 1.078673, acc: 97%] [G loss: 1.153002]\n",
      "[Epoch 6/200] [Batch 143/938] [D loss: 1.131589, acc: 96%] [G loss: 1.141179]\n",
      "[Epoch 6/200] [Batch 144/938] [D loss: 1.065651, acc: 96%] [G loss: 1.058599]\n",
      "[Epoch 6/200] [Batch 145/938] [D loss: 1.094787, acc: 97%] [G loss: 1.090203]\n",
      "[Epoch 6/200] [Batch 146/938] [D loss: 1.064148, acc: 94%] [G loss: 1.135769]\n",
      "[Epoch 6/200] [Batch 147/938] [D loss: 1.111088, acc: 91%] [G loss: 1.152843]\n",
      "[Epoch 6/200] [Batch 148/938] [D loss: 1.136013, acc: 94%] [G loss: 1.092184]\n",
      "[Epoch 6/200] [Batch 149/938] [D loss: 1.121603, acc: 92%] [G loss: 1.144549]\n",
      "[Epoch 6/200] [Batch 150/938] [D loss: 1.085284, acc: 94%] [G loss: 1.099384]\n",
      "[Epoch 6/200] [Batch 151/938] [D loss: 1.091652, acc: 96%] [G loss: 1.164102]\n",
      "[Epoch 6/200] [Batch 152/938] [D loss: 1.115252, acc: 92%] [G loss: 1.110868]\n",
      "[Epoch 6/200] [Batch 153/938] [D loss: 1.088085, acc: 95%] [G loss: 1.124102]\n",
      "[Epoch 6/200] [Batch 154/938] [D loss: 1.118331, acc: 93%] [G loss: 1.070022]\n",
      "[Epoch 6/200] [Batch 155/938] [D loss: 1.073044, acc: 96%] [G loss: 1.136808]\n",
      "[Epoch 6/200] [Batch 156/938] [D loss: 1.079726, acc: 99%] [G loss: 1.064585]\n",
      "[Epoch 6/200] [Batch 157/938] [D loss: 1.098737, acc: 97%] [G loss: 1.097280]\n",
      "[Epoch 6/200] [Batch 158/938] [D loss: 1.092679, acc: 94%] [G loss: 1.132029]\n",
      "[Epoch 6/200] [Batch 159/938] [D loss: 1.123072, acc: 91%] [G loss: 1.118644]\n",
      "[Epoch 6/200] [Batch 160/938] [D loss: 1.108804, acc: 94%] [G loss: 1.165271]\n",
      "[Epoch 6/200] [Batch 161/938] [D loss: 1.073432, acc: 96%] [G loss: 1.090468]\n",
      "[Epoch 6/200] [Batch 162/938] [D loss: 1.074694, acc: 97%] [G loss: 1.057675]\n",
      "[Epoch 6/200] [Batch 163/938] [D loss: 1.077170, acc: 96%] [G loss: 1.070698]\n",
      "[Epoch 6/200] [Batch 164/938] [D loss: 1.066545, acc: 96%] [G loss: 1.047309]\n",
      "[Epoch 6/200] [Batch 165/938] [D loss: 1.107646, acc: 98%] [G loss: 1.096282]\n",
      "[Epoch 6/200] [Batch 166/938] [D loss: 1.093349, acc: 98%] [G loss: 1.107556]\n",
      "[Epoch 6/200] [Batch 167/938] [D loss: 1.064095, acc: 96%] [G loss: 1.152244]\n",
      "[Epoch 6/200] [Batch 168/938] [D loss: 1.080980, acc: 90%] [G loss: 1.110148]\n",
      "[Epoch 6/200] [Batch 169/938] [D loss: 1.070365, acc: 97%] [G loss: 1.120419]\n",
      "[Epoch 6/200] [Batch 170/938] [D loss: 1.111450, acc: 92%] [G loss: 1.164864]\n",
      "[Epoch 6/200] [Batch 171/938] [D loss: 1.128966, acc: 95%] [G loss: 1.101807]\n",
      "[Epoch 6/200] [Batch 172/938] [D loss: 1.100360, acc: 96%] [G loss: 1.079116]\n",
      "[Epoch 6/200] [Batch 173/938] [D loss: 1.107419, acc: 92%] [G loss: 1.131144]\n",
      "[Epoch 6/200] [Batch 174/938] [D loss: 1.082913, acc: 96%] [G loss: 1.067333]\n",
      "[Epoch 6/200] [Batch 175/938] [D loss: 1.113150, acc: 96%] [G loss: 1.108700]\n",
      "[Epoch 6/200] [Batch 176/938] [D loss: 1.083049, acc: 98%] [G loss: 1.106589]\n",
      "[Epoch 6/200] [Batch 177/938] [D loss: 1.066686, acc: 96%] [G loss: 1.096665]\n",
      "[Epoch 6/200] [Batch 178/938] [D loss: 1.074449, acc: 96%] [G loss: 1.141963]\n",
      "[Epoch 6/200] [Batch 179/938] [D loss: 1.101663, acc: 91%] [G loss: 1.112032]\n",
      "[Epoch 6/200] [Batch 180/938] [D loss: 1.142739, acc: 93%] [G loss: 1.097899]\n",
      "[Epoch 6/200] [Batch 181/938] [D loss: 1.112718, acc: 95%] [G loss: 1.075579]\n",
      "[Epoch 6/200] [Batch 182/938] [D loss: 1.123264, acc: 91%] [G loss: 1.137617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 183/938] [D loss: 1.046117, acc: 96%] [G loss: 1.053746]\n",
      "[Epoch 6/200] [Batch 184/938] [D loss: 1.103583, acc: 95%] [G loss: 1.057887]\n",
      "[Epoch 6/200] [Batch 185/938] [D loss: 1.107052, acc: 97%] [G loss: 1.057343]\n",
      "[Epoch 6/200] [Batch 186/938] [D loss: 1.049367, acc: 96%] [G loss: 1.120501]\n",
      "[Epoch 6/200] [Batch 187/938] [D loss: 1.038673, acc: 96%] [G loss: 1.190474]\n",
      "[Epoch 6/200] [Batch 188/938] [D loss: 1.099069, acc: 94%] [G loss: 1.118175]\n",
      "[Epoch 6/200] [Batch 189/938] [D loss: 1.113151, acc: 97%] [G loss: 1.113696]\n",
      "[Epoch 6/200] [Batch 190/938] [D loss: 1.093471, acc: 96%] [G loss: 1.094179]\n",
      "[Epoch 6/200] [Batch 191/938] [D loss: 1.072353, acc: 96%] [G loss: 1.113467]\n",
      "[Epoch 6/200] [Batch 192/938] [D loss: 1.087168, acc: 91%] [G loss: 1.151448]\n",
      "[Epoch 6/200] [Batch 193/938] [D loss: 1.046273, acc: 97%] [G loss: 1.095065]\n",
      "[Epoch 6/200] [Batch 194/938] [D loss: 1.103438, acc: 95%] [G loss: 1.167235]\n",
      "[Epoch 6/200] [Batch 195/938] [D loss: 1.083675, acc: 96%] [G loss: 1.070302]\n",
      "[Epoch 6/200] [Batch 196/938] [D loss: 1.062042, acc: 95%] [G loss: 1.132345]\n",
      "[Epoch 6/200] [Batch 197/938] [D loss: 1.084831, acc: 96%] [G loss: 1.125510]\n",
      "[Epoch 6/200] [Batch 198/938] [D loss: 1.092359, acc: 97%] [G loss: 1.158497]\n",
      "[Epoch 6/200] [Batch 199/938] [D loss: 1.095004, acc: 96%] [G loss: 1.093250]\n",
      "[Epoch 6/200] [Batch 200/938] [D loss: 1.104095, acc: 92%] [G loss: 1.056824]\n",
      "[Epoch 6/200] [Batch 201/938] [D loss: 1.117004, acc: 94%] [G loss: 1.126556]\n",
      "[Epoch 6/200] [Batch 202/938] [D loss: 1.080517, acc: 96%] [G loss: 1.119356]\n",
      "[Epoch 6/200] [Batch 203/938] [D loss: 1.094979, acc: 96%] [G loss: 1.112453]\n",
      "[Epoch 6/200] [Batch 204/938] [D loss: 1.088394, acc: 96%] [G loss: 1.134688]\n",
      "[Epoch 6/200] [Batch 205/938] [D loss: 1.119069, acc: 96%] [G loss: 1.104705]\n",
      "[Epoch 6/200] [Batch 206/938] [D loss: 1.102208, acc: 95%] [G loss: 1.115562]\n",
      "[Epoch 6/200] [Batch 207/938] [D loss: 1.100040, acc: 92%] [G loss: 1.122082]\n",
      "[Epoch 6/200] [Batch 208/938] [D loss: 1.051107, acc: 98%] [G loss: 1.183996]\n",
      "[Epoch 6/200] [Batch 209/938] [D loss: 1.090632, acc: 93%] [G loss: 1.131671]\n",
      "[Epoch 6/200] [Batch 210/938] [D loss: 1.142616, acc: 96%] [G loss: 1.051445]\n",
      "[Epoch 6/200] [Batch 211/938] [D loss: 1.089177, acc: 92%] [G loss: 1.148930]\n",
      "[Epoch 6/200] [Batch 212/938] [D loss: 1.096384, acc: 93%] [G loss: 1.146935]\n",
      "[Epoch 6/200] [Batch 213/938] [D loss: 1.095562, acc: 97%] [G loss: 1.113033]\n",
      "[Epoch 6/200] [Batch 214/938] [D loss: 1.072225, acc: 96%] [G loss: 1.100700]\n",
      "[Epoch 6/200] [Batch 215/938] [D loss: 1.069986, acc: 96%] [G loss: 1.119859]\n",
      "[Epoch 6/200] [Batch 216/938] [D loss: 1.051928, acc: 96%] [G loss: 1.165693]\n",
      "[Epoch 6/200] [Batch 217/938] [D loss: 1.096542, acc: 92%] [G loss: 1.107687]\n",
      "[Epoch 6/200] [Batch 218/938] [D loss: 1.098542, acc: 96%] [G loss: 1.111313]\n",
      "[Epoch 6/200] [Batch 219/938] [D loss: 1.072914, acc: 96%] [G loss: 1.079412]\n",
      "[Epoch 6/200] [Batch 220/938] [D loss: 1.088602, acc: 96%] [G loss: 1.139905]\n",
      "[Epoch 6/200] [Batch 221/938] [D loss: 1.065989, acc: 96%] [G loss: 1.163175]\n",
      "[Epoch 6/200] [Batch 222/938] [D loss: 1.049028, acc: 96%] [G loss: 1.079113]\n",
      "[Epoch 6/200] [Batch 223/938] [D loss: 1.086072, acc: 92%] [G loss: 1.095410]\n",
      "[Epoch 6/200] [Batch 224/938] [D loss: 1.121693, acc: 96%] [G loss: 1.072599]\n",
      "[Epoch 6/200] [Batch 225/938] [D loss: 1.118640, acc: 96%] [G loss: 1.162691]\n",
      "[Epoch 6/200] [Batch 226/938] [D loss: 1.094584, acc: 96%] [G loss: 1.123753]\n",
      "[Epoch 6/200] [Batch 227/938] [D loss: 1.115622, acc: 92%] [G loss: 1.079728]\n",
      "[Epoch 6/200] [Batch 228/938] [D loss: 1.080983, acc: 94%] [G loss: 1.164099]\n",
      "[Epoch 6/200] [Batch 229/938] [D loss: 1.127656, acc: 95%] [G loss: 1.119751]\n",
      "[Epoch 6/200] [Batch 230/938] [D loss: 1.096084, acc: 92%] [G loss: 1.092107]\n",
      "[Epoch 6/200] [Batch 231/938] [D loss: 1.099576, acc: 96%] [G loss: 1.148465]\n",
      "[Epoch 6/200] [Batch 232/938] [D loss: 1.140234, acc: 93%] [G loss: 1.156204]\n",
      "[Epoch 6/200] [Batch 233/938] [D loss: 1.110910, acc: 95%] [G loss: 1.191924]\n",
      "[Epoch 6/200] [Batch 234/938] [D loss: 1.086327, acc: 95%] [G loss: 1.165474]\n",
      "[Epoch 6/200] [Batch 235/938] [D loss: 1.060889, acc: 96%] [G loss: 1.159739]\n",
      "[Epoch 6/200] [Batch 236/938] [D loss: 1.048074, acc: 94%] [G loss: 1.208991]\n",
      "[Epoch 6/200] [Batch 237/938] [D loss: 1.078628, acc: 94%] [G loss: 1.148461]\n",
      "[Epoch 6/200] [Batch 238/938] [D loss: 1.083188, acc: 96%] [G loss: 1.131632]\n",
      "[Epoch 6/200] [Batch 239/938] [D loss: 1.071887, acc: 99%] [G loss: 1.120974]\n",
      "[Epoch 6/200] [Batch 240/938] [D loss: 1.159570, acc: 92%] [G loss: 1.082784]\n",
      "[Epoch 6/200] [Batch 241/938] [D loss: 1.120985, acc: 95%] [G loss: 1.107445]\n",
      "[Epoch 6/200] [Batch 242/938] [D loss: 1.077618, acc: 93%] [G loss: 1.183147]\n",
      "[Epoch 6/200] [Batch 243/938] [D loss: 1.100717, acc: 96%] [G loss: 1.159832]\n",
      "[Epoch 6/200] [Batch 244/938] [D loss: 1.087029, acc: 98%] [G loss: 1.134863]\n",
      "[Epoch 6/200] [Batch 245/938] [D loss: 1.109275, acc: 97%] [G loss: 1.068485]\n",
      "[Epoch 6/200] [Batch 246/938] [D loss: 1.127620, acc: 95%] [G loss: 1.107790]\n",
      "[Epoch 6/200] [Batch 247/938] [D loss: 1.095088, acc: 92%] [G loss: 1.079884]\n",
      "[Epoch 6/200] [Batch 248/938] [D loss: 1.065161, acc: 96%] [G loss: 1.164732]\n",
      "[Epoch 6/200] [Batch 249/938] [D loss: 1.103121, acc: 96%] [G loss: 1.127915]\n",
      "[Epoch 6/200] [Batch 250/938] [D loss: 1.081105, acc: 99%] [G loss: 1.089978]\n",
      "[Epoch 6/200] [Batch 251/938] [D loss: 1.103479, acc: 94%] [G loss: 1.143699]\n",
      "[Epoch 6/200] [Batch 252/938] [D loss: 1.073076, acc: 96%] [G loss: 1.111538]\n",
      "[Epoch 6/200] [Batch 253/938] [D loss: 1.136141, acc: 97%] [G loss: 1.138611]\n",
      "[Epoch 6/200] [Batch 254/938] [D loss: 1.090919, acc: 96%] [G loss: 1.192212]\n",
      "[Epoch 6/200] [Batch 255/938] [D loss: 1.080050, acc: 98%] [G loss: 1.125667]\n",
      "[Epoch 6/200] [Batch 256/938] [D loss: 1.094828, acc: 96%] [G loss: 1.123056]\n",
      "[Epoch 6/200] [Batch 257/938] [D loss: 1.106321, acc: 95%] [G loss: 1.069227]\n",
      "[Epoch 6/200] [Batch 258/938] [D loss: 1.081402, acc: 94%] [G loss: 1.099745]\n",
      "[Epoch 6/200] [Batch 259/938] [D loss: 1.083177, acc: 92%] [G loss: 1.061595]\n",
      "[Epoch 6/200] [Batch 260/938] [D loss: 1.076345, acc: 97%] [G loss: 1.152384]\n",
      "[Epoch 6/200] [Batch 261/938] [D loss: 1.114913, acc: 91%] [G loss: 1.148202]\n",
      "[Epoch 6/200] [Batch 262/938] [D loss: 1.121223, acc: 94%] [G loss: 1.075662]\n",
      "[Epoch 6/200] [Batch 263/938] [D loss: 1.032381, acc: 98%] [G loss: 1.129950]\n",
      "[Epoch 6/200] [Batch 264/938] [D loss: 1.081706, acc: 97%] [G loss: 1.095352]\n",
      "[Epoch 6/200] [Batch 265/938] [D loss: 1.071072, acc: 96%] [G loss: 1.172201]\n",
      "[Epoch 6/200] [Batch 266/938] [D loss: 1.089694, acc: 96%] [G loss: 1.179767]\n",
      "[Epoch 6/200] [Batch 267/938] [D loss: 1.101617, acc: 95%] [G loss: 1.161262]\n",
      "[Epoch 6/200] [Batch 268/938] [D loss: 1.107182, acc: 93%] [G loss: 1.102834]\n",
      "[Epoch 6/200] [Batch 269/938] [D loss: 1.061453, acc: 98%] [G loss: 1.162439]\n",
      "[Epoch 6/200] [Batch 270/938] [D loss: 1.072142, acc: 97%] [G loss: 1.097100]\n",
      "[Epoch 6/200] [Batch 271/938] [D loss: 1.119971, acc: 96%] [G loss: 1.085756]\n",
      "[Epoch 6/200] [Batch 272/938] [D loss: 1.115687, acc: 96%] [G loss: 1.069961]\n",
      "[Epoch 6/200] [Batch 273/938] [D loss: 1.084952, acc: 96%] [G loss: 1.098792]\n",
      "[Epoch 6/200] [Batch 274/938] [D loss: 1.095408, acc: 98%] [G loss: 1.087428]\n",
      "[Epoch 6/200] [Batch 275/938] [D loss: 1.095870, acc: 97%] [G loss: 1.119178]\n",
      "[Epoch 6/200] [Batch 276/938] [D loss: 1.101223, acc: 95%] [G loss: 1.116013]\n",
      "[Epoch 6/200] [Batch 277/938] [D loss: 1.102284, acc: 96%] [G loss: 1.081003]\n",
      "[Epoch 6/200] [Batch 278/938] [D loss: 1.096608, acc: 96%] [G loss: 1.104863]\n",
      "[Epoch 6/200] [Batch 279/938] [D loss: 1.092209, acc: 94%] [G loss: 1.115324]\n",
      "[Epoch 6/200] [Batch 280/938] [D loss: 1.104398, acc: 95%] [G loss: 1.106182]\n",
      "[Epoch 6/200] [Batch 281/938] [D loss: 1.110717, acc: 97%] [G loss: 1.127529]\n",
      "[Epoch 6/200] [Batch 282/938] [D loss: 1.086338, acc: 96%] [G loss: 1.061037]\n",
      "[Epoch 6/200] [Batch 283/938] [D loss: 1.047603, acc: 96%] [G loss: 1.102862]\n",
      "[Epoch 6/200] [Batch 284/938] [D loss: 1.114147, acc: 93%] [G loss: 1.069354]\n",
      "[Epoch 6/200] [Batch 285/938] [D loss: 1.069821, acc: 95%] [G loss: 1.138241]\n",
      "[Epoch 6/200] [Batch 286/938] [D loss: 1.049375, acc: 95%] [G loss: 1.160348]\n",
      "[Epoch 6/200] [Batch 287/938] [D loss: 1.109041, acc: 94%] [G loss: 1.099106]\n",
      "[Epoch 6/200] [Batch 288/938] [D loss: 1.109905, acc: 93%] [G loss: 1.138643]\n",
      "[Epoch 6/200] [Batch 289/938] [D loss: 1.100396, acc: 96%] [G loss: 1.210281]\n",
      "[Epoch 6/200] [Batch 290/938] [D loss: 1.083306, acc: 96%] [G loss: 1.201950]\n",
      "[Epoch 6/200] [Batch 291/938] [D loss: 1.062957, acc: 98%] [G loss: 1.135738]\n",
      "[Epoch 6/200] [Batch 292/938] [D loss: 1.104373, acc: 96%] [G loss: 1.170249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 293/938] [D loss: 1.120902, acc: 98%] [G loss: 1.129943]\n",
      "[Epoch 6/200] [Batch 294/938] [D loss: 1.101326, acc: 96%] [G loss: 1.070789]\n",
      "[Epoch 6/200] [Batch 295/938] [D loss: 1.091075, acc: 96%] [G loss: 1.129466]\n",
      "[Epoch 6/200] [Batch 296/938] [D loss: 1.087779, acc: 92%] [G loss: 1.112075]\n",
      "[Epoch 6/200] [Batch 297/938] [D loss: 1.096422, acc: 94%] [G loss: 1.095911]\n",
      "[Epoch 6/200] [Batch 298/938] [D loss: 1.116364, acc: 95%] [G loss: 1.079789]\n",
      "[Epoch 6/200] [Batch 299/938] [D loss: 1.084290, acc: 96%] [G loss: 1.138856]\n",
      "[Epoch 6/200] [Batch 300/938] [D loss: 1.068463, acc: 96%] [G loss: 1.156115]\n",
      "[Epoch 6/200] [Batch 301/938] [D loss: 1.073157, acc: 98%] [G loss: 1.122078]\n",
      "[Epoch 6/200] [Batch 302/938] [D loss: 1.078423, acc: 96%] [G loss: 1.151510]\n",
      "[Epoch 6/200] [Batch 303/938] [D loss: 1.098419, acc: 95%] [G loss: 1.123295]\n",
      "[Epoch 6/200] [Batch 304/938] [D loss: 1.094256, acc: 92%] [G loss: 1.120557]\n",
      "[Epoch 6/200] [Batch 305/938] [D loss: 1.090903, acc: 96%] [G loss: 1.095882]\n",
      "[Epoch 6/200] [Batch 306/938] [D loss: 1.066286, acc: 98%] [G loss: 1.111139]\n",
      "[Epoch 6/200] [Batch 307/938] [D loss: 1.038205, acc: 96%] [G loss: 1.152541]\n",
      "[Epoch 6/200] [Batch 308/938] [D loss: 1.114421, acc: 96%] [G loss: 1.152550]\n",
      "[Epoch 6/200] [Batch 309/938] [D loss: 1.109266, acc: 96%] [G loss: 1.135140]\n",
      "[Epoch 6/200] [Batch 310/938] [D loss: 1.077961, acc: 100%] [G loss: 1.092227]\n",
      "[Epoch 6/200] [Batch 311/938] [D loss: 1.086339, acc: 95%] [G loss: 1.059587]\n",
      "[Epoch 6/200] [Batch 312/938] [D loss: 1.096565, acc: 93%] [G loss: 1.075155]\n",
      "[Epoch 6/200] [Batch 313/938] [D loss: 1.085883, acc: 97%] [G loss: 1.079499]\n",
      "[Epoch 6/200] [Batch 314/938] [D loss: 1.096080, acc: 92%] [G loss: 1.113536]\n",
      "[Epoch 6/200] [Batch 315/938] [D loss: 1.087757, acc: 92%] [G loss: 1.128849]\n",
      "[Epoch 6/200] [Batch 316/938] [D loss: 1.088546, acc: 94%] [G loss: 1.110984]\n",
      "[Epoch 6/200] [Batch 317/938] [D loss: 1.098403, acc: 92%] [G loss: 1.102437]\n",
      "[Epoch 6/200] [Batch 318/938] [D loss: 1.074212, acc: 96%] [G loss: 1.052390]\n",
      "[Epoch 6/200] [Batch 319/938] [D loss: 1.067698, acc: 93%] [G loss: 1.089635]\n",
      "[Epoch 6/200] [Batch 320/938] [D loss: 1.104559, acc: 95%] [G loss: 1.136698]\n",
      "[Epoch 6/200] [Batch 321/938] [D loss: 1.087330, acc: 95%] [G loss: 1.110212]\n",
      "[Epoch 6/200] [Batch 322/938] [D loss: 1.094972, acc: 95%] [G loss: 1.089601]\n",
      "[Epoch 6/200] [Batch 323/938] [D loss: 1.120948, acc: 92%] [G loss: 1.139127]\n",
      "[Epoch 6/200] [Batch 324/938] [D loss: 1.132232, acc: 89%] [G loss: 1.072351]\n",
      "[Epoch 6/200] [Batch 325/938] [D loss: 1.079911, acc: 96%] [G loss: 1.133246]\n",
      "[Epoch 6/200] [Batch 326/938] [D loss: 1.097825, acc: 92%] [G loss: 1.074274]\n",
      "[Epoch 6/200] [Batch 327/938] [D loss: 1.131713, acc: 96%] [G loss: 1.102366]\n",
      "[Epoch 6/200] [Batch 328/938] [D loss: 1.109861, acc: 92%] [G loss: 1.175835]\n",
      "[Epoch 6/200] [Batch 329/938] [D loss: 1.075406, acc: 94%] [G loss: 1.128060]\n",
      "[Epoch 6/200] [Batch 330/938] [D loss: 1.074641, acc: 98%] [G loss: 1.062888]\n",
      "[Epoch 6/200] [Batch 331/938] [D loss: 1.111440, acc: 92%] [G loss: 1.104068]\n",
      "[Epoch 6/200] [Batch 332/938] [D loss: 1.123707, acc: 95%] [G loss: 1.097145]\n",
      "[Epoch 6/200] [Batch 333/938] [D loss: 1.088016, acc: 96%] [G loss: 1.097332]\n",
      "[Epoch 6/200] [Batch 334/938] [D loss: 1.064703, acc: 96%] [G loss: 1.097675]\n",
      "[Epoch 6/200] [Batch 335/938] [D loss: 1.066428, acc: 97%] [G loss: 1.129903]\n",
      "[Epoch 6/200] [Batch 336/938] [D loss: 1.116426, acc: 96%] [G loss: 1.053371]\n",
      "[Epoch 6/200] [Batch 337/938] [D loss: 1.083934, acc: 97%] [G loss: 1.081081]\n",
      "[Epoch 6/200] [Batch 338/938] [D loss: 1.109268, acc: 95%] [G loss: 1.093076]\n",
      "[Epoch 6/200] [Batch 339/938] [D loss: 1.121209, acc: 96%] [G loss: 1.010016]\n",
      "[Epoch 6/200] [Batch 340/938] [D loss: 1.079145, acc: 93%] [G loss: 1.114872]\n",
      "[Epoch 6/200] [Batch 341/938] [D loss: 1.038526, acc: 99%] [G loss: 1.083852]\n",
      "[Epoch 6/200] [Batch 342/938] [D loss: 1.090260, acc: 94%] [G loss: 1.117629]\n",
      "[Epoch 6/200] [Batch 343/938] [D loss: 1.113825, acc: 94%] [G loss: 1.124993]\n",
      "[Epoch 6/200] [Batch 344/938] [D loss: 1.081933, acc: 97%] [G loss: 1.130635]\n",
      "[Epoch 6/200] [Batch 345/938] [D loss: 1.098345, acc: 95%] [G loss: 1.113584]\n",
      "[Epoch 6/200] [Batch 346/938] [D loss: 1.070869, acc: 96%] [G loss: 1.066115]\n",
      "[Epoch 6/200] [Batch 347/938] [D loss: 1.095959, acc: 96%] [G loss: 1.255555]\n",
      "[Epoch 6/200] [Batch 348/938] [D loss: 1.112364, acc: 92%] [G loss: 1.125064]\n",
      "[Epoch 6/200] [Batch 349/938] [D loss: 1.095014, acc: 95%] [G loss: 1.156936]\n",
      "[Epoch 6/200] [Batch 350/938] [D loss: 1.096771, acc: 97%] [G loss: 1.132761]\n",
      "[Epoch 6/200] [Batch 351/938] [D loss: 1.094869, acc: 99%] [G loss: 1.068581]\n",
      "[Epoch 6/200] [Batch 352/938] [D loss: 1.080440, acc: 94%] [G loss: 1.186150]\n",
      "[Epoch 6/200] [Batch 353/938] [D loss: 1.106347, acc: 91%] [G loss: 1.106883]\n",
      "[Epoch 6/200] [Batch 354/938] [D loss: 1.092214, acc: 96%] [G loss: 1.077740]\n",
      "[Epoch 6/200] [Batch 355/938] [D loss: 1.117048, acc: 95%] [G loss: 1.122437]\n",
      "[Epoch 6/200] [Batch 356/938] [D loss: 1.070176, acc: 95%] [G loss: 1.222400]\n",
      "[Epoch 6/200] [Batch 357/938] [D loss: 1.085523, acc: 96%] [G loss: 1.155555]\n",
      "[Epoch 6/200] [Batch 358/938] [D loss: 1.096067, acc: 96%] [G loss: 1.116193]\n",
      "[Epoch 6/200] [Batch 359/938] [D loss: 1.109077, acc: 96%] [G loss: 1.125056]\n",
      "[Epoch 6/200] [Batch 360/938] [D loss: 1.101070, acc: 97%] [G loss: 1.130728]\n",
      "[Epoch 6/200] [Batch 361/938] [D loss: 1.082949, acc: 96%] [G loss: 1.174583]\n",
      "[Epoch 6/200] [Batch 362/938] [D loss: 1.122267, acc: 92%] [G loss: 1.114583]\n",
      "[Epoch 6/200] [Batch 363/938] [D loss: 1.077300, acc: 96%] [G loss: 1.109991]\n",
      "[Epoch 6/200] [Batch 364/938] [D loss: 1.109280, acc: 92%] [G loss: 1.146205]\n",
      "[Epoch 6/200] [Batch 365/938] [D loss: 1.111486, acc: 96%] [G loss: 1.160327]\n",
      "[Epoch 6/200] [Batch 366/938] [D loss: 1.062695, acc: 99%] [G loss: 1.178351]\n",
      "[Epoch 6/200] [Batch 367/938] [D loss: 1.153633, acc: 92%] [G loss: 1.005827]\n",
      "[Epoch 6/200] [Batch 368/938] [D loss: 1.064486, acc: 96%] [G loss: 1.184378]\n",
      "[Epoch 6/200] [Batch 369/938] [D loss: 1.076547, acc: 96%] [G loss: 1.119298]\n",
      "[Epoch 6/200] [Batch 370/938] [D loss: 1.089072, acc: 92%] [G loss: 1.111093]\n",
      "[Epoch 6/200] [Batch 371/938] [D loss: 1.112243, acc: 95%] [G loss: 1.127120]\n",
      "[Epoch 6/200] [Batch 372/938] [D loss: 1.094264, acc: 96%] [G loss: 1.068850]\n",
      "[Epoch 6/200] [Batch 373/938] [D loss: 1.114339, acc: 93%] [G loss: 1.135342]\n",
      "[Epoch 6/200] [Batch 374/938] [D loss: 1.079198, acc: 96%] [G loss: 1.161443]\n",
      "[Epoch 6/200] [Batch 375/938] [D loss: 1.062472, acc: 97%] [G loss: 1.088802]\n",
      "[Epoch 6/200] [Batch 376/938] [D loss: 1.067050, acc: 96%] [G loss: 1.103832]\n",
      "[Epoch 6/200] [Batch 377/938] [D loss: 1.079945, acc: 97%] [G loss: 1.108556]\n",
      "[Epoch 6/200] [Batch 378/938] [D loss: 1.092832, acc: 96%] [G loss: 1.078709]\n",
      "[Epoch 6/200] [Batch 379/938] [D loss: 1.119609, acc: 93%] [G loss: 1.084047]\n",
      "[Epoch 6/200] [Batch 380/938] [D loss: 1.082670, acc: 93%] [G loss: 1.081470]\n",
      "[Epoch 6/200] [Batch 381/938] [D loss: 1.083434, acc: 96%] [G loss: 1.090506]\n",
      "[Epoch 6/200] [Batch 382/938] [D loss: 1.118227, acc: 96%] [G loss: 1.134314]\n",
      "[Epoch 6/200] [Batch 383/938] [D loss: 1.075592, acc: 97%] [G loss: 1.063566]\n",
      "[Epoch 6/200] [Batch 384/938] [D loss: 1.055428, acc: 96%] [G loss: 1.152048]\n",
      "[Epoch 6/200] [Batch 385/938] [D loss: 1.045131, acc: 96%] [G loss: 1.176214]\n",
      "[Epoch 6/200] [Batch 386/938] [D loss: 1.113413, acc: 95%] [G loss: 1.196862]\n",
      "[Epoch 6/200] [Batch 387/938] [D loss: 1.081598, acc: 95%] [G loss: 1.180040]\n",
      "[Epoch 6/200] [Batch 388/938] [D loss: 1.099428, acc: 97%] [G loss: 1.153345]\n",
      "[Epoch 6/200] [Batch 389/938] [D loss: 1.085292, acc: 95%] [G loss: 1.081127]\n",
      "[Epoch 6/200] [Batch 390/938] [D loss: 1.062644, acc: 98%] [G loss: 1.084323]\n",
      "[Epoch 6/200] [Batch 391/938] [D loss: 1.086966, acc: 93%] [G loss: 1.122699]\n",
      "[Epoch 6/200] [Batch 392/938] [D loss: 1.085138, acc: 97%] [G loss: 1.173317]\n",
      "[Epoch 6/200] [Batch 393/938] [D loss: 1.133087, acc: 94%] [G loss: 1.115774]\n",
      "[Epoch 6/200] [Batch 394/938] [D loss: 1.097755, acc: 94%] [G loss: 1.171190]\n",
      "[Epoch 6/200] [Batch 395/938] [D loss: 1.081071, acc: 95%] [G loss: 1.145091]\n",
      "[Epoch 6/200] [Batch 396/938] [D loss: 1.046705, acc: 99%] [G loss: 1.051626]\n",
      "[Epoch 6/200] [Batch 397/938] [D loss: 1.107303, acc: 96%] [G loss: 1.150774]\n",
      "[Epoch 6/200] [Batch 398/938] [D loss: 1.080054, acc: 96%] [G loss: 1.144898]\n",
      "[Epoch 6/200] [Batch 399/938] [D loss: 1.079879, acc: 96%] [G loss: 1.194507]\n",
      "[Epoch 6/200] [Batch 400/938] [D loss: 1.112953, acc: 95%] [G loss: 1.077108]\n",
      "[Epoch 6/200] [Batch 401/938] [D loss: 1.102765, acc: 93%] [G loss: 1.091512]\n",
      "[Epoch 6/200] [Batch 402/938] [D loss: 1.083294, acc: 97%] [G loss: 1.085016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 403/938] [D loss: 1.069967, acc: 96%] [G loss: 1.133379]\n",
      "[Epoch 6/200] [Batch 404/938] [D loss: 1.091204, acc: 94%] [G loss: 1.170781]\n",
      "[Epoch 6/200] [Batch 405/938] [D loss: 1.103088, acc: 96%] [G loss: 1.086665]\n",
      "[Epoch 6/200] [Batch 406/938] [D loss: 1.081431, acc: 97%] [G loss: 1.081955]\n",
      "[Epoch 6/200] [Batch 407/938] [D loss: 1.080087, acc: 97%] [G loss: 1.119401]\n",
      "[Epoch 6/200] [Batch 408/938] [D loss: 1.103127, acc: 99%] [G loss: 1.096189]\n",
      "[Epoch 6/200] [Batch 409/938] [D loss: 1.084679, acc: 95%] [G loss: 1.119458]\n",
      "[Epoch 6/200] [Batch 410/938] [D loss: 1.047920, acc: 96%] [G loss: 1.181354]\n",
      "[Epoch 6/200] [Batch 411/938] [D loss: 1.133272, acc: 94%] [G loss: 1.146158]\n",
      "[Epoch 6/200] [Batch 412/938] [D loss: 1.120526, acc: 94%] [G loss: 1.162112]\n",
      "[Epoch 6/200] [Batch 413/938] [D loss: 1.095338, acc: 95%] [G loss: 1.133860]\n",
      "[Epoch 6/200] [Batch 414/938] [D loss: 1.110831, acc: 97%] [G loss: 1.082381]\n",
      "[Epoch 6/200] [Batch 415/938] [D loss: 1.077509, acc: 97%] [G loss: 1.090765]\n",
      "[Epoch 6/200] [Batch 416/938] [D loss: 1.149517, acc: 93%] [G loss: 1.142841]\n",
      "[Epoch 6/200] [Batch 417/938] [D loss: 1.106493, acc: 96%] [G loss: 1.099376]\n",
      "[Epoch 6/200] [Batch 418/938] [D loss: 1.094075, acc: 96%] [G loss: 1.060359]\n",
      "[Epoch 6/200] [Batch 419/938] [D loss: 1.099375, acc: 91%] [G loss: 1.162573]\n",
      "[Epoch 6/200] [Batch 420/938] [D loss: 1.115643, acc: 94%] [G loss: 1.114609]\n",
      "[Epoch 6/200] [Batch 421/938] [D loss: 1.069867, acc: 96%] [G loss: 1.088642]\n",
      "[Epoch 6/200] [Batch 422/938] [D loss: 1.118473, acc: 93%] [G loss: 1.135735]\n",
      "[Epoch 6/200] [Batch 423/938] [D loss: 1.107987, acc: 94%] [G loss: 1.160315]\n",
      "[Epoch 6/200] [Batch 424/938] [D loss: 1.083172, acc: 96%] [G loss: 1.054196]\n",
      "[Epoch 6/200] [Batch 425/938] [D loss: 1.094811, acc: 96%] [G loss: 1.069382]\n",
      "[Epoch 6/200] [Batch 426/938] [D loss: 1.104683, acc: 96%] [G loss: 1.101839]\n",
      "[Epoch 6/200] [Batch 427/938] [D loss: 1.072176, acc: 98%] [G loss: 1.109235]\n",
      "[Epoch 6/200] [Batch 428/938] [D loss: 1.057115, acc: 97%] [G loss: 1.103401]\n",
      "[Epoch 6/200] [Batch 429/938] [D loss: 1.095094, acc: 95%] [G loss: 1.185073]\n",
      "[Epoch 6/200] [Batch 430/938] [D loss: 1.106798, acc: 92%] [G loss: 1.160797]\n",
      "[Epoch 6/200] [Batch 431/938] [D loss: 1.051008, acc: 94%] [G loss: 1.111878]\n",
      "[Epoch 6/200] [Batch 432/938] [D loss: 1.074674, acc: 96%] [G loss: 1.131776]\n",
      "[Epoch 6/200] [Batch 433/938] [D loss: 1.069569, acc: 93%] [G loss: 1.157273]\n",
      "[Epoch 6/200] [Batch 434/938] [D loss: 1.111971, acc: 97%] [G loss: 1.130558]\n",
      "[Epoch 6/200] [Batch 435/938] [D loss: 1.108269, acc: 96%] [G loss: 1.149541]\n",
      "[Epoch 6/200] [Batch 436/938] [D loss: 1.071175, acc: 96%] [G loss: 1.101398]\n",
      "[Epoch 6/200] [Batch 437/938] [D loss: 1.070873, acc: 96%] [G loss: 1.105412]\n",
      "[Epoch 6/200] [Batch 438/938] [D loss: 1.099170, acc: 95%] [G loss: 1.141924]\n",
      "[Epoch 6/200] [Batch 439/938] [D loss: 1.060563, acc: 98%] [G loss: 1.125269]\n",
      "[Epoch 6/200] [Batch 440/938] [D loss: 1.102581, acc: 97%] [G loss: 1.125423]\n",
      "[Epoch 6/200] [Batch 441/938] [D loss: 1.084428, acc: 96%] [G loss: 1.081223]\n",
      "[Epoch 6/200] [Batch 442/938] [D loss: 1.117080, acc: 95%] [G loss: 1.145658]\n",
      "[Epoch 6/200] [Batch 443/938] [D loss: 1.157877, acc: 97%] [G loss: 1.086465]\n",
      "[Epoch 6/200] [Batch 444/938] [D loss: 1.098393, acc: 95%] [G loss: 1.131762]\n",
      "[Epoch 6/200] [Batch 445/938] [D loss: 1.103510, acc: 96%] [G loss: 1.111098]\n",
      "[Epoch 6/200] [Batch 446/938] [D loss: 1.101702, acc: 96%] [G loss: 1.160011]\n",
      "[Epoch 6/200] [Batch 447/938] [D loss: 1.062012, acc: 97%] [G loss: 1.109769]\n",
      "[Epoch 6/200] [Batch 448/938] [D loss: 1.057936, acc: 98%] [G loss: 1.085104]\n",
      "[Epoch 6/200] [Batch 449/938] [D loss: 1.107562, acc: 96%] [G loss: 1.110468]\n",
      "[Epoch 6/200] [Batch 450/938] [D loss: 1.093300, acc: 94%] [G loss: 1.169975]\n",
      "[Epoch 6/200] [Batch 451/938] [D loss: 1.109710, acc: 95%] [G loss: 1.231519]\n",
      "[Epoch 6/200] [Batch 452/938] [D loss: 1.109933, acc: 96%] [G loss: 1.142579]\n",
      "[Epoch 6/200] [Batch 453/938] [D loss: 1.095520, acc: 94%] [G loss: 1.112576]\n",
      "[Epoch 6/200] [Batch 454/938] [D loss: 1.093067, acc: 95%] [G loss: 1.078706]\n",
      "[Epoch 6/200] [Batch 455/938] [D loss: 1.086280, acc: 96%] [G loss: 1.170262]\n",
      "[Epoch 6/200] [Batch 456/938] [D loss: 1.102809, acc: 98%] [G loss: 1.138935]\n",
      "[Epoch 6/200] [Batch 457/938] [D loss: 1.086689, acc: 93%] [G loss: 1.092711]\n",
      "[Epoch 6/200] [Batch 458/938] [D loss: 1.078111, acc: 96%] [G loss: 1.113907]\n",
      "[Epoch 6/200] [Batch 459/938] [D loss: 1.103263, acc: 94%] [G loss: 1.152737]\n",
      "[Epoch 6/200] [Batch 460/938] [D loss: 1.105182, acc: 97%] [G loss: 1.134865]\n",
      "[Epoch 6/200] [Batch 461/938] [D loss: 1.127474, acc: 94%] [G loss: 1.130543]\n",
      "[Epoch 6/200] [Batch 462/938] [D loss: 1.070650, acc: 96%] [G loss: 1.031200]\n",
      "[Epoch 6/200] [Batch 463/938] [D loss: 1.138068, acc: 96%] [G loss: 1.077535]\n",
      "[Epoch 6/200] [Batch 464/938] [D loss: 1.107044, acc: 94%] [G loss: 1.133788]\n",
      "[Epoch 6/200] [Batch 465/938] [D loss: 1.089478, acc: 96%] [G loss: 1.152868]\n",
      "[Epoch 6/200] [Batch 466/938] [D loss: 1.104426, acc: 94%] [G loss: 1.122686]\n",
      "[Epoch 6/200] [Batch 467/938] [D loss: 1.080834, acc: 95%] [G loss: 1.167281]\n",
      "[Epoch 6/200] [Batch 468/938] [D loss: 1.090893, acc: 92%] [G loss: 1.107581]\n",
      "[Epoch 6/200] [Batch 469/938] [D loss: 1.046591, acc: 98%] [G loss: 1.096041]\n",
      "[Epoch 6/200] [Batch 470/938] [D loss: 1.096052, acc: 96%] [G loss: 1.135158]\n",
      "[Epoch 6/200] [Batch 471/938] [D loss: 1.085732, acc: 99%] [G loss: 1.088998]\n",
      "[Epoch 6/200] [Batch 472/938] [D loss: 1.060192, acc: 96%] [G loss: 1.076512]\n",
      "[Epoch 6/200] [Batch 473/938] [D loss: 1.104622, acc: 96%] [G loss: 1.088432]\n",
      "[Epoch 6/200] [Batch 474/938] [D loss: 1.063285, acc: 96%] [G loss: 1.137917]\n",
      "[Epoch 6/200] [Batch 475/938] [D loss: 1.080131, acc: 96%] [G loss: 1.078717]\n",
      "[Epoch 6/200] [Batch 476/938] [D loss: 1.064270, acc: 94%] [G loss: 1.100085]\n",
      "[Epoch 6/200] [Batch 477/938] [D loss: 1.131512, acc: 94%] [G loss: 1.079049]\n",
      "[Epoch 6/200] [Batch 478/938] [D loss: 1.067922, acc: 96%] [G loss: 1.106359]\n",
      "[Epoch 6/200] [Batch 479/938] [D loss: 1.101338, acc: 95%] [G loss: 1.133090]\n",
      "[Epoch 6/200] [Batch 480/938] [D loss: 1.085016, acc: 92%] [G loss: 1.159620]\n",
      "[Epoch 6/200] [Batch 481/938] [D loss: 1.083534, acc: 96%] [G loss: 1.174480]\n",
      "[Epoch 6/200] [Batch 482/938] [D loss: 1.075578, acc: 98%] [G loss: 1.089711]\n",
      "[Epoch 6/200] [Batch 483/938] [D loss: 1.088899, acc: 93%] [G loss: 1.088983]\n",
      "[Epoch 6/200] [Batch 484/938] [D loss: 1.092238, acc: 92%] [G loss: 1.130956]\n",
      "[Epoch 6/200] [Batch 485/938] [D loss: 1.155855, acc: 92%] [G loss: 1.128809]\n",
      "[Epoch 6/200] [Batch 486/938] [D loss: 1.067636, acc: 98%] [G loss: 1.127748]\n",
      "[Epoch 6/200] [Batch 487/938] [D loss: 1.077176, acc: 98%] [G loss: 1.120660]\n",
      "[Epoch 6/200] [Batch 488/938] [D loss: 1.111691, acc: 96%] [G loss: 1.142983]\n",
      "[Epoch 6/200] [Batch 489/938] [D loss: 1.124550, acc: 94%] [G loss: 1.121676]\n",
      "[Epoch 6/200] [Batch 490/938] [D loss: 1.091190, acc: 95%] [G loss: 1.103971]\n",
      "[Epoch 6/200] [Batch 491/938] [D loss: 1.083193, acc: 93%] [G loss: 1.186549]\n",
      "[Epoch 6/200] [Batch 492/938] [D loss: 1.078153, acc: 95%] [G loss: 1.187265]\n",
      "[Epoch 6/200] [Batch 493/938] [D loss: 1.113559, acc: 95%] [G loss: 1.152423]\n",
      "[Epoch 6/200] [Batch 494/938] [D loss: 1.110186, acc: 93%] [G loss: 1.057198]\n",
      "[Epoch 6/200] [Batch 495/938] [D loss: 1.103790, acc: 94%] [G loss: 1.124355]\n",
      "[Epoch 6/200] [Batch 496/938] [D loss: 1.102834, acc: 97%] [G loss: 1.072333]\n",
      "[Epoch 6/200] [Batch 497/938] [D loss: 1.106464, acc: 93%] [G loss: 1.135437]\n",
      "[Epoch 6/200] [Batch 498/938] [D loss: 1.060333, acc: 95%] [G loss: 1.141954]\n",
      "[Epoch 6/200] [Batch 499/938] [D loss: 1.108723, acc: 94%] [G loss: 1.175996]\n",
      "[Epoch 6/200] [Batch 500/938] [D loss: 1.108682, acc: 96%] [G loss: 1.128413]\n",
      "[Epoch 6/200] [Batch 501/938] [D loss: 1.116483, acc: 91%] [G loss: 1.124367]\n",
      "[Epoch 6/200] [Batch 502/938] [D loss: 1.066448, acc: 98%] [G loss: 1.100348]\n",
      "[Epoch 6/200] [Batch 503/938] [D loss: 1.067081, acc: 97%] [G loss: 1.219280]\n",
      "[Epoch 6/200] [Batch 504/938] [D loss: 1.072658, acc: 98%] [G loss: 1.079178]\n",
      "[Epoch 6/200] [Batch 505/938] [D loss: 1.074239, acc: 97%] [G loss: 1.084999]\n",
      "[Epoch 6/200] [Batch 506/938] [D loss: 1.107880, acc: 96%] [G loss: 1.089881]\n",
      "[Epoch 6/200] [Batch 507/938] [D loss: 1.093217, acc: 96%] [G loss: 1.107121]\n",
      "[Epoch 6/200] [Batch 508/938] [D loss: 1.074769, acc: 96%] [G loss: 1.115569]\n",
      "[Epoch 6/200] [Batch 509/938] [D loss: 1.099930, acc: 96%] [G loss: 1.113435]\n",
      "[Epoch 6/200] [Batch 510/938] [D loss: 1.095594, acc: 93%] [G loss: 1.193432]\n",
      "[Epoch 6/200] [Batch 511/938] [D loss: 1.070239, acc: 96%] [G loss: 1.166060]\n",
      "[Epoch 6/200] [Batch 512/938] [D loss: 1.087306, acc: 96%] [G loss: 1.103857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 513/938] [D loss: 1.098381, acc: 97%] [G loss: 1.103164]\n",
      "[Epoch 6/200] [Batch 514/938] [D loss: 1.105100, acc: 96%] [G loss: 1.126282]\n",
      "[Epoch 6/200] [Batch 515/938] [D loss: 1.098728, acc: 98%] [G loss: 1.153095]\n",
      "[Epoch 6/200] [Batch 516/938] [D loss: 1.098388, acc: 94%] [G loss: 1.105345]\n",
      "[Epoch 6/200] [Batch 517/938] [D loss: 1.100618, acc: 95%] [G loss: 1.137273]\n",
      "[Epoch 6/200] [Batch 518/938] [D loss: 1.080213, acc: 95%] [G loss: 1.090359]\n",
      "[Epoch 6/200] [Batch 519/938] [D loss: 1.090585, acc: 96%] [G loss: 1.125310]\n",
      "[Epoch 6/200] [Batch 520/938] [D loss: 1.104526, acc: 95%] [G loss: 1.137575]\n",
      "[Epoch 6/200] [Batch 521/938] [D loss: 1.096662, acc: 98%] [G loss: 1.119796]\n",
      "[Epoch 6/200] [Batch 522/938] [D loss: 1.083442, acc: 93%] [G loss: 1.081057]\n",
      "[Epoch 6/200] [Batch 523/938] [D loss: 1.111152, acc: 96%] [G loss: 1.084127]\n",
      "[Epoch 6/200] [Batch 524/938] [D loss: 1.089628, acc: 94%] [G loss: 1.066516]\n",
      "[Epoch 6/200] [Batch 525/938] [D loss: 1.118158, acc: 96%] [G loss: 1.164762]\n",
      "[Epoch 6/200] [Batch 526/938] [D loss: 1.102558, acc: 95%] [G loss: 1.150413]\n",
      "[Epoch 6/200] [Batch 527/938] [D loss: 1.079152, acc: 96%] [G loss: 1.117440]\n",
      "[Epoch 6/200] [Batch 528/938] [D loss: 1.068708, acc: 98%] [G loss: 1.103016]\n",
      "[Epoch 6/200] [Batch 529/938] [D loss: 1.099721, acc: 95%] [G loss: 1.104055]\n",
      "[Epoch 6/200] [Batch 530/938] [D loss: 1.140974, acc: 96%] [G loss: 1.056718]\n",
      "[Epoch 6/200] [Batch 531/938] [D loss: 1.102731, acc: 95%] [G loss: 1.136145]\n",
      "[Epoch 6/200] [Batch 532/938] [D loss: 1.103644, acc: 97%] [G loss: 1.162989]\n",
      "[Epoch 6/200] [Batch 533/938] [D loss: 1.083077, acc: 95%] [G loss: 1.135972]\n",
      "[Epoch 6/200] [Batch 534/938] [D loss: 1.076413, acc: 93%] [G loss: 1.159023]\n",
      "[Epoch 6/200] [Batch 535/938] [D loss: 1.069884, acc: 96%] [G loss: 1.109402]\n",
      "[Epoch 6/200] [Batch 536/938] [D loss: 1.098595, acc: 92%] [G loss: 1.109628]\n",
      "[Epoch 6/200] [Batch 537/938] [D loss: 1.061588, acc: 94%] [G loss: 1.098122]\n",
      "[Epoch 6/200] [Batch 538/938] [D loss: 1.064194, acc: 97%] [G loss: 1.182741]\n",
      "[Epoch 6/200] [Batch 539/938] [D loss: 1.080918, acc: 94%] [G loss: 1.165235]\n",
      "[Epoch 6/200] [Batch 540/938] [D loss: 1.078524, acc: 96%] [G loss: 1.170500]\n",
      "[Epoch 6/200] [Batch 541/938] [D loss: 1.114656, acc: 97%] [G loss: 1.191094]\n",
      "[Epoch 6/200] [Batch 542/938] [D loss: 1.090284, acc: 96%] [G loss: 1.147963]\n",
      "[Epoch 6/200] [Batch 543/938] [D loss: 1.099325, acc: 97%] [G loss: 1.080453]\n",
      "[Epoch 6/200] [Batch 544/938] [D loss: 1.087718, acc: 96%] [G loss: 1.116041]\n",
      "[Epoch 6/200] [Batch 545/938] [D loss: 1.115015, acc: 93%] [G loss: 1.164053]\n",
      "[Epoch 6/200] [Batch 546/938] [D loss: 1.100683, acc: 95%] [G loss: 1.153565]\n",
      "[Epoch 6/200] [Batch 547/938] [D loss: 1.145512, acc: 91%] [G loss: 1.066845]\n",
      "[Epoch 6/200] [Batch 548/938] [D loss: 1.098821, acc: 97%] [G loss: 1.088052]\n",
      "[Epoch 6/200] [Batch 549/938] [D loss: 1.089462, acc: 96%] [G loss: 1.078870]\n",
      "[Epoch 6/200] [Batch 550/938] [D loss: 1.064856, acc: 97%] [G loss: 1.143492]\n",
      "[Epoch 6/200] [Batch 551/938] [D loss: 1.069391, acc: 96%] [G loss: 1.061448]\n",
      "[Epoch 6/200] [Batch 552/938] [D loss: 1.089431, acc: 94%] [G loss: 1.135652]\n",
      "[Epoch 6/200] [Batch 553/938] [D loss: 1.099082, acc: 100%] [G loss: 1.109704]\n",
      "[Epoch 6/200] [Batch 554/938] [D loss: 1.095684, acc: 95%] [G loss: 1.150579]\n",
      "[Epoch 6/200] [Batch 555/938] [D loss: 1.083409, acc: 96%] [G loss: 1.166447]\n",
      "[Epoch 6/200] [Batch 556/938] [D loss: 1.100164, acc: 96%] [G loss: 1.141670]\n",
      "[Epoch 6/200] [Batch 557/938] [D loss: 1.060976, acc: 99%] [G loss: 1.120651]\n",
      "[Epoch 6/200] [Batch 558/938] [D loss: 1.082290, acc: 92%] [G loss: 1.125064]\n",
      "[Epoch 6/200] [Batch 559/938] [D loss: 1.107046, acc: 96%] [G loss: 1.074605]\n",
      "[Epoch 6/200] [Batch 560/938] [D loss: 1.094594, acc: 94%] [G loss: 1.134019]\n",
      "[Epoch 6/200] [Batch 561/938] [D loss: 1.111611, acc: 95%] [G loss: 1.119572]\n",
      "[Epoch 6/200] [Batch 562/938] [D loss: 1.078637, acc: 96%] [G loss: 1.103220]\n",
      "[Epoch 6/200] [Batch 563/938] [D loss: 1.104387, acc: 96%] [G loss: 1.141410]\n",
      "[Epoch 6/200] [Batch 564/938] [D loss: 1.067453, acc: 93%] [G loss: 1.110364]\n",
      "[Epoch 6/200] [Batch 565/938] [D loss: 1.137116, acc: 96%] [G loss: 1.086607]\n",
      "[Epoch 6/200] [Batch 566/938] [D loss: 1.087706, acc: 92%] [G loss: 1.062404]\n",
      "[Epoch 6/200] [Batch 567/938] [D loss: 1.099661, acc: 97%] [G loss: 1.046517]\n",
      "[Epoch 6/200] [Batch 568/938] [D loss: 1.123539, acc: 96%] [G loss: 1.153060]\n",
      "[Epoch 6/200] [Batch 569/938] [D loss: 1.067359, acc: 97%] [G loss: 1.108510]\n",
      "[Epoch 6/200] [Batch 570/938] [D loss: 1.070857, acc: 96%] [G loss: 1.107724]\n",
      "[Epoch 6/200] [Batch 571/938] [D loss: 1.090494, acc: 97%] [G loss: 1.126979]\n",
      "[Epoch 6/200] [Batch 572/938] [D loss: 1.070028, acc: 96%] [G loss: 1.120427]\n",
      "[Epoch 6/200] [Batch 573/938] [D loss: 1.056634, acc: 98%] [G loss: 1.109095]\n",
      "[Epoch 6/200] [Batch 574/938] [D loss: 1.111641, acc: 95%] [G loss: 1.150228]\n",
      "[Epoch 6/200] [Batch 575/938] [D loss: 1.056933, acc: 98%] [G loss: 1.161619]\n",
      "[Epoch 6/200] [Batch 576/938] [D loss: 1.067026, acc: 94%] [G loss: 1.199306]\n",
      "[Epoch 6/200] [Batch 577/938] [D loss: 1.100688, acc: 96%] [G loss: 1.119278]\n",
      "[Epoch 6/200] [Batch 578/938] [D loss: 1.093542, acc: 94%] [G loss: 1.175840]\n",
      "[Epoch 6/200] [Batch 579/938] [D loss: 1.104014, acc: 92%] [G loss: 1.228020]\n",
      "[Epoch 6/200] [Batch 580/938] [D loss: 1.119839, acc: 96%] [G loss: 1.129238]\n",
      "[Epoch 6/200] [Batch 581/938] [D loss: 1.119737, acc: 95%] [G loss: 1.131265]\n",
      "[Epoch 6/200] [Batch 582/938] [D loss: 1.094326, acc: 94%] [G loss: 1.058379]\n",
      "[Epoch 6/200] [Batch 583/938] [D loss: 1.097386, acc: 97%] [G loss: 1.060620]\n",
      "[Epoch 6/200] [Batch 584/938] [D loss: 1.121819, acc: 94%] [G loss: 1.118545]\n",
      "[Epoch 6/200] [Batch 585/938] [D loss: 1.086764, acc: 97%] [G loss: 1.214720]\n",
      "[Epoch 6/200] [Batch 586/938] [D loss: 1.088980, acc: 96%] [G loss: 1.168509]\n",
      "[Epoch 6/200] [Batch 587/938] [D loss: 1.087986, acc: 92%] [G loss: 1.185424]\n",
      "[Epoch 6/200] [Batch 588/938] [D loss: 1.102839, acc: 95%] [G loss: 1.168885]\n",
      "[Epoch 6/200] [Batch 589/938] [D loss: 1.084158, acc: 98%] [G loss: 1.082860]\n",
      "[Epoch 6/200] [Batch 590/938] [D loss: 1.099666, acc: 96%] [G loss: 1.030961]\n",
      "[Epoch 6/200] [Batch 591/938] [D loss: 1.112781, acc: 96%] [G loss: 1.068523]\n",
      "[Epoch 6/200] [Batch 592/938] [D loss: 1.100722, acc: 96%] [G loss: 1.072183]\n",
      "[Epoch 6/200] [Batch 593/938] [D loss: 1.081994, acc: 97%] [G loss: 1.056200]\n",
      "[Epoch 6/200] [Batch 594/938] [D loss: 1.100327, acc: 96%] [G loss: 1.074865]\n",
      "[Epoch 6/200] [Batch 595/938] [D loss: 1.122005, acc: 98%] [G loss: 1.088377]\n",
      "[Epoch 6/200] [Batch 596/938] [D loss: 1.102711, acc: 95%] [G loss: 1.153820]\n",
      "[Epoch 6/200] [Batch 597/938] [D loss: 1.093548, acc: 96%] [G loss: 1.101532]\n",
      "[Epoch 6/200] [Batch 598/938] [D loss: 1.125391, acc: 94%] [G loss: 1.103204]\n",
      "[Epoch 6/200] [Batch 599/938] [D loss: 1.109867, acc: 96%] [G loss: 1.039264]\n",
      "[Epoch 6/200] [Batch 600/938] [D loss: 1.041127, acc: 96%] [G loss: 1.123343]\n",
      "[Epoch 6/200] [Batch 601/938] [D loss: 1.124719, acc: 96%] [G loss: 1.115950]\n",
      "[Epoch 6/200] [Batch 602/938] [D loss: 1.072410, acc: 99%] [G loss: 1.151505]\n",
      "[Epoch 6/200] [Batch 603/938] [D loss: 1.094508, acc: 93%] [G loss: 1.108886]\n",
      "[Epoch 6/200] [Batch 604/938] [D loss: 1.119155, acc: 95%] [G loss: 1.096674]\n",
      "[Epoch 6/200] [Batch 605/938] [D loss: 1.075505, acc: 97%] [G loss: 1.122667]\n",
      "[Epoch 6/200] [Batch 606/938] [D loss: 1.104719, acc: 96%] [G loss: 1.107738]\n",
      "[Epoch 6/200] [Batch 607/938] [D loss: 1.083136, acc: 94%] [G loss: 1.145113]\n",
      "[Epoch 6/200] [Batch 608/938] [D loss: 1.129218, acc: 94%] [G loss: 1.164087]\n",
      "[Epoch 6/200] [Batch 609/938] [D loss: 1.096906, acc: 98%] [G loss: 1.084847]\n",
      "[Epoch 6/200] [Batch 610/938] [D loss: 1.113390, acc: 97%] [G loss: 1.121960]\n",
      "[Epoch 6/200] [Batch 611/938] [D loss: 1.112532, acc: 96%] [G loss: 1.129779]\n",
      "[Epoch 6/200] [Batch 612/938] [D loss: 1.076006, acc: 96%] [G loss: 1.056419]\n",
      "[Epoch 6/200] [Batch 613/938] [D loss: 1.082192, acc: 95%] [G loss: 1.101445]\n",
      "[Epoch 6/200] [Batch 614/938] [D loss: 1.104553, acc: 97%] [G loss: 1.113204]\n",
      "[Epoch 6/200] [Batch 615/938] [D loss: 1.059925, acc: 96%] [G loss: 1.146757]\n",
      "[Epoch 6/200] [Batch 616/938] [D loss: 1.124956, acc: 96%] [G loss: 1.158471]\n",
      "[Epoch 6/200] [Batch 617/938] [D loss: 1.074234, acc: 96%] [G loss: 1.150659]\n",
      "[Epoch 6/200] [Batch 618/938] [D loss: 1.079957, acc: 92%] [G loss: 1.124273]\n",
      "[Epoch 6/200] [Batch 619/938] [D loss: 1.076216, acc: 96%] [G loss: 1.124089]\n",
      "[Epoch 6/200] [Batch 620/938] [D loss: 1.105562, acc: 96%] [G loss: 1.057395]\n",
      "[Epoch 6/200] [Batch 621/938] [D loss: 1.130059, acc: 95%] [G loss: 1.087202]\n",
      "[Epoch 6/200] [Batch 622/938] [D loss: 1.099385, acc: 96%] [G loss: 1.111717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 623/938] [D loss: 1.088578, acc: 92%] [G loss: 1.096053]\n",
      "[Epoch 6/200] [Batch 624/938] [D loss: 1.118869, acc: 92%] [G loss: 1.090405]\n",
      "[Epoch 6/200] [Batch 625/938] [D loss: 1.103719, acc: 96%] [G loss: 1.131434]\n",
      "[Epoch 6/200] [Batch 626/938] [D loss: 1.090500, acc: 97%] [G loss: 1.073509]\n",
      "[Epoch 6/200] [Batch 627/938] [D loss: 1.072912, acc: 95%] [G loss: 1.057920]\n",
      "[Epoch 6/200] [Batch 628/938] [D loss: 1.099408, acc: 96%] [G loss: 1.104219]\n",
      "[Epoch 6/200] [Batch 629/938] [D loss: 1.079799, acc: 97%] [G loss: 1.095718]\n",
      "[Epoch 6/200] [Batch 630/938] [D loss: 1.048592, acc: 97%] [G loss: 1.105947]\n",
      "[Epoch 6/200] [Batch 631/938] [D loss: 1.096823, acc: 96%] [G loss: 1.081418]\n",
      "[Epoch 6/200] [Batch 632/938] [D loss: 1.069226, acc: 96%] [G loss: 1.108093]\n",
      "[Epoch 6/200] [Batch 633/938] [D loss: 1.078844, acc: 96%] [G loss: 1.124803]\n",
      "[Epoch 6/200] [Batch 634/938] [D loss: 1.083106, acc: 95%] [G loss: 1.120883]\n",
      "[Epoch 6/200] [Batch 635/938] [D loss: 1.105884, acc: 97%] [G loss: 1.136039]\n",
      "[Epoch 6/200] [Batch 636/938] [D loss: 1.076773, acc: 96%] [G loss: 1.108102]\n",
      "[Epoch 6/200] [Batch 637/938] [D loss: 1.088594, acc: 94%] [G loss: 1.139711]\n",
      "[Epoch 6/200] [Batch 638/938] [D loss: 1.102497, acc: 95%] [G loss: 1.048606]\n",
      "[Epoch 6/200] [Batch 639/938] [D loss: 1.097658, acc: 96%] [G loss: 1.123906]\n",
      "[Epoch 6/200] [Batch 640/938] [D loss: 1.119581, acc: 94%] [G loss: 1.090720]\n",
      "[Epoch 6/200] [Batch 641/938] [D loss: 1.089290, acc: 96%] [G loss: 1.165104]\n",
      "[Epoch 6/200] [Batch 642/938] [D loss: 1.093358, acc: 96%] [G loss: 1.139152]\n",
      "[Epoch 6/200] [Batch 643/938] [D loss: 1.072116, acc: 95%] [G loss: 1.170051]\n",
      "[Epoch 6/200] [Batch 644/938] [D loss: 1.099921, acc: 96%] [G loss: 1.154770]\n",
      "[Epoch 6/200] [Batch 645/938] [D loss: 1.078257, acc: 95%] [G loss: 1.140365]\n",
      "[Epoch 6/200] [Batch 646/938] [D loss: 1.076610, acc: 96%] [G loss: 1.106401]\n",
      "[Epoch 6/200] [Batch 647/938] [D loss: 1.117367, acc: 97%] [G loss: 1.097649]\n",
      "[Epoch 6/200] [Batch 648/938] [D loss: 1.070661, acc: 98%] [G loss: 1.113886]\n",
      "[Epoch 6/200] [Batch 649/938] [D loss: 1.114226, acc: 95%] [G loss: 1.160990]\n",
      "[Epoch 6/200] [Batch 650/938] [D loss: 1.086331, acc: 99%] [G loss: 1.154402]\n",
      "[Epoch 6/200] [Batch 651/938] [D loss: 1.081434, acc: 96%] [G loss: 1.078960]\n",
      "[Epoch 6/200] [Batch 652/938] [D loss: 1.107713, acc: 97%] [G loss: 1.098110]\n",
      "[Epoch 6/200] [Batch 653/938] [D loss: 1.077746, acc: 97%] [G loss: 1.078614]\n",
      "[Epoch 6/200] [Batch 654/938] [D loss: 1.082930, acc: 93%] [G loss: 1.134035]\n",
      "[Epoch 6/200] [Batch 655/938] [D loss: 1.066397, acc: 98%] [G loss: 1.144613]\n",
      "[Epoch 6/200] [Batch 656/938] [D loss: 1.089414, acc: 93%] [G loss: 1.110989]\n",
      "[Epoch 6/200] [Batch 657/938] [D loss: 1.106663, acc: 96%] [G loss: 1.114044]\n",
      "[Epoch 6/200] [Batch 658/938] [D loss: 1.081297, acc: 96%] [G loss: 1.098988]\n",
      "[Epoch 6/200] [Batch 659/938] [D loss: 1.115543, acc: 95%] [G loss: 1.032878]\n",
      "[Epoch 6/200] [Batch 660/938] [D loss: 1.057432, acc: 97%] [G loss: 1.110318]\n",
      "[Epoch 6/200] [Batch 661/938] [D loss: 1.078613, acc: 96%] [G loss: 1.142292]\n",
      "[Epoch 6/200] [Batch 662/938] [D loss: 1.104154, acc: 95%] [G loss: 1.098617]\n",
      "[Epoch 6/200] [Batch 663/938] [D loss: 1.099044, acc: 96%] [G loss: 1.137475]\n",
      "[Epoch 6/200] [Batch 664/938] [D loss: 1.074223, acc: 98%] [G loss: 1.117592]\n",
      "[Epoch 6/200] [Batch 665/938] [D loss: 1.081643, acc: 94%] [G loss: 1.131964]\n",
      "[Epoch 6/200] [Batch 666/938] [D loss: 1.094534, acc: 97%] [G loss: 1.076796]\n",
      "[Epoch 6/200] [Batch 667/938] [D loss: 1.117022, acc: 96%] [G loss: 1.130916]\n",
      "[Epoch 6/200] [Batch 668/938] [D loss: 1.080848, acc: 98%] [G loss: 1.150732]\n",
      "[Epoch 6/200] [Batch 669/938] [D loss: 1.069149, acc: 96%] [G loss: 1.115923]\n",
      "[Epoch 6/200] [Batch 670/938] [D loss: 1.120846, acc: 94%] [G loss: 1.109001]\n",
      "[Epoch 6/200] [Batch 671/938] [D loss: 1.065796, acc: 97%] [G loss: 1.076060]\n",
      "[Epoch 6/200] [Batch 672/938] [D loss: 1.086025, acc: 96%] [G loss: 1.062353]\n",
      "[Epoch 6/200] [Batch 673/938] [D loss: 1.051839, acc: 97%] [G loss: 1.098370]\n",
      "[Epoch 6/200] [Batch 674/938] [D loss: 1.090132, acc: 96%] [G loss: 1.089048]\n",
      "[Epoch 6/200] [Batch 675/938] [D loss: 1.125436, acc: 95%] [G loss: 1.127872]\n",
      "[Epoch 6/200] [Batch 676/938] [D loss: 1.044249, acc: 98%] [G loss: 1.137141]\n",
      "[Epoch 6/200] [Batch 677/938] [D loss: 1.088649, acc: 95%] [G loss: 1.148277]\n",
      "[Epoch 6/200] [Batch 678/938] [D loss: 1.096470, acc: 96%] [G loss: 1.160443]\n",
      "[Epoch 6/200] [Batch 679/938] [D loss: 1.060246, acc: 97%] [G loss: 1.131928]\n",
      "[Epoch 6/200] [Batch 680/938] [D loss: 1.107026, acc: 94%] [G loss: 1.144617]\n",
      "[Epoch 6/200] [Batch 681/938] [D loss: 1.117113, acc: 94%] [G loss: 1.084006]\n",
      "[Epoch 6/200] [Batch 682/938] [D loss: 1.111699, acc: 94%] [G loss: 1.086329]\n",
      "[Epoch 6/200] [Batch 683/938] [D loss: 1.060709, acc: 98%] [G loss: 1.076066]\n",
      "[Epoch 6/200] [Batch 684/938] [D loss: 1.072262, acc: 96%] [G loss: 1.111258]\n",
      "[Epoch 6/200] [Batch 685/938] [D loss: 1.063479, acc: 93%] [G loss: 1.123825]\n",
      "[Epoch 6/200] [Batch 686/938] [D loss: 1.116812, acc: 95%] [G loss: 1.121305]\n",
      "[Epoch 6/200] [Batch 687/938] [D loss: 1.070101, acc: 94%] [G loss: 1.135378]\n",
      "[Epoch 6/200] [Batch 688/938] [D loss: 1.113341, acc: 93%] [G loss: 1.088968]\n",
      "[Epoch 6/200] [Batch 689/938] [D loss: 1.108743, acc: 92%] [G loss: 1.133408]\n",
      "[Epoch 6/200] [Batch 690/938] [D loss: 1.087979, acc: 96%] [G loss: 1.111381]\n",
      "[Epoch 6/200] [Batch 691/938] [D loss: 1.078990, acc: 98%] [G loss: 1.158989]\n",
      "[Epoch 6/200] [Batch 692/938] [D loss: 1.076611, acc: 98%] [G loss: 1.128909]\n",
      "[Epoch 6/200] [Batch 693/938] [D loss: 1.069905, acc: 96%] [G loss: 1.127013]\n",
      "[Epoch 6/200] [Batch 694/938] [D loss: 1.080228, acc: 96%] [G loss: 1.050458]\n",
      "[Epoch 6/200] [Batch 695/938] [D loss: 1.074726, acc: 94%] [G loss: 1.120097]\n",
      "[Epoch 6/200] [Batch 696/938] [D loss: 1.077672, acc: 98%] [G loss: 1.183229]\n",
      "[Epoch 6/200] [Batch 697/938] [D loss: 1.092993, acc: 96%] [G loss: 1.053512]\n",
      "[Epoch 6/200] [Batch 698/938] [D loss: 1.136163, acc: 93%] [G loss: 1.102637]\n",
      "[Epoch 6/200] [Batch 699/938] [D loss: 1.105459, acc: 95%] [G loss: 1.086371]\n",
      "[Epoch 6/200] [Batch 700/938] [D loss: 1.071701, acc: 100%] [G loss: 1.121928]\n",
      "[Epoch 6/200] [Batch 701/938] [D loss: 1.080931, acc: 96%] [G loss: 1.135396]\n",
      "[Epoch 6/200] [Batch 702/938] [D loss: 1.147032, acc: 92%] [G loss: 1.114864]\n",
      "[Epoch 6/200] [Batch 703/938] [D loss: 1.042261, acc: 97%] [G loss: 1.125848]\n",
      "[Epoch 6/200] [Batch 704/938] [D loss: 1.058644, acc: 96%] [G loss: 1.074332]\n",
      "[Epoch 6/200] [Batch 705/938] [D loss: 1.096994, acc: 96%] [G loss: 1.079566]\n",
      "[Epoch 6/200] [Batch 706/938] [D loss: 1.078240, acc: 93%] [G loss: 1.110745]\n",
      "[Epoch 6/200] [Batch 707/938] [D loss: 1.113676, acc: 96%] [G loss: 1.173667]\n",
      "[Epoch 6/200] [Batch 708/938] [D loss: 1.081134, acc: 97%] [G loss: 1.154064]\n",
      "[Epoch 6/200] [Batch 709/938] [D loss: 1.093249, acc: 96%] [G loss: 1.096079]\n",
      "[Epoch 6/200] [Batch 710/938] [D loss: 1.097592, acc: 95%] [G loss: 1.092404]\n",
      "[Epoch 6/200] [Batch 711/938] [D loss: 1.075514, acc: 95%] [G loss: 1.168813]\n",
      "[Epoch 6/200] [Batch 712/938] [D loss: 1.091168, acc: 96%] [G loss: 1.129325]\n",
      "[Epoch 6/200] [Batch 713/938] [D loss: 1.119930, acc: 97%] [G loss: 1.149637]\n",
      "[Epoch 6/200] [Batch 714/938] [D loss: 1.147021, acc: 96%] [G loss: 1.114736]\n",
      "[Epoch 6/200] [Batch 715/938] [D loss: 1.087510, acc: 96%] [G loss: 1.105206]\n",
      "[Epoch 6/200] [Batch 716/938] [D loss: 1.108220, acc: 95%] [G loss: 1.134150]\n",
      "[Epoch 6/200] [Batch 717/938] [D loss: 1.086272, acc: 98%] [G loss: 1.138107]\n",
      "[Epoch 6/200] [Batch 718/938] [D loss: 1.106960, acc: 95%] [G loss: 1.139057]\n",
      "[Epoch 6/200] [Batch 719/938] [D loss: 1.061865, acc: 97%] [G loss: 1.139265]\n",
      "[Epoch 6/200] [Batch 720/938] [D loss: 1.081850, acc: 97%] [G loss: 1.125361]\n",
      "[Epoch 6/200] [Batch 721/938] [D loss: 1.113051, acc: 96%] [G loss: 1.097131]\n",
      "[Epoch 6/200] [Batch 722/938] [D loss: 1.075594, acc: 97%] [G loss: 1.098890]\n",
      "[Epoch 6/200] [Batch 723/938] [D loss: 1.099241, acc: 92%] [G loss: 1.100597]\n",
      "[Epoch 6/200] [Batch 724/938] [D loss: 1.103226, acc: 96%] [G loss: 1.181398]\n",
      "[Epoch 6/200] [Batch 725/938] [D loss: 1.100487, acc: 96%] [G loss: 1.124346]\n",
      "[Epoch 6/200] [Batch 726/938] [D loss: 1.075130, acc: 96%] [G loss: 1.101400]\n",
      "[Epoch 6/200] [Batch 727/938] [D loss: 1.064185, acc: 98%] [G loss: 1.095503]\n",
      "[Epoch 6/200] [Batch 728/938] [D loss: 1.090880, acc: 98%] [G loss: 1.127782]\n",
      "[Epoch 6/200] [Batch 729/938] [D loss: 1.095605, acc: 96%] [G loss: 1.137260]\n",
      "[Epoch 6/200] [Batch 730/938] [D loss: 1.116412, acc: 92%] [G loss: 1.151081]\n",
      "[Epoch 6/200] [Batch 731/938] [D loss: 1.114735, acc: 97%] [G loss: 1.146590]\n",
      "[Epoch 6/200] [Batch 732/938] [D loss: 1.092252, acc: 94%] [G loss: 1.082623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 733/938] [D loss: 1.083498, acc: 94%] [G loss: 1.117773]\n",
      "[Epoch 6/200] [Batch 734/938] [D loss: 1.059882, acc: 97%] [G loss: 1.111028]\n",
      "[Epoch 6/200] [Batch 735/938] [D loss: 1.090847, acc: 97%] [G loss: 1.086422]\n",
      "[Epoch 6/200] [Batch 736/938] [D loss: 1.102264, acc: 96%] [G loss: 1.090805]\n",
      "[Epoch 6/200] [Batch 737/938] [D loss: 1.066146, acc: 97%] [G loss: 1.110723]\n",
      "[Epoch 6/200] [Batch 738/938] [D loss: 1.074035, acc: 94%] [G loss: 1.106679]\n",
      "[Epoch 6/200] [Batch 739/938] [D loss: 1.102691, acc: 93%] [G loss: 1.152699]\n",
      "[Epoch 6/200] [Batch 740/938] [D loss: 1.068271, acc: 96%] [G loss: 1.083386]\n",
      "[Epoch 6/200] [Batch 741/938] [D loss: 1.096156, acc: 95%] [G loss: 1.137633]\n",
      "[Epoch 6/200] [Batch 742/938] [D loss: 1.124900, acc: 96%] [G loss: 1.117827]\n",
      "[Epoch 6/200] [Batch 743/938] [D loss: 1.110194, acc: 96%] [G loss: 1.127214]\n",
      "[Epoch 6/200] [Batch 744/938] [D loss: 1.074981, acc: 98%] [G loss: 1.127660]\n",
      "[Epoch 6/200] [Batch 745/938] [D loss: 1.101421, acc: 96%] [G loss: 1.096457]\n",
      "[Epoch 6/200] [Batch 746/938] [D loss: 1.085380, acc: 96%] [G loss: 1.085612]\n",
      "[Epoch 6/200] [Batch 747/938] [D loss: 1.122209, acc: 97%] [G loss: 1.085540]\n",
      "[Epoch 6/200] [Batch 748/938] [D loss: 1.111851, acc: 92%] [G loss: 1.095030]\n",
      "[Epoch 6/200] [Batch 749/938] [D loss: 1.059811, acc: 96%] [G loss: 1.094109]\n",
      "[Epoch 6/200] [Batch 750/938] [D loss: 1.075312, acc: 98%] [G loss: 1.117056]\n",
      "[Epoch 6/200] [Batch 751/938] [D loss: 1.094976, acc: 96%] [G loss: 1.136896]\n",
      "[Epoch 6/200] [Batch 752/938] [D loss: 1.089174, acc: 94%] [G loss: 1.157437]\n",
      "[Epoch 6/200] [Batch 753/938] [D loss: 1.136953, acc: 96%] [G loss: 1.188455]\n",
      "[Epoch 6/200] [Batch 754/938] [D loss: 1.078338, acc: 98%] [G loss: 1.158616]\n",
      "[Epoch 6/200] [Batch 755/938] [D loss: 1.103695, acc: 93%] [G loss: 1.112254]\n",
      "[Epoch 6/200] [Batch 756/938] [D loss: 1.062423, acc: 95%] [G loss: 1.093052]\n",
      "[Epoch 6/200] [Batch 757/938] [D loss: 1.063513, acc: 97%] [G loss: 1.169733]\n",
      "[Epoch 6/200] [Batch 758/938] [D loss: 1.099665, acc: 98%] [G loss: 1.155884]\n",
      "[Epoch 6/200] [Batch 759/938] [D loss: 1.091134, acc: 97%] [G loss: 1.120392]\n",
      "[Epoch 6/200] [Batch 760/938] [D loss: 1.083737, acc: 95%] [G loss: 1.097758]\n",
      "[Epoch 6/200] [Batch 761/938] [D loss: 1.079168, acc: 96%] [G loss: 1.095656]\n",
      "[Epoch 6/200] [Batch 762/938] [D loss: 1.086373, acc: 94%] [G loss: 1.140230]\n",
      "[Epoch 6/200] [Batch 763/938] [D loss: 1.099988, acc: 92%] [G loss: 1.146253]\n",
      "[Epoch 6/200] [Batch 764/938] [D loss: 1.074251, acc: 96%] [G loss: 1.158156]\n",
      "[Epoch 6/200] [Batch 765/938] [D loss: 1.113487, acc: 97%] [G loss: 1.102734]\n",
      "[Epoch 6/200] [Batch 766/938] [D loss: 1.086342, acc: 94%] [G loss: 1.103046]\n",
      "[Epoch 6/200] [Batch 767/938] [D loss: 1.081215, acc: 96%] [G loss: 1.089875]\n",
      "[Epoch 6/200] [Batch 768/938] [D loss: 1.085669, acc: 94%] [G loss: 1.128520]\n",
      "[Epoch 6/200] [Batch 769/938] [D loss: 1.123744, acc: 95%] [G loss: 1.122502]\n",
      "[Epoch 6/200] [Batch 770/938] [D loss: 1.100897, acc: 93%] [G loss: 1.077288]\n",
      "[Epoch 6/200] [Batch 771/938] [D loss: 1.072718, acc: 99%] [G loss: 1.113414]\n",
      "[Epoch 6/200] [Batch 772/938] [D loss: 1.075500, acc: 96%] [G loss: 1.133487]\n",
      "[Epoch 6/200] [Batch 773/938] [D loss: 1.064194, acc: 100%] [G loss: 1.084556]\n",
      "[Epoch 6/200] [Batch 774/938] [D loss: 1.124088, acc: 97%] [G loss: 1.096546]\n",
      "[Epoch 6/200] [Batch 775/938] [D loss: 1.074511, acc: 97%] [G loss: 1.143537]\n",
      "[Epoch 6/200] [Batch 776/938] [D loss: 1.078882, acc: 97%] [G loss: 1.125796]\n",
      "[Epoch 6/200] [Batch 777/938] [D loss: 1.107945, acc: 90%] [G loss: 1.119423]\n",
      "[Epoch 6/200] [Batch 778/938] [D loss: 1.088624, acc: 96%] [G loss: 1.036450]\n",
      "[Epoch 6/200] [Batch 779/938] [D loss: 1.075215, acc: 96%] [G loss: 1.069084]\n",
      "[Epoch 6/200] [Batch 780/938] [D loss: 1.111449, acc: 96%] [G loss: 1.159635]\n",
      "[Epoch 6/200] [Batch 781/938] [D loss: 1.104286, acc: 95%] [G loss: 1.095795]\n",
      "[Epoch 6/200] [Batch 782/938] [D loss: 1.080869, acc: 99%] [G loss: 1.058530]\n",
      "[Epoch 6/200] [Batch 783/938] [D loss: 1.109895, acc: 95%] [G loss: 1.055076]\n",
      "[Epoch 6/200] [Batch 784/938] [D loss: 1.045395, acc: 96%] [G loss: 1.091119]\n",
      "[Epoch 6/200] [Batch 785/938] [D loss: 1.089887, acc: 98%] [G loss: 1.121499]\n",
      "[Epoch 6/200] [Batch 786/938] [D loss: 1.102952, acc: 94%] [G loss: 1.099629]\n",
      "[Epoch 6/200] [Batch 787/938] [D loss: 1.116640, acc: 92%] [G loss: 1.127618]\n",
      "[Epoch 6/200] [Batch 788/938] [D loss: 1.084695, acc: 95%] [G loss: 1.178944]\n",
      "[Epoch 6/200] [Batch 789/938] [D loss: 1.114183, acc: 96%] [G loss: 1.077636]\n",
      "[Epoch 6/200] [Batch 790/938] [D loss: 1.085738, acc: 98%] [G loss: 1.111129]\n",
      "[Epoch 6/200] [Batch 791/938] [D loss: 1.098145, acc: 95%] [G loss: 1.145623]\n",
      "[Epoch 6/200] [Batch 792/938] [D loss: 1.098569, acc: 97%] [G loss: 1.103315]\n",
      "[Epoch 6/200] [Batch 793/938] [D loss: 1.065735, acc: 97%] [G loss: 1.107359]\n",
      "[Epoch 6/200] [Batch 794/938] [D loss: 1.057944, acc: 96%] [G loss: 1.175168]\n",
      "[Epoch 6/200] [Batch 795/938] [D loss: 1.056551, acc: 96%] [G loss: 1.130479]\n",
      "[Epoch 6/200] [Batch 796/938] [D loss: 1.084687, acc: 96%] [G loss: 1.069016]\n",
      "[Epoch 6/200] [Batch 797/938] [D loss: 1.092687, acc: 97%] [G loss: 1.027265]\n",
      "[Epoch 6/200] [Batch 798/938] [D loss: 1.075354, acc: 96%] [G loss: 1.024987]\n",
      "[Epoch 6/200] [Batch 799/938] [D loss: 1.129290, acc: 97%] [G loss: 1.097372]\n",
      "[Epoch 6/200] [Batch 800/938] [D loss: 1.089822, acc: 93%] [G loss: 1.069096]\n",
      "[Epoch 6/200] [Batch 801/938] [D loss: 1.083364, acc: 94%] [G loss: 1.142417]\n",
      "[Epoch 6/200] [Batch 802/938] [D loss: 1.089714, acc: 94%] [G loss: 1.126372]\n",
      "[Epoch 6/200] [Batch 803/938] [D loss: 1.108286, acc: 92%] [G loss: 1.094069]\n",
      "[Epoch 6/200] [Batch 804/938] [D loss: 1.078666, acc: 97%] [G loss: 1.125502]\n",
      "[Epoch 6/200] [Batch 805/938] [D loss: 1.102972, acc: 97%] [G loss: 1.043373]\n",
      "[Epoch 6/200] [Batch 806/938] [D loss: 1.098567, acc: 92%] [G loss: 1.103078]\n",
      "[Epoch 6/200] [Batch 807/938] [D loss: 1.084816, acc: 94%] [G loss: 1.065367]\n",
      "[Epoch 6/200] [Batch 808/938] [D loss: 1.083700, acc: 94%] [G loss: 1.196781]\n",
      "[Epoch 6/200] [Batch 809/938] [D loss: 1.065603, acc: 96%] [G loss: 1.121223]\n",
      "[Epoch 6/200] [Batch 810/938] [D loss: 1.069157, acc: 96%] [G loss: 1.099421]\n",
      "[Epoch 6/200] [Batch 811/938] [D loss: 1.093501, acc: 96%] [G loss: 1.079637]\n",
      "[Epoch 6/200] [Batch 812/938] [D loss: 1.120185, acc: 94%] [G loss: 1.064268]\n",
      "[Epoch 6/200] [Batch 813/938] [D loss: 1.118154, acc: 96%] [G loss: 1.156913]\n",
      "[Epoch 6/200] [Batch 814/938] [D loss: 1.104928, acc: 96%] [G loss: 1.134163]\n",
      "[Epoch 6/200] [Batch 815/938] [D loss: 1.089434, acc: 96%] [G loss: 1.068877]\n",
      "[Epoch 6/200] [Batch 816/938] [D loss: 1.089715, acc: 97%] [G loss: 1.051867]\n",
      "[Epoch 6/200] [Batch 817/938] [D loss: 1.105344, acc: 96%] [G loss: 1.170373]\n",
      "[Epoch 6/200] [Batch 818/938] [D loss: 1.103281, acc: 96%] [G loss: 1.144996]\n",
      "[Epoch 6/200] [Batch 819/938] [D loss: 1.096629, acc: 96%] [G loss: 1.121914]\n",
      "[Epoch 6/200] [Batch 820/938] [D loss: 1.116392, acc: 98%] [G loss: 1.114828]\n",
      "[Epoch 6/200] [Batch 821/938] [D loss: 1.098011, acc: 96%] [G loss: 1.128097]\n",
      "[Epoch 6/200] [Batch 822/938] [D loss: 1.061692, acc: 95%] [G loss: 1.152670]\n",
      "[Epoch 6/200] [Batch 823/938] [D loss: 1.068188, acc: 90%] [G loss: 1.140318]\n",
      "[Epoch 6/200] [Batch 824/938] [D loss: 1.100996, acc: 96%] [G loss: 1.155548]\n",
      "[Epoch 6/200] [Batch 825/938] [D loss: 1.078219, acc: 97%] [G loss: 1.101039]\n",
      "[Epoch 6/200] [Batch 826/938] [D loss: 1.075306, acc: 98%] [G loss: 1.066699]\n",
      "[Epoch 6/200] [Batch 827/938] [D loss: 1.139817, acc: 92%] [G loss: 1.075328]\n",
      "[Epoch 6/200] [Batch 828/938] [D loss: 1.066216, acc: 96%] [G loss: 1.084948]\n",
      "[Epoch 6/200] [Batch 829/938] [D loss: 1.096414, acc: 96%] [G loss: 1.072734]\n",
      "[Epoch 6/200] [Batch 830/938] [D loss: 1.041610, acc: 97%] [G loss: 1.128769]\n",
      "[Epoch 6/200] [Batch 831/938] [D loss: 1.094672, acc: 92%] [G loss: 1.126409]\n",
      "[Epoch 6/200] [Batch 832/938] [D loss: 1.086658, acc: 99%] [G loss: 1.102016]\n",
      "[Epoch 6/200] [Batch 833/938] [D loss: 1.119903, acc: 98%] [G loss: 1.083185]\n",
      "[Epoch 6/200] [Batch 834/938] [D loss: 1.098760, acc: 95%] [G loss: 1.086365]\n",
      "[Epoch 6/200] [Batch 835/938] [D loss: 1.089219, acc: 97%] [G loss: 1.181427]\n",
      "[Epoch 6/200] [Batch 836/938] [D loss: 1.086081, acc: 94%] [G loss: 1.140619]\n",
      "[Epoch 6/200] [Batch 837/938] [D loss: 1.082978, acc: 95%] [G loss: 1.162191]\n",
      "[Epoch 6/200] [Batch 838/938] [D loss: 1.074420, acc: 97%] [G loss: 1.084040]\n",
      "[Epoch 6/200] [Batch 839/938] [D loss: 1.058075, acc: 97%] [G loss: 1.085307]\n",
      "[Epoch 6/200] [Batch 840/938] [D loss: 1.098436, acc: 92%] [G loss: 1.121825]\n",
      "[Epoch 6/200] [Batch 841/938] [D loss: 1.081394, acc: 93%] [G loss: 1.185828]\n",
      "[Epoch 6/200] [Batch 842/938] [D loss: 1.044611, acc: 100%] [G loss: 1.122866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 843/938] [D loss: 1.113807, acc: 92%] [G loss: 1.156121]\n",
      "[Epoch 6/200] [Batch 844/938] [D loss: 1.082825, acc: 96%] [G loss: 1.147236]\n",
      "[Epoch 6/200] [Batch 845/938] [D loss: 1.077079, acc: 96%] [G loss: 1.064850]\n",
      "[Epoch 6/200] [Batch 846/938] [D loss: 1.101278, acc: 96%] [G loss: 1.102195]\n",
      "[Epoch 6/200] [Batch 847/938] [D loss: 1.098722, acc: 96%] [G loss: 1.154437]\n",
      "[Epoch 6/200] [Batch 848/938] [D loss: 1.094893, acc: 96%] [G loss: 1.152272]\n",
      "[Epoch 6/200] [Batch 849/938] [D loss: 1.065789, acc: 98%] [G loss: 1.142735]\n",
      "[Epoch 6/200] [Batch 850/938] [D loss: 1.112349, acc: 98%] [G loss: 1.092109]\n",
      "[Epoch 6/200] [Batch 851/938] [D loss: 1.100696, acc: 96%] [G loss: 1.121933]\n",
      "[Epoch 6/200] [Batch 852/938] [D loss: 1.095045, acc: 97%] [G loss: 1.139474]\n",
      "[Epoch 6/200] [Batch 853/938] [D loss: 1.091267, acc: 97%] [G loss: 1.058693]\n",
      "[Epoch 6/200] [Batch 854/938] [D loss: 1.114832, acc: 94%] [G loss: 1.040423]\n",
      "[Epoch 6/200] [Batch 855/938] [D loss: 1.126473, acc: 96%] [G loss: 1.129813]\n",
      "[Epoch 6/200] [Batch 856/938] [D loss: 1.085114, acc: 97%] [G loss: 1.083750]\n",
      "[Epoch 6/200] [Batch 857/938] [D loss: 1.103389, acc: 96%] [G loss: 1.138172]\n",
      "[Epoch 6/200] [Batch 858/938] [D loss: 1.161431, acc: 94%] [G loss: 1.097431]\n",
      "[Epoch 6/200] [Batch 859/938] [D loss: 1.123912, acc: 94%] [G loss: 1.102258]\n",
      "[Epoch 6/200] [Batch 860/938] [D loss: 1.070145, acc: 96%] [G loss: 1.057959]\n",
      "[Epoch 6/200] [Batch 861/938] [D loss: 1.104920, acc: 95%] [G loss: 1.131874]\n",
      "[Epoch 6/200] [Batch 862/938] [D loss: 1.098581, acc: 97%] [G loss: 1.082501]\n",
      "[Epoch 6/200] [Batch 863/938] [D loss: 1.109752, acc: 94%] [G loss: 1.126180]\n",
      "[Epoch 6/200] [Batch 864/938] [D loss: 1.086567, acc: 96%] [G loss: 1.120136]\n",
      "[Epoch 6/200] [Batch 865/938] [D loss: 1.085005, acc: 96%] [G loss: 1.103336]\n",
      "[Epoch 6/200] [Batch 866/938] [D loss: 1.040709, acc: 98%] [G loss: 1.175057]\n",
      "[Epoch 6/200] [Batch 867/938] [D loss: 1.101059, acc: 96%] [G loss: 1.103829]\n",
      "[Epoch 6/200] [Batch 868/938] [D loss: 1.094180, acc: 97%] [G loss: 1.080413]\n",
      "[Epoch 6/200] [Batch 869/938] [D loss: 1.116918, acc: 94%] [G loss: 1.102637]\n",
      "[Epoch 6/200] [Batch 870/938] [D loss: 1.110553, acc: 93%] [G loss: 1.159881]\n",
      "[Epoch 6/200] [Batch 871/938] [D loss: 1.120743, acc: 96%] [G loss: 1.117433]\n",
      "[Epoch 6/200] [Batch 872/938] [D loss: 1.103058, acc: 96%] [G loss: 1.067381]\n",
      "[Epoch 6/200] [Batch 873/938] [D loss: 1.095407, acc: 98%] [G loss: 1.103771]\n",
      "[Epoch 6/200] [Batch 874/938] [D loss: 1.091600, acc: 93%] [G loss: 1.130661]\n",
      "[Epoch 6/200] [Batch 875/938] [D loss: 1.081673, acc: 99%] [G loss: 1.156539]\n",
      "[Epoch 6/200] [Batch 876/938] [D loss: 1.071985, acc: 96%] [G loss: 1.130906]\n",
      "[Epoch 6/200] [Batch 877/938] [D loss: 1.092537, acc: 97%] [G loss: 1.105872]\n",
      "[Epoch 6/200] [Batch 878/938] [D loss: 1.071432, acc: 98%] [G loss: 1.067506]\n",
      "[Epoch 6/200] [Batch 879/938] [D loss: 1.092753, acc: 96%] [G loss: 1.142950]\n",
      "[Epoch 6/200] [Batch 880/938] [D loss: 1.144063, acc: 96%] [G loss: 1.093806]\n",
      "[Epoch 6/200] [Batch 881/938] [D loss: 1.052858, acc: 99%] [G loss: 1.084942]\n",
      "[Epoch 6/200] [Batch 882/938] [D loss: 1.087433, acc: 96%] [G loss: 1.063445]\n",
      "[Epoch 6/200] [Batch 883/938] [D loss: 1.084236, acc: 95%] [G loss: 1.089773]\n",
      "[Epoch 6/200] [Batch 884/938] [D loss: 1.116316, acc: 96%] [G loss: 1.071476]\n",
      "[Epoch 6/200] [Batch 885/938] [D loss: 1.116368, acc: 94%] [G loss: 1.099249]\n",
      "[Epoch 6/200] [Batch 886/938] [D loss: 1.073938, acc: 92%] [G loss: 1.150060]\n",
      "[Epoch 6/200] [Batch 887/938] [D loss: 1.116948, acc: 93%] [G loss: 1.101549]\n",
      "[Epoch 6/200] [Batch 888/938] [D loss: 1.100528, acc: 95%] [G loss: 1.112909]\n",
      "[Epoch 6/200] [Batch 889/938] [D loss: 1.081754, acc: 96%] [G loss: 1.088473]\n",
      "[Epoch 6/200] [Batch 890/938] [D loss: 1.119108, acc: 96%] [G loss: 1.059220]\n",
      "[Epoch 6/200] [Batch 891/938] [D loss: 1.106096, acc: 90%] [G loss: 1.192326]\n",
      "[Epoch 6/200] [Batch 892/938] [D loss: 1.104510, acc: 95%] [G loss: 1.093702]\n",
      "[Epoch 6/200] [Batch 893/938] [D loss: 1.096123, acc: 96%] [G loss: 1.079747]\n",
      "[Epoch 6/200] [Batch 894/938] [D loss: 1.069422, acc: 97%] [G loss: 1.095552]\n",
      "[Epoch 6/200] [Batch 895/938] [D loss: 1.047632, acc: 96%] [G loss: 1.104348]\n",
      "[Epoch 6/200] [Batch 896/938] [D loss: 1.064838, acc: 96%] [G loss: 1.118331]\n",
      "[Epoch 6/200] [Batch 897/938] [D loss: 1.102026, acc: 95%] [G loss: 1.112408]\n",
      "[Epoch 6/200] [Batch 898/938] [D loss: 1.100068, acc: 92%] [G loss: 1.133672]\n",
      "[Epoch 6/200] [Batch 899/938] [D loss: 1.112717, acc: 96%] [G loss: 1.080076]\n",
      "[Epoch 6/200] [Batch 900/938] [D loss: 1.073262, acc: 97%] [G loss: 1.102232]\n",
      "[Epoch 6/200] [Batch 901/938] [D loss: 1.077607, acc: 97%] [G loss: 1.170152]\n",
      "[Epoch 6/200] [Batch 902/938] [D loss: 1.081470, acc: 96%] [G loss: 1.095526]\n",
      "[Epoch 6/200] [Batch 903/938] [D loss: 1.100986, acc: 95%] [G loss: 1.121570]\n",
      "[Epoch 6/200] [Batch 904/938] [D loss: 1.066520, acc: 96%] [G loss: 1.121145]\n",
      "[Epoch 6/200] [Batch 905/938] [D loss: 1.044068, acc: 99%] [G loss: 1.124804]\n",
      "[Epoch 6/200] [Batch 906/938] [D loss: 1.070410, acc: 96%] [G loss: 1.128073]\n",
      "[Epoch 6/200] [Batch 907/938] [D loss: 1.090494, acc: 96%] [G loss: 1.140761]\n",
      "[Epoch 6/200] [Batch 908/938] [D loss: 1.091276, acc: 94%] [G loss: 1.146464]\n",
      "[Epoch 6/200] [Batch 909/938] [D loss: 1.103037, acc: 96%] [G loss: 1.118213]\n",
      "[Epoch 6/200] [Batch 910/938] [D loss: 1.112783, acc: 96%] [G loss: 1.084852]\n",
      "[Epoch 6/200] [Batch 911/938] [D loss: 1.095968, acc: 95%] [G loss: 1.122952]\n",
      "[Epoch 6/200] [Batch 912/938] [D loss: 1.059219, acc: 96%] [G loss: 1.094130]\n",
      "[Epoch 6/200] [Batch 913/938] [D loss: 1.086223, acc: 95%] [G loss: 1.128413]\n",
      "[Epoch 6/200] [Batch 914/938] [D loss: 1.061528, acc: 96%] [G loss: 1.103255]\n",
      "[Epoch 6/200] [Batch 915/938] [D loss: 1.092189, acc: 96%] [G loss: 1.097480]\n",
      "[Epoch 6/200] [Batch 916/938] [D loss: 1.127751, acc: 95%] [G loss: 1.084287]\n",
      "[Epoch 6/200] [Batch 917/938] [D loss: 1.091635, acc: 95%] [G loss: 1.149978]\n",
      "[Epoch 6/200] [Batch 918/938] [D loss: 1.041917, acc: 96%] [G loss: 1.196145]\n",
      "[Epoch 6/200] [Batch 919/938] [D loss: 1.134924, acc: 92%] [G loss: 1.082134]\n",
      "[Epoch 6/200] [Batch 920/938] [D loss: 1.101327, acc: 96%] [G loss: 1.095497]\n",
      "[Epoch 6/200] [Batch 921/938] [D loss: 1.090400, acc: 95%] [G loss: 1.087425]\n",
      "[Epoch 6/200] [Batch 922/938] [D loss: 1.079893, acc: 96%] [G loss: 1.082197]\n",
      "[Epoch 6/200] [Batch 923/938] [D loss: 1.099511, acc: 92%] [G loss: 1.064675]\n",
      "[Epoch 6/200] [Batch 924/938] [D loss: 1.125283, acc: 94%] [G loss: 1.042410]\n",
      "[Epoch 6/200] [Batch 925/938] [D loss: 1.091388, acc: 96%] [G loss: 1.092458]\n",
      "[Epoch 6/200] [Batch 926/938] [D loss: 1.081970, acc: 96%] [G loss: 1.156126]\n",
      "[Epoch 6/200] [Batch 927/938] [D loss: 1.096784, acc: 99%] [G loss: 1.151258]\n",
      "[Epoch 6/200] [Batch 928/938] [D loss: 1.052139, acc: 96%] [G loss: 1.071383]\n",
      "[Epoch 6/200] [Batch 929/938] [D loss: 1.072705, acc: 96%] [G loss: 1.094131]\n",
      "[Epoch 6/200] [Batch 930/938] [D loss: 1.066663, acc: 96%] [G loss: 1.090529]\n",
      "[Epoch 6/200] [Batch 931/938] [D loss: 1.098465, acc: 96%] [G loss: 1.120110]\n",
      "[Epoch 6/200] [Batch 932/938] [D loss: 1.083484, acc: 95%] [G loss: 1.127638]\n",
      "[Epoch 6/200] [Batch 933/938] [D loss: 1.080312, acc: 97%] [G loss: 1.103170]\n",
      "[Epoch 6/200] [Batch 934/938] [D loss: 1.087040, acc: 97%] [G loss: 1.063521]\n",
      "[Epoch 6/200] [Batch 935/938] [D loss: 1.077174, acc: 95%] [G loss: 1.084160]\n",
      "[Epoch 6/200] [Batch 936/938] [D loss: 1.074893, acc: 94%] [G loss: 1.120607]\n",
      "[Epoch 6/200] [Batch 937/938] [D loss: 1.057684, acc: 98%] [G loss: 1.161735]\n",
      "[Epoch 7/200] [Batch 0/938] [D loss: 1.117718, acc: 92%] [G loss: 1.093786]\n",
      "[Epoch 7/200] [Batch 1/938] [D loss: 1.068928, acc: 97%] [G loss: 1.125031]\n",
      "[Epoch 7/200] [Batch 2/938] [D loss: 1.075433, acc: 96%] [G loss: 1.132853]\n",
      "[Epoch 7/200] [Batch 3/938] [D loss: 1.088332, acc: 93%] [G loss: 1.140465]\n",
      "[Epoch 7/200] [Batch 4/938] [D loss: 1.063785, acc: 98%] [G loss: 1.127039]\n",
      "[Epoch 7/200] [Batch 5/938] [D loss: 1.115308, acc: 96%] [G loss: 1.151777]\n",
      "[Epoch 7/200] [Batch 6/938] [D loss: 1.087035, acc: 95%] [G loss: 1.127290]\n",
      "[Epoch 7/200] [Batch 7/938] [D loss: 1.098552, acc: 94%] [G loss: 1.110508]\n",
      "[Epoch 7/200] [Batch 8/938] [D loss: 1.039235, acc: 97%] [G loss: 1.074452]\n",
      "[Epoch 7/200] [Batch 9/938] [D loss: 1.080090, acc: 97%] [G loss: 1.086072]\n",
      "[Epoch 7/200] [Batch 10/938] [D loss: 1.074581, acc: 96%] [G loss: 1.087955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 11/938] [D loss: 1.050294, acc: 96%] [G loss: 1.141161]\n",
      "[Epoch 7/200] [Batch 12/938] [D loss: 1.101681, acc: 96%] [G loss: 1.057254]\n",
      "[Epoch 7/200] [Batch 13/938] [D loss: 1.103332, acc: 96%] [G loss: 1.130765]\n",
      "[Epoch 7/200] [Batch 14/938] [D loss: 1.125660, acc: 93%] [G loss: 1.113121]\n",
      "[Epoch 7/200] [Batch 15/938] [D loss: 1.110655, acc: 92%] [G loss: 1.102960]\n",
      "[Epoch 7/200] [Batch 16/938] [D loss: 1.093015, acc: 96%] [G loss: 1.097979]\n",
      "[Epoch 7/200] [Batch 17/938] [D loss: 1.081921, acc: 96%] [G loss: 1.102723]\n",
      "[Epoch 7/200] [Batch 18/938] [D loss: 1.146032, acc: 97%] [G loss: 1.107657]\n",
      "[Epoch 7/200] [Batch 19/938] [D loss: 1.107929, acc: 94%] [G loss: 1.061959]\n",
      "[Epoch 7/200] [Batch 20/938] [D loss: 1.079427, acc: 96%] [G loss: 1.092035]\n",
      "[Epoch 7/200] [Batch 21/938] [D loss: 1.096185, acc: 92%] [G loss: 1.083979]\n",
      "[Epoch 7/200] [Batch 22/938] [D loss: 1.082446, acc: 96%] [G loss: 1.075655]\n",
      "[Epoch 7/200] [Batch 23/938] [D loss: 1.151863, acc: 94%] [G loss: 1.121688]\n",
      "[Epoch 7/200] [Batch 24/938] [D loss: 1.133156, acc: 91%] [G loss: 1.085929]\n",
      "[Epoch 7/200] [Batch 25/938] [D loss: 1.081427, acc: 96%] [G loss: 1.179597]\n",
      "[Epoch 7/200] [Batch 26/938] [D loss: 1.125771, acc: 99%] [G loss: 1.063151]\n",
      "[Epoch 7/200] [Batch 27/938] [D loss: 1.085863, acc: 96%] [G loss: 1.147505]\n",
      "[Epoch 7/200] [Batch 28/938] [D loss: 1.127218, acc: 96%] [G loss: 1.090710]\n",
      "[Epoch 7/200] [Batch 29/938] [D loss: 1.096593, acc: 95%] [G loss: 1.088631]\n",
      "[Epoch 7/200] [Batch 30/938] [D loss: 1.071437, acc: 96%] [G loss: 1.093538]\n",
      "[Epoch 7/200] [Batch 31/938] [D loss: 1.109535, acc: 94%] [G loss: 1.112661]\n",
      "[Epoch 7/200] [Batch 32/938] [D loss: 1.080950, acc: 95%] [G loss: 1.122119]\n",
      "[Epoch 7/200] [Batch 33/938] [D loss: 1.071136, acc: 99%] [G loss: 1.120856]\n",
      "[Epoch 7/200] [Batch 34/938] [D loss: 1.094020, acc: 94%] [G loss: 1.107379]\n",
      "[Epoch 7/200] [Batch 35/938] [D loss: 1.129367, acc: 96%] [G loss: 1.068333]\n",
      "[Epoch 7/200] [Batch 36/938] [D loss: 1.130201, acc: 92%] [G loss: 1.167600]\n",
      "[Epoch 7/200] [Batch 37/938] [D loss: 1.077550, acc: 98%] [G loss: 1.103893]\n",
      "[Epoch 7/200] [Batch 38/938] [D loss: 1.091490, acc: 95%] [G loss: 1.148495]\n",
      "[Epoch 7/200] [Batch 39/938] [D loss: 1.073913, acc: 97%] [G loss: 1.053562]\n",
      "[Epoch 7/200] [Batch 40/938] [D loss: 1.106676, acc: 96%] [G loss: 1.070523]\n",
      "[Epoch 7/200] [Batch 41/938] [D loss: 1.122573, acc: 95%] [G loss: 1.092022]\n",
      "[Epoch 7/200] [Batch 42/938] [D loss: 1.072729, acc: 96%] [G loss: 1.104250]\n",
      "[Epoch 7/200] [Batch 43/938] [D loss: 1.084614, acc: 97%] [G loss: 1.101224]\n",
      "[Epoch 7/200] [Batch 44/938] [D loss: 1.084189, acc: 94%] [G loss: 1.112577]\n",
      "[Epoch 7/200] [Batch 45/938] [D loss: 1.095579, acc: 98%] [G loss: 1.095879]\n",
      "[Epoch 7/200] [Batch 46/938] [D loss: 1.058226, acc: 95%] [G loss: 1.086707]\n",
      "[Epoch 7/200] [Batch 47/938] [D loss: 1.098401, acc: 97%] [G loss: 1.127127]\n",
      "[Epoch 7/200] [Batch 48/938] [D loss: 1.099526, acc: 98%] [G loss: 1.099880]\n",
      "[Epoch 7/200] [Batch 49/938] [D loss: 1.096335, acc: 96%] [G loss: 1.062947]\n",
      "[Epoch 7/200] [Batch 50/938] [D loss: 1.096871, acc: 96%] [G loss: 1.085067]\n",
      "[Epoch 7/200] [Batch 51/938] [D loss: 1.143636, acc: 94%] [G loss: 1.142401]\n",
      "[Epoch 7/200] [Batch 52/938] [D loss: 1.108369, acc: 92%] [G loss: 1.108475]\n",
      "[Epoch 7/200] [Batch 53/938] [D loss: 1.062248, acc: 96%] [G loss: 1.161549]\n",
      "[Epoch 7/200] [Batch 54/938] [D loss: 1.087401, acc: 95%] [G loss: 1.136393]\n",
      "[Epoch 7/200] [Batch 55/938] [D loss: 1.058030, acc: 97%] [G loss: 1.128147]\n",
      "[Epoch 7/200] [Batch 56/938] [D loss: 1.061715, acc: 96%] [G loss: 1.106863]\n",
      "[Epoch 7/200] [Batch 57/938] [D loss: 1.108959, acc: 94%] [G loss: 1.064749]\n",
      "[Epoch 7/200] [Batch 58/938] [D loss: 1.095299, acc: 94%] [G loss: 1.092103]\n",
      "[Epoch 7/200] [Batch 59/938] [D loss: 1.059155, acc: 98%] [G loss: 1.113919]\n",
      "[Epoch 7/200] [Batch 60/938] [D loss: 1.114691, acc: 96%] [G loss: 1.156622]\n",
      "[Epoch 7/200] [Batch 61/938] [D loss: 1.110686, acc: 92%] [G loss: 1.190518]\n",
      "[Epoch 7/200] [Batch 62/938] [D loss: 1.076508, acc: 96%] [G loss: 1.112322]\n",
      "[Epoch 7/200] [Batch 63/938] [D loss: 1.079090, acc: 98%] [G loss: 1.080553]\n",
      "[Epoch 7/200] [Batch 64/938] [D loss: 1.090314, acc: 96%] [G loss: 1.092218]\n",
      "[Epoch 7/200] [Batch 65/938] [D loss: 1.066927, acc: 95%] [G loss: 1.083577]\n",
      "[Epoch 7/200] [Batch 66/938] [D loss: 1.096013, acc: 95%] [G loss: 1.181119]\n",
      "[Epoch 7/200] [Batch 67/938] [D loss: 1.061344, acc: 94%] [G loss: 1.123508]\n",
      "[Epoch 7/200] [Batch 68/938] [D loss: 1.044120, acc: 96%] [G loss: 1.113052]\n",
      "[Epoch 7/200] [Batch 69/938] [D loss: 1.103432, acc: 96%] [G loss: 1.094762]\n",
      "[Epoch 7/200] [Batch 70/938] [D loss: 1.097658, acc: 94%] [G loss: 1.103783]\n",
      "[Epoch 7/200] [Batch 71/938] [D loss: 1.093899, acc: 96%] [G loss: 1.151912]\n",
      "[Epoch 7/200] [Batch 72/938] [D loss: 1.123167, acc: 96%] [G loss: 1.131599]\n",
      "[Epoch 7/200] [Batch 73/938] [D loss: 1.083527, acc: 93%] [G loss: 1.138933]\n",
      "[Epoch 7/200] [Batch 74/938] [D loss: 1.102522, acc: 96%] [G loss: 1.115384]\n",
      "[Epoch 7/200] [Batch 75/938] [D loss: 1.077368, acc: 98%] [G loss: 1.098693]\n",
      "[Epoch 7/200] [Batch 76/938] [D loss: 1.115910, acc: 96%] [G loss: 1.159171]\n",
      "[Epoch 7/200] [Batch 77/938] [D loss: 1.077962, acc: 96%] [G loss: 1.165617]\n",
      "[Epoch 7/200] [Batch 78/938] [D loss: 1.069732, acc: 98%] [G loss: 1.132042]\n",
      "[Epoch 7/200] [Batch 79/938] [D loss: 1.072994, acc: 96%] [G loss: 1.123579]\n",
      "[Epoch 7/200] [Batch 80/938] [D loss: 1.054769, acc: 97%] [G loss: 1.098675]\n",
      "[Epoch 7/200] [Batch 81/938] [D loss: 1.141819, acc: 92%] [G loss: 1.072985]\n",
      "[Epoch 7/200] [Batch 82/938] [D loss: 1.082396, acc: 96%] [G loss: 1.045636]\n",
      "[Epoch 7/200] [Batch 83/938] [D loss: 1.080954, acc: 96%] [G loss: 1.164016]\n",
      "[Epoch 7/200] [Batch 84/938] [D loss: 1.087325, acc: 97%] [G loss: 1.126015]\n",
      "[Epoch 7/200] [Batch 85/938] [D loss: 1.063373, acc: 97%] [G loss: 1.122641]\n",
      "[Epoch 7/200] [Batch 86/938] [D loss: 1.086188, acc: 96%] [G loss: 1.124980]\n",
      "[Epoch 7/200] [Batch 87/938] [D loss: 1.072609, acc: 96%] [G loss: 1.123981]\n",
      "[Epoch 7/200] [Batch 88/938] [D loss: 1.074203, acc: 92%] [G loss: 1.149455]\n",
      "[Epoch 7/200] [Batch 89/938] [D loss: 1.072886, acc: 96%] [G loss: 1.086228]\n",
      "[Epoch 7/200] [Batch 90/938] [D loss: 1.088468, acc: 96%] [G loss: 1.076345]\n",
      "[Epoch 7/200] [Batch 91/938] [D loss: 1.093391, acc: 97%] [G loss: 1.097550]\n",
      "[Epoch 7/200] [Batch 92/938] [D loss: 1.103523, acc: 97%] [G loss: 1.067735]\n",
      "[Epoch 7/200] [Batch 93/938] [D loss: 1.050387, acc: 94%] [G loss: 1.181682]\n",
      "[Epoch 7/200] [Batch 94/938] [D loss: 1.129664, acc: 91%] [G loss: 1.118427]\n",
      "[Epoch 7/200] [Batch 95/938] [D loss: 1.118743, acc: 91%] [G loss: 1.148303]\n",
      "[Epoch 7/200] [Batch 96/938] [D loss: 1.117391, acc: 97%] [G loss: 1.132334]\n",
      "[Epoch 7/200] [Batch 97/938] [D loss: 1.143779, acc: 95%] [G loss: 1.092527]\n",
      "[Epoch 7/200] [Batch 98/938] [D loss: 1.105752, acc: 96%] [G loss: 1.113859]\n",
      "[Epoch 7/200] [Batch 99/938] [D loss: 1.030929, acc: 98%] [G loss: 1.138451]\n",
      "[Epoch 7/200] [Batch 100/938] [D loss: 1.079035, acc: 92%] [G loss: 1.150024]\n",
      "[Epoch 7/200] [Batch 101/938] [D loss: 1.078165, acc: 95%] [G loss: 1.057797]\n",
      "[Epoch 7/200] [Batch 102/938] [D loss: 1.090573, acc: 98%] [G loss: 1.094008]\n",
      "[Epoch 7/200] [Batch 103/938] [D loss: 1.060244, acc: 96%] [G loss: 1.171620]\n",
      "[Epoch 7/200] [Batch 104/938] [D loss: 1.139560, acc: 96%] [G loss: 1.071169]\n",
      "[Epoch 7/200] [Batch 105/938] [D loss: 1.083589, acc: 98%] [G loss: 1.117471]\n",
      "[Epoch 7/200] [Batch 106/938] [D loss: 1.057946, acc: 97%] [G loss: 1.123395]\n",
      "[Epoch 7/200] [Batch 107/938] [D loss: 1.099593, acc: 98%] [G loss: 1.148328]\n",
      "[Epoch 7/200] [Batch 108/938] [D loss: 1.038598, acc: 96%] [G loss: 1.082539]\n",
      "[Epoch 7/200] [Batch 109/938] [D loss: 1.076100, acc: 93%] [G loss: 1.143619]\n",
      "[Epoch 7/200] [Batch 110/938] [D loss: 1.086587, acc: 93%] [G loss: 1.115362]\n",
      "[Epoch 7/200] [Batch 111/938] [D loss: 1.081640, acc: 92%] [G loss: 1.118960]\n",
      "[Epoch 7/200] [Batch 112/938] [D loss: 1.072020, acc: 99%] [G loss: 1.151657]\n",
      "[Epoch 7/200] [Batch 113/938] [D loss: 1.042479, acc: 96%] [G loss: 1.162914]\n",
      "[Epoch 7/200] [Batch 114/938] [D loss: 1.054043, acc: 98%] [G loss: 1.078682]\n",
      "[Epoch 7/200] [Batch 115/938] [D loss: 1.099447, acc: 97%] [G loss: 1.107333]\n",
      "[Epoch 7/200] [Batch 116/938] [D loss: 1.082892, acc: 96%] [G loss: 1.116612]\n",
      "[Epoch 7/200] [Batch 117/938] [D loss: 1.112108, acc: 96%] [G loss: 1.122748]\n",
      "[Epoch 7/200] [Batch 118/938] [D loss: 1.085370, acc: 98%] [G loss: 1.071822]\n",
      "[Epoch 7/200] [Batch 119/938] [D loss: 1.088901, acc: 96%] [G loss: 1.075233]\n",
      "[Epoch 7/200] [Batch 120/938] [D loss: 1.095801, acc: 96%] [G loss: 1.129311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 121/938] [D loss: 1.099540, acc: 97%] [G loss: 1.129765]\n",
      "[Epoch 7/200] [Batch 122/938] [D loss: 1.077127, acc: 94%] [G loss: 1.139382]\n",
      "[Epoch 7/200] [Batch 123/938] [D loss: 1.127764, acc: 96%] [G loss: 1.140199]\n",
      "[Epoch 7/200] [Batch 124/938] [D loss: 1.089287, acc: 96%] [G loss: 1.165292]\n",
      "[Epoch 7/200] [Batch 125/938] [D loss: 1.068323, acc: 96%] [G loss: 1.138605]\n",
      "[Epoch 7/200] [Batch 126/938] [D loss: 1.109938, acc: 96%] [G loss: 1.102145]\n",
      "[Epoch 7/200] [Batch 127/938] [D loss: 1.083363, acc: 98%] [G loss: 1.081502]\n",
      "[Epoch 7/200] [Batch 128/938] [D loss: 1.126176, acc: 95%] [G loss: 1.105376]\n",
      "[Epoch 7/200] [Batch 129/938] [D loss: 1.082792, acc: 99%] [G loss: 1.130157]\n",
      "[Epoch 7/200] [Batch 130/938] [D loss: 1.092263, acc: 96%] [G loss: 1.085176]\n",
      "[Epoch 7/200] [Batch 131/938] [D loss: 1.080693, acc: 95%] [G loss: 1.093493]\n",
      "[Epoch 7/200] [Batch 132/938] [D loss: 1.087712, acc: 97%] [G loss: 1.100162]\n",
      "[Epoch 7/200] [Batch 133/938] [D loss: 1.104516, acc: 96%] [G loss: 1.086875]\n",
      "[Epoch 7/200] [Batch 134/938] [D loss: 1.067286, acc: 96%] [G loss: 1.049972]\n",
      "[Epoch 7/200] [Batch 135/938] [D loss: 1.115829, acc: 93%] [G loss: 1.110173]\n",
      "[Epoch 7/200] [Batch 136/938] [D loss: 1.089179, acc: 97%] [G loss: 1.093371]\n",
      "[Epoch 7/200] [Batch 137/938] [D loss: 1.066866, acc: 96%] [G loss: 1.127326]\n",
      "[Epoch 7/200] [Batch 138/938] [D loss: 1.055923, acc: 96%] [G loss: 1.103698]\n",
      "[Epoch 7/200] [Batch 139/938] [D loss: 1.093324, acc: 96%] [G loss: 1.143071]\n",
      "[Epoch 7/200] [Batch 140/938] [D loss: 1.067356, acc: 97%] [G loss: 1.153791]\n",
      "[Epoch 7/200] [Batch 141/938] [D loss: 1.123785, acc: 96%] [G loss: 1.097911]\n",
      "[Epoch 7/200] [Batch 142/938] [D loss: 1.092376, acc: 96%] [G loss: 1.128963]\n",
      "[Epoch 7/200] [Batch 143/938] [D loss: 1.074269, acc: 96%] [G loss: 1.128701]\n",
      "[Epoch 7/200] [Batch 144/938] [D loss: 1.068979, acc: 96%] [G loss: 1.131769]\n",
      "[Epoch 7/200] [Batch 145/938] [D loss: 1.102720, acc: 95%] [G loss: 1.133856]\n",
      "[Epoch 7/200] [Batch 146/938] [D loss: 1.085875, acc: 96%] [G loss: 1.049876]\n",
      "[Epoch 7/200] [Batch 147/938] [D loss: 1.088233, acc: 95%] [G loss: 1.090148]\n",
      "[Epoch 7/200] [Batch 148/938] [D loss: 1.103191, acc: 96%] [G loss: 1.101083]\n",
      "[Epoch 7/200] [Batch 149/938] [D loss: 1.102740, acc: 98%] [G loss: 1.090448]\n",
      "[Epoch 7/200] [Batch 150/938] [D loss: 1.119319, acc: 95%] [G loss: 1.195055]\n",
      "[Epoch 7/200] [Batch 151/938] [D loss: 1.096424, acc: 94%] [G loss: 1.219842]\n",
      "[Epoch 7/200] [Batch 152/938] [D loss: 1.068351, acc: 96%] [G loss: 1.227636]\n",
      "[Epoch 7/200] [Batch 153/938] [D loss: 1.116295, acc: 95%] [G loss: 1.124783]\n",
      "[Epoch 7/200] [Batch 154/938] [D loss: 1.094295, acc: 96%] [G loss: 1.086990]\n",
      "[Epoch 7/200] [Batch 155/938] [D loss: 1.107802, acc: 98%] [G loss: 1.102397]\n",
      "[Epoch 7/200] [Batch 156/938] [D loss: 1.061144, acc: 96%] [G loss: 1.116251]\n",
      "[Epoch 7/200] [Batch 157/938] [D loss: 1.083084, acc: 95%] [G loss: 1.086779]\n",
      "[Epoch 7/200] [Batch 158/938] [D loss: 1.075047, acc: 97%] [G loss: 1.086347]\n",
      "[Epoch 7/200] [Batch 159/938] [D loss: 1.070791, acc: 97%] [G loss: 1.077337]\n",
      "[Epoch 7/200] [Batch 160/938] [D loss: 1.105379, acc: 95%] [G loss: 1.103547]\n",
      "[Epoch 7/200] [Batch 161/938] [D loss: 1.110591, acc: 95%] [G loss: 1.098763]\n",
      "[Epoch 7/200] [Batch 162/938] [D loss: 1.065906, acc: 93%] [G loss: 1.088395]\n",
      "[Epoch 7/200] [Batch 163/938] [D loss: 1.120558, acc: 96%] [G loss: 1.114323]\n",
      "[Epoch 7/200] [Batch 164/938] [D loss: 1.097564, acc: 96%] [G loss: 1.079219]\n",
      "[Epoch 7/200] [Batch 165/938] [D loss: 1.099972, acc: 96%] [G loss: 1.116589]\n",
      "[Epoch 7/200] [Batch 166/938] [D loss: 1.060497, acc: 99%] [G loss: 1.047195]\n",
      "[Epoch 7/200] [Batch 167/938] [D loss: 1.060310, acc: 97%] [G loss: 1.078441]\n",
      "[Epoch 7/200] [Batch 168/938] [D loss: 1.105521, acc: 96%] [G loss: 1.167629]\n",
      "[Epoch 7/200] [Batch 169/938] [D loss: 1.071741, acc: 96%] [G loss: 1.103932]\n",
      "[Epoch 7/200] [Batch 170/938] [D loss: 1.088544, acc: 95%] [G loss: 1.134952]\n",
      "[Epoch 7/200] [Batch 171/938] [D loss: 1.114991, acc: 96%] [G loss: 1.072633]\n",
      "[Epoch 7/200] [Batch 172/938] [D loss: 1.114051, acc: 96%] [G loss: 1.106790]\n",
      "[Epoch 7/200] [Batch 173/938] [D loss: 1.088760, acc: 96%] [G loss: 1.105419]\n",
      "[Epoch 7/200] [Batch 174/938] [D loss: 1.101190, acc: 94%] [G loss: 1.104291]\n",
      "[Epoch 7/200] [Batch 175/938] [D loss: 1.127367, acc: 96%] [G loss: 1.150508]\n",
      "[Epoch 7/200] [Batch 176/938] [D loss: 1.052661, acc: 98%] [G loss: 1.106239]\n",
      "[Epoch 7/200] [Batch 177/938] [D loss: 1.116890, acc: 94%] [G loss: 1.073469]\n",
      "[Epoch 7/200] [Batch 178/938] [D loss: 1.081458, acc: 96%] [G loss: 1.188503]\n",
      "[Epoch 7/200] [Batch 179/938] [D loss: 1.074815, acc: 96%] [G loss: 1.098762]\n",
      "[Epoch 7/200] [Batch 180/938] [D loss: 1.099220, acc: 96%] [G loss: 1.125062]\n",
      "[Epoch 7/200] [Batch 181/938] [D loss: 1.118185, acc: 94%] [G loss: 1.054708]\n",
      "[Epoch 7/200] [Batch 182/938] [D loss: 1.095345, acc: 96%] [G loss: 1.082358]\n",
      "[Epoch 7/200] [Batch 183/938] [D loss: 1.073746, acc: 93%] [G loss: 1.126004]\n",
      "[Epoch 7/200] [Batch 184/938] [D loss: 1.103138, acc: 96%] [G loss: 1.143858]\n",
      "[Epoch 7/200] [Batch 185/938] [D loss: 1.119911, acc: 91%] [G loss: 1.086937]\n",
      "[Epoch 7/200] [Batch 186/938] [D loss: 1.099257, acc: 95%] [G loss: 1.119277]\n",
      "[Epoch 7/200] [Batch 187/938] [D loss: 1.101681, acc: 96%] [G loss: 1.075940]\n",
      "[Epoch 7/200] [Batch 188/938] [D loss: 1.055671, acc: 100%] [G loss: 1.051171]\n",
      "[Epoch 7/200] [Batch 189/938] [D loss: 1.061327, acc: 93%] [G loss: 1.164238]\n",
      "[Epoch 7/200] [Batch 190/938] [D loss: 1.065550, acc: 96%] [G loss: 1.118147]\n",
      "[Epoch 7/200] [Batch 191/938] [D loss: 1.092582, acc: 96%] [G loss: 1.139706]\n",
      "[Epoch 7/200] [Batch 192/938] [D loss: 1.041438, acc: 98%] [G loss: 1.080594]\n",
      "[Epoch 7/200] [Batch 193/938] [D loss: 1.143580, acc: 96%] [G loss: 1.098814]\n",
      "[Epoch 7/200] [Batch 194/938] [D loss: 1.119040, acc: 95%] [G loss: 1.143997]\n",
      "[Epoch 7/200] [Batch 195/938] [D loss: 1.096293, acc: 93%] [G loss: 1.067395]\n",
      "[Epoch 7/200] [Batch 196/938] [D loss: 1.036242, acc: 97%] [G loss: 1.179350]\n",
      "[Epoch 7/200] [Batch 197/938] [D loss: 1.088550, acc: 96%] [G loss: 1.152906]\n",
      "[Epoch 7/200] [Batch 198/938] [D loss: 1.079625, acc: 94%] [G loss: 1.114807]\n",
      "[Epoch 7/200] [Batch 199/938] [D loss: 1.096779, acc: 96%] [G loss: 1.138479]\n",
      "[Epoch 7/200] [Batch 200/938] [D loss: 1.112132, acc: 94%] [G loss: 1.127605]\n",
      "[Epoch 7/200] [Batch 201/938] [D loss: 1.088183, acc: 95%] [G loss: 1.073119]\n",
      "[Epoch 7/200] [Batch 202/938] [D loss: 1.108945, acc: 95%] [G loss: 1.092215]\n",
      "[Epoch 7/200] [Batch 203/938] [D loss: 1.101868, acc: 96%] [G loss: 1.069705]\n",
      "[Epoch 7/200] [Batch 204/938] [D loss: 1.110113, acc: 94%] [G loss: 1.149362]\n",
      "[Epoch 7/200] [Batch 205/938] [D loss: 1.154664, acc: 92%] [G loss: 1.117024]\n",
      "[Epoch 7/200] [Batch 206/938] [D loss: 1.093634, acc: 95%] [G loss: 1.144906]\n",
      "[Epoch 7/200] [Batch 207/938] [D loss: 1.092082, acc: 96%] [G loss: 1.118105]\n",
      "[Epoch 7/200] [Batch 208/938] [D loss: 1.080794, acc: 99%] [G loss: 1.100581]\n",
      "[Epoch 7/200] [Batch 209/938] [D loss: 1.082289, acc: 97%] [G loss: 1.126292]\n",
      "[Epoch 7/200] [Batch 210/938] [D loss: 1.096802, acc: 94%] [G loss: 1.116257]\n",
      "[Epoch 7/200] [Batch 211/938] [D loss: 1.091929, acc: 95%] [G loss: 1.077623]\n",
      "[Epoch 7/200] [Batch 212/938] [D loss: 1.108209, acc: 96%] [G loss: 1.074080]\n",
      "[Epoch 7/200] [Batch 213/938] [D loss: 1.073915, acc: 98%] [G loss: 1.044111]\n",
      "[Epoch 7/200] [Batch 214/938] [D loss: 1.065777, acc: 99%] [G loss: 1.106887]\n",
      "[Epoch 7/200] [Batch 215/938] [D loss: 1.095574, acc: 95%] [G loss: 1.093420]\n",
      "[Epoch 7/200] [Batch 216/938] [D loss: 1.069398, acc: 95%] [G loss: 1.114661]\n",
      "[Epoch 7/200] [Batch 217/938] [D loss: 1.114281, acc: 96%] [G loss: 1.144033]\n",
      "[Epoch 7/200] [Batch 218/938] [D loss: 1.069184, acc: 96%] [G loss: 1.094541]\n",
      "[Epoch 7/200] [Batch 219/938] [D loss: 1.115851, acc: 96%] [G loss: 1.048483]\n",
      "[Epoch 7/200] [Batch 220/938] [D loss: 1.117855, acc: 95%] [G loss: 1.090384]\n",
      "[Epoch 7/200] [Batch 221/938] [D loss: 1.076217, acc: 96%] [G loss: 1.097167]\n",
      "[Epoch 7/200] [Batch 222/938] [D loss: 1.076821, acc: 99%] [G loss: 1.097430]\n",
      "[Epoch 7/200] [Batch 223/938] [D loss: 1.109447, acc: 96%] [G loss: 1.042555]\n",
      "[Epoch 7/200] [Batch 224/938] [D loss: 1.079216, acc: 96%] [G loss: 1.123257]\n",
      "[Epoch 7/200] [Batch 225/938] [D loss: 1.116280, acc: 92%] [G loss: 1.148364]\n",
      "[Epoch 7/200] [Batch 226/938] [D loss: 1.073893, acc: 97%] [G loss: 1.192033]\n",
      "[Epoch 7/200] [Batch 227/938] [D loss: 1.106013, acc: 95%] [G loss: 1.122132]\n",
      "[Epoch 7/200] [Batch 228/938] [D loss: 1.074165, acc: 93%] [G loss: 1.116544]\n",
      "[Epoch 7/200] [Batch 229/938] [D loss: 1.087587, acc: 99%] [G loss: 1.102454]\n",
      "[Epoch 7/200] [Batch 230/938] [D loss: 1.074649, acc: 97%] [G loss: 1.071652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 231/938] [D loss: 1.079483, acc: 96%] [G loss: 1.089900]\n",
      "[Epoch 7/200] [Batch 232/938] [D loss: 1.042373, acc: 97%] [G loss: 1.133572]\n",
      "[Epoch 7/200] [Batch 233/938] [D loss: 1.100805, acc: 96%] [G loss: 1.079201]\n",
      "[Epoch 7/200] [Batch 234/938] [D loss: 1.051124, acc: 96%] [G loss: 1.138077]\n",
      "[Epoch 7/200] [Batch 235/938] [D loss: 1.109021, acc: 94%] [G loss: 1.126877]\n",
      "[Epoch 7/200] [Batch 236/938] [D loss: 1.077472, acc: 96%] [G loss: 1.129657]\n",
      "[Epoch 7/200] [Batch 237/938] [D loss: 1.122922, acc: 94%] [G loss: 1.103557]\n",
      "[Epoch 7/200] [Batch 238/938] [D loss: 1.107636, acc: 95%] [G loss: 1.100034]\n",
      "[Epoch 7/200] [Batch 239/938] [D loss: 1.114977, acc: 96%] [G loss: 1.094851]\n",
      "[Epoch 7/200] [Batch 240/938] [D loss: 1.079507, acc: 95%] [G loss: 1.131390]\n",
      "[Epoch 7/200] [Batch 241/938] [D loss: 1.079736, acc: 96%] [G loss: 1.111174]\n",
      "[Epoch 7/200] [Batch 242/938] [D loss: 1.082138, acc: 96%] [G loss: 1.105297]\n",
      "[Epoch 7/200] [Batch 243/938] [D loss: 1.097473, acc: 96%] [G loss: 1.088014]\n",
      "[Epoch 7/200] [Batch 244/938] [D loss: 1.111136, acc: 95%] [G loss: 1.115798]\n",
      "[Epoch 7/200] [Batch 245/938] [D loss: 1.039418, acc: 98%] [G loss: 1.159601]\n",
      "[Epoch 7/200] [Batch 246/938] [D loss: 1.040852, acc: 96%] [G loss: 1.090105]\n",
      "[Epoch 7/200] [Batch 247/938] [D loss: 1.068591, acc: 96%] [G loss: 1.061280]\n",
      "[Epoch 7/200] [Batch 248/938] [D loss: 1.089761, acc: 98%] [G loss: 1.065514]\n",
      "[Epoch 7/200] [Batch 249/938] [D loss: 1.074995, acc: 96%] [G loss: 1.093869]\n",
      "[Epoch 7/200] [Batch 250/938] [D loss: 1.112838, acc: 94%] [G loss: 1.170193]\n",
      "[Epoch 7/200] [Batch 251/938] [D loss: 1.113376, acc: 96%] [G loss: 1.115788]\n",
      "[Epoch 7/200] [Batch 252/938] [D loss: 1.041940, acc: 98%] [G loss: 1.119633]\n",
      "[Epoch 7/200] [Batch 253/938] [D loss: 1.091658, acc: 97%] [G loss: 1.117223]\n",
      "[Epoch 7/200] [Batch 254/938] [D loss: 1.085837, acc: 96%] [G loss: 1.114543]\n",
      "[Epoch 7/200] [Batch 255/938] [D loss: 1.098530, acc: 93%] [G loss: 1.119864]\n",
      "[Epoch 7/200] [Batch 256/938] [D loss: 1.106218, acc: 96%] [G loss: 1.110594]\n",
      "[Epoch 7/200] [Batch 257/938] [D loss: 1.060260, acc: 95%] [G loss: 1.086455]\n",
      "[Epoch 7/200] [Batch 258/938] [D loss: 1.090457, acc: 91%] [G loss: 1.098634]\n",
      "[Epoch 7/200] [Batch 259/938] [D loss: 1.081058, acc: 98%] [G loss: 1.063746]\n",
      "[Epoch 7/200] [Batch 260/938] [D loss: 1.084404, acc: 98%] [G loss: 1.116389]\n",
      "[Epoch 7/200] [Batch 261/938] [D loss: 1.122038, acc: 93%] [G loss: 1.164908]\n",
      "[Epoch 7/200] [Batch 262/938] [D loss: 1.098352, acc: 96%] [G loss: 1.170697]\n",
      "[Epoch 7/200] [Batch 263/938] [D loss: 1.134613, acc: 96%] [G loss: 1.071641]\n",
      "[Epoch 7/200] [Batch 264/938] [D loss: 1.089728, acc: 95%] [G loss: 1.111639]\n",
      "[Epoch 7/200] [Batch 265/938] [D loss: 1.073445, acc: 95%] [G loss: 1.074143]\n",
      "[Epoch 7/200] [Batch 266/938] [D loss: 1.093922, acc: 95%] [G loss: 1.164052]\n",
      "[Epoch 7/200] [Batch 267/938] [D loss: 1.064632, acc: 99%] [G loss: 1.117973]\n",
      "[Epoch 7/200] [Batch 268/938] [D loss: 1.063917, acc: 98%] [G loss: 1.137997]\n",
      "[Epoch 7/200] [Batch 269/938] [D loss: 1.089516, acc: 96%] [G loss: 1.099769]\n",
      "[Epoch 7/200] [Batch 270/938] [D loss: 1.047143, acc: 97%] [G loss: 1.119173]\n",
      "[Epoch 7/200] [Batch 271/938] [D loss: 1.087327, acc: 96%] [G loss: 1.142326]\n",
      "[Epoch 7/200] [Batch 272/938] [D loss: 1.100381, acc: 99%] [G loss: 1.116842]\n",
      "[Epoch 7/200] [Batch 273/938] [D loss: 1.103289, acc: 96%] [G loss: 1.163476]\n",
      "[Epoch 7/200] [Batch 274/938] [D loss: 1.138981, acc: 95%] [G loss: 1.134345]\n",
      "[Epoch 7/200] [Batch 275/938] [D loss: 1.082299, acc: 96%] [G loss: 1.068424]\n",
      "[Epoch 7/200] [Batch 276/938] [D loss: 1.076876, acc: 99%] [G loss: 1.102248]\n",
      "[Epoch 7/200] [Batch 277/938] [D loss: 1.068047, acc: 96%] [G loss: 1.071552]\n",
      "[Epoch 7/200] [Batch 278/938] [D loss: 1.110297, acc: 96%] [G loss: 1.152539]\n",
      "[Epoch 7/200] [Batch 279/938] [D loss: 1.120817, acc: 96%] [G loss: 1.036516]\n",
      "[Epoch 7/200] [Batch 280/938] [D loss: 1.072350, acc: 96%] [G loss: 1.142778]\n",
      "[Epoch 7/200] [Batch 281/938] [D loss: 1.090011, acc: 96%] [G loss: 1.103141]\n",
      "[Epoch 7/200] [Batch 282/938] [D loss: 1.059795, acc: 98%] [G loss: 1.111107]\n",
      "[Epoch 7/200] [Batch 283/938] [D loss: 1.088704, acc: 97%] [G loss: 1.188479]\n",
      "[Epoch 7/200] [Batch 284/938] [D loss: 1.086000, acc: 94%] [G loss: 1.075419]\n",
      "[Epoch 7/200] [Batch 285/938] [D loss: 1.080548, acc: 94%] [G loss: 1.143025]\n",
      "[Epoch 7/200] [Batch 286/938] [D loss: 1.080864, acc: 96%] [G loss: 1.102358]\n",
      "[Epoch 7/200] [Batch 287/938] [D loss: 1.075181, acc: 97%] [G loss: 1.149377]\n",
      "[Epoch 7/200] [Batch 288/938] [D loss: 1.090515, acc: 98%] [G loss: 1.071016]\n",
      "[Epoch 7/200] [Batch 289/938] [D loss: 1.087506, acc: 93%] [G loss: 1.117838]\n",
      "[Epoch 7/200] [Batch 290/938] [D loss: 1.067912, acc: 96%] [G loss: 1.045679]\n",
      "[Epoch 7/200] [Batch 291/938] [D loss: 1.117540, acc: 93%] [G loss: 1.099591]\n",
      "[Epoch 7/200] [Batch 292/938] [D loss: 1.090046, acc: 91%] [G loss: 1.098680]\n",
      "[Epoch 7/200] [Batch 293/938] [D loss: 1.071510, acc: 96%] [G loss: 1.072004]\n",
      "[Epoch 7/200] [Batch 294/938] [D loss: 1.052825, acc: 99%] [G loss: 1.094728]\n",
      "[Epoch 7/200] [Batch 295/938] [D loss: 1.099344, acc: 98%] [G loss: 1.124835]\n",
      "[Epoch 7/200] [Batch 296/938] [D loss: 1.083403, acc: 94%] [G loss: 1.144159]\n",
      "[Epoch 7/200] [Batch 297/938] [D loss: 1.094286, acc: 94%] [G loss: 1.165286]\n",
      "[Epoch 7/200] [Batch 298/938] [D loss: 1.100264, acc: 98%] [G loss: 1.130811]\n",
      "[Epoch 7/200] [Batch 299/938] [D loss: 1.089722, acc: 97%] [G loss: 1.164087]\n",
      "[Epoch 7/200] [Batch 300/938] [D loss: 1.030870, acc: 96%] [G loss: 1.145256]\n",
      "[Epoch 7/200] [Batch 301/938] [D loss: 1.100179, acc: 96%] [G loss: 1.134234]\n",
      "[Epoch 7/200] [Batch 302/938] [D loss: 1.044034, acc: 96%] [G loss: 1.155222]\n",
      "[Epoch 7/200] [Batch 303/938] [D loss: 1.083490, acc: 96%] [G loss: 1.163277]\n",
      "[Epoch 7/200] [Batch 304/938] [D loss: 1.114791, acc: 96%] [G loss: 1.209048]\n",
      "[Epoch 7/200] [Batch 305/938] [D loss: 1.095365, acc: 95%] [G loss: 1.155336]\n",
      "[Epoch 7/200] [Batch 306/938] [D loss: 1.088297, acc: 96%] [G loss: 1.106568]\n",
      "[Epoch 7/200] [Batch 307/938] [D loss: 1.073468, acc: 98%] [G loss: 1.063241]\n",
      "[Epoch 7/200] [Batch 308/938] [D loss: 1.090177, acc: 96%] [G loss: 1.092462]\n",
      "[Epoch 7/200] [Batch 309/938] [D loss: 1.074278, acc: 96%] [G loss: 1.096365]\n",
      "[Epoch 7/200] [Batch 310/938] [D loss: 1.132444, acc: 97%] [G loss: 1.142197]\n",
      "[Epoch 7/200] [Batch 311/938] [D loss: 1.089552, acc: 95%] [G loss: 1.065403]\n",
      "[Epoch 7/200] [Batch 312/938] [D loss: 1.065489, acc: 96%] [G loss: 1.114156]\n",
      "[Epoch 7/200] [Batch 313/938] [D loss: 1.081469, acc: 94%] [G loss: 1.115008]\n",
      "[Epoch 7/200] [Batch 314/938] [D loss: 1.084673, acc: 94%] [G loss: 1.068566]\n",
      "[Epoch 7/200] [Batch 315/938] [D loss: 1.085899, acc: 97%] [G loss: 1.092837]\n",
      "[Epoch 7/200] [Batch 316/938] [D loss: 1.123940, acc: 91%] [G loss: 1.212249]\n",
      "[Epoch 7/200] [Batch 317/938] [D loss: 1.087862, acc: 94%] [G loss: 1.147821]\n",
      "[Epoch 7/200] [Batch 318/938] [D loss: 1.101628, acc: 95%] [G loss: 1.038481]\n",
      "[Epoch 7/200] [Batch 319/938] [D loss: 1.081375, acc: 96%] [G loss: 1.054311]\n",
      "[Epoch 7/200] [Batch 320/938] [D loss: 1.100857, acc: 94%] [G loss: 1.078492]\n",
      "[Epoch 7/200] [Batch 321/938] [D loss: 1.089051, acc: 96%] [G loss: 1.078949]\n",
      "[Epoch 7/200] [Batch 322/938] [D loss: 1.081917, acc: 96%] [G loss: 1.127546]\n",
      "[Epoch 7/200] [Batch 323/938] [D loss: 1.077662, acc: 95%] [G loss: 1.037065]\n",
      "[Epoch 7/200] [Batch 324/938] [D loss: 1.090367, acc: 97%] [G loss: 1.088679]\n",
      "[Epoch 7/200] [Batch 325/938] [D loss: 1.067311, acc: 96%] [G loss: 1.070112]\n",
      "[Epoch 7/200] [Batch 326/938] [D loss: 1.097845, acc: 93%] [G loss: 1.061220]\n",
      "[Epoch 7/200] [Batch 327/938] [D loss: 1.071855, acc: 99%] [G loss: 1.112798]\n",
      "[Epoch 7/200] [Batch 328/938] [D loss: 1.081672, acc: 96%] [G loss: 1.110320]\n",
      "[Epoch 7/200] [Batch 329/938] [D loss: 1.075760, acc: 98%] [G loss: 1.103612]\n",
      "[Epoch 7/200] [Batch 330/938] [D loss: 1.077599, acc: 98%] [G loss: 1.069096]\n",
      "[Epoch 7/200] [Batch 331/938] [D loss: 1.093063, acc: 96%] [G loss: 1.167000]\n",
      "[Epoch 7/200] [Batch 332/938] [D loss: 1.102882, acc: 96%] [G loss: 1.116355]\n",
      "[Epoch 7/200] [Batch 333/938] [D loss: 1.047399, acc: 94%] [G loss: 1.065018]\n",
      "[Epoch 7/200] [Batch 334/938] [D loss: 1.096825, acc: 92%] [G loss: 1.095195]\n",
      "[Epoch 7/200] [Batch 335/938] [D loss: 1.113881, acc: 95%] [G loss: 1.104115]\n",
      "[Epoch 7/200] [Batch 336/938] [D loss: 1.089130, acc: 96%] [G loss: 1.068315]\n",
      "[Epoch 7/200] [Batch 337/938] [D loss: 1.107568, acc: 94%] [G loss: 1.076269]\n",
      "[Epoch 7/200] [Batch 338/938] [D loss: 1.054225, acc: 97%] [G loss: 1.116603]\n",
      "[Epoch 7/200] [Batch 339/938] [D loss: 1.087166, acc: 100%] [G loss: 1.120706]\n",
      "[Epoch 7/200] [Batch 340/938] [D loss: 1.064036, acc: 97%] [G loss: 1.074143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 341/938] [D loss: 1.080426, acc: 98%] [G loss: 1.112661]\n",
      "[Epoch 7/200] [Batch 342/938] [D loss: 1.085321, acc: 96%] [G loss: 1.098716]\n",
      "[Epoch 7/200] [Batch 343/938] [D loss: 1.107175, acc: 93%] [G loss: 1.128533]\n",
      "[Epoch 7/200] [Batch 344/938] [D loss: 1.062768, acc: 97%] [G loss: 1.087223]\n",
      "[Epoch 7/200] [Batch 345/938] [D loss: 1.098974, acc: 96%] [G loss: 1.088315]\n",
      "[Epoch 7/200] [Batch 346/938] [D loss: 1.085145, acc: 99%] [G loss: 1.082482]\n",
      "[Epoch 7/200] [Batch 347/938] [D loss: 1.067390, acc: 93%] [G loss: 1.131740]\n",
      "[Epoch 7/200] [Batch 348/938] [D loss: 1.106592, acc: 96%] [G loss: 1.116510]\n",
      "[Epoch 7/200] [Batch 349/938] [D loss: 1.098605, acc: 96%] [G loss: 1.097252]\n",
      "[Epoch 7/200] [Batch 350/938] [D loss: 1.097999, acc: 96%] [G loss: 1.103681]\n",
      "[Epoch 7/200] [Batch 351/938] [D loss: 1.094629, acc: 94%] [G loss: 1.106687]\n",
      "[Epoch 7/200] [Batch 352/938] [D loss: 1.114551, acc: 93%] [G loss: 1.125965]\n",
      "[Epoch 7/200] [Batch 353/938] [D loss: 1.067494, acc: 97%] [G loss: 1.102107]\n",
      "[Epoch 7/200] [Batch 354/938] [D loss: 1.114288, acc: 95%] [G loss: 1.115807]\n",
      "[Epoch 7/200] [Batch 355/938] [D loss: 1.082543, acc: 95%] [G loss: 1.128995]\n",
      "[Epoch 7/200] [Batch 356/938] [D loss: 1.039159, acc: 93%] [G loss: 1.114921]\n",
      "[Epoch 7/200] [Batch 357/938] [D loss: 1.094340, acc: 96%] [G loss: 1.145592]\n",
      "[Epoch 7/200] [Batch 358/938] [D loss: 1.083380, acc: 96%] [G loss: 1.077551]\n",
      "[Epoch 7/200] [Batch 359/938] [D loss: 1.078717, acc: 97%] [G loss: 1.130249]\n",
      "[Epoch 7/200] [Batch 360/938] [D loss: 1.086893, acc: 96%] [G loss: 1.136588]\n",
      "[Epoch 7/200] [Batch 361/938] [D loss: 1.074383, acc: 96%] [G loss: 1.074438]\n",
      "[Epoch 7/200] [Batch 362/938] [D loss: 1.077244, acc: 92%] [G loss: 1.137183]\n",
      "[Epoch 7/200] [Batch 363/938] [D loss: 1.114004, acc: 92%] [G loss: 1.143949]\n",
      "[Epoch 7/200] [Batch 364/938] [D loss: 1.096389, acc: 95%] [G loss: 1.114301]\n",
      "[Epoch 7/200] [Batch 365/938] [D loss: 1.115095, acc: 93%] [G loss: 1.140257]\n",
      "[Epoch 7/200] [Batch 366/938] [D loss: 1.083335, acc: 98%] [G loss: 1.089885]\n",
      "[Epoch 7/200] [Batch 367/938] [D loss: 1.071686, acc: 95%] [G loss: 1.123971]\n",
      "[Epoch 7/200] [Batch 368/938] [D loss: 1.119070, acc: 95%] [G loss: 1.048332]\n",
      "[Epoch 7/200] [Batch 369/938] [D loss: 1.081933, acc: 94%] [G loss: 1.137017]\n",
      "[Epoch 7/200] [Batch 370/938] [D loss: 1.097669, acc: 95%] [G loss: 1.077302]\n",
      "[Epoch 7/200] [Batch 371/938] [D loss: 1.110567, acc: 96%] [G loss: 1.146654]\n",
      "[Epoch 7/200] [Batch 372/938] [D loss: 1.095305, acc: 98%] [G loss: 1.098962]\n",
      "[Epoch 7/200] [Batch 373/938] [D loss: 1.124096, acc: 97%] [G loss: 1.103016]\n",
      "[Epoch 7/200] [Batch 374/938] [D loss: 1.068632, acc: 98%] [G loss: 1.097484]\n",
      "[Epoch 7/200] [Batch 375/938] [D loss: 1.073529, acc: 92%] [G loss: 1.025101]\n",
      "[Epoch 7/200] [Batch 376/938] [D loss: 1.087191, acc: 96%] [G loss: 1.060807]\n",
      "[Epoch 7/200] [Batch 377/938] [D loss: 1.075345, acc: 100%] [G loss: 1.146695]\n",
      "[Epoch 7/200] [Batch 378/938] [D loss: 1.114028, acc: 91%] [G loss: 1.146882]\n",
      "[Epoch 7/200] [Batch 379/938] [D loss: 1.080976, acc: 96%] [G loss: 1.143488]\n",
      "[Epoch 7/200] [Batch 380/938] [D loss: 1.091197, acc: 96%] [G loss: 1.128328]\n",
      "[Epoch 7/200] [Batch 381/938] [D loss: 1.077998, acc: 95%] [G loss: 1.129218]\n",
      "[Epoch 7/200] [Batch 382/938] [D loss: 1.100570, acc: 96%] [G loss: 1.095756]\n",
      "[Epoch 7/200] [Batch 383/938] [D loss: 1.102318, acc: 95%] [G loss: 1.120943]\n",
      "[Epoch 7/200] [Batch 384/938] [D loss: 1.079648, acc: 96%] [G loss: 1.106690]\n",
      "[Epoch 7/200] [Batch 385/938] [D loss: 1.076555, acc: 93%] [G loss: 1.108175]\n",
      "[Epoch 7/200] [Batch 386/938] [D loss: 1.094031, acc: 97%] [G loss: 1.056761]\n",
      "[Epoch 7/200] [Batch 387/938] [D loss: 1.106843, acc: 98%] [G loss: 1.096287]\n",
      "[Epoch 7/200] [Batch 388/938] [D loss: 1.055777, acc: 99%] [G loss: 1.109167]\n",
      "[Epoch 7/200] [Batch 389/938] [D loss: 1.052168, acc: 95%] [G loss: 1.090597]\n",
      "[Epoch 7/200] [Batch 390/938] [D loss: 1.111404, acc: 94%] [G loss: 1.050385]\n",
      "[Epoch 7/200] [Batch 391/938] [D loss: 1.071055, acc: 98%] [G loss: 1.127841]\n",
      "[Epoch 7/200] [Batch 392/938] [D loss: 1.115793, acc: 92%] [G loss: 1.133832]\n",
      "[Epoch 7/200] [Batch 393/938] [D loss: 1.075655, acc: 96%] [G loss: 1.147502]\n",
      "[Epoch 7/200] [Batch 394/938] [D loss: 1.091349, acc: 97%] [G loss: 1.180278]\n",
      "[Epoch 7/200] [Batch 395/938] [D loss: 1.116379, acc: 96%] [G loss: 1.096996]\n",
      "[Epoch 7/200] [Batch 396/938] [D loss: 1.071278, acc: 98%] [G loss: 1.108158]\n",
      "[Epoch 7/200] [Batch 397/938] [D loss: 1.104967, acc: 94%] [G loss: 1.124531]\n",
      "[Epoch 7/200] [Batch 398/938] [D loss: 1.108035, acc: 97%] [G loss: 1.087130]\n",
      "[Epoch 7/200] [Batch 399/938] [D loss: 1.075471, acc: 96%] [G loss: 1.100103]\n",
      "[Epoch 7/200] [Batch 400/938] [D loss: 1.066400, acc: 93%] [G loss: 1.114393]\n",
      "[Epoch 7/200] [Batch 401/938] [D loss: 1.097833, acc: 95%] [G loss: 1.139371]\n",
      "[Epoch 7/200] [Batch 402/938] [D loss: 1.103415, acc: 98%] [G loss: 1.061651]\n",
      "[Epoch 7/200] [Batch 403/938] [D loss: 1.130333, acc: 93%] [G loss: 1.097020]\n",
      "[Epoch 7/200] [Batch 404/938] [D loss: 1.105090, acc: 96%] [G loss: 1.091028]\n",
      "[Epoch 7/200] [Batch 405/938] [D loss: 1.108985, acc: 95%] [G loss: 1.161955]\n",
      "[Epoch 7/200] [Batch 406/938] [D loss: 1.102362, acc: 95%] [G loss: 1.158029]\n",
      "[Epoch 7/200] [Batch 407/938] [D loss: 1.100149, acc: 94%] [G loss: 1.086279]\n",
      "[Epoch 7/200] [Batch 408/938] [D loss: 1.098937, acc: 96%] [G loss: 1.072671]\n",
      "[Epoch 7/200] [Batch 409/938] [D loss: 1.118709, acc: 96%] [G loss: 1.110535]\n",
      "[Epoch 7/200] [Batch 410/938] [D loss: 1.089192, acc: 98%] [G loss: 1.180480]\n",
      "[Epoch 7/200] [Batch 411/938] [D loss: 1.046473, acc: 99%] [G loss: 1.104317]\n",
      "[Epoch 7/200] [Batch 412/938] [D loss: 1.111270, acc: 93%] [G loss: 1.118006]\n",
      "[Epoch 7/200] [Batch 413/938] [D loss: 1.068631, acc: 97%] [G loss: 1.118510]\n",
      "[Epoch 7/200] [Batch 414/938] [D loss: 1.083491, acc: 95%] [G loss: 1.101392]\n",
      "[Epoch 7/200] [Batch 415/938] [D loss: 1.070452, acc: 98%] [G loss: 1.087731]\n",
      "[Epoch 7/200] [Batch 416/938] [D loss: 1.079097, acc: 96%] [G loss: 1.141008]\n",
      "[Epoch 7/200] [Batch 417/938] [D loss: 1.097688, acc: 97%] [G loss: 1.113077]\n",
      "[Epoch 7/200] [Batch 418/938] [D loss: 1.102045, acc: 96%] [G loss: 1.065558]\n",
      "[Epoch 7/200] [Batch 419/938] [D loss: 1.047189, acc: 95%] [G loss: 1.113730]\n",
      "[Epoch 7/200] [Batch 420/938] [D loss: 1.110749, acc: 97%] [G loss: 1.072592]\n",
      "[Epoch 7/200] [Batch 421/938] [D loss: 1.121464, acc: 95%] [G loss: 1.128699]\n",
      "[Epoch 7/200] [Batch 422/938] [D loss: 1.086867, acc: 95%] [G loss: 1.143070]\n",
      "[Epoch 7/200] [Batch 423/938] [D loss: 1.081404, acc: 96%] [G loss: 1.147525]\n",
      "[Epoch 7/200] [Batch 424/938] [D loss: 1.105949, acc: 94%] [G loss: 1.099806]\n",
      "[Epoch 7/200] [Batch 425/938] [D loss: 1.068025, acc: 96%] [G loss: 1.051064]\n",
      "[Epoch 7/200] [Batch 426/938] [D loss: 1.105891, acc: 94%] [G loss: 1.096270]\n",
      "[Epoch 7/200] [Batch 427/938] [D loss: 1.089257, acc: 96%] [G loss: 1.118790]\n",
      "[Epoch 7/200] [Batch 428/938] [D loss: 1.046243, acc: 98%] [G loss: 1.087015]\n",
      "[Epoch 7/200] [Batch 429/938] [D loss: 1.095310, acc: 94%] [G loss: 1.099299]\n",
      "[Epoch 7/200] [Batch 430/938] [D loss: 1.105507, acc: 96%] [G loss: 1.114600]\n",
      "[Epoch 7/200] [Batch 431/938] [D loss: 1.100685, acc: 95%] [G loss: 1.103814]\n",
      "[Epoch 7/200] [Batch 432/938] [D loss: 1.088258, acc: 98%] [G loss: 1.123721]\n",
      "[Epoch 7/200] [Batch 433/938] [D loss: 1.108035, acc: 97%] [G loss: 1.089650]\n",
      "[Epoch 7/200] [Batch 434/938] [D loss: 1.111195, acc: 98%] [G loss: 1.114683]\n",
      "[Epoch 7/200] [Batch 435/938] [D loss: 1.089679, acc: 93%] [G loss: 1.144299]\n",
      "[Epoch 7/200] [Batch 436/938] [D loss: 1.052464, acc: 96%] [G loss: 1.102496]\n",
      "[Epoch 7/200] [Batch 437/938] [D loss: 1.118236, acc: 93%] [G loss: 1.104202]\n",
      "[Epoch 7/200] [Batch 438/938] [D loss: 1.072284, acc: 95%] [G loss: 1.163733]\n",
      "[Epoch 7/200] [Batch 439/938] [D loss: 1.068139, acc: 97%] [G loss: 1.129764]\n",
      "[Epoch 7/200] [Batch 440/938] [D loss: 1.096144, acc: 96%] [G loss: 1.043947]\n",
      "[Epoch 7/200] [Batch 441/938] [D loss: 1.104545, acc: 94%] [G loss: 1.079593]\n",
      "[Epoch 7/200] [Batch 442/938] [D loss: 1.070412, acc: 96%] [G loss: 1.077392]\n",
      "[Epoch 7/200] [Batch 443/938] [D loss: 1.146741, acc: 95%] [G loss: 1.082334]\n",
      "[Epoch 7/200] [Batch 444/938] [D loss: 1.102330, acc: 92%] [G loss: 1.144801]\n",
      "[Epoch 7/200] [Batch 445/938] [D loss: 1.110850, acc: 95%] [G loss: 1.104534]\n",
      "[Epoch 7/200] [Batch 446/938] [D loss: 1.104554, acc: 94%] [G loss: 1.127445]\n",
      "[Epoch 7/200] [Batch 447/938] [D loss: 1.100124, acc: 95%] [G loss: 1.058732]\n",
      "[Epoch 7/200] [Batch 448/938] [D loss: 1.123741, acc: 96%] [G loss: 1.101520]\n",
      "[Epoch 7/200] [Batch 449/938] [D loss: 1.087587, acc: 96%] [G loss: 1.113071]\n",
      "[Epoch 7/200] [Batch 450/938] [D loss: 1.090525, acc: 96%] [G loss: 1.152887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 451/938] [D loss: 1.116121, acc: 95%] [G loss: 1.172514]\n",
      "[Epoch 7/200] [Batch 452/938] [D loss: 1.091888, acc: 96%] [G loss: 1.212519]\n",
      "[Epoch 7/200] [Batch 453/938] [D loss: 1.105914, acc: 93%] [G loss: 1.134500]\n",
      "[Epoch 7/200] [Batch 454/938] [D loss: 1.109302, acc: 97%] [G loss: 1.148604]\n",
      "[Epoch 7/200] [Batch 455/938] [D loss: 1.113794, acc: 95%] [G loss: 1.081518]\n",
      "[Epoch 7/200] [Batch 456/938] [D loss: 1.084364, acc: 94%] [G loss: 1.099234]\n",
      "[Epoch 7/200] [Batch 457/938] [D loss: 1.100051, acc: 97%] [G loss: 1.076231]\n",
      "[Epoch 7/200] [Batch 458/938] [D loss: 1.067469, acc: 97%] [G loss: 1.087094]\n",
      "[Epoch 7/200] [Batch 459/938] [D loss: 1.101112, acc: 99%] [G loss: 1.076980]\n",
      "[Epoch 7/200] [Batch 460/938] [D loss: 1.060742, acc: 99%] [G loss: 1.136586]\n",
      "[Epoch 7/200] [Batch 461/938] [D loss: 1.086819, acc: 98%] [G loss: 1.110230]\n",
      "[Epoch 7/200] [Batch 462/938] [D loss: 1.099086, acc: 98%] [G loss: 1.122850]\n",
      "[Epoch 7/200] [Batch 463/938] [D loss: 1.067786, acc: 96%] [G loss: 1.117659]\n",
      "[Epoch 7/200] [Batch 464/938] [D loss: 1.073166, acc: 91%] [G loss: 1.160126]\n",
      "[Epoch 7/200] [Batch 465/938] [D loss: 1.068692, acc: 96%] [G loss: 1.129288]\n",
      "[Epoch 7/200] [Batch 466/938] [D loss: 1.060040, acc: 98%] [G loss: 1.125541]\n",
      "[Epoch 7/200] [Batch 467/938] [D loss: 1.142506, acc: 95%] [G loss: 1.052147]\n",
      "[Epoch 7/200] [Batch 468/938] [D loss: 1.117458, acc: 95%] [G loss: 1.119270]\n",
      "[Epoch 7/200] [Batch 469/938] [D loss: 1.053741, acc: 97%] [G loss: 1.162917]\n",
      "[Epoch 7/200] [Batch 470/938] [D loss: 1.071426, acc: 97%] [G loss: 1.026086]\n",
      "[Epoch 7/200] [Batch 471/938] [D loss: 1.079456, acc: 97%] [G loss: 1.095885]\n",
      "[Epoch 7/200] [Batch 472/938] [D loss: 1.076467, acc: 96%] [G loss: 1.107703]\n",
      "[Epoch 7/200] [Batch 473/938] [D loss: 1.107019, acc: 97%] [G loss: 1.119686]\n",
      "[Epoch 7/200] [Batch 474/938] [D loss: 1.095563, acc: 96%] [G loss: 1.115368]\n",
      "[Epoch 7/200] [Batch 475/938] [D loss: 1.080349, acc: 93%] [G loss: 1.179664]\n",
      "[Epoch 7/200] [Batch 476/938] [D loss: 1.101686, acc: 97%] [G loss: 1.124072]\n",
      "[Epoch 7/200] [Batch 477/938] [D loss: 1.085582, acc: 96%] [G loss: 1.110584]\n",
      "[Epoch 7/200] [Batch 478/938] [D loss: 1.075891, acc: 96%] [G loss: 1.029431]\n",
      "[Epoch 7/200] [Batch 479/938] [D loss: 1.100421, acc: 98%] [G loss: 1.148645]\n",
      "[Epoch 7/200] [Batch 480/938] [D loss: 1.108226, acc: 98%] [G loss: 1.158111]\n",
      "[Epoch 7/200] [Batch 481/938] [D loss: 1.127622, acc: 92%] [G loss: 1.106455]\n",
      "[Epoch 7/200] [Batch 482/938] [D loss: 1.069874, acc: 96%] [G loss: 1.117201]\n",
      "[Epoch 7/200] [Batch 483/938] [D loss: 1.089897, acc: 96%] [G loss: 1.138446]\n",
      "[Epoch 7/200] [Batch 484/938] [D loss: 1.072928, acc: 93%] [G loss: 1.106314]\n",
      "[Epoch 7/200] [Batch 485/938] [D loss: 1.051560, acc: 96%] [G loss: 1.119670]\n",
      "[Epoch 7/200] [Batch 486/938] [D loss: 1.113015, acc: 96%] [G loss: 1.065662]\n",
      "[Epoch 7/200] [Batch 487/938] [D loss: 1.092001, acc: 96%] [G loss: 1.134773]\n",
      "[Epoch 7/200] [Batch 488/938] [D loss: 1.076484, acc: 97%] [G loss: 1.057045]\n",
      "[Epoch 7/200] [Batch 489/938] [D loss: 1.083365, acc: 97%] [G loss: 1.023098]\n",
      "[Epoch 7/200] [Batch 490/938] [D loss: 1.080802, acc: 94%] [G loss: 1.146231]\n",
      "[Epoch 7/200] [Batch 491/938] [D loss: 1.095893, acc: 96%] [G loss: 1.068771]\n",
      "[Epoch 7/200] [Batch 492/938] [D loss: 1.056790, acc: 99%] [G loss: 1.123639]\n",
      "[Epoch 7/200] [Batch 493/938] [D loss: 1.089442, acc: 96%] [G loss: 1.098225]\n",
      "[Epoch 7/200] [Batch 494/938] [D loss: 1.071417, acc: 94%] [G loss: 1.190966]\n",
      "[Epoch 7/200] [Batch 495/938] [D loss: 1.081015, acc: 95%] [G loss: 1.092095]\n",
      "[Epoch 7/200] [Batch 496/938] [D loss: 1.105558, acc: 95%] [G loss: 1.075647]\n",
      "[Epoch 7/200] [Batch 497/938] [D loss: 1.079952, acc: 96%] [G loss: 1.110319]\n",
      "[Epoch 7/200] [Batch 498/938] [D loss: 1.085338, acc: 96%] [G loss: 1.106572]\n",
      "[Epoch 7/200] [Batch 499/938] [D loss: 1.112798, acc: 95%] [G loss: 1.112569]\n",
      "[Epoch 7/200] [Batch 500/938] [D loss: 1.082004, acc: 96%] [G loss: 1.090278]\n",
      "[Epoch 7/200] [Batch 501/938] [D loss: 1.086188, acc: 96%] [G loss: 1.134606]\n",
      "[Epoch 7/200] [Batch 502/938] [D loss: 1.078766, acc: 96%] [G loss: 1.112095]\n",
      "[Epoch 7/200] [Batch 503/938] [D loss: 1.069985, acc: 95%] [G loss: 1.113035]\n",
      "[Epoch 7/200] [Batch 504/938] [D loss: 1.070198, acc: 96%] [G loss: 1.137520]\n",
      "[Epoch 7/200] [Batch 505/938] [D loss: 1.112313, acc: 98%] [G loss: 1.089592]\n",
      "[Epoch 7/200] [Batch 506/938] [D loss: 1.087964, acc: 96%] [G loss: 1.124948]\n",
      "[Epoch 7/200] [Batch 507/938] [D loss: 1.103416, acc: 92%] [G loss: 1.096097]\n",
      "[Epoch 7/200] [Batch 508/938] [D loss: 1.043103, acc: 97%] [G loss: 1.045266]\n",
      "[Epoch 7/200] [Batch 509/938] [D loss: 1.101845, acc: 96%] [G loss: 1.064007]\n",
      "[Epoch 7/200] [Batch 510/938] [D loss: 1.127146, acc: 96%] [G loss: 1.028080]\n",
      "[Epoch 7/200] [Batch 511/938] [D loss: 1.074078, acc: 97%] [G loss: 1.085573]\n",
      "[Epoch 7/200] [Batch 512/938] [D loss: 1.084114, acc: 93%] [G loss: 1.140744]\n",
      "[Epoch 7/200] [Batch 513/938] [D loss: 1.106632, acc: 97%] [G loss: 1.118762]\n",
      "[Epoch 7/200] [Batch 514/938] [D loss: 1.090030, acc: 97%] [G loss: 1.097177]\n",
      "[Epoch 7/200] [Batch 515/938] [D loss: 1.059362, acc: 96%] [G loss: 1.166375]\n",
      "[Epoch 7/200] [Batch 516/938] [D loss: 1.087848, acc: 96%] [G loss: 1.068850]\n",
      "[Epoch 7/200] [Batch 517/938] [D loss: 1.065525, acc: 97%] [G loss: 1.130093]\n",
      "[Epoch 7/200] [Batch 518/938] [D loss: 1.106008, acc: 92%] [G loss: 1.097818]\n",
      "[Epoch 7/200] [Batch 519/938] [D loss: 1.090447, acc: 96%] [G loss: 1.122627]\n",
      "[Epoch 7/200] [Batch 520/938] [D loss: 1.081208, acc: 94%] [G loss: 1.069441]\n",
      "[Epoch 7/200] [Batch 521/938] [D loss: 1.091981, acc: 96%] [G loss: 1.117579]\n",
      "[Epoch 7/200] [Batch 522/938] [D loss: 1.096362, acc: 89%] [G loss: 1.110271]\n",
      "[Epoch 7/200] [Batch 523/938] [D loss: 1.085448, acc: 97%] [G loss: 1.024326]\n",
      "[Epoch 7/200] [Batch 524/938] [D loss: 1.065637, acc: 96%] [G loss: 1.128804]\n",
      "[Epoch 7/200] [Batch 525/938] [D loss: 1.117836, acc: 96%] [G loss: 1.119487]\n",
      "[Epoch 7/200] [Batch 526/938] [D loss: 1.092081, acc: 94%] [G loss: 1.154180]\n",
      "[Epoch 7/200] [Batch 527/938] [D loss: 1.074197, acc: 97%] [G loss: 1.076131]\n",
      "[Epoch 7/200] [Batch 528/938] [D loss: 1.075394, acc: 96%] [G loss: 1.075797]\n",
      "[Epoch 7/200] [Batch 529/938] [D loss: 1.056913, acc: 97%] [G loss: 1.126090]\n",
      "[Epoch 7/200] [Batch 530/938] [D loss: 1.092844, acc: 96%] [G loss: 1.098870]\n",
      "[Epoch 7/200] [Batch 531/938] [D loss: 1.059554, acc: 100%] [G loss: 1.058918]\n",
      "[Epoch 7/200] [Batch 532/938] [D loss: 1.082588, acc: 97%] [G loss: 1.072365]\n",
      "[Epoch 7/200] [Batch 533/938] [D loss: 1.100788, acc: 98%] [G loss: 1.058340]\n",
      "[Epoch 7/200] [Batch 534/938] [D loss: 1.133405, acc: 96%] [G loss: 1.064889]\n",
      "[Epoch 7/200] [Batch 535/938] [D loss: 1.077177, acc: 95%] [G loss: 1.161575]\n",
      "[Epoch 7/200] [Batch 536/938] [D loss: 1.064571, acc: 96%] [G loss: 1.140483]\n",
      "[Epoch 7/200] [Batch 537/938] [D loss: 1.111158, acc: 97%] [G loss: 1.067300]\n",
      "[Epoch 7/200] [Batch 538/938] [D loss: 1.057918, acc: 98%] [G loss: 1.124155]\n",
      "[Epoch 7/200] [Batch 539/938] [D loss: 1.084730, acc: 96%] [G loss: 1.154644]\n",
      "[Epoch 7/200] [Batch 540/938] [D loss: 1.099360, acc: 96%] [G loss: 1.104925]\n",
      "[Epoch 7/200] [Batch 541/938] [D loss: 1.091511, acc: 96%] [G loss: 1.141086]\n",
      "[Epoch 7/200] [Batch 542/938] [D loss: 1.082131, acc: 99%] [G loss: 1.080765]\n",
      "[Epoch 7/200] [Batch 543/938] [D loss: 1.075139, acc: 98%] [G loss: 1.099743]\n",
      "[Epoch 7/200] [Batch 544/938] [D loss: 1.084867, acc: 98%] [G loss: 1.157996]\n",
      "[Epoch 7/200] [Batch 545/938] [D loss: 1.072384, acc: 97%] [G loss: 1.137028]\n",
      "[Epoch 7/200] [Batch 546/938] [D loss: 1.056480, acc: 96%] [G loss: 1.138100]\n",
      "[Epoch 7/200] [Batch 547/938] [D loss: 1.069997, acc: 96%] [G loss: 1.132132]\n",
      "[Epoch 7/200] [Batch 548/938] [D loss: 1.113349, acc: 97%] [G loss: 1.132481]\n",
      "[Epoch 7/200] [Batch 549/938] [D loss: 1.081407, acc: 94%] [G loss: 1.153180]\n",
      "[Epoch 7/200] [Batch 550/938] [D loss: 1.108480, acc: 95%] [G loss: 1.114500]\n",
      "[Epoch 7/200] [Batch 551/938] [D loss: 1.095406, acc: 96%] [G loss: 1.130198]\n",
      "[Epoch 7/200] [Batch 552/938] [D loss: 1.080608, acc: 96%] [G loss: 1.136083]\n",
      "[Epoch 7/200] [Batch 553/938] [D loss: 1.091020, acc: 96%] [G loss: 1.105658]\n",
      "[Epoch 7/200] [Batch 554/938] [D loss: 1.102628, acc: 96%] [G loss: 1.098932]\n",
      "[Epoch 7/200] [Batch 555/938] [D loss: 1.088562, acc: 92%] [G loss: 1.104406]\n",
      "[Epoch 7/200] [Batch 556/938] [D loss: 1.047718, acc: 97%] [G loss: 1.077337]\n",
      "[Epoch 7/200] [Batch 557/938] [D loss: 1.122143, acc: 96%] [G loss: 1.135969]\n",
      "[Epoch 7/200] [Batch 558/938] [D loss: 1.062684, acc: 99%] [G loss: 1.164121]\n",
      "[Epoch 7/200] [Batch 559/938] [D loss: 1.118370, acc: 95%] [G loss: 1.139173]\n",
      "[Epoch 7/200] [Batch 560/938] [D loss: 1.061070, acc: 96%] [G loss: 1.074923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 561/938] [D loss: 1.074775, acc: 98%] [G loss: 1.063233]\n",
      "[Epoch 7/200] [Batch 562/938] [D loss: 1.077593, acc: 96%] [G loss: 1.103179]\n",
      "[Epoch 7/200] [Batch 563/938] [D loss: 1.077704, acc: 97%] [G loss: 1.041303]\n",
      "[Epoch 7/200] [Batch 564/938] [D loss: 1.103481, acc: 97%] [G loss: 1.068038]\n",
      "[Epoch 7/200] [Batch 565/938] [D loss: 1.113947, acc: 95%] [G loss: 1.150585]\n",
      "[Epoch 7/200] [Batch 566/938] [D loss: 1.095604, acc: 96%] [G loss: 1.180321]\n",
      "[Epoch 7/200] [Batch 567/938] [D loss: 1.131157, acc: 96%] [G loss: 1.068555]\n",
      "[Epoch 7/200] [Batch 568/938] [D loss: 1.067470, acc: 99%] [G loss: 1.041094]\n",
      "[Epoch 7/200] [Batch 569/938] [D loss: 1.105341, acc: 93%] [G loss: 1.125023]\n",
      "[Epoch 7/200] [Batch 570/938] [D loss: 1.069294, acc: 96%] [G loss: 1.079416]\n",
      "[Epoch 7/200] [Batch 571/938] [D loss: 1.085618, acc: 94%] [G loss: 1.137641]\n",
      "[Epoch 7/200] [Batch 572/938] [D loss: 1.046431, acc: 96%] [G loss: 1.109084]\n",
      "[Epoch 7/200] [Batch 573/938] [D loss: 1.050974, acc: 96%] [G loss: 1.101234]\n",
      "[Epoch 7/200] [Batch 574/938] [D loss: 1.106504, acc: 96%] [G loss: 1.170499]\n",
      "[Epoch 7/200] [Batch 575/938] [D loss: 1.094704, acc: 96%] [G loss: 1.128858]\n",
      "[Epoch 7/200] [Batch 576/938] [D loss: 1.092011, acc: 97%] [G loss: 1.151656]\n",
      "[Epoch 7/200] [Batch 577/938] [D loss: 1.091841, acc: 96%] [G loss: 1.177153]\n",
      "[Epoch 7/200] [Batch 578/938] [D loss: 1.070342, acc: 96%] [G loss: 1.220894]\n",
      "[Epoch 7/200] [Batch 579/938] [D loss: 1.054761, acc: 93%] [G loss: 1.172942]\n",
      "[Epoch 7/200] [Batch 580/938] [D loss: 1.103071, acc: 95%] [G loss: 1.145093]\n",
      "[Epoch 7/200] [Batch 581/938] [D loss: 1.102117, acc: 96%] [G loss: 1.117606]\n",
      "[Epoch 7/200] [Batch 582/938] [D loss: 1.050083, acc: 98%] [G loss: 1.127382]\n",
      "[Epoch 7/200] [Batch 583/938] [D loss: 1.073311, acc: 97%] [G loss: 1.141932]\n",
      "[Epoch 7/200] [Batch 584/938] [D loss: 1.107677, acc: 97%] [G loss: 1.022026]\n",
      "[Epoch 7/200] [Batch 585/938] [D loss: 1.103664, acc: 96%] [G loss: 1.127860]\n",
      "[Epoch 7/200] [Batch 586/938] [D loss: 1.021487, acc: 98%] [G loss: 1.117939]\n",
      "[Epoch 7/200] [Batch 587/938] [D loss: 1.068261, acc: 98%] [G loss: 1.119207]\n",
      "[Epoch 7/200] [Batch 588/938] [D loss: 1.070765, acc: 94%] [G loss: 1.133302]\n",
      "[Epoch 7/200] [Batch 589/938] [D loss: 1.113106, acc: 96%] [G loss: 1.075824]\n",
      "[Epoch 7/200] [Batch 590/938] [D loss: 1.085159, acc: 93%] [G loss: 1.101130]\n",
      "[Epoch 7/200] [Batch 591/938] [D loss: 1.091999, acc: 96%] [G loss: 1.053687]\n",
      "[Epoch 7/200] [Batch 592/938] [D loss: 1.061055, acc: 97%] [G loss: 1.118201]\n",
      "[Epoch 7/200] [Batch 593/938] [D loss: 1.086699, acc: 97%] [G loss: 1.111623]\n",
      "[Epoch 7/200] [Batch 594/938] [D loss: 1.086105, acc: 96%] [G loss: 1.108400]\n",
      "[Epoch 7/200] [Batch 595/938] [D loss: 1.066879, acc: 96%] [G loss: 1.119204]\n",
      "[Epoch 7/200] [Batch 596/938] [D loss: 1.123742, acc: 96%] [G loss: 1.163248]\n",
      "[Epoch 7/200] [Batch 597/938] [D loss: 1.076497, acc: 96%] [G loss: 1.146995]\n",
      "[Epoch 7/200] [Batch 598/938] [D loss: 1.073326, acc: 96%] [G loss: 1.095007]\n",
      "[Epoch 7/200] [Batch 599/938] [D loss: 1.083511, acc: 94%] [G loss: 1.099926]\n",
      "[Epoch 7/200] [Batch 600/938] [D loss: 1.092833, acc: 95%] [G loss: 1.038906]\n",
      "[Epoch 7/200] [Batch 601/938] [D loss: 1.067701, acc: 96%] [G loss: 1.146471]\n",
      "[Epoch 7/200] [Batch 602/938] [D loss: 1.074996, acc: 94%] [G loss: 1.172239]\n",
      "[Epoch 7/200] [Batch 603/938] [D loss: 1.082228, acc: 96%] [G loss: 1.178619]\n",
      "[Epoch 7/200] [Batch 604/938] [D loss: 1.099586, acc: 95%] [G loss: 1.039412]\n",
      "[Epoch 7/200] [Batch 605/938] [D loss: 1.112744, acc: 95%] [G loss: 1.077256]\n",
      "[Epoch 7/200] [Batch 606/938] [D loss: 1.098786, acc: 95%] [G loss: 1.081144]\n",
      "[Epoch 7/200] [Batch 607/938] [D loss: 1.111697, acc: 94%] [G loss: 1.182946]\n",
      "[Epoch 7/200] [Batch 608/938] [D loss: 1.076131, acc: 96%] [G loss: 1.078434]\n",
      "[Epoch 7/200] [Batch 609/938] [D loss: 1.114451, acc: 96%] [G loss: 1.144139]\n",
      "[Epoch 7/200] [Batch 610/938] [D loss: 1.122707, acc: 94%] [G loss: 1.072329]\n",
      "[Epoch 7/200] [Batch 611/938] [D loss: 1.085109, acc: 92%] [G loss: 1.104734]\n",
      "[Epoch 7/200] [Batch 612/938] [D loss: 1.110250, acc: 96%] [G loss: 1.143264]\n",
      "[Epoch 7/200] [Batch 613/938] [D loss: 1.095927, acc: 99%] [G loss: 1.154784]\n",
      "[Epoch 7/200] [Batch 614/938] [D loss: 1.102579, acc: 98%] [G loss: 1.117583]\n",
      "[Epoch 7/200] [Batch 615/938] [D loss: 1.092596, acc: 97%] [G loss: 1.096646]\n",
      "[Epoch 7/200] [Batch 616/938] [D loss: 1.111243, acc: 97%] [G loss: 1.135434]\n",
      "[Epoch 7/200] [Batch 617/938] [D loss: 1.113258, acc: 93%] [G loss: 1.099047]\n",
      "[Epoch 7/200] [Batch 618/938] [D loss: 1.063528, acc: 95%] [G loss: 1.073545]\n",
      "[Epoch 7/200] [Batch 619/938] [D loss: 1.105531, acc: 94%] [G loss: 1.159209]\n",
      "[Epoch 7/200] [Batch 620/938] [D loss: 1.046918, acc: 94%] [G loss: 1.141170]\n",
      "[Epoch 7/200] [Batch 621/938] [D loss: 1.104488, acc: 99%] [G loss: 1.076600]\n",
      "[Epoch 7/200] [Batch 622/938] [D loss: 1.079514, acc: 96%] [G loss: 1.088112]\n",
      "[Epoch 7/200] [Batch 623/938] [D loss: 1.073527, acc: 94%] [G loss: 1.056555]\n",
      "[Epoch 7/200] [Batch 624/938] [D loss: 1.077554, acc: 96%] [G loss: 1.114947]\n",
      "[Epoch 7/200] [Batch 625/938] [D loss: 1.068851, acc: 99%] [G loss: 1.088790]\n",
      "[Epoch 7/200] [Batch 626/938] [D loss: 1.044540, acc: 96%] [G loss: 1.131278]\n",
      "[Epoch 7/200] [Batch 627/938] [D loss: 1.079582, acc: 96%] [G loss: 1.078801]\n",
      "[Epoch 7/200] [Batch 628/938] [D loss: 1.138475, acc: 92%] [G loss: 1.178244]\n",
      "[Epoch 7/200] [Batch 629/938] [D loss: 1.073263, acc: 96%] [G loss: 1.086525]\n",
      "[Epoch 7/200] [Batch 630/938] [D loss: 1.116009, acc: 96%] [G loss: 1.103881]\n",
      "[Epoch 7/200] [Batch 631/938] [D loss: 1.088822, acc: 96%] [G loss: 1.056720]\n",
      "[Epoch 7/200] [Batch 632/938] [D loss: 1.065274, acc: 96%] [G loss: 1.080020]\n",
      "[Epoch 7/200] [Batch 633/938] [D loss: 1.072515, acc: 97%] [G loss: 1.065016]\n",
      "[Epoch 7/200] [Batch 634/938] [D loss: 1.078949, acc: 97%] [G loss: 1.099926]\n",
      "[Epoch 7/200] [Batch 635/938] [D loss: 1.083558, acc: 96%] [G loss: 1.103309]\n",
      "[Epoch 7/200] [Batch 636/938] [D loss: 1.057200, acc: 96%] [G loss: 1.066781]\n",
      "[Epoch 7/200] [Batch 637/938] [D loss: 1.114321, acc: 95%] [G loss: 1.086458]\n",
      "[Epoch 7/200] [Batch 638/938] [D loss: 1.097954, acc: 99%] [G loss: 1.136390]\n",
      "[Epoch 7/200] [Batch 639/938] [D loss: 1.144503, acc: 98%] [G loss: 1.064223]\n",
      "[Epoch 7/200] [Batch 640/938] [D loss: 1.085837, acc: 96%] [G loss: 1.068689]\n",
      "[Epoch 7/200] [Batch 641/938] [D loss: 1.103431, acc: 95%] [G loss: 1.073828]\n",
      "[Epoch 7/200] [Batch 642/938] [D loss: 1.052759, acc: 99%] [G loss: 1.126225]\n",
      "[Epoch 7/200] [Batch 643/938] [D loss: 1.075623, acc: 96%] [G loss: 1.105914]\n",
      "[Epoch 7/200] [Batch 644/938] [D loss: 1.084008, acc: 96%] [G loss: 1.072862]\n",
      "[Epoch 7/200] [Batch 645/938] [D loss: 1.054369, acc: 96%] [G loss: 1.067716]\n",
      "[Epoch 7/200] [Batch 646/938] [D loss: 1.107452, acc: 96%] [G loss: 1.097270]\n",
      "[Epoch 7/200] [Batch 647/938] [D loss: 1.082503, acc: 95%] [G loss: 1.143777]\n",
      "[Epoch 7/200] [Batch 648/938] [D loss: 1.088901, acc: 96%] [G loss: 1.131291]\n",
      "[Epoch 7/200] [Batch 649/938] [D loss: 1.045736, acc: 96%] [G loss: 1.106673]\n",
      "[Epoch 7/200] [Batch 650/938] [D loss: 1.063708, acc: 96%] [G loss: 1.171494]\n",
      "[Epoch 7/200] [Batch 651/938] [D loss: 1.097770, acc: 97%] [G loss: 1.093588]\n",
      "[Epoch 7/200] [Batch 652/938] [D loss: 1.073886, acc: 96%] [G loss: 1.122017]\n",
      "[Epoch 7/200] [Batch 653/938] [D loss: 1.104680, acc: 92%] [G loss: 1.062618]\n",
      "[Epoch 7/200] [Batch 654/938] [D loss: 1.106983, acc: 94%] [G loss: 1.111815]\n",
      "[Epoch 7/200] [Batch 655/938] [D loss: 1.088687, acc: 94%] [G loss: 1.080315]\n",
      "[Epoch 7/200] [Batch 656/938] [D loss: 1.085265, acc: 97%] [G loss: 1.089147]\n",
      "[Epoch 7/200] [Batch 657/938] [D loss: 1.154888, acc: 95%] [G loss: 1.129871]\n",
      "[Epoch 7/200] [Batch 658/938] [D loss: 1.064034, acc: 99%] [G loss: 1.102413]\n",
      "[Epoch 7/200] [Batch 659/938] [D loss: 1.097190, acc: 95%] [G loss: 1.102724]\n",
      "[Epoch 7/200] [Batch 660/938] [D loss: 1.091038, acc: 94%] [G loss: 1.102198]\n",
      "[Epoch 7/200] [Batch 661/938] [D loss: 1.083874, acc: 96%] [G loss: 1.117781]\n",
      "[Epoch 7/200] [Batch 662/938] [D loss: 1.134395, acc: 95%] [G loss: 1.107205]\n",
      "[Epoch 7/200] [Batch 663/938] [D loss: 1.107073, acc: 97%] [G loss: 1.141463]\n",
      "[Epoch 7/200] [Batch 664/938] [D loss: 1.045818, acc: 96%] [G loss: 1.087692]\n",
      "[Epoch 7/200] [Batch 665/938] [D loss: 1.115510, acc: 93%] [G loss: 1.131035]\n",
      "[Epoch 7/200] [Batch 666/938] [D loss: 1.090768, acc: 96%] [G loss: 1.160779]\n",
      "[Epoch 7/200] [Batch 667/938] [D loss: 1.085565, acc: 96%] [G loss: 1.146966]\n",
      "[Epoch 7/200] [Batch 668/938] [D loss: 1.084405, acc: 99%] [G loss: 1.091111]\n",
      "[Epoch 7/200] [Batch 669/938] [D loss: 1.085183, acc: 96%] [G loss: 1.109214]\n",
      "[Epoch 7/200] [Batch 670/938] [D loss: 1.095220, acc: 96%] [G loss: 1.120885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 671/938] [D loss: 1.088554, acc: 95%] [G loss: 1.131407]\n",
      "[Epoch 7/200] [Batch 672/938] [D loss: 1.081719, acc: 96%] [G loss: 1.109179]\n",
      "[Epoch 7/200] [Batch 673/938] [D loss: 1.059619, acc: 96%] [G loss: 1.146770]\n",
      "[Epoch 7/200] [Batch 674/938] [D loss: 1.136818, acc: 94%] [G loss: 1.129633]\n",
      "[Epoch 7/200] [Batch 675/938] [D loss: 1.077451, acc: 96%] [G loss: 1.107746]\n",
      "[Epoch 7/200] [Batch 676/938] [D loss: 1.096791, acc: 97%] [G loss: 1.162234]\n",
      "[Epoch 7/200] [Batch 677/938] [D loss: 1.152650, acc: 95%] [G loss: 1.096066]\n",
      "[Epoch 7/200] [Batch 678/938] [D loss: 1.065395, acc: 96%] [G loss: 1.158205]\n",
      "[Epoch 7/200] [Batch 679/938] [D loss: 1.077622, acc: 96%] [G loss: 1.109495]\n",
      "[Epoch 7/200] [Batch 680/938] [D loss: 1.116320, acc: 96%] [G loss: 1.153584]\n",
      "[Epoch 7/200] [Batch 681/938] [D loss: 1.128037, acc: 95%] [G loss: 1.158332]\n",
      "[Epoch 7/200] [Batch 682/938] [D loss: 1.058548, acc: 98%] [G loss: 1.142705]\n",
      "[Epoch 7/200] [Batch 683/938] [D loss: 1.057389, acc: 99%] [G loss: 1.090443]\n",
      "[Epoch 7/200] [Batch 684/938] [D loss: 1.124914, acc: 98%] [G loss: 1.130805]\n",
      "[Epoch 7/200] [Batch 685/938] [D loss: 1.080784, acc: 99%] [G loss: 1.142282]\n",
      "[Epoch 7/200] [Batch 686/938] [D loss: 1.100388, acc: 97%] [G loss: 1.134819]\n",
      "[Epoch 7/200] [Batch 687/938] [D loss: 1.084875, acc: 97%] [G loss: 1.103078]\n",
      "[Epoch 7/200] [Batch 688/938] [D loss: 1.131049, acc: 96%] [G loss: 1.118679]\n",
      "[Epoch 7/200] [Batch 689/938] [D loss: 1.102347, acc: 95%] [G loss: 1.121186]\n",
      "[Epoch 7/200] [Batch 690/938] [D loss: 1.063553, acc: 100%] [G loss: 1.106012]\n",
      "[Epoch 7/200] [Batch 691/938] [D loss: 1.087834, acc: 97%] [G loss: 1.116004]\n",
      "[Epoch 7/200] [Batch 692/938] [D loss: 1.082944, acc: 96%] [G loss: 1.164633]\n",
      "[Epoch 7/200] [Batch 693/938] [D loss: 1.105625, acc: 94%] [G loss: 1.134350]\n",
      "[Epoch 7/200] [Batch 694/938] [D loss: 1.091664, acc: 93%] [G loss: 1.116458]\n",
      "[Epoch 7/200] [Batch 695/938] [D loss: 1.096595, acc: 96%] [G loss: 1.124799]\n",
      "[Epoch 7/200] [Batch 696/938] [D loss: 1.127935, acc: 94%] [G loss: 1.085733]\n",
      "[Epoch 7/200] [Batch 697/938] [D loss: 1.072536, acc: 98%] [G loss: 1.126383]\n",
      "[Epoch 7/200] [Batch 698/938] [D loss: 1.114855, acc: 97%] [G loss: 1.161655]\n",
      "[Epoch 7/200] [Batch 699/938] [D loss: 1.098719, acc: 94%] [G loss: 1.158399]\n",
      "[Epoch 7/200] [Batch 700/938] [D loss: 1.129484, acc: 95%] [G loss: 1.142722]\n",
      "[Epoch 7/200] [Batch 701/938] [D loss: 1.089131, acc: 96%] [G loss: 1.128541]\n",
      "[Epoch 7/200] [Batch 702/938] [D loss: 1.082015, acc: 98%] [G loss: 1.068173]\n",
      "[Epoch 7/200] [Batch 703/938] [D loss: 1.088083, acc: 93%] [G loss: 1.120232]\n",
      "[Epoch 7/200] [Batch 704/938] [D loss: 1.077735, acc: 98%] [G loss: 1.039881]\n",
      "[Epoch 7/200] [Batch 705/938] [D loss: 1.081384, acc: 94%] [G loss: 1.120650]\n",
      "[Epoch 7/200] [Batch 706/938] [D loss: 1.088709, acc: 96%] [G loss: 1.118193]\n",
      "[Epoch 7/200] [Batch 707/938] [D loss: 1.122531, acc: 96%] [G loss: 1.155827]\n",
      "[Epoch 7/200] [Batch 708/938] [D loss: 1.056730, acc: 96%] [G loss: 1.166841]\n",
      "[Epoch 7/200] [Batch 709/938] [D loss: 1.102717, acc: 96%] [G loss: 1.123082]\n",
      "[Epoch 7/200] [Batch 710/938] [D loss: 1.104930, acc: 96%] [G loss: 1.115999]\n",
      "[Epoch 7/200] [Batch 711/938] [D loss: 1.076375, acc: 96%] [G loss: 1.093149]\n",
      "[Epoch 7/200] [Batch 712/938] [D loss: 1.094563, acc: 96%] [G loss: 1.124666]\n",
      "[Epoch 7/200] [Batch 713/938] [D loss: 1.094085, acc: 94%] [G loss: 1.122638]\n",
      "[Epoch 7/200] [Batch 714/938] [D loss: 1.100424, acc: 97%] [G loss: 1.115986]\n",
      "[Epoch 7/200] [Batch 715/938] [D loss: 1.107615, acc: 95%] [G loss: 1.150488]\n",
      "[Epoch 7/200] [Batch 716/938] [D loss: 1.118086, acc: 96%] [G loss: 1.094373]\n",
      "[Epoch 7/200] [Batch 717/938] [D loss: 1.106705, acc: 99%] [G loss: 1.016827]\n",
      "[Epoch 7/200] [Batch 718/938] [D loss: 1.052973, acc: 95%] [G loss: 1.117196]\n",
      "[Epoch 7/200] [Batch 719/938] [D loss: 1.041741, acc: 97%] [G loss: 1.113204]\n",
      "[Epoch 7/200] [Batch 720/938] [D loss: 1.092359, acc: 94%] [G loss: 1.095711]\n",
      "[Epoch 7/200] [Batch 721/938] [D loss: 1.128269, acc: 96%] [G loss: 1.076949]\n",
      "[Epoch 7/200] [Batch 722/938] [D loss: 1.132323, acc: 98%] [G loss: 1.077154]\n",
      "[Epoch 7/200] [Batch 723/938] [D loss: 1.080492, acc: 97%] [G loss: 1.079664]\n",
      "[Epoch 7/200] [Batch 724/938] [D loss: 1.054211, acc: 98%] [G loss: 1.052774]\n",
      "[Epoch 7/200] [Batch 725/938] [D loss: 1.111432, acc: 96%] [G loss: 1.049276]\n",
      "[Epoch 7/200] [Batch 726/938] [D loss: 1.100335, acc: 98%] [G loss: 1.084376]\n",
      "[Epoch 7/200] [Batch 727/938] [D loss: 1.072897, acc: 93%] [G loss: 1.112865]\n",
      "[Epoch 7/200] [Batch 728/938] [D loss: 1.094008, acc: 98%] [G loss: 1.172350]\n",
      "[Epoch 7/200] [Batch 729/938] [D loss: 1.121456, acc: 93%] [G loss: 1.160693]\n",
      "[Epoch 7/200] [Batch 730/938] [D loss: 1.077728, acc: 97%] [G loss: 1.074044]\n",
      "[Epoch 7/200] [Batch 731/938] [D loss: 1.089776, acc: 96%] [G loss: 1.085904]\n",
      "[Epoch 7/200] [Batch 732/938] [D loss: 1.086337, acc: 95%] [G loss: 1.177453]\n",
      "[Epoch 7/200] [Batch 733/938] [D loss: 1.049066, acc: 98%] [G loss: 1.149820]\n",
      "[Epoch 7/200] [Batch 734/938] [D loss: 1.099253, acc: 96%] [G loss: 1.042835]\n",
      "[Epoch 7/200] [Batch 735/938] [D loss: 1.108684, acc: 93%] [G loss: 1.068441]\n",
      "[Epoch 7/200] [Batch 736/938] [D loss: 1.091981, acc: 96%] [G loss: 1.123929]\n",
      "[Epoch 7/200] [Batch 737/938] [D loss: 1.070914, acc: 99%] [G loss: 1.051113]\n",
      "[Epoch 7/200] [Batch 738/938] [D loss: 1.079811, acc: 95%] [G loss: 1.125320]\n",
      "[Epoch 7/200] [Batch 739/938] [D loss: 1.061542, acc: 96%] [G loss: 1.075832]\n",
      "[Epoch 7/200] [Batch 740/938] [D loss: 1.098975, acc: 93%] [G loss: 1.110464]\n",
      "[Epoch 7/200] [Batch 741/938] [D loss: 1.069094, acc: 98%] [G loss: 1.111475]\n",
      "[Epoch 7/200] [Batch 742/938] [D loss: 1.102437, acc: 99%] [G loss: 1.131323]\n",
      "[Epoch 7/200] [Batch 743/938] [D loss: 1.071698, acc: 97%] [G loss: 1.162866]\n",
      "[Epoch 7/200] [Batch 744/938] [D loss: 1.072769, acc: 98%] [G loss: 1.105195]\n",
      "[Epoch 7/200] [Batch 745/938] [D loss: 1.089717, acc: 97%] [G loss: 1.093077]\n",
      "[Epoch 7/200] [Batch 746/938] [D loss: 1.082280, acc: 98%] [G loss: 1.116737]\n",
      "[Epoch 7/200] [Batch 747/938] [D loss: 1.114251, acc: 92%] [G loss: 1.090462]\n",
      "[Epoch 7/200] [Batch 748/938] [D loss: 1.074406, acc: 97%] [G loss: 1.129226]\n",
      "[Epoch 7/200] [Batch 749/938] [D loss: 1.117110, acc: 93%] [G loss: 1.140228]\n",
      "[Epoch 7/200] [Batch 750/938] [D loss: 1.081015, acc: 95%] [G loss: 1.154132]\n",
      "[Epoch 7/200] [Batch 751/938] [D loss: 1.088918, acc: 93%] [G loss: 1.117595]\n",
      "[Epoch 7/200] [Batch 752/938] [D loss: 1.156883, acc: 95%] [G loss: 1.008929]\n",
      "[Epoch 7/200] [Batch 753/938] [D loss: 1.038758, acc: 96%] [G loss: 1.082599]\n",
      "[Epoch 7/200] [Batch 754/938] [D loss: 1.092043, acc: 93%] [G loss: 1.141089]\n",
      "[Epoch 7/200] [Batch 755/938] [D loss: 1.077402, acc: 98%] [G loss: 1.048262]\n",
      "[Epoch 7/200] [Batch 756/938] [D loss: 1.088328, acc: 96%] [G loss: 1.086475]\n",
      "[Epoch 7/200] [Batch 757/938] [D loss: 1.120874, acc: 97%] [G loss: 1.130463]\n",
      "[Epoch 7/200] [Batch 758/938] [D loss: 1.046584, acc: 96%] [G loss: 1.180475]\n",
      "[Epoch 7/200] [Batch 759/938] [D loss: 1.127684, acc: 94%] [G loss: 1.093475]\n",
      "[Epoch 7/200] [Batch 760/938] [D loss: 1.071026, acc: 97%] [G loss: 1.151008]\n",
      "[Epoch 7/200] [Batch 761/938] [D loss: 1.131843, acc: 93%] [G loss: 1.125439]\n",
      "[Epoch 7/200] [Batch 762/938] [D loss: 1.092815, acc: 95%] [G loss: 1.049206]\n",
      "[Epoch 7/200] [Batch 763/938] [D loss: 1.081792, acc: 98%] [G loss: 1.110545]\n",
      "[Epoch 7/200] [Batch 764/938] [D loss: 1.126922, acc: 97%] [G loss: 1.068550]\n",
      "[Epoch 7/200] [Batch 765/938] [D loss: 1.075452, acc: 99%] [G loss: 1.127692]\n",
      "[Epoch 7/200] [Batch 766/938] [D loss: 1.052071, acc: 96%] [G loss: 1.158064]\n",
      "[Epoch 7/200] [Batch 767/938] [D loss: 1.070450, acc: 94%] [G loss: 1.113251]\n",
      "[Epoch 7/200] [Batch 768/938] [D loss: 1.097742, acc: 97%] [G loss: 1.099718]\n",
      "[Epoch 7/200] [Batch 769/938] [D loss: 1.111908, acc: 98%] [G loss: 1.079815]\n",
      "[Epoch 7/200] [Batch 770/938] [D loss: 1.084696, acc: 99%] [G loss: 1.115349]\n",
      "[Epoch 7/200] [Batch 771/938] [D loss: 1.093797, acc: 97%] [G loss: 1.103175]\n",
      "[Epoch 7/200] [Batch 772/938] [D loss: 1.067559, acc: 96%] [G loss: 1.019118]\n",
      "[Epoch 7/200] [Batch 773/938] [D loss: 1.083873, acc: 96%] [G loss: 1.105499]\n",
      "[Epoch 7/200] [Batch 774/938] [D loss: 1.059952, acc: 99%] [G loss: 1.102579]\n",
      "[Epoch 7/200] [Batch 775/938] [D loss: 1.078418, acc: 92%] [G loss: 1.105718]\n",
      "[Epoch 7/200] [Batch 776/938] [D loss: 1.086671, acc: 96%] [G loss: 1.070918]\n",
      "[Epoch 7/200] [Batch 777/938] [D loss: 1.115995, acc: 95%] [G loss: 1.117209]\n",
      "[Epoch 7/200] [Batch 778/938] [D loss: 1.119294, acc: 96%] [G loss: 1.072069]\n",
      "[Epoch 7/200] [Batch 779/938] [D loss: 1.054629, acc: 97%] [G loss: 1.102189]\n",
      "[Epoch 7/200] [Batch 780/938] [D loss: 1.076954, acc: 96%] [G loss: 1.162372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 781/938] [D loss: 1.074340, acc: 96%] [G loss: 1.126485]\n",
      "[Epoch 7/200] [Batch 782/938] [D loss: 1.094551, acc: 92%] [G loss: 1.109551]\n",
      "[Epoch 7/200] [Batch 783/938] [D loss: 1.101741, acc: 99%] [G loss: 1.064298]\n",
      "[Epoch 7/200] [Batch 784/938] [D loss: 1.095205, acc: 96%] [G loss: 1.053988]\n",
      "[Epoch 7/200] [Batch 785/938] [D loss: 1.084167, acc: 95%] [G loss: 1.120849]\n",
      "[Epoch 7/200] [Batch 786/938] [D loss: 1.119966, acc: 95%] [G loss: 1.057382]\n",
      "[Epoch 7/200] [Batch 787/938] [D loss: 1.080387, acc: 96%] [G loss: 1.131758]\n",
      "[Epoch 7/200] [Batch 788/938] [D loss: 1.056488, acc: 96%] [G loss: 1.065059]\n",
      "[Epoch 7/200] [Batch 789/938] [D loss: 1.066940, acc: 98%] [G loss: 1.138600]\n",
      "[Epoch 7/200] [Batch 790/938] [D loss: 1.081943, acc: 97%] [G loss: 1.097082]\n",
      "[Epoch 7/200] [Batch 791/938] [D loss: 1.091080, acc: 97%] [G loss: 1.078670]\n",
      "[Epoch 7/200] [Batch 792/938] [D loss: 1.106622, acc: 98%] [G loss: 1.132452]\n",
      "[Epoch 7/200] [Batch 793/938] [D loss: 1.085772, acc: 97%] [G loss: 1.163122]\n",
      "[Epoch 7/200] [Batch 794/938] [D loss: 1.074159, acc: 95%] [G loss: 1.112073]\n",
      "[Epoch 7/200] [Batch 795/938] [D loss: 1.067285, acc: 97%] [G loss: 1.086285]\n",
      "[Epoch 7/200] [Batch 796/938] [D loss: 1.088300, acc: 98%] [G loss: 1.091182]\n",
      "[Epoch 7/200] [Batch 797/938] [D loss: 1.093616, acc: 96%] [G loss: 1.147669]\n",
      "[Epoch 7/200] [Batch 798/938] [D loss: 1.093516, acc: 98%] [G loss: 1.097401]\n",
      "[Epoch 7/200] [Batch 799/938] [D loss: 1.111902, acc: 96%] [G loss: 1.188377]\n",
      "[Epoch 7/200] [Batch 800/938] [D loss: 1.101668, acc: 96%] [G loss: 1.191765]\n",
      "[Epoch 7/200] [Batch 801/938] [D loss: 1.118821, acc: 96%] [G loss: 1.078854]\n",
      "[Epoch 7/200] [Batch 802/938] [D loss: 1.114741, acc: 96%] [G loss: 1.114982]\n",
      "[Epoch 7/200] [Batch 803/938] [D loss: 1.076766, acc: 99%] [G loss: 1.127236]\n",
      "[Epoch 7/200] [Batch 804/938] [D loss: 1.103271, acc: 98%] [G loss: 1.113922]\n",
      "[Epoch 7/200] [Batch 805/938] [D loss: 1.103981, acc: 95%] [G loss: 1.089052]\n",
      "[Epoch 7/200] [Batch 806/938] [D loss: 1.101277, acc: 95%] [G loss: 1.144500]\n",
      "[Epoch 7/200] [Batch 807/938] [D loss: 1.105338, acc: 96%] [G loss: 1.096257]\n",
      "[Epoch 7/200] [Batch 808/938] [D loss: 1.078673, acc: 99%] [G loss: 1.073592]\n",
      "[Epoch 7/200] [Batch 809/938] [D loss: 1.108264, acc: 96%] [G loss: 1.046877]\n",
      "[Epoch 7/200] [Batch 810/938] [D loss: 1.119596, acc: 96%] [G loss: 1.098985]\n",
      "[Epoch 7/200] [Batch 811/938] [D loss: 1.094491, acc: 98%] [G loss: 1.154126]\n",
      "[Epoch 7/200] [Batch 812/938] [D loss: 1.077058, acc: 95%] [G loss: 1.088320]\n",
      "[Epoch 7/200] [Batch 813/938] [D loss: 1.090997, acc: 96%] [G loss: 1.102233]\n",
      "[Epoch 7/200] [Batch 814/938] [D loss: 1.041600, acc: 100%] [G loss: 1.089214]\n",
      "[Epoch 7/200] [Batch 815/938] [D loss: 1.108325, acc: 93%] [G loss: 1.078779]\n",
      "[Epoch 7/200] [Batch 816/938] [D loss: 1.066542, acc: 94%] [G loss: 1.121542]\n",
      "[Epoch 7/200] [Batch 817/938] [D loss: 1.127340, acc: 97%] [G loss: 1.099438]\n",
      "[Epoch 7/200] [Batch 818/938] [D loss: 1.065101, acc: 98%] [G loss: 1.117757]\n",
      "[Epoch 7/200] [Batch 819/938] [D loss: 1.078775, acc: 95%] [G loss: 1.092695]\n",
      "[Epoch 7/200] [Batch 820/938] [D loss: 1.052864, acc: 100%] [G loss: 1.066704]\n",
      "[Epoch 7/200] [Batch 821/938] [D loss: 1.073408, acc: 97%] [G loss: 1.122249]\n",
      "[Epoch 7/200] [Batch 822/938] [D loss: 1.092073, acc: 98%] [G loss: 1.062725]\n",
      "[Epoch 7/200] [Batch 823/938] [D loss: 1.097230, acc: 97%] [G loss: 1.048272]\n",
      "[Epoch 7/200] [Batch 824/938] [D loss: 1.089428, acc: 96%] [G loss: 1.115886]\n",
      "[Epoch 7/200] [Batch 825/938] [D loss: 1.111771, acc: 96%] [G loss: 1.161164]\n",
      "[Epoch 7/200] [Batch 826/938] [D loss: 1.105655, acc: 98%] [G loss: 1.106104]\n",
      "[Epoch 7/200] [Batch 827/938] [D loss: 1.110324, acc: 98%] [G loss: 1.081137]\n",
      "[Epoch 7/200] [Batch 828/938] [D loss: 1.095909, acc: 98%] [G loss: 1.092650]\n",
      "[Epoch 7/200] [Batch 829/938] [D loss: 1.091271, acc: 99%] [G loss: 1.102699]\n",
      "[Epoch 7/200] [Batch 830/938] [D loss: 1.110906, acc: 95%] [G loss: 1.122725]\n",
      "[Epoch 7/200] [Batch 831/938] [D loss: 1.100098, acc: 96%] [G loss: 1.139572]\n",
      "[Epoch 7/200] [Batch 832/938] [D loss: 1.067950, acc: 94%] [G loss: 1.143422]\n",
      "[Epoch 7/200] [Batch 833/938] [D loss: 1.079730, acc: 96%] [G loss: 1.133138]\n",
      "[Epoch 7/200] [Batch 834/938] [D loss: 1.069467, acc: 98%] [G loss: 1.114861]\n",
      "[Epoch 7/200] [Batch 835/938] [D loss: 1.101991, acc: 96%] [G loss: 1.149116]\n",
      "[Epoch 7/200] [Batch 836/938] [D loss: 1.126660, acc: 96%] [G loss: 1.201902]\n",
      "[Epoch 7/200] [Batch 837/938] [D loss: 1.096380, acc: 96%] [G loss: 1.122807]\n",
      "[Epoch 7/200] [Batch 838/938] [D loss: 1.087460, acc: 98%] [G loss: 1.056726]\n",
      "[Epoch 7/200] [Batch 839/938] [D loss: 1.106417, acc: 96%] [G loss: 1.072693]\n",
      "[Epoch 7/200] [Batch 840/938] [D loss: 1.070465, acc: 99%] [G loss: 1.110834]\n",
      "[Epoch 7/200] [Batch 841/938] [D loss: 1.101027, acc: 95%] [G loss: 1.150417]\n",
      "[Epoch 7/200] [Batch 842/938] [D loss: 1.066348, acc: 98%] [G loss: 1.184432]\n",
      "[Epoch 7/200] [Batch 843/938] [D loss: 1.114565, acc: 96%] [G loss: 1.009576]\n",
      "[Epoch 7/200] [Batch 844/938] [D loss: 1.088682, acc: 95%] [G loss: 1.095059]\n",
      "[Epoch 7/200] [Batch 845/938] [D loss: 1.113390, acc: 98%] [G loss: 1.055055]\n",
      "[Epoch 7/200] [Batch 846/938] [D loss: 1.078576, acc: 97%] [G loss: 1.146694]\n",
      "[Epoch 7/200] [Batch 847/938] [D loss: 1.089630, acc: 96%] [G loss: 1.099677]\n",
      "[Epoch 7/200] [Batch 848/938] [D loss: 1.092805, acc: 93%] [G loss: 1.089051]\n",
      "[Epoch 7/200] [Batch 849/938] [D loss: 1.084431, acc: 96%] [G loss: 1.092876]\n",
      "[Epoch 7/200] [Batch 850/938] [D loss: 1.083263, acc: 96%] [G loss: 1.157951]\n",
      "[Epoch 7/200] [Batch 851/938] [D loss: 1.123280, acc: 93%] [G loss: 1.135713]\n",
      "[Epoch 7/200] [Batch 852/938] [D loss: 1.098335, acc: 95%] [G loss: 1.122562]\n",
      "[Epoch 7/200] [Batch 853/938] [D loss: 1.096553, acc: 95%] [G loss: 1.105503]\n",
      "[Epoch 7/200] [Batch 854/938] [D loss: 1.051027, acc: 96%] [G loss: 1.082762]\n",
      "[Epoch 7/200] [Batch 855/938] [D loss: 1.081453, acc: 97%] [G loss: 1.162369]\n",
      "[Epoch 7/200] [Batch 856/938] [D loss: 1.078437, acc: 99%] [G loss: 1.068233]\n",
      "[Epoch 7/200] [Batch 857/938] [D loss: 1.046530, acc: 97%] [G loss: 1.093073]\n",
      "[Epoch 7/200] [Batch 858/938] [D loss: 1.088429, acc: 96%] [G loss: 1.067269]\n",
      "[Epoch 7/200] [Batch 859/938] [D loss: 1.057304, acc: 99%] [G loss: 1.132648]\n",
      "[Epoch 7/200] [Batch 860/938] [D loss: 1.053113, acc: 98%] [G loss: 1.120149]\n",
      "[Epoch 7/200] [Batch 861/938] [D loss: 1.105029, acc: 93%] [G loss: 1.087746]\n",
      "[Epoch 7/200] [Batch 862/938] [D loss: 1.110311, acc: 95%] [G loss: 1.091980]\n",
      "[Epoch 7/200] [Batch 863/938] [D loss: 1.085360, acc: 98%] [G loss: 1.089986]\n",
      "[Epoch 7/200] [Batch 864/938] [D loss: 1.088391, acc: 96%] [G loss: 1.061952]\n",
      "[Epoch 7/200] [Batch 865/938] [D loss: 1.113633, acc: 94%] [G loss: 1.139998]\n",
      "[Epoch 7/200] [Batch 866/938] [D loss: 1.077103, acc: 97%] [G loss: 1.163750]\n",
      "[Epoch 7/200] [Batch 867/938] [D loss: 1.054047, acc: 97%] [G loss: 1.085065]\n",
      "[Epoch 7/200] [Batch 868/938] [D loss: 1.061225, acc: 93%] [G loss: 1.101898]\n",
      "[Epoch 7/200] [Batch 869/938] [D loss: 1.059903, acc: 98%] [G loss: 1.144090]\n",
      "[Epoch 7/200] [Batch 870/938] [D loss: 1.108727, acc: 95%] [G loss: 1.133975]\n",
      "[Epoch 7/200] [Batch 871/938] [D loss: 1.083475, acc: 94%] [G loss: 1.092824]\n",
      "[Epoch 7/200] [Batch 872/938] [D loss: 1.069264, acc: 100%] [G loss: 1.124427]\n",
      "[Epoch 7/200] [Batch 873/938] [D loss: 1.087433, acc: 96%] [G loss: 1.127738]\n",
      "[Epoch 7/200] [Batch 874/938] [D loss: 1.107098, acc: 95%] [G loss: 1.082392]\n",
      "[Epoch 7/200] [Batch 875/938] [D loss: 1.083933, acc: 98%] [G loss: 1.103131]\n",
      "[Epoch 7/200] [Batch 876/938] [D loss: 1.115320, acc: 94%] [G loss: 1.117290]\n",
      "[Epoch 7/200] [Batch 877/938] [D loss: 1.147580, acc: 97%] [G loss: 1.084748]\n",
      "[Epoch 7/200] [Batch 878/938] [D loss: 1.088652, acc: 96%] [G loss: 1.088038]\n",
      "[Epoch 7/200] [Batch 879/938] [D loss: 1.094707, acc: 96%] [G loss: 1.098295]\n",
      "[Epoch 7/200] [Batch 880/938] [D loss: 1.104499, acc: 94%] [G loss: 1.083960]\n",
      "[Epoch 7/200] [Batch 881/938] [D loss: 1.118988, acc: 94%] [G loss: 1.101074]\n",
      "[Epoch 7/200] [Batch 882/938] [D loss: 1.091602, acc: 96%] [G loss: 1.040630]\n",
      "[Epoch 7/200] [Batch 883/938] [D loss: 1.094033, acc: 96%] [G loss: 1.106313]\n",
      "[Epoch 7/200] [Batch 884/938] [D loss: 1.096363, acc: 96%] [G loss: 1.102195]\n",
      "[Epoch 7/200] [Batch 885/938] [D loss: 1.096635, acc: 92%] [G loss: 1.115796]\n",
      "[Epoch 7/200] [Batch 886/938] [D loss: 1.091069, acc: 94%] [G loss: 1.096939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/200] [Batch 887/938] [D loss: 1.079660, acc: 94%] [G loss: 1.094319]\n",
      "[Epoch 7/200] [Batch 888/938] [D loss: 1.079540, acc: 96%] [G loss: 1.114430]\n",
      "[Epoch 7/200] [Batch 889/938] [D loss: 1.093954, acc: 92%] [G loss: 1.121328]\n",
      "[Epoch 7/200] [Batch 890/938] [D loss: 1.046055, acc: 98%] [G loss: 1.102756]\n",
      "[Epoch 7/200] [Batch 891/938] [D loss: 1.061128, acc: 98%] [G loss: 1.155939]\n",
      "[Epoch 7/200] [Batch 892/938] [D loss: 1.110530, acc: 95%] [G loss: 1.095867]\n",
      "[Epoch 7/200] [Batch 893/938] [D loss: 1.097397, acc: 96%] [G loss: 1.071625]\n",
      "[Epoch 7/200] [Batch 894/938] [D loss: 1.090556, acc: 98%] [G loss: 1.080216]\n",
      "[Epoch 7/200] [Batch 895/938] [D loss: 1.111076, acc: 96%] [G loss: 1.172855]\n",
      "[Epoch 7/200] [Batch 896/938] [D loss: 1.128022, acc: 92%] [G loss: 1.176482]\n",
      "[Epoch 7/200] [Batch 897/938] [D loss: 1.086999, acc: 94%] [G loss: 1.101948]\n",
      "[Epoch 7/200] [Batch 898/938] [D loss: 1.106432, acc: 95%] [G loss: 1.061500]\n",
      "[Epoch 7/200] [Batch 899/938] [D loss: 1.110839, acc: 96%] [G loss: 1.177279]\n",
      "[Epoch 7/200] [Batch 900/938] [D loss: 1.104711, acc: 96%] [G loss: 1.124449]\n",
      "[Epoch 7/200] [Batch 901/938] [D loss: 1.052963, acc: 96%] [G loss: 1.129437]\n",
      "[Epoch 7/200] [Batch 902/938] [D loss: 1.054237, acc: 98%] [G loss: 1.124574]\n",
      "[Epoch 7/200] [Batch 903/938] [D loss: 1.086975, acc: 96%] [G loss: 1.102143]\n",
      "[Epoch 7/200] [Batch 904/938] [D loss: 1.074324, acc: 94%] [G loss: 1.058691]\n",
      "[Epoch 7/200] [Batch 905/938] [D loss: 1.099442, acc: 96%] [G loss: 1.171174]\n",
      "[Epoch 7/200] [Batch 906/938] [D loss: 1.099261, acc: 96%] [G loss: 1.090737]\n",
      "[Epoch 7/200] [Batch 907/938] [D loss: 1.119482, acc: 92%] [G loss: 1.055532]\n",
      "[Epoch 7/200] [Batch 908/938] [D loss: 1.080443, acc: 96%] [G loss: 1.094888]\n",
      "[Epoch 7/200] [Batch 909/938] [D loss: 1.079257, acc: 96%] [G loss: 1.086117]\n",
      "[Epoch 7/200] [Batch 910/938] [D loss: 1.117603, acc: 95%] [G loss: 1.136548]\n",
      "[Epoch 7/200] [Batch 911/938] [D loss: 1.078180, acc: 96%] [G loss: 1.181188]\n",
      "[Epoch 7/200] [Batch 912/938] [D loss: 1.085817, acc: 95%] [G loss: 1.065815]\n",
      "[Epoch 7/200] [Batch 913/938] [D loss: 1.109605, acc: 95%] [G loss: 1.117749]\n",
      "[Epoch 7/200] [Batch 914/938] [D loss: 1.094143, acc: 97%] [G loss: 1.076436]\n",
      "[Epoch 7/200] [Batch 915/938] [D loss: 1.089232, acc: 96%] [G loss: 1.096266]\n",
      "[Epoch 7/200] [Batch 916/938] [D loss: 1.095958, acc: 97%] [G loss: 1.152711]\n",
      "[Epoch 7/200] [Batch 917/938] [D loss: 1.084857, acc: 97%] [G loss: 1.065963]\n",
      "[Epoch 7/200] [Batch 918/938] [D loss: 1.093492, acc: 96%] [G loss: 1.125973]\n",
      "[Epoch 7/200] [Batch 919/938] [D loss: 1.075258, acc: 94%] [G loss: 1.132082]\n",
      "[Epoch 7/200] [Batch 920/938] [D loss: 1.079571, acc: 99%] [G loss: 1.174807]\n",
      "[Epoch 7/200] [Batch 921/938] [D loss: 1.051617, acc: 96%] [G loss: 1.116648]\n",
      "[Epoch 7/200] [Batch 922/938] [D loss: 1.067896, acc: 94%] [G loss: 1.221537]\n",
      "[Epoch 7/200] [Batch 923/938] [D loss: 1.106210, acc: 95%] [G loss: 1.148591]\n",
      "[Epoch 7/200] [Batch 924/938] [D loss: 1.107150, acc: 96%] [G loss: 1.114152]\n",
      "[Epoch 7/200] [Batch 925/938] [D loss: 1.083364, acc: 97%] [G loss: 1.083121]\n",
      "[Epoch 7/200] [Batch 926/938] [D loss: 1.090501, acc: 95%] [G loss: 1.168922]\n",
      "[Epoch 7/200] [Batch 927/938] [D loss: 1.076961, acc: 97%] [G loss: 1.100172]\n",
      "[Epoch 7/200] [Batch 928/938] [D loss: 1.122040, acc: 97%] [G loss: 1.099315]\n",
      "[Epoch 7/200] [Batch 929/938] [D loss: 1.093799, acc: 96%] [G loss: 1.083336]\n",
      "[Epoch 7/200] [Batch 930/938] [D loss: 1.104789, acc: 97%] [G loss: 1.090853]\n",
      "[Epoch 7/200] [Batch 931/938] [D loss: 1.135984, acc: 95%] [G loss: 1.145734]\n",
      "[Epoch 7/200] [Batch 932/938] [D loss: 1.083917, acc: 95%] [G loss: 1.085227]\n",
      "[Epoch 7/200] [Batch 933/938] [D loss: 1.053658, acc: 97%] [G loss: 1.108136]\n",
      "[Epoch 7/200] [Batch 934/938] [D loss: 1.093199, acc: 96%] [G loss: 1.076258]\n",
      "[Epoch 7/200] [Batch 935/938] [D loss: 1.094921, acc: 96%] [G loss: 1.049685]\n",
      "[Epoch 7/200] [Batch 936/938] [D loss: 1.102255, acc: 93%] [G loss: 1.087342]\n",
      "[Epoch 7/200] [Batch 937/938] [D loss: 1.068473, acc: 93%] [G loss: 1.156489]\n",
      "[Epoch 8/200] [Batch 0/938] [D loss: 1.088126, acc: 96%] [G loss: 1.141895]\n",
      "[Epoch 8/200] [Batch 1/938] [D loss: 1.077878, acc: 95%] [G loss: 1.052817]\n",
      "[Epoch 8/200] [Batch 2/938] [D loss: 1.074092, acc: 96%] [G loss: 1.087620]\n",
      "[Epoch 8/200] [Batch 3/938] [D loss: 1.109815, acc: 93%] [G loss: 1.125108]\n",
      "[Epoch 8/200] [Batch 4/938] [D loss: 1.096324, acc: 96%] [G loss: 1.098670]\n",
      "[Epoch 8/200] [Batch 5/938] [D loss: 1.088917, acc: 93%] [G loss: 1.088466]\n",
      "[Epoch 8/200] [Batch 6/938] [D loss: 1.126780, acc: 96%] [G loss: 1.034919]\n",
      "[Epoch 8/200] [Batch 7/938] [D loss: 1.077196, acc: 97%] [G loss: 1.081352]\n",
      "[Epoch 8/200] [Batch 8/938] [D loss: 1.074636, acc: 97%] [G loss: 1.124886]\n",
      "[Epoch 8/200] [Batch 9/938] [D loss: 1.098494, acc: 97%] [G loss: 1.083577]\n",
      "[Epoch 8/200] [Batch 10/938] [D loss: 1.113950, acc: 96%] [G loss: 1.143612]\n",
      "[Epoch 8/200] [Batch 11/938] [D loss: 1.111606, acc: 95%] [G loss: 1.112586]\n",
      "[Epoch 8/200] [Batch 12/938] [D loss: 1.071517, acc: 96%] [G loss: 1.088720]\n",
      "[Epoch 8/200] [Batch 13/938] [D loss: 1.112427, acc: 96%] [G loss: 1.144106]\n",
      "[Epoch 8/200] [Batch 14/938] [D loss: 1.108937, acc: 96%] [G loss: 1.072427]\n",
      "[Epoch 8/200] [Batch 15/938] [D loss: 1.092814, acc: 94%] [G loss: 1.043196]\n",
      "[Epoch 8/200] [Batch 16/938] [D loss: 1.092418, acc: 99%] [G loss: 1.044284]\n",
      "[Epoch 8/200] [Batch 17/938] [D loss: 1.085327, acc: 96%] [G loss: 1.149424]\n",
      "[Epoch 8/200] [Batch 18/938] [D loss: 1.129124, acc: 96%] [G loss: 1.146167]\n",
      "[Epoch 8/200] [Batch 19/938] [D loss: 1.114629, acc: 96%] [G loss: 1.131414]\n",
      "[Epoch 8/200] [Batch 20/938] [D loss: 1.108149, acc: 98%] [G loss: 1.079965]\n",
      "[Epoch 8/200] [Batch 21/938] [D loss: 1.117906, acc: 94%] [G loss: 1.090708]\n",
      "[Epoch 8/200] [Batch 22/938] [D loss: 1.084226, acc: 94%] [G loss: 1.089112]\n",
      "[Epoch 8/200] [Batch 23/938] [D loss: 1.094762, acc: 98%] [G loss: 1.107260]\n",
      "[Epoch 8/200] [Batch 24/938] [D loss: 1.074439, acc: 99%] [G loss: 1.076269]\n",
      "[Epoch 8/200] [Batch 25/938] [D loss: 1.088660, acc: 96%] [G loss: 1.099721]\n",
      "[Epoch 8/200] [Batch 26/938] [D loss: 1.074570, acc: 100%] [G loss: 1.059563]\n",
      "[Epoch 8/200] [Batch 27/938] [D loss: 1.095096, acc: 98%] [G loss: 1.077383]\n",
      "[Epoch 8/200] [Batch 28/938] [D loss: 1.068829, acc: 97%] [G loss: 1.099696]\n",
      "[Epoch 8/200] [Batch 29/938] [D loss: 1.093518, acc: 96%] [G loss: 1.090398]\n",
      "[Epoch 8/200] [Batch 30/938] [D loss: 1.076723, acc: 95%] [G loss: 1.128572]\n",
      "[Epoch 8/200] [Batch 31/938] [D loss: 1.089508, acc: 95%] [G loss: 1.134041]\n",
      "[Epoch 8/200] [Batch 32/938] [D loss: 1.105702, acc: 95%] [G loss: 1.125685]\n",
      "[Epoch 8/200] [Batch 33/938] [D loss: 1.077913, acc: 95%] [G loss: 1.174938]\n",
      "[Epoch 8/200] [Batch 34/938] [D loss: 1.083399, acc: 92%] [G loss: 1.124547]\n",
      "[Epoch 8/200] [Batch 35/938] [D loss: 1.096885, acc: 96%] [G loss: 1.082705]\n",
      "[Epoch 8/200] [Batch 36/938] [D loss: 1.120950, acc: 95%] [G loss: 1.070174]\n",
      "[Epoch 8/200] [Batch 37/938] [D loss: 1.061293, acc: 96%] [G loss: 1.078047]\n",
      "[Epoch 8/200] [Batch 38/938] [D loss: 1.098776, acc: 96%] [G loss: 1.100428]\n",
      "[Epoch 8/200] [Batch 39/938] [D loss: 1.077673, acc: 96%] [G loss: 1.105483]\n",
      "[Epoch 8/200] [Batch 40/938] [D loss: 1.086830, acc: 98%] [G loss: 1.139856]\n",
      "[Epoch 8/200] [Batch 41/938] [D loss: 1.118166, acc: 96%] [G loss: 1.075287]\n",
      "[Epoch 8/200] [Batch 42/938] [D loss: 1.077414, acc: 94%] [G loss: 1.111249]\n",
      "[Epoch 8/200] [Batch 43/938] [D loss: 1.072442, acc: 96%] [G loss: 1.062751]\n",
      "[Epoch 8/200] [Batch 44/938] [D loss: 1.079823, acc: 99%] [G loss: 1.118283]\n",
      "[Epoch 8/200] [Batch 45/938] [D loss: 1.122375, acc: 96%] [G loss: 1.159850]\n",
      "[Epoch 8/200] [Batch 46/938] [D loss: 1.138618, acc: 98%] [G loss: 1.072775]\n",
      "[Epoch 8/200] [Batch 47/938] [D loss: 1.104168, acc: 95%] [G loss: 1.109769]\n",
      "[Epoch 8/200] [Batch 48/938] [D loss: 1.057987, acc: 95%] [G loss: 1.104468]\n",
      "[Epoch 8/200] [Batch 49/938] [D loss: 1.075576, acc: 99%] [G loss: 1.152234]\n",
      "[Epoch 8/200] [Batch 50/938] [D loss: 1.073466, acc: 95%] [G loss: 1.152443]\n",
      "[Epoch 8/200] [Batch 51/938] [D loss: 1.090507, acc: 96%] [G loss: 1.104742]\n",
      "[Epoch 8/200] [Batch 52/938] [D loss: 1.075804, acc: 96%] [G loss: 1.159234]\n",
      "[Epoch 8/200] [Batch 53/938] [D loss: 1.097418, acc: 96%] [G loss: 1.085733]\n",
      "[Epoch 8/200] [Batch 54/938] [D loss: 1.093675, acc: 100%] [G loss: 1.153036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 55/938] [D loss: 1.067527, acc: 97%] [G loss: 1.165065]\n",
      "[Epoch 8/200] [Batch 56/938] [D loss: 1.097204, acc: 95%] [G loss: 1.095050]\n",
      "[Epoch 8/200] [Batch 57/938] [D loss: 1.088210, acc: 96%] [G loss: 1.092844]\n",
      "[Epoch 8/200] [Batch 58/938] [D loss: 1.084337, acc: 96%] [G loss: 1.109334]\n",
      "[Epoch 8/200] [Batch 59/938] [D loss: 1.101368, acc: 96%] [G loss: 1.109606]\n",
      "[Epoch 8/200] [Batch 60/938] [D loss: 1.078571, acc: 92%] [G loss: 1.161550]\n",
      "[Epoch 8/200] [Batch 61/938] [D loss: 1.061015, acc: 93%] [G loss: 1.098065]\n",
      "[Epoch 8/200] [Batch 62/938] [D loss: 1.072931, acc: 97%] [G loss: 1.124071]\n",
      "[Epoch 8/200] [Batch 63/938] [D loss: 1.108016, acc: 96%] [G loss: 1.072541]\n",
      "[Epoch 8/200] [Batch 64/938] [D loss: 1.102555, acc: 93%] [G loss: 1.103190]\n",
      "[Epoch 8/200] [Batch 65/938] [D loss: 1.081370, acc: 98%] [G loss: 1.073805]\n",
      "[Epoch 8/200] [Batch 66/938] [D loss: 1.089400, acc: 94%] [G loss: 1.152310]\n",
      "[Epoch 8/200] [Batch 67/938] [D loss: 1.065542, acc: 97%] [G loss: 1.121284]\n",
      "[Epoch 8/200] [Batch 68/938] [D loss: 1.088797, acc: 93%] [G loss: 1.132389]\n",
      "[Epoch 8/200] [Batch 69/938] [D loss: 1.092075, acc: 96%] [G loss: 1.080356]\n",
      "[Epoch 8/200] [Batch 70/938] [D loss: 1.085064, acc: 97%] [G loss: 1.080106]\n",
      "[Epoch 8/200] [Batch 71/938] [D loss: 1.096411, acc: 96%] [G loss: 1.101210]\n",
      "[Epoch 8/200] [Batch 72/938] [D loss: 1.092968, acc: 96%] [G loss: 1.104647]\n",
      "[Epoch 8/200] [Batch 73/938] [D loss: 1.092793, acc: 96%] [G loss: 1.148254]\n",
      "[Epoch 8/200] [Batch 74/938] [D loss: 1.086854, acc: 96%] [G loss: 1.122698]\n",
      "[Epoch 8/200] [Batch 75/938] [D loss: 1.040021, acc: 100%] [G loss: 1.127006]\n",
      "[Epoch 8/200] [Batch 76/938] [D loss: 1.121552, acc: 97%] [G loss: 1.134939]\n",
      "[Epoch 8/200] [Batch 77/938] [D loss: 1.055224, acc: 99%] [G loss: 1.047638]\n",
      "[Epoch 8/200] [Batch 78/938] [D loss: 1.098142, acc: 98%] [G loss: 1.104393]\n",
      "[Epoch 8/200] [Batch 79/938] [D loss: 1.098125, acc: 94%] [G loss: 1.154046]\n",
      "[Epoch 8/200] [Batch 80/938] [D loss: 1.108555, acc: 96%] [G loss: 1.073692]\n",
      "[Epoch 8/200] [Batch 81/938] [D loss: 1.067822, acc: 94%] [G loss: 1.113089]\n",
      "[Epoch 8/200] [Batch 82/938] [D loss: 1.105149, acc: 96%] [G loss: 1.135504]\n",
      "[Epoch 8/200] [Batch 83/938] [D loss: 1.123987, acc: 96%] [G loss: 1.125751]\n",
      "[Epoch 8/200] [Batch 84/938] [D loss: 1.119644, acc: 95%] [G loss: 1.106369]\n",
      "[Epoch 8/200] [Batch 85/938] [D loss: 1.116211, acc: 97%] [G loss: 1.138225]\n",
      "[Epoch 8/200] [Batch 86/938] [D loss: 1.080380, acc: 96%] [G loss: 1.074661]\n",
      "[Epoch 8/200] [Batch 87/938] [D loss: 1.094644, acc: 98%] [G loss: 1.046937]\n",
      "[Epoch 8/200] [Batch 88/938] [D loss: 1.082535, acc: 99%] [G loss: 1.010381]\n",
      "[Epoch 8/200] [Batch 89/938] [D loss: 1.099509, acc: 95%] [G loss: 1.119899]\n",
      "[Epoch 8/200] [Batch 90/938] [D loss: 1.079683, acc: 98%] [G loss: 1.098707]\n",
      "[Epoch 8/200] [Batch 91/938] [D loss: 1.051027, acc: 98%] [G loss: 1.155732]\n",
      "[Epoch 8/200] [Batch 92/938] [D loss: 1.079112, acc: 96%] [G loss: 1.072154]\n",
      "[Epoch 8/200] [Batch 93/938] [D loss: 1.110784, acc: 92%] [G loss: 1.106044]\n",
      "[Epoch 8/200] [Batch 94/938] [D loss: 1.090309, acc: 96%] [G loss: 1.145439]\n",
      "[Epoch 8/200] [Batch 95/938] [D loss: 1.082420, acc: 98%] [G loss: 1.095597]\n",
      "[Epoch 8/200] [Batch 96/938] [D loss: 1.110250, acc: 96%] [G loss: 1.111335]\n",
      "[Epoch 8/200] [Batch 97/938] [D loss: 1.125568, acc: 96%] [G loss: 1.173676]\n",
      "[Epoch 8/200] [Batch 98/938] [D loss: 1.099025, acc: 93%] [G loss: 1.057715]\n",
      "[Epoch 8/200] [Batch 99/938] [D loss: 1.053584, acc: 96%] [G loss: 1.169500]\n",
      "[Epoch 8/200] [Batch 100/938] [D loss: 1.072692, acc: 97%] [G loss: 1.096797]\n",
      "[Epoch 8/200] [Batch 101/938] [D loss: 1.079569, acc: 96%] [G loss: 1.105371]\n",
      "[Epoch 8/200] [Batch 102/938] [D loss: 1.122616, acc: 94%] [G loss: 1.131499]\n",
      "[Epoch 8/200] [Batch 103/938] [D loss: 1.064074, acc: 97%] [G loss: 1.094490]\n",
      "[Epoch 8/200] [Batch 104/938] [D loss: 1.048497, acc: 97%] [G loss: 1.141768]\n",
      "[Epoch 8/200] [Batch 105/938] [D loss: 1.090888, acc: 96%] [G loss: 1.086256]\n",
      "[Epoch 8/200] [Batch 106/938] [D loss: 1.107244, acc: 96%] [G loss: 1.117445]\n",
      "[Epoch 8/200] [Batch 107/938] [D loss: 1.078878, acc: 92%] [G loss: 1.077624]\n",
      "[Epoch 8/200] [Batch 108/938] [D loss: 1.087994, acc: 96%] [G loss: 1.080527]\n",
      "[Epoch 8/200] [Batch 109/938] [D loss: 1.052397, acc: 96%] [G loss: 1.145586]\n",
      "[Epoch 8/200] [Batch 110/938] [D loss: 1.103707, acc: 94%] [G loss: 1.089803]\n",
      "[Epoch 8/200] [Batch 111/938] [D loss: 1.134365, acc: 93%] [G loss: 1.102676]\n",
      "[Epoch 8/200] [Batch 112/938] [D loss: 1.096789, acc: 96%] [G loss: 1.091414]\n",
      "[Epoch 8/200] [Batch 113/938] [D loss: 1.057840, acc: 99%] [G loss: 1.157141]\n",
      "[Epoch 8/200] [Batch 114/938] [D loss: 1.124189, acc: 93%] [G loss: 1.063569]\n",
      "[Epoch 8/200] [Batch 115/938] [D loss: 1.085151, acc: 96%] [G loss: 1.122625]\n",
      "[Epoch 8/200] [Batch 116/938] [D loss: 1.085029, acc: 94%] [G loss: 1.059717]\n",
      "[Epoch 8/200] [Batch 117/938] [D loss: 1.070300, acc: 96%] [G loss: 1.122860]\n",
      "[Epoch 8/200] [Batch 118/938] [D loss: 1.059529, acc: 98%] [G loss: 1.162334]\n",
      "[Epoch 8/200] [Batch 119/938] [D loss: 1.101701, acc: 93%] [G loss: 1.178025]\n",
      "[Epoch 8/200] [Batch 120/938] [D loss: 1.116100, acc: 97%] [G loss: 1.097421]\n",
      "[Epoch 8/200] [Batch 121/938] [D loss: 1.083265, acc: 96%] [G loss: 1.093509]\n",
      "[Epoch 8/200] [Batch 122/938] [D loss: 1.092345, acc: 97%] [G loss: 1.084379]\n",
      "[Epoch 8/200] [Batch 123/938] [D loss: 1.151956, acc: 92%] [G loss: 1.178554]\n",
      "[Epoch 8/200] [Batch 124/938] [D loss: 1.081599, acc: 98%] [G loss: 1.125326]\n",
      "[Epoch 8/200] [Batch 125/938] [D loss: 1.134072, acc: 96%] [G loss: 1.075344]\n",
      "[Epoch 8/200] [Batch 126/938] [D loss: 1.098708, acc: 96%] [G loss: 1.041565]\n",
      "[Epoch 8/200] [Batch 127/938] [D loss: 1.111605, acc: 97%] [G loss: 1.057075]\n",
      "[Epoch 8/200] [Batch 128/938] [D loss: 1.095201, acc: 96%] [G loss: 1.117899]\n",
      "[Epoch 8/200] [Batch 129/938] [D loss: 1.099135, acc: 97%] [G loss: 1.031775]\n",
      "[Epoch 8/200] [Batch 130/938] [D loss: 1.115314, acc: 95%] [G loss: 1.119012]\n",
      "[Epoch 8/200] [Batch 131/938] [D loss: 1.114689, acc: 94%] [G loss: 1.072042]\n",
      "[Epoch 8/200] [Batch 132/938] [D loss: 1.092621, acc: 95%] [G loss: 1.194381]\n",
      "[Epoch 8/200] [Batch 133/938] [D loss: 1.097987, acc: 96%] [G loss: 1.141871]\n",
      "[Epoch 8/200] [Batch 134/938] [D loss: 1.107584, acc: 93%] [G loss: 1.100957]\n",
      "[Epoch 8/200] [Batch 135/938] [D loss: 1.093253, acc: 97%] [G loss: 1.213104]\n",
      "[Epoch 8/200] [Batch 136/938] [D loss: 1.090225, acc: 95%] [G loss: 1.099638]\n",
      "[Epoch 8/200] [Batch 137/938] [D loss: 1.108184, acc: 97%] [G loss: 1.109985]\n",
      "[Epoch 8/200] [Batch 138/938] [D loss: 1.060323, acc: 99%] [G loss: 1.124958]\n",
      "[Epoch 8/200] [Batch 139/938] [D loss: 1.113755, acc: 96%] [G loss: 1.099430]\n",
      "[Epoch 8/200] [Batch 140/938] [D loss: 1.086941, acc: 96%] [G loss: 1.120134]\n",
      "[Epoch 8/200] [Batch 141/938] [D loss: 1.038213, acc: 100%] [G loss: 1.119596]\n",
      "[Epoch 8/200] [Batch 142/938] [D loss: 1.068276, acc: 97%] [G loss: 1.046948]\n",
      "[Epoch 8/200] [Batch 143/938] [D loss: 1.094205, acc: 96%] [G loss: 1.093767]\n",
      "[Epoch 8/200] [Batch 144/938] [D loss: 1.109480, acc: 95%] [G loss: 1.077355]\n",
      "[Epoch 8/200] [Batch 145/938] [D loss: 1.096855, acc: 97%] [G loss: 1.064753]\n",
      "[Epoch 8/200] [Batch 146/938] [D loss: 1.072305, acc: 98%] [G loss: 1.102528]\n",
      "[Epoch 8/200] [Batch 147/938] [D loss: 1.079699, acc: 96%] [G loss: 1.060041]\n",
      "[Epoch 8/200] [Batch 148/938] [D loss: 1.099427, acc: 96%] [G loss: 1.063071]\n",
      "[Epoch 8/200] [Batch 149/938] [D loss: 1.079468, acc: 96%] [G loss: 1.085828]\n",
      "[Epoch 8/200] [Batch 150/938] [D loss: 1.092107, acc: 97%] [G loss: 1.055481]\n",
      "[Epoch 8/200] [Batch 151/938] [D loss: 1.071323, acc: 96%] [G loss: 1.084490]\n",
      "[Epoch 8/200] [Batch 152/938] [D loss: 1.082200, acc: 93%] [G loss: 1.089593]\n",
      "[Epoch 8/200] [Batch 153/938] [D loss: 1.083151, acc: 96%] [G loss: 1.158999]\n",
      "[Epoch 8/200] [Batch 154/938] [D loss: 1.116088, acc: 93%] [G loss: 1.094769]\n",
      "[Epoch 8/200] [Batch 155/938] [D loss: 1.099560, acc: 99%] [G loss: 1.069551]\n",
      "[Epoch 8/200] [Batch 156/938] [D loss: 1.124921, acc: 98%] [G loss: 1.070864]\n",
      "[Epoch 8/200] [Batch 157/938] [D loss: 1.115756, acc: 97%] [G loss: 1.052071]\n",
      "[Epoch 8/200] [Batch 158/938] [D loss: 1.084040, acc: 96%] [G loss: 1.103084]\n",
      "[Epoch 8/200] [Batch 159/938] [D loss: 1.051403, acc: 96%] [G loss: 1.146644]\n",
      "[Epoch 8/200] [Batch 160/938] [D loss: 1.106618, acc: 96%] [G loss: 1.103049]\n",
      "[Epoch 8/200] [Batch 161/938] [D loss: 1.104066, acc: 96%] [G loss: 1.183739]\n",
      "[Epoch 8/200] [Batch 162/938] [D loss: 1.093550, acc: 95%] [G loss: 1.094638]\n",
      "[Epoch 8/200] [Batch 163/938] [D loss: 1.066696, acc: 96%] [G loss: 1.066207]\n",
      "[Epoch 8/200] [Batch 164/938] [D loss: 1.100182, acc: 96%] [G loss: 1.095324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 165/938] [D loss: 1.108190, acc: 92%] [G loss: 1.085966]\n",
      "[Epoch 8/200] [Batch 166/938] [D loss: 1.105574, acc: 97%] [G loss: 1.117742]\n",
      "[Epoch 8/200] [Batch 167/938] [D loss: 1.093704, acc: 99%] [G loss: 1.053341]\n",
      "[Epoch 8/200] [Batch 168/938] [D loss: 1.123667, acc: 96%] [G loss: 1.102532]\n",
      "[Epoch 8/200] [Batch 169/938] [D loss: 1.134598, acc: 92%] [G loss: 1.112574]\n",
      "[Epoch 8/200] [Batch 170/938] [D loss: 1.108819, acc: 96%] [G loss: 1.069999]\n",
      "[Epoch 8/200] [Batch 171/938] [D loss: 1.102053, acc: 97%] [G loss: 1.063894]\n",
      "[Epoch 8/200] [Batch 172/938] [D loss: 1.063865, acc: 99%] [G loss: 1.079885]\n",
      "[Epoch 8/200] [Batch 173/938] [D loss: 1.128912, acc: 96%] [G loss: 1.096914]\n",
      "[Epoch 8/200] [Batch 174/938] [D loss: 1.106694, acc: 94%] [G loss: 1.086536]\n",
      "[Epoch 8/200] [Batch 175/938] [D loss: 1.079721, acc: 96%] [G loss: 1.152967]\n",
      "[Epoch 8/200] [Batch 176/938] [D loss: 1.091685, acc: 97%] [G loss: 1.069885]\n",
      "[Epoch 8/200] [Batch 177/938] [D loss: 1.113983, acc: 96%] [G loss: 1.124810]\n",
      "[Epoch 8/200] [Batch 178/938] [D loss: 1.048542, acc: 98%] [G loss: 1.140083]\n",
      "[Epoch 8/200] [Batch 179/938] [D loss: 1.092903, acc: 99%] [G loss: 1.175095]\n",
      "[Epoch 8/200] [Batch 180/938] [D loss: 1.073185, acc: 97%] [G loss: 1.071305]\n",
      "[Epoch 8/200] [Batch 181/938] [D loss: 1.136549, acc: 96%] [G loss: 1.095027]\n",
      "[Epoch 8/200] [Batch 182/938] [D loss: 1.085905, acc: 96%] [G loss: 1.155171]\n",
      "[Epoch 8/200] [Batch 183/938] [D loss: 1.056677, acc: 96%] [G loss: 1.157392]\n",
      "[Epoch 8/200] [Batch 184/938] [D loss: 1.084368, acc: 99%] [G loss: 1.150188]\n",
      "[Epoch 8/200] [Batch 185/938] [D loss: 1.098484, acc: 94%] [G loss: 1.118334]\n",
      "[Epoch 8/200] [Batch 186/938] [D loss: 1.117615, acc: 97%] [G loss: 1.138132]\n",
      "[Epoch 8/200] [Batch 187/938] [D loss: 1.114304, acc: 96%] [G loss: 1.093143]\n",
      "[Epoch 8/200] [Batch 188/938] [D loss: 1.106828, acc: 93%] [G loss: 1.039312]\n",
      "[Epoch 8/200] [Batch 189/938] [D loss: 1.081281, acc: 96%] [G loss: 1.092027]\n",
      "[Epoch 8/200] [Batch 190/938] [D loss: 1.086439, acc: 98%] [G loss: 1.123999]\n",
      "[Epoch 8/200] [Batch 191/938] [D loss: 1.093172, acc: 96%] [G loss: 1.163556]\n",
      "[Epoch 8/200] [Batch 192/938] [D loss: 1.064049, acc: 96%] [G loss: 1.148696]\n",
      "[Epoch 8/200] [Batch 193/938] [D loss: 1.079916, acc: 97%] [G loss: 1.148770]\n",
      "[Epoch 8/200] [Batch 194/938] [D loss: 1.059388, acc: 99%] [G loss: 1.094862]\n",
      "[Epoch 8/200] [Batch 195/938] [D loss: 1.089255, acc: 96%] [G loss: 1.095667]\n",
      "[Epoch 8/200] [Batch 196/938] [D loss: 1.107908, acc: 94%] [G loss: 1.057623]\n",
      "[Epoch 8/200] [Batch 197/938] [D loss: 1.049907, acc: 96%] [G loss: 1.108957]\n",
      "[Epoch 8/200] [Batch 198/938] [D loss: 1.073031, acc: 96%] [G loss: 1.109711]\n",
      "[Epoch 8/200] [Batch 199/938] [D loss: 1.078955, acc: 96%] [G loss: 1.124013]\n",
      "[Epoch 8/200] [Batch 200/938] [D loss: 1.019953, acc: 100%] [G loss: 1.126661]\n",
      "[Epoch 8/200] [Batch 201/938] [D loss: 1.086623, acc: 93%] [G loss: 1.142324]\n",
      "[Epoch 8/200] [Batch 202/938] [D loss: 1.067460, acc: 96%] [G loss: 1.088302]\n",
      "[Epoch 8/200] [Batch 203/938] [D loss: 1.090924, acc: 99%] [G loss: 1.129175]\n",
      "[Epoch 8/200] [Batch 204/938] [D loss: 1.120057, acc: 96%] [G loss: 1.057256]\n",
      "[Epoch 8/200] [Batch 205/938] [D loss: 1.081633, acc: 96%] [G loss: 1.128303]\n",
      "[Epoch 8/200] [Batch 206/938] [D loss: 1.082951, acc: 96%] [G loss: 1.061430]\n",
      "[Epoch 8/200] [Batch 207/938] [D loss: 1.086712, acc: 95%] [G loss: 1.102492]\n",
      "[Epoch 8/200] [Batch 208/938] [D loss: 1.085979, acc: 96%] [G loss: 1.150092]\n",
      "[Epoch 8/200] [Batch 209/938] [D loss: 1.128444, acc: 92%] [G loss: 1.149738]\n",
      "[Epoch 8/200] [Batch 210/938] [D loss: 1.105807, acc: 97%] [G loss: 1.051868]\n",
      "[Epoch 8/200] [Batch 211/938] [D loss: 1.110723, acc: 96%] [G loss: 1.112701]\n",
      "[Epoch 8/200] [Batch 212/938] [D loss: 1.087207, acc: 97%] [G loss: 1.097202]\n",
      "[Epoch 8/200] [Batch 213/938] [D loss: 1.088482, acc: 97%] [G loss: 1.084726]\n",
      "[Epoch 8/200] [Batch 214/938] [D loss: 1.094713, acc: 98%] [G loss: 1.109954]\n",
      "[Epoch 8/200] [Batch 215/938] [D loss: 1.073369, acc: 99%] [G loss: 1.123271]\n",
      "[Epoch 8/200] [Batch 216/938] [D loss: 1.100262, acc: 95%] [G loss: 1.183436]\n",
      "[Epoch 8/200] [Batch 217/938] [D loss: 1.073058, acc: 96%] [G loss: 1.156463]\n",
      "[Epoch 8/200] [Batch 218/938] [D loss: 1.110786, acc: 93%] [G loss: 1.079915]\n",
      "[Epoch 8/200] [Batch 219/938] [D loss: 1.060679, acc: 97%] [G loss: 1.063686]\n",
      "[Epoch 8/200] [Batch 220/938] [D loss: 1.061250, acc: 96%] [G loss: 1.080804]\n",
      "[Epoch 8/200] [Batch 221/938] [D loss: 1.126192, acc: 95%] [G loss: 1.075947]\n",
      "[Epoch 8/200] [Batch 222/938] [D loss: 1.152832, acc: 95%] [G loss: 1.104519]\n",
      "[Epoch 8/200] [Batch 223/938] [D loss: 1.090233, acc: 96%] [G loss: 1.094330]\n",
      "[Epoch 8/200] [Batch 224/938] [D loss: 1.092513, acc: 96%] [G loss: 1.093105]\n",
      "[Epoch 8/200] [Batch 225/938] [D loss: 1.064001, acc: 96%] [G loss: 1.169251]\n",
      "[Epoch 8/200] [Batch 226/938] [D loss: 1.097690, acc: 96%] [G loss: 1.124237]\n",
      "[Epoch 8/200] [Batch 227/938] [D loss: 1.122811, acc: 96%] [G loss: 1.085888]\n",
      "[Epoch 8/200] [Batch 228/938] [D loss: 1.116317, acc: 93%] [G loss: 1.140373]\n",
      "[Epoch 8/200] [Batch 229/938] [D loss: 1.089271, acc: 97%] [G loss: 1.149246]\n",
      "[Epoch 8/200] [Batch 230/938] [D loss: 1.076508, acc: 99%] [G loss: 1.127035]\n",
      "[Epoch 8/200] [Batch 231/938] [D loss: 1.113282, acc: 96%] [G loss: 1.109370]\n",
      "[Epoch 8/200] [Batch 232/938] [D loss: 1.102475, acc: 97%] [G loss: 1.105145]\n",
      "[Epoch 8/200] [Batch 233/938] [D loss: 1.071054, acc: 94%] [G loss: 1.104746]\n",
      "[Epoch 8/200] [Batch 234/938] [D loss: 1.090320, acc: 97%] [G loss: 1.093912]\n",
      "[Epoch 8/200] [Batch 235/938] [D loss: 1.066962, acc: 100%] [G loss: 1.069937]\n",
      "[Epoch 8/200] [Batch 236/938] [D loss: 1.105622, acc: 96%] [G loss: 1.042337]\n",
      "[Epoch 8/200] [Batch 237/938] [D loss: 1.119795, acc: 92%] [G loss: 1.064363]\n",
      "[Epoch 8/200] [Batch 238/938] [D loss: 1.092010, acc: 96%] [G loss: 1.089613]\n",
      "[Epoch 8/200] [Batch 239/938] [D loss: 1.086190, acc: 95%] [G loss: 1.118849]\n",
      "[Epoch 8/200] [Batch 240/938] [D loss: 1.067902, acc: 96%] [G loss: 1.094473]\n",
      "[Epoch 8/200] [Batch 241/938] [D loss: 1.102050, acc: 97%] [G loss: 1.082818]\n",
      "[Epoch 8/200] [Batch 242/938] [D loss: 1.083565, acc: 96%] [G loss: 1.104311]\n",
      "[Epoch 8/200] [Batch 243/938] [D loss: 1.068748, acc: 97%] [G loss: 1.119291]\n",
      "[Epoch 8/200] [Batch 244/938] [D loss: 1.075085, acc: 96%] [G loss: 1.218563]\n",
      "[Epoch 8/200] [Batch 245/938] [D loss: 1.077330, acc: 98%] [G loss: 1.075677]\n",
      "[Epoch 8/200] [Batch 246/938] [D loss: 1.094166, acc: 97%] [G loss: 1.108148]\n",
      "[Epoch 8/200] [Batch 247/938] [D loss: 1.085466, acc: 97%] [G loss: 1.162241]\n",
      "[Epoch 8/200] [Batch 248/938] [D loss: 1.072622, acc: 99%] [G loss: 1.147085]\n",
      "[Epoch 8/200] [Batch 249/938] [D loss: 1.075986, acc: 96%] [G loss: 1.127305]\n",
      "[Epoch 8/200] [Batch 250/938] [D loss: 1.083802, acc: 96%] [G loss: 1.149374]\n",
      "[Epoch 8/200] [Batch 251/938] [D loss: 1.067092, acc: 93%] [G loss: 1.124682]\n",
      "[Epoch 8/200] [Batch 252/938] [D loss: 1.081710, acc: 97%] [G loss: 1.129786]\n",
      "[Epoch 8/200] [Batch 253/938] [D loss: 1.077093, acc: 94%] [G loss: 1.111754]\n",
      "[Epoch 8/200] [Batch 254/938] [D loss: 1.114058, acc: 95%] [G loss: 1.140508]\n",
      "[Epoch 8/200] [Batch 255/938] [D loss: 1.079890, acc: 97%] [G loss: 1.122244]\n",
      "[Epoch 8/200] [Batch 256/938] [D loss: 1.110089, acc: 96%] [G loss: 1.120688]\n",
      "[Epoch 8/200] [Batch 257/938] [D loss: 1.093769, acc: 94%] [G loss: 1.054664]\n",
      "[Epoch 8/200] [Batch 258/938] [D loss: 1.085739, acc: 98%] [G loss: 1.076191]\n",
      "[Epoch 8/200] [Batch 259/938] [D loss: 1.118919, acc: 98%] [G loss: 1.124054]\n",
      "[Epoch 8/200] [Batch 260/938] [D loss: 1.072159, acc: 96%] [G loss: 1.128239]\n",
      "[Epoch 8/200] [Batch 261/938] [D loss: 1.090319, acc: 96%] [G loss: 1.163002]\n",
      "[Epoch 8/200] [Batch 262/938] [D loss: 1.085963, acc: 95%] [G loss: 1.106058]\n",
      "[Epoch 8/200] [Batch 263/938] [D loss: 1.101565, acc: 95%] [G loss: 1.095014]\n",
      "[Epoch 8/200] [Batch 264/938] [D loss: 1.088030, acc: 98%] [G loss: 1.075436]\n",
      "[Epoch 8/200] [Batch 265/938] [D loss: 1.079071, acc: 97%] [G loss: 1.065567]\n",
      "[Epoch 8/200] [Batch 266/938] [D loss: 1.123544, acc: 95%] [G loss: 1.136648]\n",
      "[Epoch 8/200] [Batch 267/938] [D loss: 1.122620, acc: 96%] [G loss: 1.084546]\n",
      "[Epoch 8/200] [Batch 268/938] [D loss: 1.063808, acc: 98%] [G loss: 1.116585]\n",
      "[Epoch 8/200] [Batch 269/938] [D loss: 1.117691, acc: 96%] [G loss: 1.121528]\n",
      "[Epoch 8/200] [Batch 270/938] [D loss: 1.075163, acc: 99%] [G loss: 1.177305]\n",
      "[Epoch 8/200] [Batch 271/938] [D loss: 1.107562, acc: 96%] [G loss: 1.060761]\n",
      "[Epoch 8/200] [Batch 272/938] [D loss: 1.099308, acc: 96%] [G loss: 1.108746]\n",
      "[Epoch 8/200] [Batch 273/938] [D loss: 1.097427, acc: 96%] [G loss: 1.134703]\n",
      "[Epoch 8/200] [Batch 274/938] [D loss: 1.070601, acc: 96%] [G loss: 1.132042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 275/938] [D loss: 1.085156, acc: 95%] [G loss: 1.106719]\n",
      "[Epoch 8/200] [Batch 276/938] [D loss: 1.097853, acc: 98%] [G loss: 1.087928]\n",
      "[Epoch 8/200] [Batch 277/938] [D loss: 1.103302, acc: 95%] [G loss: 1.125822]\n",
      "[Epoch 8/200] [Batch 278/938] [D loss: 1.074252, acc: 96%] [G loss: 1.104579]\n",
      "[Epoch 8/200] [Batch 279/938] [D loss: 1.103889, acc: 96%] [G loss: 1.071461]\n",
      "[Epoch 8/200] [Batch 280/938] [D loss: 1.060637, acc: 97%] [G loss: 1.123338]\n",
      "[Epoch 8/200] [Batch 281/938] [D loss: 1.106780, acc: 94%] [G loss: 1.066182]\n",
      "[Epoch 8/200] [Batch 282/938] [D loss: 1.093408, acc: 96%] [G loss: 1.076695]\n",
      "[Epoch 8/200] [Batch 283/938] [D loss: 1.059927, acc: 99%] [G loss: 1.085744]\n",
      "[Epoch 8/200] [Batch 284/938] [D loss: 1.054988, acc: 96%] [G loss: 1.134911]\n",
      "[Epoch 8/200] [Batch 285/938] [D loss: 1.128376, acc: 97%] [G loss: 1.119753]\n",
      "[Epoch 8/200] [Batch 286/938] [D loss: 1.098389, acc: 96%] [G loss: 1.065177]\n",
      "[Epoch 8/200] [Batch 287/938] [D loss: 1.103788, acc: 98%] [G loss: 1.107728]\n",
      "[Epoch 8/200] [Batch 288/938] [D loss: 1.080351, acc: 94%] [G loss: 1.088654]\n",
      "[Epoch 8/200] [Batch 289/938] [D loss: 1.075722, acc: 99%] [G loss: 1.094502]\n",
      "[Epoch 8/200] [Batch 290/938] [D loss: 1.106963, acc: 96%] [G loss: 1.104515]\n",
      "[Epoch 8/200] [Batch 291/938] [D loss: 1.099707, acc: 94%] [G loss: 1.094738]\n",
      "[Epoch 8/200] [Batch 292/938] [D loss: 1.087487, acc: 98%] [G loss: 1.149937]\n",
      "[Epoch 8/200] [Batch 293/938] [D loss: 1.079557, acc: 96%] [G loss: 1.100687]\n",
      "[Epoch 8/200] [Batch 294/938] [D loss: 1.048897, acc: 100%] [G loss: 1.106897]\n",
      "[Epoch 8/200] [Batch 295/938] [D loss: 1.081131, acc: 96%] [G loss: 1.046035]\n",
      "[Epoch 8/200] [Batch 296/938] [D loss: 1.063608, acc: 95%] [G loss: 1.136736]\n",
      "[Epoch 8/200] [Batch 297/938] [D loss: 1.095938, acc: 96%] [G loss: 1.135600]\n",
      "[Epoch 8/200] [Batch 298/938] [D loss: 1.073236, acc: 96%] [G loss: 1.084591]\n",
      "[Epoch 8/200] [Batch 299/938] [D loss: 1.094390, acc: 96%] [G loss: 1.106829]\n",
      "[Epoch 8/200] [Batch 300/938] [D loss: 1.091359, acc: 95%] [G loss: 1.145526]\n",
      "[Epoch 8/200] [Batch 301/938] [D loss: 1.091591, acc: 96%] [G loss: 1.081147]\n",
      "[Epoch 8/200] [Batch 302/938] [D loss: 1.076651, acc: 96%] [G loss: 1.085789]\n",
      "[Epoch 8/200] [Batch 303/938] [D loss: 1.096037, acc: 95%] [G loss: 1.094500]\n",
      "[Epoch 8/200] [Batch 304/938] [D loss: 1.104714, acc: 96%] [G loss: 1.041302]\n",
      "[Epoch 8/200] [Batch 305/938] [D loss: 1.078474, acc: 97%] [G loss: 1.078804]\n",
      "[Epoch 8/200] [Batch 306/938] [D loss: 1.119532, acc: 99%] [G loss: 1.086372]\n",
      "[Epoch 8/200] [Batch 307/938] [D loss: 1.089636, acc: 96%] [G loss: 1.135356]\n",
      "[Epoch 8/200] [Batch 308/938] [D loss: 1.049292, acc: 98%] [G loss: 1.154853]\n",
      "[Epoch 8/200] [Batch 309/938] [D loss: 1.100489, acc: 99%] [G loss: 1.114545]\n",
      "[Epoch 8/200] [Batch 310/938] [D loss: 1.070184, acc: 98%] [G loss: 1.117974]\n",
      "[Epoch 8/200] [Batch 311/938] [D loss: 1.118776, acc: 98%] [G loss: 1.050972]\n",
      "[Epoch 8/200] [Batch 312/938] [D loss: 1.076107, acc: 96%] [G loss: 1.057746]\n",
      "[Epoch 8/200] [Batch 313/938] [D loss: 1.098245, acc: 95%] [G loss: 1.071281]\n",
      "[Epoch 8/200] [Batch 314/938] [D loss: 1.101180, acc: 95%] [G loss: 1.072126]\n",
      "[Epoch 8/200] [Batch 315/938] [D loss: 1.094278, acc: 92%] [G loss: 1.127869]\n",
      "[Epoch 8/200] [Batch 316/938] [D loss: 1.091799, acc: 97%] [G loss: 1.114927]\n",
      "[Epoch 8/200] [Batch 317/938] [D loss: 1.072168, acc: 96%] [G loss: 1.100438]\n",
      "[Epoch 8/200] [Batch 318/938] [D loss: 1.112065, acc: 93%] [G loss: 1.086833]\n",
      "[Epoch 8/200] [Batch 319/938] [D loss: 1.102044, acc: 96%] [G loss: 1.106751]\n",
      "[Epoch 8/200] [Batch 320/938] [D loss: 1.114098, acc: 98%] [G loss: 1.125247]\n",
      "[Epoch 8/200] [Batch 321/938] [D loss: 1.093044, acc: 96%] [G loss: 1.135330]\n",
      "[Epoch 8/200] [Batch 322/938] [D loss: 1.162353, acc: 94%] [G loss: 1.099193]\n",
      "[Epoch 8/200] [Batch 323/938] [D loss: 1.081769, acc: 96%] [G loss: 1.108377]\n",
      "[Epoch 8/200] [Batch 324/938] [D loss: 1.075240, acc: 98%] [G loss: 1.078304]\n",
      "[Epoch 8/200] [Batch 325/938] [D loss: 1.079804, acc: 94%] [G loss: 1.085477]\n",
      "[Epoch 8/200] [Batch 326/938] [D loss: 1.068462, acc: 96%] [G loss: 1.101572]\n",
      "[Epoch 8/200] [Batch 327/938] [D loss: 1.069867, acc: 96%] [G loss: 1.078867]\n",
      "[Epoch 8/200] [Batch 328/938] [D loss: 1.064581, acc: 96%] [G loss: 1.116276]\n",
      "[Epoch 8/200] [Batch 329/938] [D loss: 1.089987, acc: 95%] [G loss: 1.096230]\n",
      "[Epoch 8/200] [Batch 330/938] [D loss: 1.047498, acc: 96%] [G loss: 1.115830]\n",
      "[Epoch 8/200] [Batch 331/938] [D loss: 1.074659, acc: 93%] [G loss: 1.180692]\n",
      "[Epoch 8/200] [Batch 332/938] [D loss: 1.078500, acc: 98%] [G loss: 1.126907]\n",
      "[Epoch 8/200] [Batch 333/938] [D loss: 1.098528, acc: 98%] [G loss: 1.084091]\n",
      "[Epoch 8/200] [Batch 334/938] [D loss: 1.069504, acc: 93%] [G loss: 1.121781]\n",
      "[Epoch 8/200] [Batch 335/938] [D loss: 1.055829, acc: 93%] [G loss: 1.107763]\n",
      "[Epoch 8/200] [Batch 336/938] [D loss: 1.090816, acc: 96%] [G loss: 1.173944]\n",
      "[Epoch 8/200] [Batch 337/938] [D loss: 1.129761, acc: 94%] [G loss: 1.101556]\n",
      "[Epoch 8/200] [Batch 338/938] [D loss: 1.079582, acc: 96%] [G loss: 1.134637]\n",
      "[Epoch 8/200] [Batch 339/938] [D loss: 1.079809, acc: 96%] [G loss: 1.060442]\n",
      "[Epoch 8/200] [Batch 340/938] [D loss: 1.082137, acc: 98%] [G loss: 1.083033]\n",
      "[Epoch 8/200] [Batch 341/938] [D loss: 1.125694, acc: 94%] [G loss: 1.058609]\n",
      "[Epoch 8/200] [Batch 342/938] [D loss: 1.108947, acc: 96%] [G loss: 1.107432]\n",
      "[Epoch 8/200] [Batch 343/938] [D loss: 1.096915, acc: 97%] [G loss: 1.137261]\n",
      "[Epoch 8/200] [Batch 344/938] [D loss: 1.086719, acc: 96%] [G loss: 1.094058]\n",
      "[Epoch 8/200] [Batch 345/938] [D loss: 1.076746, acc: 96%] [G loss: 1.147302]\n",
      "[Epoch 8/200] [Batch 346/938] [D loss: 1.079430, acc: 96%] [G loss: 1.063082]\n",
      "[Epoch 8/200] [Batch 347/938] [D loss: 1.115869, acc: 96%] [G loss: 1.051360]\n",
      "[Epoch 8/200] [Batch 348/938] [D loss: 1.062415, acc: 99%] [G loss: 1.075056]\n",
      "[Epoch 8/200] [Batch 349/938] [D loss: 1.079034, acc: 94%] [G loss: 1.149058]\n",
      "[Epoch 8/200] [Batch 350/938] [D loss: 1.102793, acc: 97%] [G loss: 1.125758]\n",
      "[Epoch 8/200] [Batch 351/938] [D loss: 1.102084, acc: 96%] [G loss: 1.123800]\n",
      "[Epoch 8/200] [Batch 352/938] [D loss: 1.079281, acc: 99%] [G loss: 1.111349]\n",
      "[Epoch 8/200] [Batch 353/938] [D loss: 1.099419, acc: 92%] [G loss: 1.119711]\n",
      "[Epoch 8/200] [Batch 354/938] [D loss: 1.101571, acc: 97%] [G loss: 1.081726]\n",
      "[Epoch 8/200] [Batch 355/938] [D loss: 1.087768, acc: 99%] [G loss: 1.113540]\n",
      "[Epoch 8/200] [Batch 356/938] [D loss: 1.081179, acc: 92%] [G loss: 1.088819]\n",
      "[Epoch 8/200] [Batch 357/938] [D loss: 1.080170, acc: 97%] [G loss: 1.062046]\n",
      "[Epoch 8/200] [Batch 358/938] [D loss: 1.105116, acc: 98%] [G loss: 1.096222]\n",
      "[Epoch 8/200] [Batch 359/938] [D loss: 1.124565, acc: 96%] [G loss: 1.132977]\n",
      "[Epoch 8/200] [Batch 360/938] [D loss: 1.068394, acc: 98%] [G loss: 1.171668]\n",
      "[Epoch 8/200] [Batch 361/938] [D loss: 1.073076, acc: 98%] [G loss: 1.147820]\n",
      "[Epoch 8/200] [Batch 362/938] [D loss: 1.096037, acc: 99%] [G loss: 1.092469]\n",
      "[Epoch 8/200] [Batch 363/938] [D loss: 1.043344, acc: 97%] [G loss: 1.111029]\n",
      "[Epoch 8/200] [Batch 364/938] [D loss: 1.102423, acc: 96%] [G loss: 1.022642]\n",
      "[Epoch 8/200] [Batch 365/938] [D loss: 1.053946, acc: 98%] [G loss: 1.076914]\n",
      "[Epoch 8/200] [Batch 366/938] [D loss: 1.105762, acc: 94%] [G loss: 1.202587]\n",
      "[Epoch 8/200] [Batch 367/938] [D loss: 1.118508, acc: 96%] [G loss: 1.114172]\n",
      "[Epoch 8/200] [Batch 368/938] [D loss: 1.080488, acc: 95%] [G loss: 1.089133]\n",
      "[Epoch 8/200] [Batch 369/938] [D loss: 1.079776, acc: 95%] [G loss: 1.117813]\n",
      "[Epoch 8/200] [Batch 370/938] [D loss: 1.115660, acc: 95%] [G loss: 1.070729]\n",
      "[Epoch 8/200] [Batch 371/938] [D loss: 1.119661, acc: 95%] [G loss: 1.078142]\n",
      "[Epoch 8/200] [Batch 372/938] [D loss: 1.065612, acc: 96%] [G loss: 1.100479]\n",
      "[Epoch 8/200] [Batch 373/938] [D loss: 1.100215, acc: 96%] [G loss: 1.070457]\n",
      "[Epoch 8/200] [Batch 374/938] [D loss: 1.085755, acc: 98%] [G loss: 1.142216]\n",
      "[Epoch 8/200] [Batch 375/938] [D loss: 1.093459, acc: 98%] [G loss: 1.087816]\n",
      "[Epoch 8/200] [Batch 376/938] [D loss: 1.082955, acc: 94%] [G loss: 1.153993]\n",
      "[Epoch 8/200] [Batch 377/938] [D loss: 1.085408, acc: 97%] [G loss: 1.118175]\n",
      "[Epoch 8/200] [Batch 378/938] [D loss: 1.076475, acc: 97%] [G loss: 1.153127]\n",
      "[Epoch 8/200] [Batch 379/938] [D loss: 1.068015, acc: 93%] [G loss: 1.099342]\n",
      "[Epoch 8/200] [Batch 380/938] [D loss: 1.083448, acc: 96%] [G loss: 1.083849]\n",
      "[Epoch 8/200] [Batch 381/938] [D loss: 1.055713, acc: 95%] [G loss: 1.149505]\n",
      "[Epoch 8/200] [Batch 382/938] [D loss: 1.102699, acc: 96%] [G loss: 1.039749]\n",
      "[Epoch 8/200] [Batch 383/938] [D loss: 1.104228, acc: 96%] [G loss: 1.081347]\n",
      "[Epoch 8/200] [Batch 384/938] [D loss: 1.096088, acc: 95%] [G loss: 1.160994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 385/938] [D loss: 1.111133, acc: 96%] [G loss: 1.120860]\n",
      "[Epoch 8/200] [Batch 386/938] [D loss: 1.085514, acc: 97%] [G loss: 1.130917]\n",
      "[Epoch 8/200] [Batch 387/938] [D loss: 1.070754, acc: 96%] [G loss: 1.176288]\n",
      "[Epoch 8/200] [Batch 388/938] [D loss: 1.079127, acc: 95%] [G loss: 1.065306]\n",
      "[Epoch 8/200] [Batch 389/938] [D loss: 1.128977, acc: 98%] [G loss: 1.111478]\n",
      "[Epoch 8/200] [Batch 390/938] [D loss: 1.083523, acc: 96%] [G loss: 1.120962]\n",
      "[Epoch 8/200] [Batch 391/938] [D loss: 1.103344, acc: 98%] [G loss: 1.134655]\n",
      "[Epoch 8/200] [Batch 392/938] [D loss: 1.130863, acc: 92%] [G loss: 1.076710]\n",
      "[Epoch 8/200] [Batch 393/938] [D loss: 1.084112, acc: 99%] [G loss: 1.092981]\n",
      "[Epoch 8/200] [Batch 394/938] [D loss: 1.097081, acc: 96%] [G loss: 1.137680]\n",
      "[Epoch 8/200] [Batch 395/938] [D loss: 1.088737, acc: 96%] [G loss: 1.104920]\n",
      "[Epoch 8/200] [Batch 396/938] [D loss: 1.099736, acc: 93%] [G loss: 1.096985]\n",
      "[Epoch 8/200] [Batch 397/938] [D loss: 1.119307, acc: 95%] [G loss: 1.068510]\n",
      "[Epoch 8/200] [Batch 398/938] [D loss: 1.092038, acc: 97%] [G loss: 1.075012]\n",
      "[Epoch 8/200] [Batch 399/938] [D loss: 1.098463, acc: 96%] [G loss: 1.115404]\n",
      "[Epoch 8/200] [Batch 400/938] [D loss: 1.078808, acc: 96%] [G loss: 1.128565]\n",
      "[Epoch 8/200] [Batch 401/938] [D loss: 1.092147, acc: 98%] [G loss: 1.019466]\n",
      "[Epoch 8/200] [Batch 402/938] [D loss: 1.074402, acc: 98%] [G loss: 1.102873]\n",
      "[Epoch 8/200] [Batch 403/938] [D loss: 1.090893, acc: 96%] [G loss: 1.123920]\n",
      "[Epoch 8/200] [Batch 404/938] [D loss: 1.092221, acc: 96%] [G loss: 1.135681]\n",
      "[Epoch 8/200] [Batch 405/938] [D loss: 1.095756, acc: 96%] [G loss: 1.111814]\n",
      "[Epoch 8/200] [Batch 406/938] [D loss: 1.082537, acc: 96%] [G loss: 1.135847]\n",
      "[Epoch 8/200] [Batch 407/938] [D loss: 1.100361, acc: 98%] [G loss: 1.080599]\n",
      "[Epoch 8/200] [Batch 408/938] [D loss: 1.104622, acc: 96%] [G loss: 1.092407]\n",
      "[Epoch 8/200] [Batch 409/938] [D loss: 1.097339, acc: 97%] [G loss: 1.142202]\n",
      "[Epoch 8/200] [Batch 410/938] [D loss: 1.061581, acc: 97%] [G loss: 1.158621]\n",
      "[Epoch 8/200] [Batch 411/938] [D loss: 1.096700, acc: 99%] [G loss: 1.130519]\n",
      "[Epoch 8/200] [Batch 412/938] [D loss: 1.112380, acc: 95%] [G loss: 1.089434]\n",
      "[Epoch 8/200] [Batch 413/938] [D loss: 1.127542, acc: 96%] [G loss: 1.072170]\n",
      "[Epoch 8/200] [Batch 414/938] [D loss: 1.125468, acc: 93%] [G loss: 1.091808]\n",
      "[Epoch 8/200] [Batch 415/938] [D loss: 1.104769, acc: 96%] [G loss: 1.038190]\n",
      "[Epoch 8/200] [Batch 416/938] [D loss: 1.078313, acc: 96%] [G loss: 1.121904]\n",
      "[Epoch 8/200] [Batch 417/938] [D loss: 1.109701, acc: 94%] [G loss: 1.137694]\n",
      "[Epoch 8/200] [Batch 418/938] [D loss: 1.082208, acc: 95%] [G loss: 1.098582]\n",
      "[Epoch 8/200] [Batch 419/938] [D loss: 1.117967, acc: 96%] [G loss: 1.077567]\n",
      "[Epoch 8/200] [Batch 420/938] [D loss: 1.111643, acc: 95%] [G loss: 1.058646]\n",
      "[Epoch 8/200] [Batch 421/938] [D loss: 1.101918, acc: 96%] [G loss: 1.038025]\n",
      "[Epoch 8/200] [Batch 422/938] [D loss: 1.081185, acc: 97%] [G loss: 1.047731]\n",
      "[Epoch 8/200] [Batch 423/938] [D loss: 1.076327, acc: 100%] [G loss: 1.018160]\n",
      "[Epoch 8/200] [Batch 424/938] [D loss: 1.068601, acc: 96%] [G loss: 1.058474]\n",
      "[Epoch 8/200] [Batch 425/938] [D loss: 1.115683, acc: 95%] [G loss: 1.056558]\n",
      "[Epoch 8/200] [Batch 426/938] [D loss: 1.105365, acc: 95%] [G loss: 1.155638]\n",
      "[Epoch 8/200] [Batch 427/938] [D loss: 1.097395, acc: 96%] [G loss: 1.189012]\n",
      "[Epoch 8/200] [Batch 428/938] [D loss: 1.100512, acc: 98%] [G loss: 1.159692]\n",
      "[Epoch 8/200] [Batch 429/938] [D loss: 1.070704, acc: 95%] [G loss: 1.073521]\n",
      "[Epoch 8/200] [Batch 430/938] [D loss: 1.097681, acc: 98%] [G loss: 1.060039]\n",
      "[Epoch 8/200] [Batch 431/938] [D loss: 1.112160, acc: 92%] [G loss: 1.078416]\n",
      "[Epoch 8/200] [Batch 432/938] [D loss: 1.101105, acc: 96%] [G loss: 1.047242]\n",
      "[Epoch 8/200] [Batch 433/938] [D loss: 1.085809, acc: 94%] [G loss: 1.052601]\n",
      "[Epoch 8/200] [Batch 434/938] [D loss: 1.075228, acc: 96%] [G loss: 1.156593]\n",
      "[Epoch 8/200] [Batch 435/938] [D loss: 1.088821, acc: 96%] [G loss: 1.135902]\n",
      "[Epoch 8/200] [Batch 436/938] [D loss: 1.068952, acc: 97%] [G loss: 1.123634]\n",
      "[Epoch 8/200] [Batch 437/938] [D loss: 1.078166, acc: 93%] [G loss: 1.157291]\n",
      "[Epoch 8/200] [Batch 438/938] [D loss: 1.095443, acc: 96%] [G loss: 1.097555]\n",
      "[Epoch 8/200] [Batch 439/938] [D loss: 1.087174, acc: 93%] [G loss: 1.150110]\n",
      "[Epoch 8/200] [Batch 440/938] [D loss: 1.099146, acc: 96%] [G loss: 1.090242]\n",
      "[Epoch 8/200] [Batch 441/938] [D loss: 1.076020, acc: 96%] [G loss: 1.173231]\n",
      "[Epoch 8/200] [Batch 442/938] [D loss: 1.097394, acc: 95%] [G loss: 1.133659]\n",
      "[Epoch 8/200] [Batch 443/938] [D loss: 1.090654, acc: 96%] [G loss: 1.129528]\n",
      "[Epoch 8/200] [Batch 444/938] [D loss: 1.069587, acc: 94%] [G loss: 1.051547]\n",
      "[Epoch 8/200] [Batch 445/938] [D loss: 1.121528, acc: 97%] [G loss: 1.064945]\n",
      "[Epoch 8/200] [Batch 446/938] [D loss: 1.059180, acc: 97%] [G loss: 1.128291]\n",
      "[Epoch 8/200] [Batch 447/938] [D loss: 1.064117, acc: 95%] [G loss: 1.110794]\n",
      "[Epoch 8/200] [Batch 448/938] [D loss: 1.067449, acc: 100%] [G loss: 1.101714]\n",
      "[Epoch 8/200] [Batch 449/938] [D loss: 1.121176, acc: 96%] [G loss: 1.075781]\n",
      "[Epoch 8/200] [Batch 450/938] [D loss: 1.135619, acc: 90%] [G loss: 1.056786]\n",
      "[Epoch 8/200] [Batch 451/938] [D loss: 1.149426, acc: 95%] [G loss: 1.072271]\n",
      "[Epoch 8/200] [Batch 452/938] [D loss: 1.083653, acc: 98%] [G loss: 1.107608]\n",
      "[Epoch 8/200] [Batch 453/938] [D loss: 1.071874, acc: 96%] [G loss: 1.088576]\n",
      "[Epoch 8/200] [Batch 454/938] [D loss: 1.096004, acc: 97%] [G loss: 1.122067]\n",
      "[Epoch 8/200] [Batch 455/938] [D loss: 1.088227, acc: 96%] [G loss: 1.064506]\n",
      "[Epoch 8/200] [Batch 456/938] [D loss: 1.088854, acc: 98%] [G loss: 1.063548]\n",
      "[Epoch 8/200] [Batch 457/938] [D loss: 1.093685, acc: 95%] [G loss: 1.140060]\n",
      "[Epoch 8/200] [Batch 458/938] [D loss: 1.066739, acc: 97%] [G loss: 1.130907]\n",
      "[Epoch 8/200] [Batch 459/938] [D loss: 1.075019, acc: 98%] [G loss: 1.123710]\n",
      "[Epoch 8/200] [Batch 460/938] [D loss: 1.101989, acc: 96%] [G loss: 1.119293]\n",
      "[Epoch 8/200] [Batch 461/938] [D loss: 1.087258, acc: 95%] [G loss: 1.105420]\n",
      "[Epoch 8/200] [Batch 462/938] [D loss: 1.080662, acc: 96%] [G loss: 1.142298]\n",
      "[Epoch 8/200] [Batch 463/938] [D loss: 1.073785, acc: 99%] [G loss: 1.151133]\n",
      "[Epoch 8/200] [Batch 464/938] [D loss: 1.076051, acc: 97%] [G loss: 1.099685]\n",
      "[Epoch 8/200] [Batch 465/938] [D loss: 1.100440, acc: 94%] [G loss: 1.088055]\n",
      "[Epoch 8/200] [Batch 466/938] [D loss: 1.083394, acc: 99%] [G loss: 1.070013]\n",
      "[Epoch 8/200] [Batch 467/938] [D loss: 1.091410, acc: 98%] [G loss: 1.136114]\n",
      "[Epoch 8/200] [Batch 468/938] [D loss: 1.081643, acc: 97%] [G loss: 1.103745]\n",
      "[Epoch 8/200] [Batch 469/938] [D loss: 1.083477, acc: 96%] [G loss: 1.115386]\n",
      "[Epoch 8/200] [Batch 470/938] [D loss: 1.090240, acc: 96%] [G loss: 1.136075]\n",
      "[Epoch 8/200] [Batch 471/938] [D loss: 1.092892, acc: 99%] [G loss: 1.113121]\n",
      "[Epoch 8/200] [Batch 472/938] [D loss: 1.078987, acc: 99%] [G loss: 1.132477]\n",
      "[Epoch 8/200] [Batch 473/938] [D loss: 1.089535, acc: 96%] [G loss: 1.134638]\n",
      "[Epoch 8/200] [Batch 474/938] [D loss: 1.098384, acc: 96%] [G loss: 1.117341]\n",
      "[Epoch 8/200] [Batch 475/938] [D loss: 1.064325, acc: 97%] [G loss: 1.112434]\n",
      "[Epoch 8/200] [Batch 476/938] [D loss: 1.085389, acc: 97%] [G loss: 1.078068]\n",
      "[Epoch 8/200] [Batch 477/938] [D loss: 1.105649, acc: 98%] [G loss: 1.106639]\n",
      "[Epoch 8/200] [Batch 478/938] [D loss: 1.085783, acc: 96%] [G loss: 1.068655]\n",
      "[Epoch 8/200] [Batch 479/938] [D loss: 1.089325, acc: 98%] [G loss: 1.096627]\n",
      "[Epoch 8/200] [Batch 480/938] [D loss: 1.060837, acc: 96%] [G loss: 1.152686]\n",
      "[Epoch 8/200] [Batch 481/938] [D loss: 1.082346, acc: 99%] [G loss: 1.093652]\n",
      "[Epoch 8/200] [Batch 482/938] [D loss: 1.101260, acc: 96%] [G loss: 1.089664]\n",
      "[Epoch 8/200] [Batch 483/938] [D loss: 1.087339, acc: 96%] [G loss: 1.059542]\n",
      "[Epoch 8/200] [Batch 484/938] [D loss: 1.103988, acc: 96%] [G loss: 1.068611]\n",
      "[Epoch 8/200] [Batch 485/938] [D loss: 1.109518, acc: 96%] [G loss: 1.113072]\n",
      "[Epoch 8/200] [Batch 486/938] [D loss: 1.099856, acc: 97%] [G loss: 1.107175]\n",
      "[Epoch 8/200] [Batch 487/938] [D loss: 1.075444, acc: 96%] [G loss: 1.105893]\n",
      "[Epoch 8/200] [Batch 488/938] [D loss: 1.077856, acc: 95%] [G loss: 1.118393]\n",
      "[Epoch 8/200] [Batch 489/938] [D loss: 1.124534, acc: 96%] [G loss: 1.110991]\n",
      "[Epoch 8/200] [Batch 490/938] [D loss: 1.073072, acc: 97%] [G loss: 1.126527]\n",
      "[Epoch 8/200] [Batch 491/938] [D loss: 1.082383, acc: 97%] [G loss: 1.095652]\n",
      "[Epoch 8/200] [Batch 492/938] [D loss: 1.088163, acc: 96%] [G loss: 1.139677]\n",
      "[Epoch 8/200] [Batch 493/938] [D loss: 1.098616, acc: 97%] [G loss: 1.148518]\n",
      "[Epoch 8/200] [Batch 494/938] [D loss: 1.058376, acc: 99%] [G loss: 1.055346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 495/938] [D loss: 1.078969, acc: 97%] [G loss: 1.104549]\n",
      "[Epoch 8/200] [Batch 496/938] [D loss: 1.093569, acc: 94%] [G loss: 1.129379]\n",
      "[Epoch 8/200] [Batch 497/938] [D loss: 1.057118, acc: 97%] [G loss: 1.145516]\n",
      "[Epoch 8/200] [Batch 498/938] [D loss: 1.102904, acc: 95%] [G loss: 1.207494]\n",
      "[Epoch 8/200] [Batch 499/938] [D loss: 1.113075, acc: 94%] [G loss: 1.115574]\n",
      "[Epoch 8/200] [Batch 500/938] [D loss: 1.110108, acc: 95%] [G loss: 1.085860]\n",
      "[Epoch 8/200] [Batch 501/938] [D loss: 1.074282, acc: 97%] [G loss: 1.069395]\n",
      "[Epoch 8/200] [Batch 502/938] [D loss: 1.070767, acc: 99%] [G loss: 1.084635]\n",
      "[Epoch 8/200] [Batch 503/938] [D loss: 1.074584, acc: 95%] [G loss: 1.089618]\n",
      "[Epoch 8/200] [Batch 504/938] [D loss: 1.097436, acc: 94%] [G loss: 1.084571]\n",
      "[Epoch 8/200] [Batch 505/938] [D loss: 1.083855, acc: 96%] [G loss: 1.067800]\n",
      "[Epoch 8/200] [Batch 506/938] [D loss: 1.113040, acc: 98%] [G loss: 1.101771]\n",
      "[Epoch 8/200] [Batch 507/938] [D loss: 1.089328, acc: 96%] [G loss: 1.128831]\n",
      "[Epoch 8/200] [Batch 508/938] [D loss: 1.103658, acc: 98%] [G loss: 1.097650]\n",
      "[Epoch 8/200] [Batch 509/938] [D loss: 1.101603, acc: 96%] [G loss: 1.093068]\n",
      "[Epoch 8/200] [Batch 510/938] [D loss: 1.102097, acc: 98%] [G loss: 1.081508]\n",
      "[Epoch 8/200] [Batch 511/938] [D loss: 1.081784, acc: 97%] [G loss: 1.115283]\n",
      "[Epoch 8/200] [Batch 512/938] [D loss: 1.105417, acc: 94%] [G loss: 1.083251]\n",
      "[Epoch 8/200] [Batch 513/938] [D loss: 1.073518, acc: 97%] [G loss: 1.043221]\n",
      "[Epoch 8/200] [Batch 514/938] [D loss: 1.068811, acc: 99%] [G loss: 1.120529]\n",
      "[Epoch 8/200] [Batch 515/938] [D loss: 1.095032, acc: 97%] [G loss: 1.070447]\n",
      "[Epoch 8/200] [Batch 516/938] [D loss: 1.156405, acc: 96%] [G loss: 1.080587]\n",
      "[Epoch 8/200] [Batch 517/938] [D loss: 1.082725, acc: 95%] [G loss: 1.063918]\n",
      "[Epoch 8/200] [Batch 518/938] [D loss: 1.105351, acc: 98%] [G loss: 1.063614]\n",
      "[Epoch 8/200] [Batch 519/938] [D loss: 1.085261, acc: 95%] [G loss: 1.137320]\n",
      "[Epoch 8/200] [Batch 520/938] [D loss: 1.059250, acc: 98%] [G loss: 1.120103]\n",
      "[Epoch 8/200] [Batch 521/938] [D loss: 1.091817, acc: 94%] [G loss: 1.140767]\n",
      "[Epoch 8/200] [Batch 522/938] [D loss: 1.096419, acc: 96%] [G loss: 1.132154]\n",
      "[Epoch 8/200] [Batch 523/938] [D loss: 1.094507, acc: 98%] [G loss: 1.111765]\n",
      "[Epoch 8/200] [Batch 524/938] [D loss: 1.118552, acc: 96%] [G loss: 1.060106]\n",
      "[Epoch 8/200] [Batch 525/938] [D loss: 1.071964, acc: 92%] [G loss: 1.111130]\n",
      "[Epoch 8/200] [Batch 526/938] [D loss: 1.137351, acc: 95%] [G loss: 1.066082]\n",
      "[Epoch 8/200] [Batch 527/938] [D loss: 1.109868, acc: 98%] [G loss: 1.082841]\n",
      "[Epoch 8/200] [Batch 528/938] [D loss: 1.099807, acc: 96%] [G loss: 1.151593]\n",
      "[Epoch 8/200] [Batch 529/938] [D loss: 1.101312, acc: 96%] [G loss: 1.120904]\n",
      "[Epoch 8/200] [Batch 530/938] [D loss: 1.079078, acc: 99%] [G loss: 1.122938]\n",
      "[Epoch 8/200] [Batch 531/938] [D loss: 1.127003, acc: 97%] [G loss: 1.100271]\n",
      "[Epoch 8/200] [Batch 532/938] [D loss: 1.103018, acc: 96%] [G loss: 1.130762]\n",
      "[Epoch 8/200] [Batch 533/938] [D loss: 1.093570, acc: 95%] [G loss: 1.102426]\n",
      "[Epoch 8/200] [Batch 534/938] [D loss: 1.060078, acc: 97%] [G loss: 1.077907]\n",
      "[Epoch 8/200] [Batch 535/938] [D loss: 1.084084, acc: 97%] [G loss: 1.104543]\n",
      "[Epoch 8/200] [Batch 536/938] [D loss: 1.109040, acc: 97%] [G loss: 1.078662]\n",
      "[Epoch 8/200] [Batch 537/938] [D loss: 1.110248, acc: 96%] [G loss: 1.037871]\n",
      "[Epoch 8/200] [Batch 538/938] [D loss: 1.077446, acc: 96%] [G loss: 1.085407]\n",
      "[Epoch 8/200] [Batch 539/938] [D loss: 1.091570, acc: 96%] [G loss: 1.080554]\n",
      "[Epoch 8/200] [Batch 540/938] [D loss: 1.078598, acc: 96%] [G loss: 1.044011]\n",
      "[Epoch 8/200] [Batch 541/938] [D loss: 1.096819, acc: 95%] [G loss: 1.127719]\n",
      "[Epoch 8/200] [Batch 542/938] [D loss: 1.112192, acc: 97%] [G loss: 1.098339]\n",
      "[Epoch 8/200] [Batch 543/938] [D loss: 1.068794, acc: 98%] [G loss: 1.154853]\n",
      "[Epoch 8/200] [Batch 544/938] [D loss: 1.101371, acc: 96%] [G loss: 1.130872]\n",
      "[Epoch 8/200] [Batch 545/938] [D loss: 1.136354, acc: 98%] [G loss: 1.134563]\n",
      "[Epoch 8/200] [Batch 546/938] [D loss: 1.074517, acc: 94%] [G loss: 1.113942]\n",
      "[Epoch 8/200] [Batch 547/938] [D loss: 1.085685, acc: 96%] [G loss: 1.100578]\n",
      "[Epoch 8/200] [Batch 548/938] [D loss: 1.056433, acc: 95%] [G loss: 1.129550]\n",
      "[Epoch 8/200] [Batch 549/938] [D loss: 1.076954, acc: 97%] [G loss: 1.155647]\n",
      "[Epoch 8/200] [Batch 550/938] [D loss: 1.070196, acc: 96%] [G loss: 1.153921]\n",
      "[Epoch 8/200] [Batch 551/938] [D loss: 1.076933, acc: 96%] [G loss: 1.104506]\n",
      "[Epoch 8/200] [Batch 552/938] [D loss: 1.111854, acc: 97%] [G loss: 1.055344]\n",
      "[Epoch 8/200] [Batch 553/938] [D loss: 1.084976, acc: 97%] [G loss: 1.127801]\n",
      "[Epoch 8/200] [Batch 554/938] [D loss: 1.073452, acc: 96%] [G loss: 1.122792]\n",
      "[Epoch 8/200] [Batch 555/938] [D loss: 1.091156, acc: 98%] [G loss: 1.068184]\n",
      "[Epoch 8/200] [Batch 556/938] [D loss: 1.071232, acc: 99%] [G loss: 1.075815]\n",
      "[Epoch 8/200] [Batch 557/938] [D loss: 1.100676, acc: 95%] [G loss: 1.078556]\n",
      "[Epoch 8/200] [Batch 558/938] [D loss: 1.075046, acc: 98%] [G loss: 1.119969]\n",
      "[Epoch 8/200] [Batch 559/938] [D loss: 1.077880, acc: 96%] [G loss: 1.077794]\n",
      "[Epoch 8/200] [Batch 560/938] [D loss: 1.041934, acc: 98%] [G loss: 1.150509]\n",
      "[Epoch 8/200] [Batch 561/938] [D loss: 1.101865, acc: 96%] [G loss: 1.082785]\n",
      "[Epoch 8/200] [Batch 562/938] [D loss: 1.100142, acc: 98%] [G loss: 1.077610]\n",
      "[Epoch 8/200] [Batch 563/938] [D loss: 1.129477, acc: 95%] [G loss: 1.130289]\n",
      "[Epoch 8/200] [Batch 564/938] [D loss: 1.084037, acc: 95%] [G loss: 1.121032]\n",
      "[Epoch 8/200] [Batch 565/938] [D loss: 1.110175, acc: 96%] [G loss: 1.135751]\n",
      "[Epoch 8/200] [Batch 566/938] [D loss: 1.087627, acc: 97%] [G loss: 1.073919]\n",
      "[Epoch 8/200] [Batch 567/938] [D loss: 1.131855, acc: 98%] [G loss: 1.120956]\n",
      "[Epoch 8/200] [Batch 568/938] [D loss: 1.058418, acc: 99%] [G loss: 1.100632]\n",
      "[Epoch 8/200] [Batch 569/938] [D loss: 1.076546, acc: 96%] [G loss: 1.093243]\n",
      "[Epoch 8/200] [Batch 570/938] [D loss: 1.101259, acc: 95%] [G loss: 1.054450]\n",
      "[Epoch 8/200] [Batch 571/938] [D loss: 1.096971, acc: 96%] [G loss: 1.109097]\n",
      "[Epoch 8/200] [Batch 572/938] [D loss: 1.059558, acc: 98%] [G loss: 1.089831]\n",
      "[Epoch 8/200] [Batch 573/938] [D loss: 1.055229, acc: 95%] [G loss: 1.079933]\n",
      "[Epoch 8/200] [Batch 574/938] [D loss: 1.084245, acc: 98%] [G loss: 1.121048]\n",
      "[Epoch 8/200] [Batch 575/938] [D loss: 1.031882, acc: 97%] [G loss: 1.199535]\n",
      "[Epoch 8/200] [Batch 576/938] [D loss: 1.079627, acc: 99%] [G loss: 1.153678]\n",
      "[Epoch 8/200] [Batch 577/938] [D loss: 1.065945, acc: 97%] [G loss: 1.090566]\n",
      "[Epoch 8/200] [Batch 578/938] [D loss: 1.122257, acc: 97%] [G loss: 1.073072]\n",
      "[Epoch 8/200] [Batch 579/938] [D loss: 1.092860, acc: 98%] [G loss: 1.149269]\n",
      "[Epoch 8/200] [Batch 580/938] [D loss: 1.100811, acc: 97%] [G loss: 1.065130]\n",
      "[Epoch 8/200] [Batch 581/938] [D loss: 1.061784, acc: 99%] [G loss: 1.081850]\n",
      "[Epoch 8/200] [Batch 582/938] [D loss: 1.093054, acc: 99%] [G loss: 1.130686]\n",
      "[Epoch 8/200] [Batch 583/938] [D loss: 1.123024, acc: 96%] [G loss: 1.060044]\n",
      "[Epoch 8/200] [Batch 584/938] [D loss: 1.097265, acc: 94%] [G loss: 1.133444]\n",
      "[Epoch 8/200] [Batch 585/938] [D loss: 1.094498, acc: 94%] [G loss: 1.056509]\n",
      "[Epoch 8/200] [Batch 586/938] [D loss: 1.035758, acc: 97%] [G loss: 1.125745]\n",
      "[Epoch 8/200] [Batch 587/938] [D loss: 1.074847, acc: 95%] [G loss: 1.094167]\n",
      "[Epoch 8/200] [Batch 588/938] [D loss: 1.087460, acc: 96%] [G loss: 1.086705]\n",
      "[Epoch 8/200] [Batch 589/938] [D loss: 1.084334, acc: 99%] [G loss: 1.133716]\n",
      "[Epoch 8/200] [Batch 590/938] [D loss: 1.095654, acc: 97%] [G loss: 1.082385]\n",
      "[Epoch 8/200] [Batch 591/938] [D loss: 1.111750, acc: 96%] [G loss: 1.123666]\n",
      "[Epoch 8/200] [Batch 592/938] [D loss: 1.075583, acc: 95%] [G loss: 1.155262]\n",
      "[Epoch 8/200] [Batch 593/938] [D loss: 1.100299, acc: 96%] [G loss: 1.050170]\n",
      "[Epoch 8/200] [Batch 594/938] [D loss: 1.067247, acc: 97%] [G loss: 1.047928]\n",
      "[Epoch 8/200] [Batch 595/938] [D loss: 1.090378, acc: 98%] [G loss: 1.087907]\n",
      "[Epoch 8/200] [Batch 596/938] [D loss: 1.107852, acc: 96%] [G loss: 1.045402]\n",
      "[Epoch 8/200] [Batch 597/938] [D loss: 1.109757, acc: 92%] [G loss: 1.155476]\n",
      "[Epoch 8/200] [Batch 598/938] [D loss: 1.085168, acc: 97%] [G loss: 1.159155]\n",
      "[Epoch 8/200] [Batch 599/938] [D loss: 1.102705, acc: 94%] [G loss: 1.141973]\n",
      "[Epoch 8/200] [Batch 600/938] [D loss: 1.106767, acc: 98%] [G loss: 1.086332]\n",
      "[Epoch 8/200] [Batch 601/938] [D loss: 1.108918, acc: 94%] [G loss: 1.099971]\n",
      "[Epoch 8/200] [Batch 602/938] [D loss: 1.097022, acc: 96%] [G loss: 1.080435]\n",
      "[Epoch 8/200] [Batch 603/938] [D loss: 1.087824, acc: 96%] [G loss: 1.066240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 604/938] [D loss: 1.099664, acc: 96%] [G loss: 1.116042]\n",
      "[Epoch 8/200] [Batch 605/938] [D loss: 1.102900, acc: 93%] [G loss: 1.162827]\n",
      "[Epoch 8/200] [Batch 606/938] [D loss: 1.101524, acc: 97%] [G loss: 1.100467]\n",
      "[Epoch 8/200] [Batch 607/938] [D loss: 1.056096, acc: 96%] [G loss: 1.065562]\n",
      "[Epoch 8/200] [Batch 608/938] [D loss: 1.075799, acc: 96%] [G loss: 1.160921]\n",
      "[Epoch 8/200] [Batch 609/938] [D loss: 1.097619, acc: 96%] [G loss: 1.094591]\n",
      "[Epoch 8/200] [Batch 610/938] [D loss: 1.095822, acc: 96%] [G loss: 1.085620]\n",
      "[Epoch 8/200] [Batch 611/938] [D loss: 1.086007, acc: 92%] [G loss: 1.074768]\n",
      "[Epoch 8/200] [Batch 612/938] [D loss: 1.075400, acc: 98%] [G loss: 1.122362]\n",
      "[Epoch 8/200] [Batch 613/938] [D loss: 1.101531, acc: 96%] [G loss: 1.149589]\n",
      "[Epoch 8/200] [Batch 614/938] [D loss: 1.074800, acc: 96%] [G loss: 1.180634]\n",
      "[Epoch 8/200] [Batch 615/938] [D loss: 1.131217, acc: 92%] [G loss: 1.102634]\n",
      "[Epoch 8/200] [Batch 616/938] [D loss: 1.096335, acc: 96%] [G loss: 1.106368]\n",
      "[Epoch 8/200] [Batch 617/938] [D loss: 1.091849, acc: 96%] [G loss: 1.077219]\n",
      "[Epoch 8/200] [Batch 618/938] [D loss: 1.106444, acc: 96%] [G loss: 1.102693]\n",
      "[Epoch 8/200] [Batch 619/938] [D loss: 1.047733, acc: 98%] [G loss: 1.117564]\n",
      "[Epoch 8/200] [Batch 620/938] [D loss: 1.106594, acc: 96%] [G loss: 1.117710]\n",
      "[Epoch 8/200] [Batch 621/938] [D loss: 1.078351, acc: 98%] [G loss: 1.196847]\n",
      "[Epoch 8/200] [Batch 622/938] [D loss: 1.091020, acc: 96%] [G loss: 1.094878]\n",
      "[Epoch 8/200] [Batch 623/938] [D loss: 1.083045, acc: 99%] [G loss: 1.094463]\n",
      "[Epoch 8/200] [Batch 624/938] [D loss: 1.097287, acc: 95%] [G loss: 1.050951]\n",
      "[Epoch 8/200] [Batch 625/938] [D loss: 1.078495, acc: 97%] [G loss: 1.115570]\n",
      "[Epoch 8/200] [Batch 626/938] [D loss: 1.072765, acc: 96%] [G loss: 1.102181]\n",
      "[Epoch 8/200] [Batch 627/938] [D loss: 1.080211, acc: 96%] [G loss: 1.141191]\n",
      "[Epoch 8/200] [Batch 628/938] [D loss: 1.098161, acc: 95%] [G loss: 1.187039]\n",
      "[Epoch 8/200] [Batch 629/938] [D loss: 1.069913, acc: 96%] [G loss: 1.144877]\n",
      "[Epoch 8/200] [Batch 630/938] [D loss: 1.077327, acc: 98%] [G loss: 1.106609]\n",
      "[Epoch 8/200] [Batch 631/938] [D loss: 1.104123, acc: 96%] [G loss: 1.109876]\n",
      "[Epoch 8/200] [Batch 632/938] [D loss: 1.124613, acc: 94%] [G loss: 1.107280]\n",
      "[Epoch 8/200] [Batch 633/938] [D loss: 1.113840, acc: 97%] [G loss: 1.115995]\n",
      "[Epoch 8/200] [Batch 634/938] [D loss: 1.055280, acc: 97%] [G loss: 1.067029]\n",
      "[Epoch 8/200] [Batch 635/938] [D loss: 1.094243, acc: 97%] [G loss: 1.135211]\n",
      "[Epoch 8/200] [Batch 636/938] [D loss: 1.087379, acc: 96%] [G loss: 1.097202]\n",
      "[Epoch 8/200] [Batch 637/938] [D loss: 1.094970, acc: 96%] [G loss: 1.054496]\n",
      "[Epoch 8/200] [Batch 638/938] [D loss: 1.077767, acc: 97%] [G loss: 1.079014]\n",
      "[Epoch 8/200] [Batch 639/938] [D loss: 1.096782, acc: 96%] [G loss: 1.060380]\n",
      "[Epoch 8/200] [Batch 640/938] [D loss: 1.098584, acc: 94%] [G loss: 1.108921]\n",
      "[Epoch 8/200] [Batch 641/938] [D loss: 1.077910, acc: 96%] [G loss: 1.086774]\n",
      "[Epoch 8/200] [Batch 642/938] [D loss: 1.069700, acc: 98%] [G loss: 1.128737]\n",
      "[Epoch 8/200] [Batch 643/938] [D loss: 1.050547, acc: 100%] [G loss: 1.122890]\n",
      "[Epoch 8/200] [Batch 644/938] [D loss: 1.083301, acc: 96%] [G loss: 1.089562]\n",
      "[Epoch 8/200] [Batch 645/938] [D loss: 1.072214, acc: 98%] [G loss: 1.066594]\n",
      "[Epoch 8/200] [Batch 646/938] [D loss: 1.099596, acc: 99%] [G loss: 1.122313]\n",
      "[Epoch 8/200] [Batch 647/938] [D loss: 1.076443, acc: 96%] [G loss: 1.059801]\n",
      "[Epoch 8/200] [Batch 648/938] [D loss: 1.061951, acc: 97%] [G loss: 1.115652]\n",
      "[Epoch 8/200] [Batch 649/938] [D loss: 1.098876, acc: 96%] [G loss: 1.104793]\n",
      "[Epoch 8/200] [Batch 650/938] [D loss: 1.076854, acc: 96%] [G loss: 1.080438]\n",
      "[Epoch 8/200] [Batch 651/938] [D loss: 1.071726, acc: 94%] [G loss: 1.066588]\n",
      "[Epoch 8/200] [Batch 652/938] [D loss: 1.130801, acc: 96%] [G loss: 1.083946]\n",
      "[Epoch 8/200] [Batch 653/938] [D loss: 1.107870, acc: 97%] [G loss: 1.163430]\n",
      "[Epoch 8/200] [Batch 654/938] [D loss: 1.073951, acc: 98%] [G loss: 1.184456]\n",
      "[Epoch 8/200] [Batch 655/938] [D loss: 1.063159, acc: 94%] [G loss: 1.124627]\n",
      "[Epoch 8/200] [Batch 656/938] [D loss: 1.086681, acc: 95%] [G loss: 1.112359]\n",
      "[Epoch 8/200] [Batch 657/938] [D loss: 1.068541, acc: 97%] [G loss: 1.113288]\n",
      "[Epoch 8/200] [Batch 658/938] [D loss: 1.100044, acc: 97%] [G loss: 1.143663]\n",
      "[Epoch 8/200] [Batch 659/938] [D loss: 1.087926, acc: 96%] [G loss: 1.062105]\n",
      "[Epoch 8/200] [Batch 660/938] [D loss: 1.100076, acc: 93%] [G loss: 1.057414]\n",
      "[Epoch 8/200] [Batch 661/938] [D loss: 1.074455, acc: 96%] [G loss: 1.051089]\n",
      "[Epoch 8/200] [Batch 662/938] [D loss: 1.099500, acc: 98%] [G loss: 1.142003]\n",
      "[Epoch 8/200] [Batch 663/938] [D loss: 1.087480, acc: 96%] [G loss: 1.107902]\n",
      "[Epoch 8/200] [Batch 664/938] [D loss: 1.147358, acc: 92%] [G loss: 1.097323]\n",
      "[Epoch 8/200] [Batch 665/938] [D loss: 1.071249, acc: 98%] [G loss: 1.051066]\n",
      "[Epoch 8/200] [Batch 666/938] [D loss: 1.090144, acc: 99%] [G loss: 1.109426]\n",
      "[Epoch 8/200] [Batch 667/938] [D loss: 1.082482, acc: 96%] [G loss: 1.066594]\n",
      "[Epoch 8/200] [Batch 668/938] [D loss: 1.087660, acc: 96%] [G loss: 1.143286]\n",
      "[Epoch 8/200] [Batch 669/938] [D loss: 1.082833, acc: 96%] [G loss: 1.092475]\n",
      "[Epoch 8/200] [Batch 670/938] [D loss: 1.050449, acc: 98%] [G loss: 1.114858]\n",
      "[Epoch 8/200] [Batch 671/938] [D loss: 1.085084, acc: 96%] [G loss: 1.075290]\n",
      "[Epoch 8/200] [Batch 672/938] [D loss: 1.103463, acc: 93%] [G loss: 1.098993]\n",
      "[Epoch 8/200] [Batch 673/938] [D loss: 1.106203, acc: 96%] [G loss: 1.095372]\n",
      "[Epoch 8/200] [Batch 674/938] [D loss: 1.081895, acc: 96%] [G loss: 1.058569]\n",
      "[Epoch 8/200] [Batch 675/938] [D loss: 1.049224, acc: 99%] [G loss: 1.130944]\n",
      "[Epoch 8/200] [Batch 676/938] [D loss: 1.100179, acc: 96%] [G loss: 1.064682]\n",
      "[Epoch 8/200] [Batch 677/938] [D loss: 1.067448, acc: 96%] [G loss: 1.104028]\n",
      "[Epoch 8/200] [Batch 678/938] [D loss: 1.092157, acc: 95%] [G loss: 1.103168]\n",
      "[Epoch 8/200] [Batch 679/938] [D loss: 1.111654, acc: 94%] [G loss: 1.091286]\n",
      "[Epoch 8/200] [Batch 680/938] [D loss: 1.025643, acc: 99%] [G loss: 1.073817]\n",
      "[Epoch 8/200] [Batch 681/938] [D loss: 1.085807, acc: 96%] [G loss: 1.110146]\n",
      "[Epoch 8/200] [Batch 682/938] [D loss: 1.067780, acc: 99%] [G loss: 1.079252]\n",
      "[Epoch 8/200] [Batch 683/938] [D loss: 1.083424, acc: 96%] [G loss: 1.086661]\n",
      "[Epoch 8/200] [Batch 684/938] [D loss: 1.078404, acc: 97%] [G loss: 1.069500]\n",
      "[Epoch 8/200] [Batch 685/938] [D loss: 1.092884, acc: 95%] [G loss: 1.079602]\n",
      "[Epoch 8/200] [Batch 686/938] [D loss: 1.078880, acc: 96%] [G loss: 1.143961]\n",
      "[Epoch 8/200] [Batch 687/938] [D loss: 1.110165, acc: 95%] [G loss: 1.101508]\n",
      "[Epoch 8/200] [Batch 688/938] [D loss: 1.060300, acc: 97%] [G loss: 1.078182]\n",
      "[Epoch 8/200] [Batch 689/938] [D loss: 1.115139, acc: 96%] [G loss: 1.079146]\n",
      "[Epoch 8/200] [Batch 690/938] [D loss: 1.087162, acc: 96%] [G loss: 1.130365]\n",
      "[Epoch 8/200] [Batch 691/938] [D loss: 1.085410, acc: 97%] [G loss: 1.067876]\n",
      "[Epoch 8/200] [Batch 692/938] [D loss: 1.101117, acc: 94%] [G loss: 1.103632]\n",
      "[Epoch 8/200] [Batch 693/938] [D loss: 1.104126, acc: 95%] [G loss: 1.073633]\n",
      "[Epoch 8/200] [Batch 694/938] [D loss: 1.086030, acc: 97%] [G loss: 1.106425]\n",
      "[Epoch 8/200] [Batch 695/938] [D loss: 1.070424, acc: 97%] [G loss: 1.092161]\n",
      "[Epoch 8/200] [Batch 696/938] [D loss: 1.069931, acc: 97%] [G loss: 1.082317]\n",
      "[Epoch 8/200] [Batch 697/938] [D loss: 1.089923, acc: 97%] [G loss: 1.153444]\n",
      "[Epoch 8/200] [Batch 698/938] [D loss: 1.082235, acc: 97%] [G loss: 1.118755]\n",
      "[Epoch 8/200] [Batch 699/938] [D loss: 1.090342, acc: 95%] [G loss: 1.121307]\n",
      "[Epoch 8/200] [Batch 700/938] [D loss: 1.123920, acc: 96%] [G loss: 1.085175]\n",
      "[Epoch 8/200] [Batch 701/938] [D loss: 1.101646, acc: 96%] [G loss: 1.124024]\n",
      "[Epoch 8/200] [Batch 702/938] [D loss: 1.103146, acc: 97%] [G loss: 1.124136]\n",
      "[Epoch 8/200] [Batch 703/938] [D loss: 1.068183, acc: 97%] [G loss: 1.102013]\n",
      "[Epoch 8/200] [Batch 704/938] [D loss: 1.120646, acc: 96%] [G loss: 1.113554]\n",
      "[Epoch 8/200] [Batch 705/938] [D loss: 1.093356, acc: 95%] [G loss: 1.119483]\n",
      "[Epoch 8/200] [Batch 706/938] [D loss: 1.077836, acc: 98%] [G loss: 1.132685]\n",
      "[Epoch 8/200] [Batch 707/938] [D loss: 1.082127, acc: 93%] [G loss: 1.080872]\n",
      "[Epoch 8/200] [Batch 708/938] [D loss: 1.090012, acc: 95%] [G loss: 1.091328]\n",
      "[Epoch 8/200] [Batch 709/938] [D loss: 1.096506, acc: 94%] [G loss: 1.092346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 710/938] [D loss: 1.098011, acc: 94%] [G loss: 1.061332]\n",
      "[Epoch 8/200] [Batch 711/938] [D loss: 1.116033, acc: 94%] [G loss: 1.043156]\n",
      "[Epoch 8/200] [Batch 712/938] [D loss: 1.059128, acc: 97%] [G loss: 1.059960]\n",
      "[Epoch 8/200] [Batch 713/938] [D loss: 1.093786, acc: 98%] [G loss: 1.113076]\n",
      "[Epoch 8/200] [Batch 714/938] [D loss: 1.100357, acc: 93%] [G loss: 1.161594]\n",
      "[Epoch 8/200] [Batch 715/938] [D loss: 1.124062, acc: 96%] [G loss: 1.137912]\n",
      "[Epoch 8/200] [Batch 716/938] [D loss: 1.074781, acc: 96%] [G loss: 1.056970]\n",
      "[Epoch 8/200] [Batch 717/938] [D loss: 1.096837, acc: 98%] [G loss: 1.129476]\n",
      "[Epoch 8/200] [Batch 718/938] [D loss: 1.106149, acc: 96%] [G loss: 1.088620]\n",
      "[Epoch 8/200] [Batch 719/938] [D loss: 1.075835, acc: 95%] [G loss: 1.143245]\n",
      "[Epoch 8/200] [Batch 720/938] [D loss: 1.135150, acc: 97%] [G loss: 1.080950]\n",
      "[Epoch 8/200] [Batch 721/938] [D loss: 1.121773, acc: 95%] [G loss: 1.052793]\n",
      "[Epoch 8/200] [Batch 722/938] [D loss: 1.055688, acc: 100%] [G loss: 1.104250]\n",
      "[Epoch 8/200] [Batch 723/938] [D loss: 1.117137, acc: 98%] [G loss: 1.068743]\n",
      "[Epoch 8/200] [Batch 724/938] [D loss: 1.050743, acc: 96%] [G loss: 1.109133]\n",
      "[Epoch 8/200] [Batch 725/938] [D loss: 1.047816, acc: 96%] [G loss: 1.083187]\n",
      "[Epoch 8/200] [Batch 726/938] [D loss: 1.076336, acc: 98%] [G loss: 1.118716]\n",
      "[Epoch 8/200] [Batch 727/938] [D loss: 1.050679, acc: 99%] [G loss: 1.088487]\n",
      "[Epoch 8/200] [Batch 728/938] [D loss: 1.068303, acc: 96%] [G loss: 1.114716]\n",
      "[Epoch 8/200] [Batch 729/938] [D loss: 1.042225, acc: 96%] [G loss: 1.092812]\n",
      "[Epoch 8/200] [Batch 730/938] [D loss: 1.087753, acc: 97%] [G loss: 1.107786]\n",
      "[Epoch 8/200] [Batch 731/938] [D loss: 1.107332, acc: 97%] [G loss: 1.059449]\n",
      "[Epoch 8/200] [Batch 732/938] [D loss: 1.083196, acc: 96%] [G loss: 1.109317]\n",
      "[Epoch 8/200] [Batch 733/938] [D loss: 1.101712, acc: 96%] [G loss: 1.154304]\n",
      "[Epoch 8/200] [Batch 734/938] [D loss: 1.099983, acc: 98%] [G loss: 1.115573]\n",
      "[Epoch 8/200] [Batch 735/938] [D loss: 1.093575, acc: 96%] [G loss: 1.045605]\n",
      "[Epoch 8/200] [Batch 736/938] [D loss: 1.057895, acc: 98%] [G loss: 1.048429]\n",
      "[Epoch 8/200] [Batch 737/938] [D loss: 1.102001, acc: 99%] [G loss: 1.117769]\n",
      "[Epoch 8/200] [Batch 738/938] [D loss: 1.081918, acc: 96%] [G loss: 1.080346]\n",
      "[Epoch 8/200] [Batch 739/938] [D loss: 1.108202, acc: 95%] [G loss: 1.116484]\n",
      "[Epoch 8/200] [Batch 740/938] [D loss: 1.077492, acc: 97%] [G loss: 1.111015]\n",
      "[Epoch 8/200] [Batch 741/938] [D loss: 1.098255, acc: 96%] [G loss: 1.097211]\n",
      "[Epoch 8/200] [Batch 742/938] [D loss: 1.079415, acc: 98%] [G loss: 1.045368]\n",
      "[Epoch 8/200] [Batch 743/938] [D loss: 1.113544, acc: 96%] [G loss: 1.085800]\n",
      "[Epoch 8/200] [Batch 744/938] [D loss: 1.092134, acc: 92%] [G loss: 1.134429]\n",
      "[Epoch 8/200] [Batch 745/938] [D loss: 1.077875, acc: 97%] [G loss: 1.105596]\n",
      "[Epoch 8/200] [Batch 746/938] [D loss: 1.098981, acc: 96%] [G loss: 1.072577]\n",
      "[Epoch 8/200] [Batch 747/938] [D loss: 1.078042, acc: 97%] [G loss: 1.123599]\n",
      "[Epoch 8/200] [Batch 748/938] [D loss: 1.082467, acc: 99%] [G loss: 1.109993]\n",
      "[Epoch 8/200] [Batch 749/938] [D loss: 1.090489, acc: 96%] [G loss: 1.159366]\n",
      "[Epoch 8/200] [Batch 750/938] [D loss: 1.112758, acc: 96%] [G loss: 1.154769]\n",
      "[Epoch 8/200] [Batch 751/938] [D loss: 1.086331, acc: 96%] [G loss: 1.111300]\n",
      "[Epoch 8/200] [Batch 752/938] [D loss: 1.139990, acc: 94%] [G loss: 1.031851]\n",
      "[Epoch 8/200] [Batch 753/938] [D loss: 1.071247, acc: 96%] [G loss: 1.117051]\n",
      "[Epoch 8/200] [Batch 754/938] [D loss: 1.099487, acc: 95%] [G loss: 1.179790]\n",
      "[Epoch 8/200] [Batch 755/938] [D loss: 1.089244, acc: 98%] [G loss: 1.129098]\n",
      "[Epoch 8/200] [Batch 756/938] [D loss: 1.105156, acc: 96%] [G loss: 1.084309]\n",
      "[Epoch 8/200] [Batch 757/938] [D loss: 1.116877, acc: 95%] [G loss: 1.105219]\n",
      "[Epoch 8/200] [Batch 758/938] [D loss: 1.102282, acc: 94%] [G loss: 1.113025]\n",
      "[Epoch 8/200] [Batch 759/938] [D loss: 1.079267, acc: 97%] [G loss: 1.088382]\n",
      "[Epoch 8/200] [Batch 760/938] [D loss: 1.086161, acc: 97%] [G loss: 1.149099]\n",
      "[Epoch 8/200] [Batch 761/938] [D loss: 1.084905, acc: 96%] [G loss: 1.140986]\n",
      "[Epoch 8/200] [Batch 762/938] [D loss: 1.070503, acc: 96%] [G loss: 1.129353]\n",
      "[Epoch 8/200] [Batch 763/938] [D loss: 1.077655, acc: 97%] [G loss: 1.142357]\n",
      "[Epoch 8/200] [Batch 764/938] [D loss: 1.098037, acc: 99%] [G loss: 1.061737]\n",
      "[Epoch 8/200] [Batch 765/938] [D loss: 1.068899, acc: 99%] [G loss: 1.138539]\n",
      "[Epoch 8/200] [Batch 766/938] [D loss: 1.097026, acc: 97%] [G loss: 1.073207]\n",
      "[Epoch 8/200] [Batch 767/938] [D loss: 1.117006, acc: 92%] [G loss: 1.109516]\n",
      "[Epoch 8/200] [Batch 768/938] [D loss: 1.054337, acc: 96%] [G loss: 1.140511]\n",
      "[Epoch 8/200] [Batch 769/938] [D loss: 1.071303, acc: 99%] [G loss: 1.133007]\n",
      "[Epoch 8/200] [Batch 770/938] [D loss: 1.081826, acc: 96%] [G loss: 1.127691]\n",
      "[Epoch 8/200] [Batch 771/938] [D loss: 1.065020, acc: 96%] [G loss: 1.125087]\n",
      "[Epoch 8/200] [Batch 772/938] [D loss: 1.071172, acc: 98%] [G loss: 1.127790]\n",
      "[Epoch 8/200] [Batch 773/938] [D loss: 1.098229, acc: 97%] [G loss: 1.075860]\n",
      "[Epoch 8/200] [Batch 774/938] [D loss: 1.098723, acc: 93%] [G loss: 1.094787]\n",
      "[Epoch 8/200] [Batch 775/938] [D loss: 1.111027, acc: 96%] [G loss: 1.162594]\n",
      "[Epoch 8/200] [Batch 776/938] [D loss: 1.090585, acc: 96%] [G loss: 1.066683]\n",
      "[Epoch 8/200] [Batch 777/938] [D loss: 1.092211, acc: 96%] [G loss: 1.094796]\n",
      "[Epoch 8/200] [Batch 778/938] [D loss: 1.082216, acc: 96%] [G loss: 1.098979]\n",
      "[Epoch 8/200] [Batch 779/938] [D loss: 1.061730, acc: 96%] [G loss: 1.114218]\n",
      "[Epoch 8/200] [Batch 780/938] [D loss: 1.102291, acc: 96%] [G loss: 1.142486]\n",
      "[Epoch 8/200] [Batch 781/938] [D loss: 1.082628, acc: 96%] [G loss: 1.097639]\n",
      "[Epoch 8/200] [Batch 782/938] [D loss: 1.100549, acc: 94%] [G loss: 1.121809]\n",
      "[Epoch 8/200] [Batch 783/938] [D loss: 1.091357, acc: 95%] [G loss: 1.082924]\n",
      "[Epoch 8/200] [Batch 784/938] [D loss: 1.128905, acc: 94%] [G loss: 1.087221]\n",
      "[Epoch 8/200] [Batch 785/938] [D loss: 1.096390, acc: 96%] [G loss: 1.111696]\n",
      "[Epoch 8/200] [Batch 786/938] [D loss: 1.082733, acc: 97%] [G loss: 1.124793]\n",
      "[Epoch 8/200] [Batch 787/938] [D loss: 1.068476, acc: 98%] [G loss: 1.127799]\n",
      "[Epoch 8/200] [Batch 788/938] [D loss: 1.057516, acc: 96%] [G loss: 1.108283]\n",
      "[Epoch 8/200] [Batch 789/938] [D loss: 1.091151, acc: 96%] [G loss: 1.158977]\n",
      "[Epoch 8/200] [Batch 790/938] [D loss: 1.095111, acc: 95%] [G loss: 1.083705]\n",
      "[Epoch 8/200] [Batch 791/938] [D loss: 1.055490, acc: 97%] [G loss: 1.077723]\n",
      "[Epoch 8/200] [Batch 792/938] [D loss: 1.113756, acc: 96%] [G loss: 1.106294]\n",
      "[Epoch 8/200] [Batch 793/938] [D loss: 1.069515, acc: 98%] [G loss: 1.154502]\n",
      "[Epoch 8/200] [Batch 794/938] [D loss: 1.095584, acc: 95%] [G loss: 1.105083]\n",
      "[Epoch 8/200] [Batch 795/938] [D loss: 1.087928, acc: 93%] [G loss: 1.135401]\n",
      "[Epoch 8/200] [Batch 796/938] [D loss: 1.115248, acc: 92%] [G loss: 1.104472]\n",
      "[Epoch 8/200] [Batch 797/938] [D loss: 1.084767, acc: 95%] [G loss: 1.110562]\n",
      "[Epoch 8/200] [Batch 798/938] [D loss: 1.099805, acc: 96%] [G loss: 1.155521]\n",
      "[Epoch 8/200] [Batch 799/938] [D loss: 1.099140, acc: 96%] [G loss: 1.111945]\n",
      "[Epoch 8/200] [Batch 800/938] [D loss: 1.080090, acc: 93%] [G loss: 1.132590]\n",
      "[Epoch 8/200] [Batch 801/938] [D loss: 1.069643, acc: 98%] [G loss: 1.077762]\n",
      "[Epoch 8/200] [Batch 802/938] [D loss: 1.088990, acc: 96%] [G loss: 1.087623]\n",
      "[Epoch 8/200] [Batch 803/938] [D loss: 1.073887, acc: 98%] [G loss: 1.101515]\n",
      "[Epoch 8/200] [Batch 804/938] [D loss: 1.067422, acc: 97%] [G loss: 1.157778]\n",
      "[Epoch 8/200] [Batch 805/938] [D loss: 1.072813, acc: 98%] [G loss: 1.142715]\n",
      "[Epoch 8/200] [Batch 806/938] [D loss: 1.068309, acc: 93%] [G loss: 1.108966]\n",
      "[Epoch 8/200] [Batch 807/938] [D loss: 1.087134, acc: 99%] [G loss: 1.051898]\n",
      "[Epoch 8/200] [Batch 808/938] [D loss: 1.076527, acc: 96%] [G loss: 1.097056]\n",
      "[Epoch 8/200] [Batch 809/938] [D loss: 1.110219, acc: 96%] [G loss: 1.141511]\n",
      "[Epoch 8/200] [Batch 810/938] [D loss: 1.112162, acc: 97%] [G loss: 1.143966]\n",
      "[Epoch 8/200] [Batch 811/938] [D loss: 1.096841, acc: 96%] [G loss: 1.064849]\n",
      "[Epoch 8/200] [Batch 812/938] [D loss: 1.087735, acc: 94%] [G loss: 1.123183]\n",
      "[Epoch 8/200] [Batch 813/938] [D loss: 1.102512, acc: 94%] [G loss: 1.050829]\n",
      "[Epoch 8/200] [Batch 814/938] [D loss: 1.117150, acc: 95%] [G loss: 1.149986]\n",
      "[Epoch 8/200] [Batch 815/938] [D loss: 1.107001, acc: 97%] [G loss: 1.094200]\n",
      "[Epoch 8/200] [Batch 816/938] [D loss: 1.084858, acc: 99%] [G loss: 1.155347]\n",
      "[Epoch 8/200] [Batch 817/938] [D loss: 1.081178, acc: 98%] [G loss: 1.139049]\n",
      "[Epoch 8/200] [Batch 818/938] [D loss: 1.091523, acc: 96%] [G loss: 1.057205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 819/938] [D loss: 1.097408, acc: 94%] [G loss: 1.077902]\n",
      "[Epoch 8/200] [Batch 820/938] [D loss: 1.122633, acc: 98%] [G loss: 1.084612]\n",
      "[Epoch 8/200] [Batch 821/938] [D loss: 1.065452, acc: 97%] [G loss: 1.134288]\n",
      "[Epoch 8/200] [Batch 822/938] [D loss: 1.080829, acc: 95%] [G loss: 1.090633]\n",
      "[Epoch 8/200] [Batch 823/938] [D loss: 1.076254, acc: 97%] [G loss: 1.104088]\n",
      "[Epoch 8/200] [Batch 824/938] [D loss: 1.105811, acc: 97%] [G loss: 1.094408]\n",
      "[Epoch 8/200] [Batch 825/938] [D loss: 1.089310, acc: 97%] [G loss: 1.078633]\n",
      "[Epoch 8/200] [Batch 826/938] [D loss: 1.113207, acc: 97%] [G loss: 1.081893]\n",
      "[Epoch 8/200] [Batch 827/938] [D loss: 1.073242, acc: 96%] [G loss: 1.115092]\n",
      "[Epoch 8/200] [Batch 828/938] [D loss: 1.096198, acc: 96%] [G loss: 1.041844]\n",
      "[Epoch 8/200] [Batch 829/938] [D loss: 1.083134, acc: 96%] [G loss: 1.115145]\n",
      "[Epoch 8/200] [Batch 830/938] [D loss: 1.061314, acc: 97%] [G loss: 1.110334]\n",
      "[Epoch 8/200] [Batch 831/938] [D loss: 1.100965, acc: 95%] [G loss: 1.082720]\n",
      "[Epoch 8/200] [Batch 832/938] [D loss: 1.121620, acc: 95%] [G loss: 1.072026]\n",
      "[Epoch 8/200] [Batch 833/938] [D loss: 1.127717, acc: 98%] [G loss: 1.107449]\n",
      "[Epoch 8/200] [Batch 834/938] [D loss: 1.082719, acc: 98%] [G loss: 1.114761]\n",
      "[Epoch 8/200] [Batch 835/938] [D loss: 1.077204, acc: 99%] [G loss: 1.069848]\n",
      "[Epoch 8/200] [Batch 836/938] [D loss: 1.096516, acc: 93%] [G loss: 1.107091]\n",
      "[Epoch 8/200] [Batch 837/938] [D loss: 1.087266, acc: 96%] [G loss: 1.146910]\n",
      "[Epoch 8/200] [Batch 838/938] [D loss: 1.112488, acc: 95%] [G loss: 1.136467]\n",
      "[Epoch 8/200] [Batch 839/938] [D loss: 1.059106, acc: 97%] [G loss: 1.116070]\n",
      "[Epoch 8/200] [Batch 840/938] [D loss: 1.072402, acc: 97%] [G loss: 1.152954]\n",
      "[Epoch 8/200] [Batch 841/938] [D loss: 1.090997, acc: 96%] [G loss: 1.104624]\n",
      "[Epoch 8/200] [Batch 842/938] [D loss: 1.124245, acc: 91%] [G loss: 1.095738]\n",
      "[Epoch 8/200] [Batch 843/938] [D loss: 1.084375, acc: 97%] [G loss: 1.081083]\n",
      "[Epoch 8/200] [Batch 844/938] [D loss: 1.092883, acc: 98%] [G loss: 1.114189]\n",
      "[Epoch 8/200] [Batch 845/938] [D loss: 1.090819, acc: 98%] [G loss: 1.097849]\n",
      "[Epoch 8/200] [Batch 846/938] [D loss: 1.126536, acc: 92%] [G loss: 1.115599]\n",
      "[Epoch 8/200] [Batch 847/938] [D loss: 1.074554, acc: 99%] [G loss: 1.045944]\n",
      "[Epoch 8/200] [Batch 848/938] [D loss: 1.126120, acc: 92%] [G loss: 1.115309]\n",
      "[Epoch 8/200] [Batch 849/938] [D loss: 1.099739, acc: 96%] [G loss: 1.110182]\n",
      "[Epoch 8/200] [Batch 850/938] [D loss: 1.048910, acc: 96%] [G loss: 1.134099]\n",
      "[Epoch 8/200] [Batch 851/938] [D loss: 1.101168, acc: 97%] [G loss: 1.143365]\n",
      "[Epoch 8/200] [Batch 852/938] [D loss: 1.090991, acc: 97%] [G loss: 1.131938]\n",
      "[Epoch 8/200] [Batch 853/938] [D loss: 1.111412, acc: 98%] [G loss: 1.081658]\n",
      "[Epoch 8/200] [Batch 854/938] [D loss: 1.101191, acc: 98%] [G loss: 1.093018]\n",
      "[Epoch 8/200] [Batch 855/938] [D loss: 1.066204, acc: 94%] [G loss: 1.074755]\n",
      "[Epoch 8/200] [Batch 856/938] [D loss: 1.083517, acc: 97%] [G loss: 1.040510]\n",
      "[Epoch 8/200] [Batch 857/938] [D loss: 1.067340, acc: 96%] [G loss: 1.089847]\n",
      "[Epoch 8/200] [Batch 858/938] [D loss: 1.069628, acc: 94%] [G loss: 1.136238]\n",
      "[Epoch 8/200] [Batch 859/938] [D loss: 1.095649, acc: 96%] [G loss: 1.146861]\n",
      "[Epoch 8/200] [Batch 860/938] [D loss: 1.123874, acc: 94%] [G loss: 1.104711]\n",
      "[Epoch 8/200] [Batch 861/938] [D loss: 1.087343, acc: 96%] [G loss: 1.073517]\n",
      "[Epoch 8/200] [Batch 862/938] [D loss: 1.076110, acc: 96%] [G loss: 1.091975]\n",
      "[Epoch 8/200] [Batch 863/938] [D loss: 1.098620, acc: 94%] [G loss: 1.044386]\n",
      "[Epoch 8/200] [Batch 864/938] [D loss: 1.062292, acc: 99%] [G loss: 1.075312]\n",
      "[Epoch 8/200] [Batch 865/938] [D loss: 1.073602, acc: 97%] [G loss: 1.147959]\n",
      "[Epoch 8/200] [Batch 866/938] [D loss: 1.066049, acc: 95%] [G loss: 1.128706]\n",
      "[Epoch 8/200] [Batch 867/938] [D loss: 1.085125, acc: 97%] [G loss: 1.089024]\n",
      "[Epoch 8/200] [Batch 868/938] [D loss: 1.122037, acc: 98%] [G loss: 1.054180]\n",
      "[Epoch 8/200] [Batch 869/938] [D loss: 1.078355, acc: 99%] [G loss: 1.082761]\n",
      "[Epoch 8/200] [Batch 870/938] [D loss: 1.073327, acc: 96%] [G loss: 1.062547]\n",
      "[Epoch 8/200] [Batch 871/938] [D loss: 1.109114, acc: 96%] [G loss: 1.146105]\n",
      "[Epoch 8/200] [Batch 872/938] [D loss: 1.093284, acc: 94%] [G loss: 1.110270]\n",
      "[Epoch 8/200] [Batch 873/938] [D loss: 1.062725, acc: 96%] [G loss: 1.125302]\n",
      "[Epoch 8/200] [Batch 874/938] [D loss: 1.104440, acc: 95%] [G loss: 1.115077]\n",
      "[Epoch 8/200] [Batch 875/938] [D loss: 1.097395, acc: 96%] [G loss: 1.121575]\n",
      "[Epoch 8/200] [Batch 876/938] [D loss: 1.120893, acc: 95%] [G loss: 1.129346]\n",
      "[Epoch 8/200] [Batch 877/938] [D loss: 1.056311, acc: 98%] [G loss: 1.089897]\n",
      "[Epoch 8/200] [Batch 878/938] [D loss: 1.143385, acc: 95%] [G loss: 1.131474]\n",
      "[Epoch 8/200] [Batch 879/938] [D loss: 1.125501, acc: 93%] [G loss: 1.092444]\n",
      "[Epoch 8/200] [Batch 880/938] [D loss: 1.079704, acc: 96%] [G loss: 1.065728]\n",
      "[Epoch 8/200] [Batch 881/938] [D loss: 1.115872, acc: 96%] [G loss: 1.115473]\n",
      "[Epoch 8/200] [Batch 882/938] [D loss: 1.098861, acc: 95%] [G loss: 1.054995]\n",
      "[Epoch 8/200] [Batch 883/938] [D loss: 1.102056, acc: 97%] [G loss: 1.098559]\n",
      "[Epoch 8/200] [Batch 884/938] [D loss: 1.103538, acc: 95%] [G loss: 1.126493]\n",
      "[Epoch 8/200] [Batch 885/938] [D loss: 1.089249, acc: 96%] [G loss: 1.087642]\n",
      "[Epoch 8/200] [Batch 886/938] [D loss: 1.107049, acc: 97%] [G loss: 1.125608]\n",
      "[Epoch 8/200] [Batch 887/938] [D loss: 1.089907, acc: 94%] [G loss: 1.109985]\n",
      "[Epoch 8/200] [Batch 888/938] [D loss: 1.097846, acc: 96%] [G loss: 1.095603]\n",
      "[Epoch 8/200] [Batch 889/938] [D loss: 1.076178, acc: 96%] [G loss: 1.087325]\n",
      "[Epoch 8/200] [Batch 890/938] [D loss: 1.088575, acc: 93%] [G loss: 1.138772]\n",
      "[Epoch 8/200] [Batch 891/938] [D loss: 1.075881, acc: 97%] [G loss: 1.076949]\n",
      "[Epoch 8/200] [Batch 892/938] [D loss: 1.077335, acc: 97%] [G loss: 1.120786]\n",
      "[Epoch 8/200] [Batch 893/938] [D loss: 1.118223, acc: 94%] [G loss: 1.081619]\n",
      "[Epoch 8/200] [Batch 894/938] [D loss: 1.089910, acc: 96%] [G loss: 1.197861]\n",
      "[Epoch 8/200] [Batch 895/938] [D loss: 1.071354, acc: 95%] [G loss: 1.120402]\n",
      "[Epoch 8/200] [Batch 896/938] [D loss: 1.098671, acc: 96%] [G loss: 1.064265]\n",
      "[Epoch 8/200] [Batch 897/938] [D loss: 1.113291, acc: 96%] [G loss: 1.054518]\n",
      "[Epoch 8/200] [Batch 898/938] [D loss: 1.077889, acc: 97%] [G loss: 1.111501]\n",
      "[Epoch 8/200] [Batch 899/938] [D loss: 1.090745, acc: 96%] [G loss: 1.065814]\n",
      "[Epoch 8/200] [Batch 900/938] [D loss: 1.081296, acc: 95%] [G loss: 1.106543]\n",
      "[Epoch 8/200] [Batch 901/938] [D loss: 1.071676, acc: 95%] [G loss: 1.086890]\n",
      "[Epoch 8/200] [Batch 902/938] [D loss: 1.112266, acc: 95%] [G loss: 1.075066]\n",
      "[Epoch 8/200] [Batch 903/938] [D loss: 1.064756, acc: 97%] [G loss: 1.153507]\n",
      "[Epoch 8/200] [Batch 904/938] [D loss: 1.087767, acc: 98%] [G loss: 1.078333]\n",
      "[Epoch 8/200] [Batch 905/938] [D loss: 1.099599, acc: 99%] [G loss: 1.126789]\n",
      "[Epoch 8/200] [Batch 906/938] [D loss: 1.091622, acc: 98%] [G loss: 1.075024]\n",
      "[Epoch 8/200] [Batch 907/938] [D loss: 1.104206, acc: 97%] [G loss: 1.136426]\n",
      "[Epoch 8/200] [Batch 908/938] [D loss: 1.103398, acc: 96%] [G loss: 1.109761]\n",
      "[Epoch 8/200] [Batch 909/938] [D loss: 1.097759, acc: 96%] [G loss: 1.051494]\n",
      "[Epoch 8/200] [Batch 910/938] [D loss: 1.115390, acc: 97%] [G loss: 1.102575]\n",
      "[Epoch 8/200] [Batch 911/938] [D loss: 1.102907, acc: 95%] [G loss: 1.099211]\n",
      "[Epoch 8/200] [Batch 912/938] [D loss: 1.093472, acc: 96%] [G loss: 1.213678]\n",
      "[Epoch 8/200] [Batch 913/938] [D loss: 1.081529, acc: 95%] [G loss: 1.091914]\n",
      "[Epoch 8/200] [Batch 914/938] [D loss: 1.112280, acc: 92%] [G loss: 1.081869]\n",
      "[Epoch 8/200] [Batch 915/938] [D loss: 1.059976, acc: 95%] [G loss: 1.129290]\n",
      "[Epoch 8/200] [Batch 916/938] [D loss: 1.078321, acc: 99%] [G loss: 1.093764]\n",
      "[Epoch 8/200] [Batch 917/938] [D loss: 1.055904, acc: 97%] [G loss: 1.060359]\n",
      "[Epoch 8/200] [Batch 918/938] [D loss: 1.052477, acc: 96%] [G loss: 1.078109]\n",
      "[Epoch 8/200] [Batch 919/938] [D loss: 1.099098, acc: 95%] [G loss: 1.084203]\n",
      "[Epoch 8/200] [Batch 920/938] [D loss: 1.112404, acc: 96%] [G loss: 1.074662]\n",
      "[Epoch 8/200] [Batch 921/938] [D loss: 1.093376, acc: 98%] [G loss: 1.143738]\n",
      "[Epoch 8/200] [Batch 922/938] [D loss: 1.087240, acc: 94%] [G loss: 1.197252]\n",
      "[Epoch 8/200] [Batch 923/938] [D loss: 1.091328, acc: 97%] [G loss: 1.101582]\n",
      "[Epoch 8/200] [Batch 924/938] [D loss: 1.119502, acc: 97%] [G loss: 1.086428]\n",
      "[Epoch 8/200] [Batch 925/938] [D loss: 1.078316, acc: 97%] [G loss: 1.137305]\n",
      "[Epoch 8/200] [Batch 926/938] [D loss: 1.109172, acc: 98%] [G loss: 1.054523]\n",
      "[Epoch 8/200] [Batch 927/938] [D loss: 1.066305, acc: 98%] [G loss: 1.104466]\n",
      "[Epoch 8/200] [Batch 928/938] [D loss: 1.094469, acc: 97%] [G loss: 1.126841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/200] [Batch 929/938] [D loss: 1.092715, acc: 96%] [G loss: 1.071534]\n",
      "[Epoch 8/200] [Batch 930/938] [D loss: 1.073765, acc: 99%] [G loss: 1.057191]\n",
      "[Epoch 8/200] [Batch 931/938] [D loss: 1.122041, acc: 95%] [G loss: 1.055537]\n",
      "[Epoch 8/200] [Batch 932/938] [D loss: 1.107912, acc: 96%] [G loss: 1.159456]\n",
      "[Epoch 8/200] [Batch 933/938] [D loss: 1.074915, acc: 95%] [G loss: 1.123515]\n",
      "[Epoch 8/200] [Batch 934/938] [D loss: 1.071726, acc: 97%] [G loss: 1.094538]\n",
      "[Epoch 8/200] [Batch 935/938] [D loss: 1.106859, acc: 92%] [G loss: 1.073968]\n",
      "[Epoch 8/200] [Batch 936/938] [D loss: 1.080982, acc: 96%] [G loss: 1.076472]\n",
      "[Epoch 8/200] [Batch 937/938] [D loss: 1.048832, acc: 92%] [G loss: 1.049721]\n",
      "[Epoch 9/200] [Batch 0/938] [D loss: 1.078842, acc: 96%] [G loss: 1.108161]\n",
      "[Epoch 9/200] [Batch 1/938] [D loss: 1.111308, acc: 96%] [G loss: 1.094204]\n",
      "[Epoch 9/200] [Batch 2/938] [D loss: 1.092463, acc: 96%] [G loss: 1.062805]\n",
      "[Epoch 9/200] [Batch 3/938] [D loss: 1.122050, acc: 96%] [G loss: 1.120720]\n",
      "[Epoch 9/200] [Batch 4/938] [D loss: 1.121765, acc: 96%] [G loss: 1.113361]\n",
      "[Epoch 9/200] [Batch 5/938] [D loss: 1.074134, acc: 97%] [G loss: 1.142409]\n",
      "[Epoch 9/200] [Batch 6/938] [D loss: 1.064466, acc: 96%] [G loss: 1.073207]\n",
      "[Epoch 9/200] [Batch 7/938] [D loss: 1.079292, acc: 96%] [G loss: 1.087504]\n",
      "[Epoch 9/200] [Batch 8/938] [D loss: 1.066553, acc: 95%] [G loss: 1.088576]\n",
      "[Epoch 9/200] [Batch 9/938] [D loss: 1.116405, acc: 96%] [G loss: 1.074828]\n",
      "[Epoch 9/200] [Batch 10/938] [D loss: 1.098425, acc: 95%] [G loss: 1.101914]\n",
      "[Epoch 9/200] [Batch 11/938] [D loss: 1.117606, acc: 96%] [G loss: 1.096033]\n",
      "[Epoch 9/200] [Batch 12/938] [D loss: 1.072027, acc: 96%] [G loss: 1.094297]\n",
      "[Epoch 9/200] [Batch 13/938] [D loss: 1.077173, acc: 98%] [G loss: 1.092090]\n",
      "[Epoch 9/200] [Batch 14/938] [D loss: 1.071308, acc: 96%] [G loss: 1.095241]\n",
      "[Epoch 9/200] [Batch 15/938] [D loss: 1.088908, acc: 98%] [G loss: 1.121808]\n",
      "[Epoch 9/200] [Batch 16/938] [D loss: 1.098875, acc: 100%] [G loss: 1.062748]\n",
      "[Epoch 9/200] [Batch 17/938] [D loss: 1.100569, acc: 95%] [G loss: 1.070736]\n",
      "[Epoch 9/200] [Batch 18/938] [D loss: 1.072131, acc: 98%] [G loss: 1.066553]\n",
      "[Epoch 9/200] [Batch 19/938] [D loss: 1.129408, acc: 96%] [G loss: 1.048974]\n",
      "[Epoch 9/200] [Batch 20/938] [D loss: 1.119261, acc: 96%] [G loss: 1.111291]\n",
      "[Epoch 9/200] [Batch 21/938] [D loss: 1.105249, acc: 97%] [G loss: 1.148057]\n",
      "[Epoch 9/200] [Batch 22/938] [D loss: 1.127355, acc: 95%] [G loss: 1.085647]\n",
      "[Epoch 9/200] [Batch 23/938] [D loss: 1.099811, acc: 97%] [G loss: 1.044117]\n",
      "[Epoch 9/200] [Batch 24/938] [D loss: 1.077610, acc: 97%] [G loss: 1.123593]\n",
      "[Epoch 9/200] [Batch 25/938] [D loss: 1.068755, acc: 97%] [G loss: 1.085782]\n",
      "[Epoch 9/200] [Batch 26/938] [D loss: 1.147268, acc: 97%] [G loss: 1.120132]\n",
      "[Epoch 9/200] [Batch 27/938] [D loss: 1.105853, acc: 96%] [G loss: 1.145182]\n",
      "[Epoch 9/200] [Batch 28/938] [D loss: 1.082442, acc: 92%] [G loss: 1.079836]\n",
      "[Epoch 9/200] [Batch 29/938] [D loss: 1.097649, acc: 96%] [G loss: 1.065226]\n",
      "[Epoch 9/200] [Batch 30/938] [D loss: 1.090350, acc: 96%] [G loss: 1.069379]\n",
      "[Epoch 9/200] [Batch 31/938] [D loss: 1.035097, acc: 99%] [G loss: 1.122730]\n",
      "[Epoch 9/200] [Batch 32/938] [D loss: 1.094877, acc: 96%] [G loss: 1.167341]\n",
      "[Epoch 9/200] [Batch 33/938] [D loss: 1.049056, acc: 94%] [G loss: 1.122841]\n",
      "[Epoch 9/200] [Batch 34/938] [D loss: 1.059870, acc: 97%] [G loss: 1.102310]\n",
      "[Epoch 9/200] [Batch 35/938] [D loss: 1.112765, acc: 94%] [G loss: 1.132251]\n",
      "[Epoch 9/200] [Batch 36/938] [D loss: 1.078584, acc: 96%] [G loss: 1.057796]\n",
      "[Epoch 9/200] [Batch 37/938] [D loss: 1.093624, acc: 96%] [G loss: 1.074400]\n",
      "[Epoch 9/200] [Batch 38/938] [D loss: 1.079107, acc: 98%] [G loss: 1.085892]\n",
      "[Epoch 9/200] [Batch 39/938] [D loss: 1.092474, acc: 96%] [G loss: 1.091090]\n",
      "[Epoch 9/200] [Batch 40/938] [D loss: 1.104535, acc: 95%] [G loss: 1.100310]\n",
      "[Epoch 9/200] [Batch 41/938] [D loss: 1.035688, acc: 98%] [G loss: 1.119742]\n",
      "[Epoch 9/200] [Batch 42/938] [D loss: 1.082148, acc: 97%] [G loss: 1.102594]\n",
      "[Epoch 9/200] [Batch 43/938] [D loss: 1.082211, acc: 99%] [G loss: 1.117386]\n",
      "[Epoch 9/200] [Batch 44/938] [D loss: 1.087379, acc: 97%] [G loss: 1.138866]\n",
      "[Epoch 9/200] [Batch 45/938] [D loss: 1.116269, acc: 95%] [G loss: 1.083905]\n",
      "[Epoch 9/200] [Batch 46/938] [D loss: 1.112540, acc: 96%] [G loss: 1.142751]\n",
      "[Epoch 9/200] [Batch 47/938] [D loss: 1.087559, acc: 97%] [G loss: 1.102359]\n",
      "[Epoch 9/200] [Batch 48/938] [D loss: 1.071150, acc: 95%] [G loss: 1.085982]\n",
      "[Epoch 9/200] [Batch 49/938] [D loss: 1.114369, acc: 97%] [G loss: 1.077138]\n",
      "[Epoch 9/200] [Batch 50/938] [D loss: 1.096875, acc: 96%] [G loss: 1.067979]\n",
      "[Epoch 9/200] [Batch 51/938] [D loss: 1.067199, acc: 96%] [G loss: 1.098896]\n",
      "[Epoch 9/200] [Batch 52/938] [D loss: 1.054868, acc: 97%] [G loss: 1.121324]\n",
      "[Epoch 9/200] [Batch 53/938] [D loss: 1.093326, acc: 98%] [G loss: 1.104451]\n",
      "[Epoch 9/200] [Batch 54/938] [D loss: 1.061938, acc: 98%] [G loss: 1.109849]\n",
      "[Epoch 9/200] [Batch 55/938] [D loss: 1.122034, acc: 96%] [G loss: 1.049768]\n",
      "[Epoch 9/200] [Batch 56/938] [D loss: 1.095743, acc: 97%] [G loss: 1.088631]\n",
      "[Epoch 9/200] [Batch 57/938] [D loss: 1.068007, acc: 97%] [G loss: 1.111160]\n",
      "[Epoch 9/200] [Batch 58/938] [D loss: 1.090763, acc: 94%] [G loss: 1.108544]\n",
      "[Epoch 9/200] [Batch 59/938] [D loss: 1.049705, acc: 97%] [G loss: 1.096874]\n",
      "[Epoch 9/200] [Batch 60/938] [D loss: 1.074630, acc: 96%] [G loss: 1.124074]\n",
      "[Epoch 9/200] [Batch 61/938] [D loss: 1.091334, acc: 97%] [G loss: 1.114637]\n",
      "[Epoch 9/200] [Batch 62/938] [D loss: 1.081279, acc: 96%] [G loss: 1.058742]\n",
      "[Epoch 9/200] [Batch 63/938] [D loss: 1.113177, acc: 94%] [G loss: 1.061291]\n",
      "[Epoch 9/200] [Batch 64/938] [D loss: 1.094545, acc: 98%] [G loss: 1.092563]\n",
      "[Epoch 9/200] [Batch 65/938] [D loss: 1.070058, acc: 96%] [G loss: 1.154299]\n",
      "[Epoch 9/200] [Batch 66/938] [D loss: 1.112900, acc: 96%] [G loss: 1.083582]\n",
      "[Epoch 9/200] [Batch 67/938] [D loss: 1.089072, acc: 96%] [G loss: 1.063759]\n",
      "[Epoch 9/200] [Batch 68/938] [D loss: 1.087100, acc: 97%] [G loss: 1.090352]\n",
      "[Epoch 9/200] [Batch 69/938] [D loss: 1.091438, acc: 95%] [G loss: 1.143681]\n",
      "[Epoch 9/200] [Batch 70/938] [D loss: 1.088429, acc: 97%] [G loss: 1.064637]\n",
      "[Epoch 9/200] [Batch 71/938] [D loss: 1.101438, acc: 93%] [G loss: 1.143460]\n",
      "[Epoch 9/200] [Batch 72/938] [D loss: 1.104505, acc: 96%] [G loss: 1.162817]\n",
      "[Epoch 9/200] [Batch 73/938] [D loss: 1.083535, acc: 96%] [G loss: 1.106776]\n",
      "[Epoch 9/200] [Batch 74/938] [D loss: 1.083239, acc: 95%] [G loss: 1.132810]\n",
      "[Epoch 9/200] [Batch 75/938] [D loss: 1.071013, acc: 95%] [G loss: 1.132279]\n",
      "[Epoch 9/200] [Batch 76/938] [D loss: 1.083652, acc: 96%] [G loss: 1.106199]\n",
      "[Epoch 9/200] [Batch 77/938] [D loss: 1.057559, acc: 96%] [G loss: 1.073426]\n",
      "[Epoch 9/200] [Batch 78/938] [D loss: 1.105060, acc: 98%] [G loss: 1.061969]\n",
      "[Epoch 9/200] [Batch 79/938] [D loss: 1.106786, acc: 96%] [G loss: 1.101129]\n",
      "[Epoch 9/200] [Batch 80/938] [D loss: 1.111532, acc: 96%] [G loss: 1.106582]\n",
      "[Epoch 9/200] [Batch 81/938] [D loss: 1.076169, acc: 96%] [G loss: 1.110016]\n",
      "[Epoch 9/200] [Batch 82/938] [D loss: 1.068923, acc: 97%] [G loss: 1.122687]\n",
      "[Epoch 9/200] [Batch 83/938] [D loss: 1.059527, acc: 98%] [G loss: 1.099449]\n",
      "[Epoch 9/200] [Batch 84/938] [D loss: 1.090844, acc: 98%] [G loss: 1.082427]\n",
      "[Epoch 9/200] [Batch 85/938] [D loss: 1.091515, acc: 96%] [G loss: 1.087790]\n",
      "[Epoch 9/200] [Batch 86/938] [D loss: 1.074667, acc: 96%] [G loss: 1.121789]\n",
      "[Epoch 9/200] [Batch 87/938] [D loss: 1.049071, acc: 97%] [G loss: 1.104950]\n",
      "[Epoch 9/200] [Batch 88/938] [D loss: 1.112894, acc: 94%] [G loss: 1.114161]\n",
      "[Epoch 9/200] [Batch 89/938] [D loss: 1.094931, acc: 95%] [G loss: 1.137116]\n",
      "[Epoch 9/200] [Batch 90/938] [D loss: 1.084663, acc: 98%] [G loss: 1.120728]\n",
      "[Epoch 9/200] [Batch 91/938] [D loss: 1.101880, acc: 97%] [G loss: 1.104852]\n",
      "[Epoch 9/200] [Batch 92/938] [D loss: 1.097008, acc: 95%] [G loss: 1.203708]\n",
      "[Epoch 9/200] [Batch 93/938] [D loss: 1.060533, acc: 96%] [G loss: 1.089297]\n",
      "[Epoch 9/200] [Batch 94/938] [D loss: 1.071228, acc: 100%] [G loss: 1.123639]\n",
      "[Epoch 9/200] [Batch 95/938] [D loss: 1.130186, acc: 96%] [G loss: 1.089380]\n",
      "[Epoch 9/200] [Batch 96/938] [D loss: 1.116123, acc: 91%] [G loss: 1.134307]\n",
      "[Epoch 9/200] [Batch 97/938] [D loss: 1.085253, acc: 94%] [G loss: 1.098890]\n",
      "[Epoch 9/200] [Batch 98/938] [D loss: 1.081926, acc: 96%] [G loss: 1.106129]\n",
      "[Epoch 9/200] [Batch 99/938] [D loss: 1.108824, acc: 96%] [G loss: 1.159476]\n",
      "[Epoch 9/200] [Batch 100/938] [D loss: 1.080090, acc: 99%] [G loss: 1.077286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 101/938] [D loss: 1.088243, acc: 96%] [G loss: 1.053071]\n",
      "[Epoch 9/200] [Batch 102/938] [D loss: 1.107103, acc: 95%] [G loss: 1.100469]\n",
      "[Epoch 9/200] [Batch 103/938] [D loss: 1.067894, acc: 96%] [G loss: 1.123281]\n",
      "[Epoch 9/200] [Batch 104/938] [D loss: 1.084931, acc: 97%] [G loss: 1.096444]\n",
      "[Epoch 9/200] [Batch 105/938] [D loss: 1.094676, acc: 98%] [G loss: 1.153758]\n",
      "[Epoch 9/200] [Batch 106/938] [D loss: 1.089485, acc: 96%] [G loss: 1.127700]\n",
      "[Epoch 9/200] [Batch 107/938] [D loss: 1.150892, acc: 97%] [G loss: 1.109011]\n",
      "[Epoch 9/200] [Batch 108/938] [D loss: 1.102617, acc: 95%] [G loss: 1.100997]\n",
      "[Epoch 9/200] [Batch 109/938] [D loss: 1.092821, acc: 99%] [G loss: 1.041244]\n",
      "[Epoch 9/200] [Batch 110/938] [D loss: 1.072225, acc: 96%] [G loss: 1.094471]\n",
      "[Epoch 9/200] [Batch 111/938] [D loss: 1.068772, acc: 98%] [G loss: 1.093387]\n",
      "[Epoch 9/200] [Batch 112/938] [D loss: 1.097300, acc: 92%] [G loss: 1.128276]\n",
      "[Epoch 9/200] [Batch 113/938] [D loss: 1.095329, acc: 98%] [G loss: 1.055999]\n",
      "[Epoch 9/200] [Batch 114/938] [D loss: 1.094488, acc: 96%] [G loss: 1.100806]\n",
      "[Epoch 9/200] [Batch 115/938] [D loss: 1.126966, acc: 95%] [G loss: 1.102201]\n",
      "[Epoch 9/200] [Batch 116/938] [D loss: 1.081444, acc: 98%] [G loss: 1.103661]\n",
      "[Epoch 9/200] [Batch 117/938] [D loss: 1.035851, acc: 99%] [G loss: 1.107464]\n",
      "[Epoch 9/200] [Batch 118/938] [D loss: 1.105623, acc: 95%] [G loss: 1.049969]\n",
      "[Epoch 9/200] [Batch 119/938] [D loss: 1.101815, acc: 97%] [G loss: 1.062603]\n",
      "[Epoch 9/200] [Batch 120/938] [D loss: 1.108497, acc: 96%] [G loss: 1.132599]\n",
      "[Epoch 9/200] [Batch 121/938] [D loss: 1.080371, acc: 96%] [G loss: 1.102470]\n",
      "[Epoch 9/200] [Batch 122/938] [D loss: 1.096842, acc: 96%] [G loss: 1.101254]\n",
      "[Epoch 9/200] [Batch 123/938] [D loss: 1.104941, acc: 97%] [G loss: 1.132674]\n",
      "[Epoch 9/200] [Batch 124/938] [D loss: 1.090830, acc: 96%] [G loss: 1.092238]\n",
      "[Epoch 9/200] [Batch 125/938] [D loss: 1.085460, acc: 97%] [G loss: 1.108440]\n",
      "[Epoch 9/200] [Batch 126/938] [D loss: 1.080060, acc: 93%] [G loss: 1.102650]\n",
      "[Epoch 9/200] [Batch 127/938] [D loss: 1.084399, acc: 96%] [G loss: 1.064713]\n",
      "[Epoch 9/200] [Batch 128/938] [D loss: 1.137370, acc: 96%] [G loss: 1.094935]\n",
      "[Epoch 9/200] [Batch 129/938] [D loss: 1.062439, acc: 98%] [G loss: 1.062003]\n",
      "[Epoch 9/200] [Batch 130/938] [D loss: 1.151860, acc: 94%] [G loss: 1.141193]\n",
      "[Epoch 9/200] [Batch 131/938] [D loss: 1.060847, acc: 95%] [G loss: 1.108717]\n",
      "[Epoch 9/200] [Batch 132/938] [D loss: 1.055091, acc: 98%] [G loss: 1.063594]\n",
      "[Epoch 9/200] [Batch 133/938] [D loss: 1.086037, acc: 97%] [G loss: 1.125617]\n",
      "[Epoch 9/200] [Batch 134/938] [D loss: 1.096989, acc: 96%] [G loss: 1.053861]\n",
      "[Epoch 9/200] [Batch 135/938] [D loss: 1.082712, acc: 99%] [G loss: 1.115377]\n",
      "[Epoch 9/200] [Batch 136/938] [D loss: 1.069692, acc: 95%] [G loss: 1.137054]\n",
      "[Epoch 9/200] [Batch 137/938] [D loss: 1.069294, acc: 98%] [G loss: 1.045723]\n",
      "[Epoch 9/200] [Batch 138/938] [D loss: 1.079551, acc: 97%] [G loss: 1.075155]\n",
      "[Epoch 9/200] [Batch 139/938] [D loss: 1.098583, acc: 96%] [G loss: 1.044509]\n",
      "[Epoch 9/200] [Batch 140/938] [D loss: 1.103150, acc: 98%] [G loss: 1.069312]\n",
      "[Epoch 9/200] [Batch 141/938] [D loss: 1.117772, acc: 96%] [G loss: 1.120531]\n",
      "[Epoch 9/200] [Batch 142/938] [D loss: 1.085055, acc: 95%] [G loss: 1.169093]\n",
      "[Epoch 9/200] [Batch 143/938] [D loss: 1.088832, acc: 98%] [G loss: 1.175606]\n",
      "[Epoch 9/200] [Batch 144/938] [D loss: 1.098188, acc: 96%] [G loss: 1.171297]\n",
      "[Epoch 9/200] [Batch 145/938] [D loss: 1.113641, acc: 98%] [G loss: 1.048977]\n",
      "[Epoch 9/200] [Batch 146/938] [D loss: 1.099904, acc: 94%] [G loss: 1.136111]\n",
      "[Epoch 9/200] [Batch 147/938] [D loss: 1.093328, acc: 99%] [G loss: 1.117503]\n",
      "[Epoch 9/200] [Batch 148/938] [D loss: 1.073171, acc: 98%] [G loss: 1.081765]\n",
      "[Epoch 9/200] [Batch 149/938] [D loss: 1.093542, acc: 98%] [G loss: 1.110459]\n",
      "[Epoch 9/200] [Batch 150/938] [D loss: 1.106825, acc: 97%] [G loss: 1.164811]\n",
      "[Epoch 9/200] [Batch 151/938] [D loss: 1.094935, acc: 96%] [G loss: 1.072987]\n",
      "[Epoch 9/200] [Batch 152/938] [D loss: 1.110263, acc: 96%] [G loss: 1.092573]\n",
      "[Epoch 9/200] [Batch 153/938] [D loss: 1.077935, acc: 99%] [G loss: 1.063284]\n",
      "[Epoch 9/200] [Batch 154/938] [D loss: 1.118065, acc: 96%] [G loss: 1.077068]\n",
      "[Epoch 9/200] [Batch 155/938] [D loss: 1.121337, acc: 92%] [G loss: 1.049092]\n",
      "[Epoch 9/200] [Batch 156/938] [D loss: 1.082079, acc: 96%] [G loss: 1.074013]\n",
      "[Epoch 9/200] [Batch 157/938] [D loss: 1.064488, acc: 97%] [G loss: 1.105843]\n",
      "[Epoch 9/200] [Batch 158/938] [D loss: 1.078365, acc: 98%] [G loss: 1.178170]\n",
      "[Epoch 9/200] [Batch 159/938] [D loss: 1.077806, acc: 96%] [G loss: 1.058288]\n",
      "[Epoch 9/200] [Batch 160/938] [D loss: 1.066690, acc: 96%] [G loss: 1.070983]\n",
      "[Epoch 9/200] [Batch 161/938] [D loss: 1.089524, acc: 97%] [G loss: 1.084629]\n",
      "[Epoch 9/200] [Batch 162/938] [D loss: 1.088971, acc: 99%] [G loss: 1.173736]\n",
      "[Epoch 9/200] [Batch 163/938] [D loss: 1.066300, acc: 96%] [G loss: 1.124846]\n",
      "[Epoch 9/200] [Batch 164/938] [D loss: 1.110495, acc: 99%] [G loss: 1.140490]\n",
      "[Epoch 9/200] [Batch 165/938] [D loss: 1.082126, acc: 96%] [G loss: 1.091472]\n",
      "[Epoch 9/200] [Batch 166/938] [D loss: 1.075811, acc: 100%] [G loss: 1.069812]\n",
      "[Epoch 9/200] [Batch 167/938] [D loss: 1.089618, acc: 96%] [G loss: 1.123876]\n",
      "[Epoch 9/200] [Batch 168/938] [D loss: 1.117349, acc: 96%] [G loss: 1.070674]\n",
      "[Epoch 9/200] [Batch 169/938] [D loss: 1.078476, acc: 100%] [G loss: 1.153268]\n",
      "[Epoch 9/200] [Batch 170/938] [D loss: 1.134525, acc: 93%] [G loss: 1.033217]\n",
      "[Epoch 9/200] [Batch 171/938] [D loss: 1.088620, acc: 96%] [G loss: 1.084406]\n",
      "[Epoch 9/200] [Batch 172/938] [D loss: 1.087736, acc: 94%] [G loss: 1.086358]\n",
      "[Epoch 9/200] [Batch 173/938] [D loss: 1.104702, acc: 97%] [G loss: 1.101386]\n",
      "[Epoch 9/200] [Batch 174/938] [D loss: 1.072180, acc: 98%] [G loss: 1.138253]\n",
      "[Epoch 9/200] [Batch 175/938] [D loss: 1.072452, acc: 95%] [G loss: 1.134215]\n",
      "[Epoch 9/200] [Batch 176/938] [D loss: 1.081330, acc: 96%] [G loss: 1.094844]\n",
      "[Epoch 9/200] [Batch 177/938] [D loss: 1.080193, acc: 97%] [G loss: 1.080248]\n",
      "[Epoch 9/200] [Batch 178/938] [D loss: 1.062597, acc: 98%] [G loss: 1.105208]\n",
      "[Epoch 9/200] [Batch 179/938] [D loss: 1.065951, acc: 99%] [G loss: 1.157289]\n",
      "[Epoch 9/200] [Batch 180/938] [D loss: 1.081254, acc: 96%] [G loss: 1.153222]\n",
      "[Epoch 9/200] [Batch 181/938] [D loss: 1.097515, acc: 96%] [G loss: 1.108728]\n",
      "[Epoch 9/200] [Batch 182/938] [D loss: 1.086020, acc: 97%] [G loss: 1.079751]\n",
      "[Epoch 9/200] [Batch 183/938] [D loss: 1.118090, acc: 97%] [G loss: 1.071321]\n",
      "[Epoch 9/200] [Batch 184/938] [D loss: 1.094205, acc: 94%] [G loss: 1.111828]\n",
      "[Epoch 9/200] [Batch 185/938] [D loss: 1.068247, acc: 97%] [G loss: 1.154378]\n",
      "[Epoch 9/200] [Batch 186/938] [D loss: 1.115625, acc: 96%] [G loss: 1.126677]\n",
      "[Epoch 9/200] [Batch 187/938] [D loss: 1.071147, acc: 98%] [G loss: 1.141055]\n",
      "[Epoch 9/200] [Batch 188/938] [D loss: 1.066540, acc: 96%] [G loss: 1.098069]\n",
      "[Epoch 9/200] [Batch 189/938] [D loss: 1.077778, acc: 96%] [G loss: 1.040081]\n",
      "[Epoch 9/200] [Batch 190/938] [D loss: 1.092597, acc: 93%] [G loss: 1.106724]\n",
      "[Epoch 9/200] [Batch 191/938] [D loss: 1.081267, acc: 97%] [G loss: 1.108313]\n",
      "[Epoch 9/200] [Batch 192/938] [D loss: 1.100423, acc: 97%] [G loss: 1.071310]\n",
      "[Epoch 9/200] [Batch 193/938] [D loss: 1.100597, acc: 95%] [G loss: 1.113756]\n",
      "[Epoch 9/200] [Batch 194/938] [D loss: 1.124075, acc: 92%] [G loss: 1.114350]\n",
      "[Epoch 9/200] [Batch 195/938] [D loss: 1.057969, acc: 98%] [G loss: 1.144540]\n",
      "[Epoch 9/200] [Batch 196/938] [D loss: 1.068703, acc: 98%] [G loss: 1.128230]\n",
      "[Epoch 9/200] [Batch 197/938] [D loss: 1.095253, acc: 96%] [G loss: 1.103870]\n",
      "[Epoch 9/200] [Batch 198/938] [D loss: 1.086820, acc: 96%] [G loss: 1.135628]\n",
      "[Epoch 9/200] [Batch 199/938] [D loss: 1.120943, acc: 96%] [G loss: 1.113262]\n",
      "[Epoch 9/200] [Batch 200/938] [D loss: 1.105412, acc: 96%] [G loss: 1.104343]\n",
      "[Epoch 9/200] [Batch 201/938] [D loss: 1.118541, acc: 92%] [G loss: 1.124066]\n",
      "[Epoch 9/200] [Batch 202/938] [D loss: 1.068467, acc: 96%] [G loss: 1.087311]\n",
      "[Epoch 9/200] [Batch 203/938] [D loss: 1.099470, acc: 97%] [G loss: 1.090552]\n",
      "[Epoch 9/200] [Batch 204/938] [D loss: 1.070345, acc: 95%] [G loss: 1.081321]\n",
      "[Epoch 9/200] [Batch 205/938] [D loss: 1.063771, acc: 99%] [G loss: 1.074506]\n",
      "[Epoch 9/200] [Batch 206/938] [D loss: 1.098826, acc: 97%] [G loss: 1.128865]\n",
      "[Epoch 9/200] [Batch 207/938] [D loss: 1.104939, acc: 97%] [G loss: 1.099890]\n",
      "[Epoch 9/200] [Batch 208/938] [D loss: 1.097659, acc: 98%] [G loss: 1.076069]\n",
      "[Epoch 9/200] [Batch 209/938] [D loss: 1.100465, acc: 96%] [G loss: 1.135609]\n",
      "[Epoch 9/200] [Batch 210/938] [D loss: 1.135067, acc: 94%] [G loss: 1.074610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 211/938] [D loss: 1.124114, acc: 96%] [G loss: 1.183327]\n",
      "[Epoch 9/200] [Batch 212/938] [D loss: 1.087461, acc: 94%] [G loss: 1.179678]\n",
      "[Epoch 9/200] [Batch 213/938] [D loss: 1.123741, acc: 96%] [G loss: 1.144558]\n",
      "[Epoch 9/200] [Batch 214/938] [D loss: 1.085512, acc: 96%] [G loss: 1.149875]\n",
      "[Epoch 9/200] [Batch 215/938] [D loss: 1.073860, acc: 98%] [G loss: 1.075983]\n",
      "[Epoch 9/200] [Batch 216/938] [D loss: 1.112816, acc: 95%] [G loss: 1.144235]\n",
      "[Epoch 9/200] [Batch 217/938] [D loss: 1.105653, acc: 98%] [G loss: 1.049294]\n",
      "[Epoch 9/200] [Batch 218/938] [D loss: 1.084786, acc: 96%] [G loss: 1.067402]\n",
      "[Epoch 9/200] [Batch 219/938] [D loss: 1.108804, acc: 97%] [G loss: 1.049030]\n",
      "[Epoch 9/200] [Batch 220/938] [D loss: 1.124819, acc: 96%] [G loss: 1.058244]\n",
      "[Epoch 9/200] [Batch 221/938] [D loss: 1.107798, acc: 96%] [G loss: 1.088852]\n",
      "[Epoch 9/200] [Batch 222/938] [D loss: 1.078800, acc: 98%] [G loss: 1.085496]\n",
      "[Epoch 9/200] [Batch 223/938] [D loss: 1.085742, acc: 98%] [G loss: 1.139042]\n",
      "[Epoch 9/200] [Batch 224/938] [D loss: 1.087829, acc: 97%] [G loss: 1.076827]\n",
      "[Epoch 9/200] [Batch 225/938] [D loss: 1.105451, acc: 96%] [G loss: 1.136417]\n",
      "[Epoch 9/200] [Batch 226/938] [D loss: 1.103200, acc: 95%] [G loss: 1.110501]\n",
      "[Epoch 9/200] [Batch 227/938] [D loss: 1.116132, acc: 96%] [G loss: 1.093881]\n",
      "[Epoch 9/200] [Batch 228/938] [D loss: 1.073743, acc: 98%] [G loss: 1.063113]\n",
      "[Epoch 9/200] [Batch 229/938] [D loss: 1.027945, acc: 97%] [G loss: 1.082196]\n",
      "[Epoch 9/200] [Batch 230/938] [D loss: 1.088816, acc: 96%] [G loss: 1.126538]\n",
      "[Epoch 9/200] [Batch 231/938] [D loss: 1.082522, acc: 97%] [G loss: 1.105224]\n",
      "[Epoch 9/200] [Batch 232/938] [D loss: 1.068849, acc: 96%] [G loss: 1.133549]\n",
      "[Epoch 9/200] [Batch 233/938] [D loss: 1.068604, acc: 98%] [G loss: 1.142777]\n",
      "[Epoch 9/200] [Batch 234/938] [D loss: 1.103834, acc: 92%] [G loss: 1.116912]\n",
      "[Epoch 9/200] [Batch 235/938] [D loss: 1.111837, acc: 97%] [G loss: 1.093772]\n",
      "[Epoch 9/200] [Batch 236/938] [D loss: 1.066085, acc: 97%] [G loss: 1.086163]\n",
      "[Epoch 9/200] [Batch 237/938] [D loss: 1.095034, acc: 96%] [G loss: 1.030484]\n",
      "[Epoch 9/200] [Batch 238/938] [D loss: 1.090796, acc: 95%] [G loss: 1.077921]\n",
      "[Epoch 9/200] [Batch 239/938] [D loss: 1.054066, acc: 96%] [G loss: 1.064314]\n",
      "[Epoch 9/200] [Batch 240/938] [D loss: 1.078388, acc: 97%] [G loss: 1.061229]\n",
      "[Epoch 9/200] [Batch 241/938] [D loss: 1.086776, acc: 96%] [G loss: 1.169565]\n",
      "[Epoch 9/200] [Batch 242/938] [D loss: 1.137436, acc: 96%] [G loss: 1.059732]\n",
      "[Epoch 9/200] [Batch 243/938] [D loss: 1.130767, acc: 96%] [G loss: 1.083757]\n",
      "[Epoch 9/200] [Batch 244/938] [D loss: 1.102213, acc: 96%] [G loss: 1.093230]\n",
      "[Epoch 9/200] [Batch 245/938] [D loss: 1.074170, acc: 94%] [G loss: 1.155567]\n",
      "[Epoch 9/200] [Batch 246/938] [D loss: 1.103351, acc: 96%] [G loss: 1.047825]\n",
      "[Epoch 9/200] [Batch 247/938] [D loss: 1.106442, acc: 99%] [G loss: 1.074591]\n",
      "[Epoch 9/200] [Batch 248/938] [D loss: 1.062631, acc: 97%] [G loss: 1.079008]\n",
      "[Epoch 9/200] [Batch 249/938] [D loss: 1.096465, acc: 92%] [G loss: 1.037420]\n",
      "[Epoch 9/200] [Batch 250/938] [D loss: 1.083965, acc: 94%] [G loss: 1.094827]\n",
      "[Epoch 9/200] [Batch 251/938] [D loss: 1.126565, acc: 94%] [G loss: 1.144337]\n",
      "[Epoch 9/200] [Batch 252/938] [D loss: 1.091132, acc: 97%] [G loss: 1.101603]\n",
      "[Epoch 9/200] [Batch 253/938] [D loss: 1.065003, acc: 98%] [G loss: 1.162583]\n",
      "[Epoch 9/200] [Batch 254/938] [D loss: 1.112787, acc: 96%] [G loss: 1.091170]\n",
      "[Epoch 9/200] [Batch 255/938] [D loss: 1.113324, acc: 96%] [G loss: 1.117748]\n",
      "[Epoch 9/200] [Batch 256/938] [D loss: 1.094625, acc: 92%] [G loss: 1.136906]\n",
      "[Epoch 9/200] [Batch 257/938] [D loss: 1.104054, acc: 96%] [G loss: 1.070786]\n",
      "[Epoch 9/200] [Batch 258/938] [D loss: 1.094474, acc: 96%] [G loss: 1.071159]\n",
      "[Epoch 9/200] [Batch 259/938] [D loss: 1.082527, acc: 96%] [G loss: 1.103720]\n",
      "[Epoch 9/200] [Batch 260/938] [D loss: 1.076725, acc: 97%] [G loss: 1.114283]\n",
      "[Epoch 9/200] [Batch 261/938] [D loss: 1.099135, acc: 95%] [G loss: 1.131249]\n",
      "[Epoch 9/200] [Batch 262/938] [D loss: 1.112043, acc: 97%] [G loss: 1.111094]\n",
      "[Epoch 9/200] [Batch 263/938] [D loss: 1.090899, acc: 95%] [G loss: 1.102906]\n",
      "[Epoch 9/200] [Batch 264/938] [D loss: 1.103689, acc: 98%] [G loss: 1.135819]\n",
      "[Epoch 9/200] [Batch 265/938] [D loss: 1.066430, acc: 95%] [G loss: 1.128738]\n",
      "[Epoch 9/200] [Batch 266/938] [D loss: 1.095883, acc: 96%] [G loss: 1.125450]\n",
      "[Epoch 9/200] [Batch 267/938] [D loss: 1.081438, acc: 95%] [G loss: 1.079530]\n",
      "[Epoch 9/200] [Batch 268/938] [D loss: 1.104389, acc: 99%] [G loss: 1.135027]\n",
      "[Epoch 9/200] [Batch 269/938] [D loss: 1.102793, acc: 97%] [G loss: 1.049847]\n",
      "[Epoch 9/200] [Batch 270/938] [D loss: 1.119010, acc: 95%] [G loss: 1.095666]\n",
      "[Epoch 9/200] [Batch 271/938] [D loss: 1.106877, acc: 96%] [G loss: 1.170329]\n",
      "[Epoch 9/200] [Batch 272/938] [D loss: 1.111781, acc: 92%] [G loss: 1.114809]\n",
      "[Epoch 9/200] [Batch 273/938] [D loss: 1.101175, acc: 96%] [G loss: 1.120536]\n",
      "[Epoch 9/200] [Batch 274/938] [D loss: 1.078714, acc: 96%] [G loss: 1.111138]\n",
      "[Epoch 9/200] [Batch 275/938] [D loss: 1.095717, acc: 97%] [G loss: 1.066260]\n",
      "[Epoch 9/200] [Batch 276/938] [D loss: 1.117648, acc: 96%] [G loss: 1.054632]\n",
      "[Epoch 9/200] [Batch 277/938] [D loss: 1.079385, acc: 97%] [G loss: 1.077440]\n",
      "[Epoch 9/200] [Batch 278/938] [D loss: 1.082788, acc: 98%] [G loss: 1.095139]\n",
      "[Epoch 9/200] [Batch 279/938] [D loss: 1.123574, acc: 95%] [G loss: 1.074746]\n",
      "[Epoch 9/200] [Batch 280/938] [D loss: 1.066882, acc: 98%] [G loss: 1.102219]\n",
      "[Epoch 9/200] [Batch 281/938] [D loss: 1.096645, acc: 97%] [G loss: 1.170769]\n",
      "[Epoch 9/200] [Batch 282/938] [D loss: 1.140213, acc: 97%] [G loss: 1.068276]\n",
      "[Epoch 9/200] [Batch 283/938] [D loss: 1.127603, acc: 97%] [G loss: 1.092775]\n",
      "[Epoch 9/200] [Batch 284/938] [D loss: 1.105731, acc: 92%] [G loss: 1.163021]\n",
      "[Epoch 9/200] [Batch 285/938] [D loss: 1.049401, acc: 98%] [G loss: 1.068161]\n",
      "[Epoch 9/200] [Batch 286/938] [D loss: 1.082667, acc: 97%] [G loss: 1.140886]\n",
      "[Epoch 9/200] [Batch 287/938] [D loss: 1.091025, acc: 96%] [G loss: 1.093174]\n",
      "[Epoch 9/200] [Batch 288/938] [D loss: 1.087818, acc: 98%] [G loss: 1.111499]\n",
      "[Epoch 9/200] [Batch 289/938] [D loss: 1.118204, acc: 97%] [G loss: 1.108491]\n",
      "[Epoch 9/200] [Batch 290/938] [D loss: 1.062899, acc: 97%] [G loss: 1.092660]\n",
      "[Epoch 9/200] [Batch 291/938] [D loss: 1.087767, acc: 93%] [G loss: 1.126530]\n",
      "[Epoch 9/200] [Batch 292/938] [D loss: 1.086905, acc: 94%] [G loss: 1.178130]\n",
      "[Epoch 9/200] [Batch 293/938] [D loss: 1.080600, acc: 100%] [G loss: 1.116837]\n",
      "[Epoch 9/200] [Batch 294/938] [D loss: 1.090680, acc: 97%] [G loss: 1.115308]\n",
      "[Epoch 9/200] [Batch 295/938] [D loss: 1.076121, acc: 94%] [G loss: 1.127326]\n",
      "[Epoch 9/200] [Batch 296/938] [D loss: 1.087116, acc: 94%] [G loss: 1.080256]\n",
      "[Epoch 9/200] [Batch 297/938] [D loss: 1.132099, acc: 93%] [G loss: 1.142022]\n",
      "[Epoch 9/200] [Batch 298/938] [D loss: 1.091611, acc: 92%] [G loss: 1.044405]\n",
      "[Epoch 9/200] [Batch 299/938] [D loss: 1.081691, acc: 95%] [G loss: 1.079176]\n",
      "[Epoch 9/200] [Batch 300/938] [D loss: 1.099750, acc: 96%] [G loss: 1.039532]\n",
      "[Epoch 9/200] [Batch 301/938] [D loss: 1.080268, acc: 96%] [G loss: 1.105921]\n",
      "[Epoch 9/200] [Batch 302/938] [D loss: 1.092500, acc: 96%] [G loss: 1.105866]\n",
      "[Epoch 9/200] [Batch 303/938] [D loss: 1.114391, acc: 97%] [G loss: 1.072860]\n",
      "[Epoch 9/200] [Batch 304/938] [D loss: 1.083757, acc: 96%] [G loss: 1.106319]\n",
      "[Epoch 9/200] [Batch 305/938] [D loss: 1.054757, acc: 96%] [G loss: 1.110367]\n",
      "[Epoch 9/200] [Batch 306/938] [D loss: 1.071232, acc: 97%] [G loss: 1.135642]\n",
      "[Epoch 9/200] [Batch 307/938] [D loss: 1.073272, acc: 97%] [G loss: 1.183562]\n",
      "[Epoch 9/200] [Batch 308/938] [D loss: 1.082791, acc: 99%] [G loss: 1.076257]\n",
      "[Epoch 9/200] [Batch 309/938] [D loss: 1.084944, acc: 97%] [G loss: 1.071283]\n",
      "[Epoch 9/200] [Batch 310/938] [D loss: 1.106446, acc: 92%] [G loss: 1.108070]\n",
      "[Epoch 9/200] [Batch 311/938] [D loss: 1.068157, acc: 98%] [G loss: 1.105020]\n",
      "[Epoch 9/200] [Batch 312/938] [D loss: 1.130256, acc: 95%] [G loss: 1.127559]\n",
      "[Epoch 9/200] [Batch 313/938] [D loss: 1.091332, acc: 96%] [G loss: 1.078502]\n",
      "[Epoch 9/200] [Batch 314/938] [D loss: 1.098632, acc: 96%] [G loss: 1.077600]\n",
      "[Epoch 9/200] [Batch 315/938] [D loss: 1.048980, acc: 98%] [G loss: 1.089139]\n",
      "[Epoch 9/200] [Batch 316/938] [D loss: 1.079146, acc: 98%] [G loss: 1.103923]\n",
      "[Epoch 9/200] [Batch 317/938] [D loss: 1.098703, acc: 99%] [G loss: 1.115771]\n",
      "[Epoch 9/200] [Batch 318/938] [D loss: 1.109667, acc: 97%] [G loss: 1.092097]\n",
      "[Epoch 9/200] [Batch 319/938] [D loss: 1.075907, acc: 97%] [G loss: 1.094211]\n",
      "[Epoch 9/200] [Batch 320/938] [D loss: 1.074808, acc: 95%] [G loss: 1.055980]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 321/938] [D loss: 1.067906, acc: 98%] [G loss: 1.108505]\n",
      "[Epoch 9/200] [Batch 322/938] [D loss: 1.102483, acc: 95%] [G loss: 1.075915]\n",
      "[Epoch 9/200] [Batch 323/938] [D loss: 1.102683, acc: 94%] [G loss: 1.132824]\n",
      "[Epoch 9/200] [Batch 324/938] [D loss: 1.083328, acc: 97%] [G loss: 1.091440]\n",
      "[Epoch 9/200] [Batch 325/938] [D loss: 1.074704, acc: 97%] [G loss: 1.187520]\n",
      "[Epoch 9/200] [Batch 326/938] [D loss: 1.083032, acc: 99%] [G loss: 1.028088]\n",
      "[Epoch 9/200] [Batch 327/938] [D loss: 1.084313, acc: 94%] [G loss: 1.103103]\n",
      "[Epoch 9/200] [Batch 328/938] [D loss: 1.098739, acc: 97%] [G loss: 1.140667]\n",
      "[Epoch 9/200] [Batch 329/938] [D loss: 1.094163, acc: 100%] [G loss: 1.108829]\n",
      "[Epoch 9/200] [Batch 330/938] [D loss: 1.047839, acc: 96%] [G loss: 1.096711]\n",
      "[Epoch 9/200] [Batch 331/938] [D loss: 1.090537, acc: 96%] [G loss: 1.132466]\n",
      "[Epoch 9/200] [Batch 332/938] [D loss: 1.068974, acc: 96%] [G loss: 1.075137]\n",
      "[Epoch 9/200] [Batch 333/938] [D loss: 1.095346, acc: 96%] [G loss: 1.089165]\n",
      "[Epoch 9/200] [Batch 334/938] [D loss: 1.130462, acc: 96%] [G loss: 1.086145]\n",
      "[Epoch 9/200] [Batch 335/938] [D loss: 1.131335, acc: 96%] [G loss: 1.125685]\n",
      "[Epoch 9/200] [Batch 336/938] [D loss: 1.079936, acc: 95%] [G loss: 1.113961]\n",
      "[Epoch 9/200] [Batch 337/938] [D loss: 1.094531, acc: 95%] [G loss: 1.062243]\n",
      "[Epoch 9/200] [Batch 338/938] [D loss: 1.100035, acc: 97%] [G loss: 1.174560]\n",
      "[Epoch 9/200] [Batch 339/938] [D loss: 1.090293, acc: 96%] [G loss: 1.080684]\n",
      "[Epoch 9/200] [Batch 340/938] [D loss: 1.100651, acc: 99%] [G loss: 1.084224]\n",
      "[Epoch 9/200] [Batch 341/938] [D loss: 1.114590, acc: 98%] [G loss: 1.021132]\n",
      "[Epoch 9/200] [Batch 342/938] [D loss: 1.092328, acc: 94%] [G loss: 1.045826]\n",
      "[Epoch 9/200] [Batch 343/938] [D loss: 1.094700, acc: 99%] [G loss: 1.139774]\n",
      "[Epoch 9/200] [Batch 344/938] [D loss: 1.069646, acc: 99%] [G loss: 1.137877]\n",
      "[Epoch 9/200] [Batch 345/938] [D loss: 1.100672, acc: 96%] [G loss: 1.076262]\n",
      "[Epoch 9/200] [Batch 346/938] [D loss: 1.080175, acc: 97%] [G loss: 1.073050]\n",
      "[Epoch 9/200] [Batch 347/938] [D loss: 1.109628, acc: 97%] [G loss: 1.127986]\n",
      "[Epoch 9/200] [Batch 348/938] [D loss: 1.095598, acc: 96%] [G loss: 1.103899]\n",
      "[Epoch 9/200] [Batch 349/938] [D loss: 1.101972, acc: 96%] [G loss: 1.108845]\n",
      "[Epoch 9/200] [Batch 350/938] [D loss: 1.082422, acc: 94%] [G loss: 1.076632]\n",
      "[Epoch 9/200] [Batch 351/938] [D loss: 1.105363, acc: 97%] [G loss: 1.076843]\n",
      "[Epoch 9/200] [Batch 352/938] [D loss: 1.080702, acc: 99%] [G loss: 1.114329]\n",
      "[Epoch 9/200] [Batch 353/938] [D loss: 1.073563, acc: 96%] [G loss: 1.158489]\n",
      "[Epoch 9/200] [Batch 354/938] [D loss: 1.084493, acc: 97%] [G loss: 1.084405]\n",
      "[Epoch 9/200] [Batch 355/938] [D loss: 1.074390, acc: 96%] [G loss: 1.087955]\n",
      "[Epoch 9/200] [Batch 356/938] [D loss: 1.062216, acc: 100%] [G loss: 1.039470]\n",
      "[Epoch 9/200] [Batch 357/938] [D loss: 1.095810, acc: 97%] [G loss: 1.069652]\n",
      "[Epoch 9/200] [Batch 358/938] [D loss: 1.104907, acc: 99%] [G loss: 1.086981]\n",
      "[Epoch 9/200] [Batch 359/938] [D loss: 1.072668, acc: 97%] [G loss: 1.087110]\n",
      "[Epoch 9/200] [Batch 360/938] [D loss: 1.102678, acc: 97%] [G loss: 1.105709]\n",
      "[Epoch 9/200] [Batch 361/938] [D loss: 1.099266, acc: 97%] [G loss: 1.076682]\n",
      "[Epoch 9/200] [Batch 362/938] [D loss: 1.088550, acc: 97%] [G loss: 1.076306]\n",
      "[Epoch 9/200] [Batch 363/938] [D loss: 1.055295, acc: 98%] [G loss: 1.146715]\n",
      "[Epoch 9/200] [Batch 364/938] [D loss: 1.076668, acc: 98%] [G loss: 1.109439]\n",
      "[Epoch 9/200] [Batch 365/938] [D loss: 1.098261, acc: 96%] [G loss: 1.063389]\n",
      "[Epoch 9/200] [Batch 366/938] [D loss: 1.103207, acc: 95%] [G loss: 1.121231]\n",
      "[Epoch 9/200] [Batch 367/938] [D loss: 1.082970, acc: 98%] [G loss: 1.063068]\n",
      "[Epoch 9/200] [Batch 368/938] [D loss: 1.093234, acc: 95%] [G loss: 1.061235]\n",
      "[Epoch 9/200] [Batch 369/938] [D loss: 1.055842, acc: 98%] [G loss: 1.097978]\n",
      "[Epoch 9/200] [Batch 370/938] [D loss: 1.081058, acc: 97%] [G loss: 1.098492]\n",
      "[Epoch 9/200] [Batch 371/938] [D loss: 1.104500, acc: 96%] [G loss: 1.105722]\n",
      "[Epoch 9/200] [Batch 372/938] [D loss: 1.109731, acc: 95%] [G loss: 1.093076]\n",
      "[Epoch 9/200] [Batch 373/938] [D loss: 1.077743, acc: 96%] [G loss: 1.091012]\n",
      "[Epoch 9/200] [Batch 374/938] [D loss: 1.087545, acc: 98%] [G loss: 1.086908]\n",
      "[Epoch 9/200] [Batch 375/938] [D loss: 1.080282, acc: 96%] [G loss: 1.104145]\n",
      "[Epoch 9/200] [Batch 376/938] [D loss: 1.079822, acc: 95%] [G loss: 1.056274]\n",
      "[Epoch 9/200] [Batch 377/938] [D loss: 1.105932, acc: 96%] [G loss: 1.092794]\n",
      "[Epoch 9/200] [Batch 378/938] [D loss: 1.112287, acc: 96%] [G loss: 1.059037]\n",
      "[Epoch 9/200] [Batch 379/938] [D loss: 1.088936, acc: 98%] [G loss: 1.041515]\n",
      "[Epoch 9/200] [Batch 380/938] [D loss: 1.068696, acc: 96%] [G loss: 1.130969]\n",
      "[Epoch 9/200] [Batch 381/938] [D loss: 1.100533, acc: 96%] [G loss: 1.069004]\n",
      "[Epoch 9/200] [Batch 382/938] [D loss: 1.088586, acc: 97%] [G loss: 1.113782]\n",
      "[Epoch 9/200] [Batch 383/938] [D loss: 1.113723, acc: 94%] [G loss: 1.092680]\n",
      "[Epoch 9/200] [Batch 384/938] [D loss: 1.080786, acc: 96%] [G loss: 1.140850]\n",
      "[Epoch 9/200] [Batch 385/938] [D loss: 1.088619, acc: 98%] [G loss: 1.138905]\n",
      "[Epoch 9/200] [Batch 386/938] [D loss: 1.095239, acc: 94%] [G loss: 1.104751]\n",
      "[Epoch 9/200] [Batch 387/938] [D loss: 1.101042, acc: 97%] [G loss: 1.118134]\n",
      "[Epoch 9/200] [Batch 388/938] [D loss: 1.094702, acc: 96%] [G loss: 1.073671]\n",
      "[Epoch 9/200] [Batch 389/938] [D loss: 1.086619, acc: 98%] [G loss: 1.090981]\n",
      "[Epoch 9/200] [Batch 390/938] [D loss: 1.111261, acc: 96%] [G loss: 1.116850]\n",
      "[Epoch 9/200] [Batch 391/938] [D loss: 1.081758, acc: 98%] [G loss: 1.127422]\n",
      "[Epoch 9/200] [Batch 392/938] [D loss: 1.095862, acc: 96%] [G loss: 1.034856]\n",
      "[Epoch 9/200] [Batch 393/938] [D loss: 1.090383, acc: 96%] [G loss: 1.127673]\n",
      "[Epoch 9/200] [Batch 394/938] [D loss: 1.079386, acc: 96%] [G loss: 1.116358]\n",
      "[Epoch 9/200] [Batch 395/938] [D loss: 1.124035, acc: 98%] [G loss: 1.094667]\n",
      "[Epoch 9/200] [Batch 396/938] [D loss: 1.073963, acc: 96%] [G loss: 1.125414]\n",
      "[Epoch 9/200] [Batch 397/938] [D loss: 1.082657, acc: 98%] [G loss: 1.088398]\n",
      "[Epoch 9/200] [Batch 398/938] [D loss: 1.072269, acc: 97%] [G loss: 1.119290]\n",
      "[Epoch 9/200] [Batch 399/938] [D loss: 1.088057, acc: 96%] [G loss: 1.115336]\n",
      "[Epoch 9/200] [Batch 400/938] [D loss: 1.099673, acc: 96%] [G loss: 1.119055]\n",
      "[Epoch 9/200] [Batch 401/938] [D loss: 1.074043, acc: 96%] [G loss: 1.143354]\n",
      "[Epoch 9/200] [Batch 402/938] [D loss: 1.064918, acc: 95%] [G loss: 1.080679]\n",
      "[Epoch 9/200] [Batch 403/938] [D loss: 1.108107, acc: 96%] [G loss: 1.122561]\n",
      "[Epoch 9/200] [Batch 404/938] [D loss: 1.088110, acc: 96%] [G loss: 1.150588]\n",
      "[Epoch 9/200] [Batch 405/938] [D loss: 1.098467, acc: 96%] [G loss: 1.081339]\n",
      "[Epoch 9/200] [Batch 406/938] [D loss: 1.091110, acc: 97%] [G loss: 1.122184]\n",
      "[Epoch 9/200] [Batch 407/938] [D loss: 1.058992, acc: 99%] [G loss: 1.027650]\n",
      "[Epoch 9/200] [Batch 408/938] [D loss: 1.064714, acc: 97%] [G loss: 1.130293]\n",
      "[Epoch 9/200] [Batch 409/938] [D loss: 1.061097, acc: 96%] [G loss: 1.063389]\n",
      "[Epoch 9/200] [Batch 410/938] [D loss: 1.084624, acc: 96%] [G loss: 1.091115]\n",
      "[Epoch 9/200] [Batch 411/938] [D loss: 1.091137, acc: 97%] [G loss: 1.153051]\n",
      "[Epoch 9/200] [Batch 412/938] [D loss: 1.065444, acc: 96%] [G loss: 1.094788]\n",
      "[Epoch 9/200] [Batch 413/938] [D loss: 1.071276, acc: 96%] [G loss: 1.096834]\n",
      "[Epoch 9/200] [Batch 414/938] [D loss: 1.075734, acc: 100%] [G loss: 1.086451]\n",
      "[Epoch 9/200] [Batch 415/938] [D loss: 1.072638, acc: 96%] [G loss: 1.113113]\n",
      "[Epoch 9/200] [Batch 416/938] [D loss: 1.056871, acc: 97%] [G loss: 1.112251]\n",
      "[Epoch 9/200] [Batch 417/938] [D loss: 1.112689, acc: 94%] [G loss: 1.104295]\n",
      "[Epoch 9/200] [Batch 418/938] [D loss: 1.076637, acc: 98%] [G loss: 1.031691]\n",
      "[Epoch 9/200] [Batch 419/938] [D loss: 1.068059, acc: 97%] [G loss: 1.115199]\n",
      "[Epoch 9/200] [Batch 420/938] [D loss: 1.122330, acc: 96%] [G loss: 1.100901]\n",
      "[Epoch 9/200] [Batch 421/938] [D loss: 1.095624, acc: 98%] [G loss: 1.032108]\n",
      "[Epoch 9/200] [Batch 422/938] [D loss: 1.106754, acc: 95%] [G loss: 1.102834]\n",
      "[Epoch 9/200] [Batch 423/938] [D loss: 1.059472, acc: 97%] [G loss: 1.083020]\n",
      "[Epoch 9/200] [Batch 424/938] [D loss: 1.096499, acc: 97%] [G loss: 1.101397]\n",
      "[Epoch 9/200] [Batch 425/938] [D loss: 1.101822, acc: 99%] [G loss: 1.065506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 426/938] [D loss: 1.085093, acc: 96%] [G loss: 1.151905]\n",
      "[Epoch 9/200] [Batch 427/938] [D loss: 1.103019, acc: 96%] [G loss: 1.164798]\n",
      "[Epoch 9/200] [Batch 428/938] [D loss: 1.085092, acc: 96%] [G loss: 1.124659]\n",
      "[Epoch 9/200] [Batch 429/938] [D loss: 1.094836, acc: 96%] [G loss: 1.047928]\n",
      "[Epoch 9/200] [Batch 430/938] [D loss: 1.101620, acc: 97%] [G loss: 1.077176]\n",
      "[Epoch 9/200] [Batch 431/938] [D loss: 1.104989, acc: 98%] [G loss: 1.083390]\n",
      "[Epoch 9/200] [Batch 432/938] [D loss: 1.070819, acc: 97%] [G loss: 1.128084]\n",
      "[Epoch 9/200] [Batch 433/938] [D loss: 1.089094, acc: 96%] [G loss: 1.090495]\n",
      "[Epoch 9/200] [Batch 434/938] [D loss: 1.122532, acc: 98%] [G loss: 1.097129]\n",
      "[Epoch 9/200] [Batch 435/938] [D loss: 1.080924, acc: 96%] [G loss: 1.105747]\n",
      "[Epoch 9/200] [Batch 436/938] [D loss: 1.083529, acc: 96%] [G loss: 1.134473]\n",
      "[Epoch 9/200] [Batch 437/938] [D loss: 1.123328, acc: 95%] [G loss: 1.108833]\n",
      "[Epoch 9/200] [Batch 438/938] [D loss: 1.130277, acc: 93%] [G loss: 1.066009]\n",
      "[Epoch 9/200] [Batch 439/938] [D loss: 1.095994, acc: 96%] [G loss: 1.160465]\n",
      "[Epoch 9/200] [Batch 440/938] [D loss: 1.050743, acc: 98%] [G loss: 1.191364]\n",
      "[Epoch 9/200] [Batch 441/938] [D loss: 1.123234, acc: 98%] [G loss: 1.063029]\n",
      "[Epoch 9/200] [Batch 442/938] [D loss: 1.093724, acc: 99%] [G loss: 1.038337]\n",
      "[Epoch 9/200] [Batch 443/938] [D loss: 1.097515, acc: 96%] [G loss: 1.128220]\n",
      "[Epoch 9/200] [Batch 444/938] [D loss: 1.072062, acc: 94%] [G loss: 1.068555]\n",
      "[Epoch 9/200] [Batch 445/938] [D loss: 1.085723, acc: 97%] [G loss: 1.094908]\n",
      "[Epoch 9/200] [Batch 446/938] [D loss: 1.112340, acc: 96%] [G loss: 1.089447]\n",
      "[Epoch 9/200] [Batch 447/938] [D loss: 1.097412, acc: 95%] [G loss: 1.137459]\n",
      "[Epoch 9/200] [Batch 448/938] [D loss: 1.124317, acc: 96%] [G loss: 1.112594]\n",
      "[Epoch 9/200] [Batch 449/938] [D loss: 1.102275, acc: 95%] [G loss: 1.149296]\n",
      "[Epoch 9/200] [Batch 450/938] [D loss: 1.068455, acc: 98%] [G loss: 1.048961]\n",
      "[Epoch 9/200] [Batch 451/938] [D loss: 1.085926, acc: 97%] [G loss: 1.096726]\n",
      "[Epoch 9/200] [Batch 452/938] [D loss: 1.105512, acc: 94%] [G loss: 1.101476]\n",
      "[Epoch 9/200] [Batch 453/938] [D loss: 1.112674, acc: 93%] [G loss: 1.077800]\n",
      "[Epoch 9/200] [Batch 454/938] [D loss: 1.092101, acc: 96%] [G loss: 1.151795]\n",
      "[Epoch 9/200] [Batch 455/938] [D loss: 1.046999, acc: 98%] [G loss: 1.109851]\n",
      "[Epoch 9/200] [Batch 456/938] [D loss: 1.080490, acc: 96%] [G loss: 1.081727]\n",
      "[Epoch 9/200] [Batch 457/938] [D loss: 1.112677, acc: 98%] [G loss: 1.112178]\n",
      "[Epoch 9/200] [Batch 458/938] [D loss: 1.091311, acc: 96%] [G loss: 1.089582]\n",
      "[Epoch 9/200] [Batch 459/938] [D loss: 1.128382, acc: 95%] [G loss: 1.059534]\n",
      "[Epoch 9/200] [Batch 460/938] [D loss: 1.084396, acc: 95%] [G loss: 1.051927]\n",
      "[Epoch 9/200] [Batch 461/938] [D loss: 1.103562, acc: 97%] [G loss: 1.049304]\n",
      "[Epoch 9/200] [Batch 462/938] [D loss: 1.069815, acc: 96%] [G loss: 1.104751]\n",
      "[Epoch 9/200] [Batch 463/938] [D loss: 1.084337, acc: 96%] [G loss: 1.098168]\n",
      "[Epoch 9/200] [Batch 464/938] [D loss: 1.074831, acc: 98%] [G loss: 1.131102]\n",
      "[Epoch 9/200] [Batch 465/938] [D loss: 1.059480, acc: 97%] [G loss: 1.098243]\n",
      "[Epoch 9/200] [Batch 466/938] [D loss: 1.065548, acc: 96%] [G loss: 1.070086]\n",
      "[Epoch 9/200] [Batch 467/938] [D loss: 1.125324, acc: 96%] [G loss: 1.082102]\n",
      "[Epoch 9/200] [Batch 468/938] [D loss: 1.083867, acc: 100%] [G loss: 1.115089]\n",
      "[Epoch 9/200] [Batch 469/938] [D loss: 1.107434, acc: 94%] [G loss: 1.095162]\n",
      "[Epoch 9/200] [Batch 470/938] [D loss: 1.083389, acc: 95%] [G loss: 1.100017]\n",
      "[Epoch 9/200] [Batch 471/938] [D loss: 1.097762, acc: 95%] [G loss: 1.074885]\n",
      "[Epoch 9/200] [Batch 472/938] [D loss: 1.066538, acc: 97%] [G loss: 1.092301]\n",
      "[Epoch 9/200] [Batch 473/938] [D loss: 1.061969, acc: 97%] [G loss: 1.035246]\n",
      "[Epoch 9/200] [Batch 474/938] [D loss: 1.082506, acc: 98%] [G loss: 1.078837]\n",
      "[Epoch 9/200] [Batch 475/938] [D loss: 1.087277, acc: 96%] [G loss: 1.096901]\n",
      "[Epoch 9/200] [Batch 476/938] [D loss: 1.104383, acc: 97%] [G loss: 1.152003]\n",
      "[Epoch 9/200] [Batch 477/938] [D loss: 1.122712, acc: 96%] [G loss: 1.142118]\n",
      "[Epoch 9/200] [Batch 478/938] [D loss: 1.088780, acc: 94%] [G loss: 1.119674]\n",
      "[Epoch 9/200] [Batch 479/938] [D loss: 1.093264, acc: 95%] [G loss: 1.065598]\n",
      "[Epoch 9/200] [Batch 480/938] [D loss: 1.088909, acc: 96%] [G loss: 1.069698]\n",
      "[Epoch 9/200] [Batch 481/938] [D loss: 1.134628, acc: 96%] [G loss: 1.069910]\n",
      "[Epoch 9/200] [Batch 482/938] [D loss: 1.063373, acc: 98%] [G loss: 1.171197]\n",
      "[Epoch 9/200] [Batch 483/938] [D loss: 1.114015, acc: 95%] [G loss: 1.050992]\n",
      "[Epoch 9/200] [Batch 484/938] [D loss: 1.104387, acc: 96%] [G loss: 1.101992]\n",
      "[Epoch 9/200] [Batch 485/938] [D loss: 1.123471, acc: 94%] [G loss: 1.129448]\n",
      "[Epoch 9/200] [Batch 486/938] [D loss: 1.094041, acc: 99%] [G loss: 1.091523]\n",
      "[Epoch 9/200] [Batch 487/938] [D loss: 1.103209, acc: 96%] [G loss: 1.080181]\n",
      "[Epoch 9/200] [Batch 488/938] [D loss: 1.111967, acc: 94%] [G loss: 1.126115]\n",
      "[Epoch 9/200] [Batch 489/938] [D loss: 1.077080, acc: 96%] [G loss: 1.079734]\n",
      "[Epoch 9/200] [Batch 490/938] [D loss: 1.049515, acc: 96%] [G loss: 1.097315]\n",
      "[Epoch 9/200] [Batch 491/938] [D loss: 1.089018, acc: 92%] [G loss: 1.065981]\n",
      "[Epoch 9/200] [Batch 492/938] [D loss: 1.096474, acc: 93%] [G loss: 1.085766]\n",
      "[Epoch 9/200] [Batch 493/938] [D loss: 1.116660, acc: 95%] [G loss: 1.068242]\n",
      "[Epoch 9/200] [Batch 494/938] [D loss: 1.105009, acc: 99%] [G loss: 1.119265]\n",
      "[Epoch 9/200] [Batch 495/938] [D loss: 1.094773, acc: 97%] [G loss: 1.110788]\n",
      "[Epoch 9/200] [Batch 496/938] [D loss: 1.057910, acc: 100%] [G loss: 1.090499]\n",
      "[Epoch 9/200] [Batch 497/938] [D loss: 1.103334, acc: 96%] [G loss: 1.093468]\n",
      "[Epoch 9/200] [Batch 498/938] [D loss: 1.099345, acc: 96%] [G loss: 1.108636]\n",
      "[Epoch 9/200] [Batch 499/938] [D loss: 1.111147, acc: 96%] [G loss: 1.126925]\n",
      "[Epoch 9/200] [Batch 500/938] [D loss: 1.088894, acc: 94%] [G loss: 1.119935]\n",
      "[Epoch 9/200] [Batch 501/938] [D loss: 1.134730, acc: 95%] [G loss: 1.081513]\n",
      "[Epoch 9/200] [Batch 502/938] [D loss: 1.103814, acc: 96%] [G loss: 1.160828]\n",
      "[Epoch 9/200] [Batch 503/938] [D loss: 1.116317, acc: 96%] [G loss: 1.125864]\n",
      "[Epoch 9/200] [Batch 504/938] [D loss: 1.092025, acc: 96%] [G loss: 1.065655]\n",
      "[Epoch 9/200] [Batch 505/938] [D loss: 1.128891, acc: 98%] [G loss: 1.113482]\n",
      "[Epoch 9/200] [Batch 506/938] [D loss: 1.092287, acc: 96%] [G loss: 1.129317]\n",
      "[Epoch 9/200] [Batch 507/938] [D loss: 1.096984, acc: 96%] [G loss: 1.170049]\n",
      "[Epoch 9/200] [Batch 508/938] [D loss: 1.073349, acc: 99%] [G loss: 1.124924]\n",
      "[Epoch 9/200] [Batch 509/938] [D loss: 1.102125, acc: 96%] [G loss: 1.120329]\n",
      "[Epoch 9/200] [Batch 510/938] [D loss: 1.090896, acc: 97%] [G loss: 1.057778]\n",
      "[Epoch 9/200] [Batch 511/938] [D loss: 1.096765, acc: 98%] [G loss: 1.055802]\n",
      "[Epoch 9/200] [Batch 512/938] [D loss: 1.115540, acc: 96%] [G loss: 1.049834]\n",
      "[Epoch 9/200] [Batch 513/938] [D loss: 1.069961, acc: 96%] [G loss: 1.180682]\n",
      "[Epoch 9/200] [Batch 514/938] [D loss: 1.063773, acc: 97%] [G loss: 1.129100]\n",
      "[Epoch 9/200] [Batch 515/938] [D loss: 1.065142, acc: 96%] [G loss: 1.159665]\n",
      "[Epoch 9/200] [Batch 516/938] [D loss: 1.057784, acc: 98%] [G loss: 1.166764]\n",
      "[Epoch 9/200] [Batch 517/938] [D loss: 1.105501, acc: 96%] [G loss: 1.119504]\n",
      "[Epoch 9/200] [Batch 518/938] [D loss: 1.119467, acc: 97%] [G loss: 1.083169]\n",
      "[Epoch 9/200] [Batch 519/938] [D loss: 1.133003, acc: 95%] [G loss: 1.105496]\n",
      "[Epoch 9/200] [Batch 520/938] [D loss: 1.092609, acc: 95%] [G loss: 1.095638]\n",
      "[Epoch 9/200] [Batch 521/938] [D loss: 1.037831, acc: 97%] [G loss: 1.100310]\n",
      "[Epoch 9/200] [Batch 522/938] [D loss: 1.080992, acc: 96%] [G loss: 1.059437]\n",
      "[Epoch 9/200] [Batch 523/938] [D loss: 1.088772, acc: 98%] [G loss: 1.103899]\n",
      "[Epoch 9/200] [Batch 524/938] [D loss: 1.106500, acc: 94%] [G loss: 1.030968]\n",
      "[Epoch 9/200] [Batch 525/938] [D loss: 1.073555, acc: 96%] [G loss: 1.074727]\n",
      "[Epoch 9/200] [Batch 526/938] [D loss: 1.069689, acc: 96%] [G loss: 1.104160]\n",
      "[Epoch 9/200] [Batch 527/938] [D loss: 1.095691, acc: 96%] [G loss: 1.113840]\n",
      "[Epoch 9/200] [Batch 528/938] [D loss: 1.101695, acc: 99%] [G loss: 1.139530]\n",
      "[Epoch 9/200] [Batch 529/938] [D loss: 1.142122, acc: 96%] [G loss: 1.052338]\n",
      "[Epoch 9/200] [Batch 530/938] [D loss: 1.091486, acc: 94%] [G loss: 1.101367]\n",
      "[Epoch 9/200] [Batch 531/938] [D loss: 1.112176, acc: 95%] [G loss: 1.070844]\n",
      "[Epoch 9/200] [Batch 532/938] [D loss: 1.067195, acc: 97%] [G loss: 1.085363]\n",
      "[Epoch 9/200] [Batch 533/938] [D loss: 1.077842, acc: 96%] [G loss: 1.058799]\n",
      "[Epoch 9/200] [Batch 534/938] [D loss: 1.063411, acc: 99%] [G loss: 1.075971]\n",
      "[Epoch 9/200] [Batch 535/938] [D loss: 1.126592, acc: 97%] [G loss: 1.108766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 536/938] [D loss: 1.109717, acc: 96%] [G loss: 1.128879]\n",
      "[Epoch 9/200] [Batch 537/938] [D loss: 1.111459, acc: 98%] [G loss: 1.118430]\n",
      "[Epoch 9/200] [Batch 538/938] [D loss: 1.113173, acc: 95%] [G loss: 1.064378]\n",
      "[Epoch 9/200] [Batch 539/938] [D loss: 1.117844, acc: 95%] [G loss: 1.141148]\n",
      "[Epoch 9/200] [Batch 540/938] [D loss: 1.108821, acc: 97%] [G loss: 1.140903]\n",
      "[Epoch 9/200] [Batch 541/938] [D loss: 1.088153, acc: 97%] [G loss: 1.114690]\n",
      "[Epoch 9/200] [Batch 542/938] [D loss: 1.063594, acc: 96%] [G loss: 1.100572]\n",
      "[Epoch 9/200] [Batch 543/938] [D loss: 1.077328, acc: 99%] [G loss: 1.116255]\n",
      "[Epoch 9/200] [Batch 544/938] [D loss: 1.088593, acc: 97%] [G loss: 1.097299]\n",
      "[Epoch 9/200] [Batch 545/938] [D loss: 1.105308, acc: 97%] [G loss: 1.112789]\n",
      "[Epoch 9/200] [Batch 546/938] [D loss: 1.109605, acc: 97%] [G loss: 1.093323]\n",
      "[Epoch 9/200] [Batch 547/938] [D loss: 1.070852, acc: 98%] [G loss: 1.121828]\n",
      "[Epoch 9/200] [Batch 548/938] [D loss: 1.103852, acc: 95%] [G loss: 1.123328]\n",
      "[Epoch 9/200] [Batch 549/938] [D loss: 1.058759, acc: 98%] [G loss: 1.067231]\n",
      "[Epoch 9/200] [Batch 550/938] [D loss: 1.098899, acc: 97%] [G loss: 1.076914]\n",
      "[Epoch 9/200] [Batch 551/938] [D loss: 1.105483, acc: 95%] [G loss: 1.099084]\n",
      "[Epoch 9/200] [Batch 552/938] [D loss: 1.054166, acc: 96%] [G loss: 1.155720]\n",
      "[Epoch 9/200] [Batch 553/938] [D loss: 1.095693, acc: 96%] [G loss: 1.139048]\n",
      "[Epoch 9/200] [Batch 554/938] [D loss: 1.076225, acc: 95%] [G loss: 1.077446]\n",
      "[Epoch 9/200] [Batch 555/938] [D loss: 1.099111, acc: 97%] [G loss: 1.104357]\n",
      "[Epoch 9/200] [Batch 556/938] [D loss: 1.082867, acc: 97%] [G loss: 1.022243]\n",
      "[Epoch 9/200] [Batch 557/938] [D loss: 1.100464, acc: 95%] [G loss: 1.048334]\n",
      "[Epoch 9/200] [Batch 558/938] [D loss: 1.091496, acc: 98%] [G loss: 1.089619]\n",
      "[Epoch 9/200] [Batch 559/938] [D loss: 1.074184, acc: 97%] [G loss: 1.126095]\n",
      "[Epoch 9/200] [Batch 560/938] [D loss: 1.108069, acc: 95%] [G loss: 1.114709]\n",
      "[Epoch 9/200] [Batch 561/938] [D loss: 1.079210, acc: 96%] [G loss: 1.188621]\n",
      "[Epoch 9/200] [Batch 562/938] [D loss: 1.078191, acc: 98%] [G loss: 1.170691]\n",
      "[Epoch 9/200] [Batch 563/938] [D loss: 1.092071, acc: 95%] [G loss: 1.137949]\n",
      "[Epoch 9/200] [Batch 564/938] [D loss: 1.141741, acc: 96%] [G loss: 1.121362]\n",
      "[Epoch 9/200] [Batch 565/938] [D loss: 1.067275, acc: 95%] [G loss: 1.111768]\n",
      "[Epoch 9/200] [Batch 566/938] [D loss: 1.076688, acc: 97%] [G loss: 1.117258]\n",
      "[Epoch 9/200] [Batch 567/938] [D loss: 1.051513, acc: 99%] [G loss: 1.064865]\n",
      "[Epoch 9/200] [Batch 568/938] [D loss: 1.075154, acc: 96%] [G loss: 1.111279]\n",
      "[Epoch 9/200] [Batch 569/938] [D loss: 1.075591, acc: 97%] [G loss: 1.088442]\n",
      "[Epoch 9/200] [Batch 570/938] [D loss: 1.070100, acc: 96%] [G loss: 1.078075]\n",
      "[Epoch 9/200] [Batch 571/938] [D loss: 1.075370, acc: 96%] [G loss: 1.172099]\n",
      "[Epoch 9/200] [Batch 572/938] [D loss: 1.122805, acc: 96%] [G loss: 1.109336]\n",
      "[Epoch 9/200] [Batch 573/938] [D loss: 1.037188, acc: 97%] [G loss: 1.115660]\n",
      "[Epoch 9/200] [Batch 574/938] [D loss: 1.109393, acc: 94%] [G loss: 1.079905]\n",
      "[Epoch 9/200] [Batch 575/938] [D loss: 1.098750, acc: 96%] [G loss: 1.121063]\n",
      "[Epoch 9/200] [Batch 576/938] [D loss: 1.051840, acc: 97%] [G loss: 1.082892]\n",
      "[Epoch 9/200] [Batch 577/938] [D loss: 1.054032, acc: 97%] [G loss: 1.097439]\n",
      "[Epoch 9/200] [Batch 578/938] [D loss: 1.041152, acc: 96%] [G loss: 1.060950]\n",
      "[Epoch 9/200] [Batch 579/938] [D loss: 1.106322, acc: 96%] [G loss: 1.056312]\n",
      "[Epoch 9/200] [Batch 580/938] [D loss: 1.101630, acc: 96%] [G loss: 1.092678]\n",
      "[Epoch 9/200] [Batch 581/938] [D loss: 1.070268, acc: 99%] [G loss: 1.108667]\n",
      "[Epoch 9/200] [Batch 582/938] [D loss: 1.108366, acc: 94%] [G loss: 1.128200]\n",
      "[Epoch 9/200] [Batch 583/938] [D loss: 1.082260, acc: 98%] [G loss: 1.102846]\n",
      "[Epoch 9/200] [Batch 584/938] [D loss: 1.078448, acc: 96%] [G loss: 1.092636]\n",
      "[Epoch 9/200] [Batch 585/938] [D loss: 1.091031, acc: 96%] [G loss: 1.155850]\n",
      "[Epoch 9/200] [Batch 586/938] [D loss: 1.063915, acc: 96%] [G loss: 1.193726]\n",
      "[Epoch 9/200] [Batch 587/938] [D loss: 1.052696, acc: 97%] [G loss: 1.077172]\n",
      "[Epoch 9/200] [Batch 588/938] [D loss: 1.108032, acc: 99%] [G loss: 1.063242]\n",
      "[Epoch 9/200] [Batch 589/938] [D loss: 1.062777, acc: 96%] [G loss: 1.126431]\n",
      "[Epoch 9/200] [Batch 590/938] [D loss: 1.080270, acc: 96%] [G loss: 1.102275]\n",
      "[Epoch 9/200] [Batch 591/938] [D loss: 1.103905, acc: 96%] [G loss: 1.092744]\n",
      "[Epoch 9/200] [Batch 592/938] [D loss: 1.099377, acc: 97%] [G loss: 1.080970]\n",
      "[Epoch 9/200] [Batch 593/938] [D loss: 1.111770, acc: 94%] [G loss: 1.083613]\n",
      "[Epoch 9/200] [Batch 594/938] [D loss: 1.122398, acc: 95%] [G loss: 1.033463]\n",
      "[Epoch 9/200] [Batch 595/938] [D loss: 1.075079, acc: 96%] [G loss: 1.078340]\n",
      "[Epoch 9/200] [Batch 596/938] [D loss: 1.105280, acc: 94%] [G loss: 1.062079]\n",
      "[Epoch 9/200] [Batch 597/938] [D loss: 1.109831, acc: 95%] [G loss: 1.086421]\n",
      "[Epoch 9/200] [Batch 598/938] [D loss: 1.076728, acc: 96%] [G loss: 1.116348]\n",
      "[Epoch 9/200] [Batch 599/938] [D loss: 1.070269, acc: 98%] [G loss: 1.077422]\n",
      "[Epoch 9/200] [Batch 600/938] [D loss: 1.077512, acc: 96%] [G loss: 1.045813]\n",
      "[Epoch 9/200] [Batch 601/938] [D loss: 1.088262, acc: 96%] [G loss: 1.088602]\n",
      "[Epoch 9/200] [Batch 602/938] [D loss: 1.097048, acc: 93%] [G loss: 1.075393]\n",
      "[Epoch 9/200] [Batch 603/938] [D loss: 1.083519, acc: 99%] [G loss: 1.126049]\n",
      "[Epoch 9/200] [Batch 604/938] [D loss: 1.107587, acc: 96%] [G loss: 1.158004]\n",
      "[Epoch 9/200] [Batch 605/938] [D loss: 1.112830, acc: 96%] [G loss: 1.128346]\n",
      "[Epoch 9/200] [Batch 606/938] [D loss: 1.092683, acc: 95%] [G loss: 1.060990]\n",
      "[Epoch 9/200] [Batch 607/938] [D loss: 1.089872, acc: 95%] [G loss: 1.108716]\n",
      "[Epoch 9/200] [Batch 608/938] [D loss: 1.095042, acc: 99%] [G loss: 1.091696]\n",
      "[Epoch 9/200] [Batch 609/938] [D loss: 1.072096, acc: 97%] [G loss: 1.062943]\n",
      "[Epoch 9/200] [Batch 610/938] [D loss: 1.140980, acc: 96%] [G loss: 1.072272]\n",
      "[Epoch 9/200] [Batch 611/938] [D loss: 1.100636, acc: 97%] [G loss: 1.155476]\n",
      "[Epoch 9/200] [Batch 612/938] [D loss: 1.123047, acc: 95%] [G loss: 1.129189]\n",
      "[Epoch 9/200] [Batch 613/938] [D loss: 1.084887, acc: 98%] [G loss: 1.115195]\n",
      "[Epoch 9/200] [Batch 614/938] [D loss: 1.093477, acc: 97%] [G loss: 1.083619]\n",
      "[Epoch 9/200] [Batch 615/938] [D loss: 1.102159, acc: 94%] [G loss: 1.082660]\n",
      "[Epoch 9/200] [Batch 616/938] [D loss: 1.099331, acc: 95%] [G loss: 1.127769]\n",
      "[Epoch 9/200] [Batch 617/938] [D loss: 1.109148, acc: 96%] [G loss: 1.061721]\n",
      "[Epoch 9/200] [Batch 618/938] [D loss: 1.068878, acc: 100%] [G loss: 1.141073]\n",
      "[Epoch 9/200] [Batch 619/938] [D loss: 1.091276, acc: 97%] [G loss: 1.150579]\n",
      "[Epoch 9/200] [Batch 620/938] [D loss: 1.111080, acc: 97%] [G loss: 1.073708]\n",
      "[Epoch 9/200] [Batch 621/938] [D loss: 1.103793, acc: 97%] [G loss: 1.083051]\n",
      "[Epoch 9/200] [Batch 622/938] [D loss: 1.080408, acc: 98%] [G loss: 1.116821]\n",
      "[Epoch 9/200] [Batch 623/938] [D loss: 1.098328, acc: 96%] [G loss: 1.082452]\n",
      "[Epoch 9/200] [Batch 624/938] [D loss: 1.110362, acc: 94%] [G loss: 1.177238]\n",
      "[Epoch 9/200] [Batch 625/938] [D loss: 1.079174, acc: 96%] [G loss: 1.113657]\n",
      "[Epoch 9/200] [Batch 626/938] [D loss: 1.102386, acc: 94%] [G loss: 1.060137]\n",
      "[Epoch 9/200] [Batch 627/938] [D loss: 1.107699, acc: 98%] [G loss: 1.107603]\n",
      "[Epoch 9/200] [Batch 628/938] [D loss: 1.097786, acc: 96%] [G loss: 1.111685]\n",
      "[Epoch 9/200] [Batch 629/938] [D loss: 1.136696, acc: 92%] [G loss: 1.097203]\n",
      "[Epoch 9/200] [Batch 630/938] [D loss: 1.082671, acc: 98%] [G loss: 1.022880]\n",
      "[Epoch 9/200] [Batch 631/938] [D loss: 1.092915, acc: 97%] [G loss: 1.126768]\n",
      "[Epoch 9/200] [Batch 632/938] [D loss: 1.132813, acc: 94%] [G loss: 1.094941]\n",
      "[Epoch 9/200] [Batch 633/938] [D loss: 1.067156, acc: 96%] [G loss: 1.103674]\n",
      "[Epoch 9/200] [Batch 634/938] [D loss: 1.066064, acc: 96%] [G loss: 1.043488]\n",
      "[Epoch 9/200] [Batch 635/938] [D loss: 1.063487, acc: 99%] [G loss: 1.131933]\n",
      "[Epoch 9/200] [Batch 636/938] [D loss: 1.074078, acc: 96%] [G loss: 1.111269]\n",
      "[Epoch 9/200] [Batch 637/938] [D loss: 1.090297, acc: 96%] [G loss: 1.143700]\n",
      "[Epoch 9/200] [Batch 638/938] [D loss: 1.103514, acc: 95%] [G loss: 1.094072]\n",
      "[Epoch 9/200] [Batch 639/938] [D loss: 1.059004, acc: 96%] [G loss: 1.100518]\n",
      "[Epoch 9/200] [Batch 640/938] [D loss: 1.112108, acc: 97%] [G loss: 1.064467]\n",
      "[Epoch 9/200] [Batch 641/938] [D loss: 1.081139, acc: 96%] [G loss: 1.065884]\n",
      "[Epoch 9/200] [Batch 642/938] [D loss: 1.093412, acc: 94%] [G loss: 1.103566]\n",
      "[Epoch 9/200] [Batch 643/938] [D loss: 1.099312, acc: 98%] [G loss: 1.140996]\n",
      "[Epoch 9/200] [Batch 644/938] [D loss: 1.100582, acc: 98%] [G loss: 1.104123]\n",
      "[Epoch 9/200] [Batch 645/938] [D loss: 1.116622, acc: 96%] [G loss: 1.050022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/200] [Batch 646/938] [D loss: 1.089566, acc: 98%] [G loss: 1.100420]\n",
      "[Epoch 9/200] [Batch 647/938] [D loss: 1.080558, acc: 97%] [G loss: 1.078786]\n",
      "[Epoch 9/200] [Batch 648/938] [D loss: 1.088964, acc: 94%] [G loss: 1.130198]\n",
      "[Epoch 9/200] [Batch 649/938] [D loss: 1.078973, acc: 96%] [G loss: 1.121805]\n",
      "[Epoch 9/200] [Batch 650/938] [D loss: 1.074155, acc: 97%] [G loss: 1.129241]\n",
      "[Epoch 9/200] [Batch 651/938] [D loss: 1.096089, acc: 96%] [G loss: 1.070014]\n",
      "[Epoch 9/200] [Batch 652/938] [D loss: 1.090037, acc: 100%] [G loss: 1.130458]\n",
      "[Epoch 9/200] [Batch 653/938] [D loss: 1.123326, acc: 92%] [G loss: 1.088299]\n",
      "[Epoch 9/200] [Batch 654/938] [D loss: 1.102554, acc: 96%] [G loss: 1.103059]\n",
      "[Epoch 9/200] [Batch 655/938] [D loss: 1.126745, acc: 96%] [G loss: 1.095302]\n",
      "[Epoch 9/200] [Batch 656/938] [D loss: 1.110697, acc: 96%] [G loss: 1.086614]\n",
      "[Epoch 9/200] [Batch 657/938] [D loss: 1.102913, acc: 92%] [G loss: 1.105318]\n",
      "[Epoch 9/200] [Batch 658/938] [D loss: 1.080597, acc: 99%] [G loss: 1.112665]\n",
      "[Epoch 9/200] [Batch 659/938] [D loss: 1.075975, acc: 96%] [G loss: 1.123306]\n",
      "[Epoch 9/200] [Batch 660/938] [D loss: 1.054437, acc: 95%] [G loss: 1.090230]\n",
      "[Epoch 9/200] [Batch 661/938] [D loss: 1.093296, acc: 96%] [G loss: 1.086289]\n",
      "[Epoch 9/200] [Batch 662/938] [D loss: 1.077511, acc: 98%] [G loss: 1.108850]\n",
      "[Epoch 9/200] [Batch 663/938] [D loss: 1.070833, acc: 97%] [G loss: 1.081148]\n",
      "[Epoch 9/200] [Batch 664/938] [D loss: 1.087606, acc: 97%] [G loss: 1.100353]\n",
      "[Epoch 9/200] [Batch 665/938] [D loss: 1.102270, acc: 96%] [G loss: 1.103794]\n",
      "[Epoch 9/200] [Batch 666/938] [D loss: 1.116898, acc: 96%] [G loss: 1.108638]\n",
      "[Epoch 9/200] [Batch 667/938] [D loss: 1.100089, acc: 96%] [G loss: 1.139781]\n",
      "[Epoch 9/200] [Batch 668/938] [D loss: 1.085336, acc: 97%] [G loss: 1.065261]\n",
      "[Epoch 9/200] [Batch 669/938] [D loss: 1.063160, acc: 98%] [G loss: 1.106054]\n",
      "[Epoch 9/200] [Batch 670/938] [D loss: 1.070598, acc: 97%] [G loss: 1.051871]\n",
      "[Epoch 9/200] [Batch 671/938] [D loss: 1.125464, acc: 96%] [G loss: 1.069400]\n",
      "[Epoch 9/200] [Batch 672/938] [D loss: 1.112373, acc: 96%] [G loss: 1.050613]\n",
      "[Epoch 9/200] [Batch 673/938] [D loss: 1.057834, acc: 96%] [G loss: 1.076187]\n",
      "[Epoch 9/200] [Batch 674/938] [D loss: 1.111251, acc: 94%] [G loss: 1.106246]\n",
      "[Epoch 9/200] [Batch 675/938] [D loss: 1.099547, acc: 96%] [G loss: 1.088373]\n",
      "[Epoch 9/200] [Batch 676/938] [D loss: 1.096646, acc: 97%] [G loss: 1.063056]\n",
      "[Epoch 9/200] [Batch 677/938] [D loss: 1.089000, acc: 96%] [G loss: 1.137555]\n",
      "[Epoch 9/200] [Batch 678/938] [D loss: 1.106389, acc: 97%] [G loss: 1.024981]\n",
      "[Epoch 9/200] [Batch 679/938] [D loss: 1.088525, acc: 96%] [G loss: 1.078899]\n",
      "[Epoch 9/200] [Batch 680/938] [D loss: 1.080838, acc: 96%] [G loss: 1.109834]\n",
      "[Epoch 9/200] [Batch 681/938] [D loss: 1.094780, acc: 95%] [G loss: 1.100460]\n",
      "[Epoch 9/200] [Batch 682/938] [D loss: 1.070314, acc: 97%] [G loss: 1.072616]\n",
      "[Epoch 9/200] [Batch 683/938] [D loss: 1.070675, acc: 98%] [G loss: 1.131046]\n",
      "[Epoch 9/200] [Batch 684/938] [D loss: 1.075838, acc: 96%] [G loss: 1.128465]\n",
      "[Epoch 9/200] [Batch 685/938] [D loss: 1.108665, acc: 96%] [G loss: 1.140077]\n",
      "[Epoch 9/200] [Batch 686/938] [D loss: 1.078066, acc: 98%] [G loss: 1.096263]\n",
      "[Epoch 9/200] [Batch 687/938] [D loss: 1.101137, acc: 96%] [G loss: 1.101775]\n",
      "[Epoch 9/200] [Batch 688/938] [D loss: 1.059438, acc: 96%] [G loss: 1.065388]\n",
      "[Epoch 9/200] [Batch 689/938] [D loss: 1.079920, acc: 98%] [G loss: 1.111795]\n",
      "[Epoch 9/200] [Batch 690/938] [D loss: 1.102396, acc: 99%] [G loss: 1.129198]\n",
      "[Epoch 9/200] [Batch 691/938] [D loss: 1.092736, acc: 95%] [G loss: 1.167610]\n",
      "[Epoch 9/200] [Batch 692/938] [D loss: 1.122651, acc: 95%] [G loss: 1.144527]\n",
      "[Epoch 9/200] [Batch 693/938] [D loss: 1.077680, acc: 95%] [G loss: 1.119947]\n",
      "[Epoch 9/200] [Batch 694/938] [D loss: 1.075430, acc: 98%] [G loss: 1.119751]\n",
      "[Epoch 9/200] [Batch 695/938] [D loss: 1.110494, acc: 96%] [G loss: 1.109685]\n",
      "[Epoch 9/200] [Batch 696/938] [D loss: 1.094626, acc: 95%] [G loss: 1.113573]\n",
      "[Epoch 9/200] [Batch 697/938] [D loss: 1.062481, acc: 96%] [G loss: 1.064612]\n",
      "[Epoch 9/200] [Batch 698/938] [D loss: 1.090085, acc: 96%] [G loss: 1.140497]\n",
      "[Epoch 9/200] [Batch 699/938] [D loss: 1.121602, acc: 96%] [G loss: 1.140601]\n",
      "[Epoch 9/200] [Batch 700/938] [D loss: 1.106744, acc: 93%] [G loss: 1.100447]\n",
      "[Epoch 9/200] [Batch 701/938] [D loss: 1.085972, acc: 98%] [G loss: 1.070419]\n",
      "[Epoch 9/200] [Batch 702/938] [D loss: 1.112124, acc: 93%] [G loss: 1.077805]\n",
      "[Epoch 9/200] [Batch 703/938] [D loss: 1.088800, acc: 99%] [G loss: 1.120333]\n",
      "[Epoch 9/200] [Batch 704/938] [D loss: 1.088891, acc: 96%] [G loss: 1.115219]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-38dd3e16a739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Loss for real images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mreal_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0md_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mauxiliary_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_aux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Loss for fake images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AdversarialRobustness/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AdversarialRobustness/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/AdversarialRobustness/venv/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2074\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2076\u001b[0;31m     return torch._C._nn.binary_cross_entropy(\n\u001b[0m\u001b[1;32m   2077\u001b[0m         input, target, weight, reduction_enum)\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = Variable(labels.type(LongTensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "        gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z, gen_labels)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity, pred_label = discriminator(gen_imgs)\n",
    "        g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        real_pred, real_aux = discriminator(real_imgs)\n",
    "        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "        # Loss for fake images\n",
    "        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n",
    "        )\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_image(n_row=10, batches_done=batches_done)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
